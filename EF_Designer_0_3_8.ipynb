{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "73Z-uPv6Bi__",
        "qWIsh2NxBdPy",
        "1KFM0G8SF1o-",
        "lXpaUovYF9UO",
        "Vn39PBOtGZXO",
        "RvF1W5QeGfkG",
        "LSzgwcZeGqDi",
        "LaXVOixrMDHY",
        "HT2VOpnMMwOV",
        "PaBDv2hRRUA7",
        "C07r1Om1Rk_p",
        "tC20megQRlQ9"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN1+2xcthv/RNx5qZ00fJYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinkyoHan/NAS-SR/blob/main/EF_Designer_0_3_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **E.F Designer**\n",
        "> Empirical Formula Designer\n",
        ">\n",
        "> **ver 0.3.8**\n",
        "---\n",
        "> Written by **Jinkyo Han**, OST, SNU NAOE\n",
        ">\n",
        "> * 38jinkyo@snu.ac.kr\n",
        ">\n",
        "> Supervised by **Do Kyun Kim**, OST, SNU NAOE\n"
      ],
      "metadata": {
        "id": "gwdqhaK_E0Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ![Untitled.jpg](data:image/jpeg;base64,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)\n",
        ">\n",
        ">* # contact OST [here](https://ost.snu.ac.kr/home)\n",
        "\n",
        "---\n",
        "\n",
        "¬ Copyright (c) 2023 Jinkyo Han\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ],
      "metadata": {
        "id": "5DNGxgVqBTLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Chapter.0 Introduction\n",
        "\n",
        "---\n",
        "\n",
        "# Here are 4 main tasks herein\n",
        "\n",
        "1.   Generate nondimensionalized parameters from you dataset.\n",
        "> * during (1), task (2) could be applied\n",
        "\n",
        "2.   By random forest regression: select a few nondimensionalized parameters, which can most greatly represent the dataset.\n",
        "3.   Using NAS algorithm, generate the most-fitted & simple MLP model, **\"SumNET\"** (=MLP+MLP)\n",
        "> * During searching by NAS, NuSVR would estimate the model's performance, which described by Baker et al., 2017.\n",
        "> * visit [here](https://colab.research.google.com/github/JinkyoHan/JinkyoHan/blob/main/ann_designer_basic_1_0_0.ipynb) for NAS tutorials\n",
        "4.   By Symbolic Regression, based on GP method: automatically generate empirical formula, using PySR package by Cranmer et al., 2023.(which achieved the best score within *EmpiricalBench*)\n",
        "\n",
        "# **[Reference]**\n",
        "\n",
        "># [NAS]\n",
        ">\n",
        "> Elsken, T., Metzen, J. H., & Hutter, F. (2019). Neural architecture search: A survey. The Journal of Machine Learning Research, 20(1), 1997-2017.\n",
        "* https://arxiv.org/abs/1808.05377\n",
        ">\n",
        "> Baker, B., Gupta, O., Raskar, R., & Naik, N. (2017). Accelerating neural architecture search using performance prediction. arXiv preprint arXiv:1705.10823.\n",
        "* https://arxiv.org/abs/1705.10823\n",
        "\n",
        "># [PySR]\n",
        ">\n",
        "> Cranmer, M. (2023). Interpretable machine learning for science with PySR and SymbolicRegression. jl. arXiv preprint arXiv:2305.01582.\n",
        "* https://arxiv.org/abs/2305.01582\n",
        ">\n",
        "> Cranmer, M., Sanchez Gonzalez, A., Battaglia, P., Xu, R., Cranmer, K., Spergel, D., & Ho, S. (2020). Discovering symbolic models from deep learning with inductive biases. Advances in Neural Information Processing Systems, 33, 17429-17442.\n",
        "* https://arxiv.org/abs/2006.11287\n",
        ">\n",
        "> Miles Cranmer Github\n",
        "* https://github.com/MilesCranmer/PySR"
      ],
      "metadata": {
        "id": "kdsHs3iVBWGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Chapter.1 Nondim' Parameters\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VAzwsc1ZOHRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Julia\n",
        "\n",
        "---\n",
        "\n",
        "![logo.svg](data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="320pt" height="200pt" version="1.1" viewBox="0 0 320 200"><g id="surface61"><path fill="#000" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 67.871094 164.3125 C 67.871094 171.847656 67.023438 177.933594 65.328125 182.566406 C 63.632812 187.203125 61.222656 190.800781 58.09375 193.363281 C 54.96875 195.925781 51.21875 197.640625 46.847656 198.507812 C 42.476562 199.371094 37.613281 199.804688 32.265625 199.804688 C 25.027344 199.804688 19.488281 198.675781 15.648438 196.414062 C 11.804688 194.152344 9.882812 191.441406 9.882812 188.273438 C 9.882812 185.636719 10.953125 183.414062 13.101562 181.605469 C 15.25 179.796875 18.132812 178.894531 21.75 178.894531 C 24.464844 178.894531 26.632812 179.628906 28.25 181.097656 C 29.871094 182.566406 31.210938 184.019531 32.265625 185.449219 C 33.46875 187.03125 34.488281 188.085938 35.316406 188.613281 C 36.144531 189.140625 36.898438 189.40625 37.578125 189.40625 C 39.007812 189.40625 40.101562 188.558594 40.855469 186.863281 C 41.609375 185.167969 41.984375 181.871094 41.984375 176.972656 L 41.984375 84.050781 L 67.871094 76.929688 L 67.871094 164.3125 M 104.738281 79.414062 L 104.738281 139.214844 C 104.738281 140.875 105.058594 142.4375 105.699219 143.90625 C 106.339844 145.375 107.226562 146.640625 108.355469 147.695312 C 109.488281 148.75 110.804688 149.597656 112.3125 150.238281 C 113.820312 150.878906 115.441406 151.199219 117.175781 151.199219 C 119.132812 151.199219 121.359375 150.101562 124.070312 148.203125 C 128.363281 145.195312 130.964844 143.128906 130.964844 140.683594 C 130.964844 140.097656 130.964844 79.414062 130.964844 79.414062 L 156.738281 79.414062 L 156.738281 164.3125 L 130.964844 164.3125 L 130.964844 156.398438 C 127.574219 159.261719 123.957031 161.558594 120.113281 163.292969 C 116.269531 165.027344 112.539062 165.894531 108.921875 165.894531 C 104.703125 165.894531 100.78125 165.195312 97.164062 163.800781 C 93.546875 162.40625 90.382812 160.503906 87.671875 158.09375 C 84.957031 155.683594 82.828125 152.855469 81.28125 149.613281 C 79.738281 146.375 78.964844 142.90625 78.964844 139.214844 L 78.964844 79.414062 L 104.738281 79.414062 M 192.882812 164.3125 L 167.222656 164.3125 L 167.222656 45.277344 L 192.882812 38.15625 L 192.882812 164.3125 M 203.601562 84.050781 L 229.375 76.929688 L 229.375 164.3125 L 203.601562 164.3125 L 203.601562 84.050781 M 283.226562 120.449219 C 280.738281 121.507812 278.230469 122.730469 275.707031 124.125 C 273.183594 125.519531 270.882812 127.046875 268.8125 128.703125 C 266.738281 130.359375 265.0625 132.132812 263.78125 134.015625 C 262.5 135.898438 261.859375 137.859375 261.859375 139.894531 C 261.859375 141.476562 262.066406 143.003906 262.480469 144.472656 C 262.894531 145.941406 263.480469 147.203125 264.234375 148.257812 C 264.988281 149.3125 265.816406 150.160156 266.722656 150.800781 C 267.625 151.441406 268.605469 151.761719 269.660156 151.761719 C 271.769531 151.761719 273.898438 151.121094 276.046875 149.839844 C 278.195312 148.558594 280.585938 146.941406 283.226562 144.980469 L 283.226562 120.449219 M 309.109375 164.3125 L 283.226562 164.3125 L 283.226562 157.527344 C 281.792969 158.734375 280.398438 159.847656 279.042969 160.863281 C 277.6875 161.878906 276.160156 162.765625 274.464844 163.519531 C 272.769531 164.273438 270.867188 164.855469 268.753906 165.273438 C 266.644531 165.6875 264.15625 165.894531 261.296875 165.894531 C 257.375 165.894531 253.851562 165.328125 250.726562 164.199219 C 247.597656 163.066406 244.941406 161.523438 242.757812 159.5625 C 240.570312 157.605469 238.894531 155.285156 237.726562 152.609375 C 236.558594 149.9375 235.972656 147.015625 235.972656 143.851562 C 235.972656 140.609375 236.59375 137.671875 237.839844 135.03125 C 239.082031 132.394531 240.777344 130.023438 242.925781 127.910156 C 245.074219 125.800781 247.578125 123.917969 250.441406 122.257812 C 253.304688 120.601562 256.378906 119.074219 259.65625 117.679688 C 262.933594 116.285156 266.34375 115.007812 269.886719 113.839844 C 273.425781 112.671875 276.933594 111.558594 280.398438 110.503906 L 283.226562 109.824219 L 283.226562 101.460938 C 283.226562 96.035156 282.1875 92.191406 280.117188 89.929688 C 278.042969 87.667969 275.273438 86.539062 271.808594 86.539062 C 267.738281 86.539062 264.910156 87.519531 263.328125 89.476562 C 261.746094 91.4375 260.953125 93.808594 260.953125 96.597656 C 260.953125 98.179688 260.785156 99.726562 260.445312 101.234375 C 260.109375 102.742188 259.523438 104.058594 258.695312 105.191406 C 257.867188 106.320312 256.679688 107.226562 255.132812 107.902344 C 253.589844 108.582031 251.648438 108.921875 249.3125 108.921875 C 245.695312 108.921875 242.757812 107.882812 240.496094 105.8125 C 238.234375 103.738281 237.105469 101.121094 237.105469 97.953125 C 237.105469 95.015625 238.101562 92.285156 240.097656 89.761719 C 242.097656 87.234375 244.789062 85.066406 248.183594 83.261719 C 251.574219 81.449219 255.492188 80.019531 259.9375 78.964844 C 264.382812 77.910156 269.09375 77.382812 274.066406 77.382812 C 280.171875 77.382812 285.429688 77.929688 289.839844 79.019531 C 294.246094 80.113281 297.882812 81.675781 300.746094 83.710938 C 303.609375 85.746094 305.71875 88.195312 307.074219 91.058594 C 308.433594 93.921875 309.109375 97.128906 309.109375 100.667969 L 309.109375 164.3125"/><path fill="#CB3C33" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 235.273438 55.089844 C 235.273438 64.757812 227.4375 72.589844 217.773438 72.589844 C 208.105469 72.589844 200.273438 64.757812 200.273438 55.089844 C 200.273438 45.425781 208.105469 37.589844 217.773438 37.589844 C 227.4375 37.589844 235.273438 45.425781 235.273438 55.089844"/><path fill="#4063D8" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 72.953125 55.089844 C 72.953125 64.757812 65.117188 72.589844 55.453125 72.589844 C 45.789062 72.589844 37.953125 64.757812 37.953125 55.089844 C 37.953125 45.425781 45.789062 37.589844 55.453125 37.589844 C 65.117188 37.589844 72.953125 45.425781 72.953125 55.089844"/><path fill="#9558B2" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 277.320312 55.089844 C 277.320312 64.757812 269.484375 72.589844 259.820312 72.589844 C 250.15625 72.589844 242.320312 64.757812 242.320312 55.089844 C 242.320312 45.425781 250.15625 37.589844 259.820312 37.589844 C 269.484375 37.589844 277.320312 45.425781 277.320312 55.089844"/><path fill="#389826" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 256.300781 18.671875 C 256.300781 28.335938 248.464844 36.171875 238.800781 36.171875 C 229.132812 36.171875 221.300781 28.335938 221.300781 18.671875 C 221.300781 9.007812 229.132812 1.171875 238.800781 1.171875 C 248.464844 1.171875 256.300781 9.007812 256.300781 18.671875"/></g></svg>)\n",
        "\n",
        "Julia is a new-born computational data science language, developed at 2012.\n",
        "\n",
        "PySR will fluently help you out with executing Julia at back-end, so no worries.\n",
        "\n",
        "Within Colab, order below would automatically install Julia.\n",
        "\n",
        "If you want to execute PySR at *VS Code* environment, please visit [here](https://julialang.org/downloads/)"
      ],
      "metadata": {
        "id": "73Z-uPv6Bi__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bctYJkhBNRF",
        "outputId": "06791de0-7997-4b8d-92d0-5523ca711ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [962 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,079 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,059 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,230 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,254 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,180 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,119 kB]\n",
            "Fetched 9,271 kB in 7s (1,415 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "16 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  base-files binutils binutils-common binutils-x86-64-linux-gnu cuda-keyring\n",
            "  cuda-toolkit-config-common libbinutils libcap2 libctf-nobfd0 libctf0\n",
            "  libldap-2.5-0 linux-libc-dev\n",
            "12 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 5,039 kB of archives.\n",
            "After this operation, 47.1 kB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-keyring 1.1-1 [4,332 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-config-common 12.2.140-1 [16.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 base-files amd64 12ubuntu4.4 [62.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcap2 amd64 1:2.44-1ubuntu0.22.04.1 [18.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.3 [103 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf-nobfd0 amd64 2.38-4ubuntu2.3 [107 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.3 [2,327 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.3 [662 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.3 [3,190 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.3 [222 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libldap-2.5-0 amd64 2.5.16+dfsg-0ubuntu0.22.04.1 [183 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-libc-dev amd64 5.15.0-83.92 [1,330 kB]\n",
            "Fetched 5,039 kB in 2s (2,606 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 12.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_12ubuntu4.4_amd64.deb ...\n",
            "Unpacking base-files (12ubuntu4.4) over (12ubuntu4.3) ...\n",
            "Setting up base-files (12ubuntu4.4) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libcap2_1%3a2.44-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libcap2:amd64 (1:2.44-1ubuntu0.22.04.1) over (1:2.44-1build3) ...\n",
            "Setting up libcap2:amd64 (1:2.44-1ubuntu0.22.04.1) ...\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libctf0_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libctf0:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../1-libctf-nobfd0_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libctf-nobfd0:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../2-binutils-x86-64-linux-gnu_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../3-libbinutils_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../4-binutils_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../5-binutils-common_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../6-cuda-keyring_1.1-1_all.deb ...\n",
            "Unpacking cuda-keyring (1.1-1) over (1.0-1) ...\n",
            "Preparing to unpack .../7-cuda-toolkit-config-common_12.2.140-1_all.deb ...\n",
            "Unpacking cuda-toolkit-config-common (12.2.140-1) over (12.1.105-1) ...\n",
            "Preparing to unpack .../8-libldap-2.5-0_2.5.16+dfsg-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libldap-2.5-0:amd64 (2.5.16+dfsg-0ubuntu0.22.04.1) over (2.5.14+dfsg-0ubuntu0.22.04.2) ...\n",
            "Preparing to unpack .../9-linux-libc-dev_5.15.0-83.92_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (5.15.0-83.92) over (5.15.0-75.82) ...\n",
            "Setting up cuda-toolkit-config-common (12.2.140-1) ...\n",
            "Setting up binutils-common:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up linux-libc-dev:amd64 (5.15.0-83.92) ...\n",
            "Setting up libctf-nobfd0:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up libldap-2.5-0:amd64 (2.5.16+dfsg-0ubuntu0.22.04.1) ...\n",
            "Setting up cuda-keyring (1.1-1) ...\n",
            "Setting up libbinutils:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up libctf0:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.3) ...\n",
            "Setting up binutils (2.38-4ubuntu2.3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "--2023-09-11 10:16:50--  https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz\n",
            "Resolving julialang-s3.julialang.org (julialang-s3.julialang.org)... 151.101.2.49, 151.101.66.49, 151.101.130.49, ...\n",
            "Connecting to julialang-s3.julialang.org (julialang-s3.julialang.org)|151.101.2.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 gce internal redirect trigger\n",
            "Location: https://storage.googleapis.com/julialang2/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz [following]\n",
            "--2023-09-11 10:16:50--  https://storage.googleapis.com/julialang2/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.4.207, 172.253.118.207, 74.125.200.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.4.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146268149 (139M) [application/x-tar]\n",
            "Saving to: ‘julia-1.9.3-linux-x86_64.tar.gz’\n",
            "\n",
            "julia-1.9.3-linux-x 100%[===================>] 139.49M  18.5MB/s    in 9.4s    \n",
            "\n",
            "2023-09-11 10:17:00 (14.8 MB/s) - ‘julia-1.9.3-linux-x86_64.tar.gz’ saved [146268149/146268149]\n",
            "\n",
            "julia-1.9.3/\n",
            "julia-1.9.3/lib/\n",
            "julia-1.9.3/lib/libjulia.so.1.9\n",
            "julia-1.9.3/lib/libjulia.so\n",
            "julia-1.9.3/lib/libjulia.so.1\n",
            "julia-1.9.3/lib/julia/\n",
            "julia-1.9.3/lib/julia/libcholmod.so.3.0.14\n",
            "julia-1.9.3/lib/julia/libuv.so.2\n",
            "julia-1.9.3/lib/julia/libuv.so.2.0.0\n",
            "julia-1.9.3/lib/julia/libopenlibm.so.4.0\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so.0\n",
            "julia-1.9.3/lib/julia/libstdc++.so.6\n",
            "julia-1.9.3/lib/julia/libunwind.so\n",
            "julia-1.9.3/lib/julia/libccalltest.so.debug\n",
            "julia-1.9.3/lib/julia/libnghttp2.so.14\n",
            "julia-1.9.3/lib/julia/libatomic.so.1.2.0\n",
            "julia-1.9.3/lib/julia/libopenlibm.so.4\n",
            "julia-1.9.3/lib/julia/libquadmath.so\n",
            "julia-1.9.3/lib/julia/libklu.so.1\n",
            "julia-1.9.3/lib/julia/libgfortran.so.5.0.0\n",
            "julia-1.9.3/lib/julia/librbio.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so\n",
            "julia-1.9.3/lib/julia/libccolamd.so.2.9.6\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so.5.10.1\n",
            "julia-1.9.3/lib/julia/libssp.so.0\n",
            "julia-1.9.3/lib/julia/libopenblas64_.so.0\n",
            "julia-1.9.3/lib/julia/sys.so\n",
            "julia-1.9.3/lib/julia/libopenlibm.so\n",
            "julia-1.9.3/lib/julia/libgmpxx.so.4.6.1\n",
            "julia-1.9.3/lib/julia/libz.so.1.2.13\n",
            "julia-1.9.3/lib/julia/libbtf.so.1\n",
            "julia-1.9.3/lib/julia/libgit2.so.1.5\n",
            "julia-1.9.3/lib/julia/libstdc++.so.6.0.30\n",
            "julia-1.9.3/lib/julia/libldl.so.2\n",
            "julia-1.9.3/lib/julia/libssh2.so.1.0.1\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so.1\n",
            "julia-1.9.3/lib/julia/libunwind.so.8\n",
            "julia-1.9.3/lib/julia/libgmpxx.so.4\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so.5.4.0\n",
            "julia-1.9.3/lib/julia/libz.so.1\n",
            "julia-1.9.3/lib/julia/libLLVM-14jl.so\n",
            "julia-1.9.3/lib/julia/libgmp.so.10\n",
            "julia-1.9.3/lib/julia/libgomp.so.1\n",
            "julia-1.9.3/lib/julia/libcolamd.so\n",
            "julia-1.9.3/lib/julia/libgmp.so.10.4.1\n",
            "julia-1.9.3/lib/julia/libklu.so.1.3.8\n",
            "julia-1.9.3/lib/julia/libgcc_s.so.1\n",
            "julia-1.9.3/lib/julia/libccolamd.so\n",
            "julia-1.9.3/lib/julia/libLLVM.so\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so.0.11.2\n",
            "julia-1.9.3/lib/julia/libspqr.so.2\n",
            "julia-1.9.3/lib/julia/libunwind.so.8.0.1\n",
            "julia-1.9.3/lib/julia/libcamd.so\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so.1.9\n",
            "julia-1.9.3/lib/julia/libllvmcalltest.so\n",
            "julia-1.9.3/lib/julia/libatomic.so\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so.1\n",
            "julia-1.9.3/lib/julia/libquadmath.so.0.0.0\n",
            "julia-1.9.3/lib/julia/libssh2.so\n",
            "julia-1.9.3/lib/julia/libbtf.so.1.2.6\n",
            "julia-1.9.3/lib/julia/libldl.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so.7\n",
            "julia-1.9.3/lib/julia/libssh2.so.1\n",
            "julia-1.9.3/lib/julia/libgit2.so.1.5.0\n",
            "julia-1.9.3/lib/julia/libstdc++.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so.14\n",
            "julia-1.9.3/lib/julia/libgfortran.so\n",
            "julia-1.9.3/lib/julia/libcamd.so.2\n",
            "julia-1.9.3/lib/julia/libgit2.so\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so\n",
            "julia-1.9.3/lib/julia/libcholmod.so.3\n",
            "julia-1.9.3/lib/julia/libccolamd.so.2\n",
            "julia-1.9.3/lib/julia/libmbedx509.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libklu.so\n",
            "julia-1.9.3/lib/julia/libumfpack.so\n",
            "julia-1.9.3/lib/julia/libgfortran.so.5\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so\n",
            "julia-1.9.3/lib/julia/libbtf.so\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so\n",
            "julia-1.9.3/lib/julia/libz.so\n",
            "julia-1.9.3/lib/julia/libcolamd.so.2.9.6\n",
            "julia-1.9.3/lib/julia/libccalltest.so\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so.5\n",
            "julia-1.9.3/lib/julia/libcurl.so\n",
            "julia-1.9.3/lib/julia/libopenblas64_.so\n",
            "julia-1.9.3/lib/julia/libgomp.so.1.0.0\n",
            "julia-1.9.3/lib/julia/libmpfr.so.6\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so.1.9\n",
            "julia-1.9.3/lib/julia/libnghttp2.so\n",
            "julia-1.9.3/lib/julia/libamd.so.2.4.6\n",
            "julia-1.9.3/lib/julia/libmpfr.so\n",
            "julia-1.9.3/lib/julia/libcholmod.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libssp.so.0.0.0\n",
            "julia-1.9.3/lib/julia/libgmp.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libmbedx509.so.1\n",
            "julia-1.9.3/lib/julia/libumfpack.so.5\n",
            "julia-1.9.3/lib/julia/libcurl.so.4.8.0\n",
            "julia-1.9.3/lib/julia/libcamd.so.2.4.6\n",
            "julia-1.9.3/lib/julia/librbio.so.2\n",
            "julia-1.9.3/lib/julia/libgmpxx.so\n",
            "julia-1.9.3/lib/julia/libspqr.so\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so.5\n",
            "julia-1.9.3/lib/julia/libmbedx509.so\n",
            "julia-1.9.3/lib/julia/libamd.so.2\n",
            "julia-1.9.3/lib/julia/libssp.so\n",
            "julia-1.9.3/lib/julia/libcurl.so.4\n",
            "julia-1.9.3/lib/julia/libmpfr.so.6.1.1\n",
            "julia-1.9.3/lib/julia/libatomic.so.1\n",
            "julia-1.9.3/lib/julia/libldl.so.2.2.6\n",
            "julia-1.9.3/lib/julia/librbio.so.2.2.6\n",
            "julia-1.9.3/lib/julia/libdSFMT.so\n",
            "julia-1.9.3/lib/julia/libquadmath.so.0\n",
            "julia-1.9.3/lib/julia/libumfpack.so.5.7.9\n",
            "julia-1.9.3/lib/julia/libnghttp2.so.14.22.0\n",
            "julia-1.9.3/lib/julia/libamd.so\n",
            "julia-1.9.3/lib/julia/libopenblas64_.0.3.21.so\n",
            "julia-1.9.3/lib/julia/libgomp.so\n",
            "julia-1.9.3/lib/julia/libuv.so\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so\n",
            "julia-1.9.3/lib/julia/libspqr.so.2.0.9\n",
            "julia-1.9.3/lib/julia/libcolamd.so.2\n",
            "julia-1.9.3/share/\n",
            "julia-1.9.3/share/doc/\n",
            "julia-1.9.3/share/doc/julia/\n",
            "julia-1.9.3/share/doc/julia/html/\n",
            "julia-1.9.3/share/doc/julia/html/en/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/cover-splash.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themeswap.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/warner.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/documenter.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/cover.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/julia.ico\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/search.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/custom.sty\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo.svg\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/preamble.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/documenter-light.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/documenter-dark.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/julia-manual.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo-dark.svg\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/missing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/environment-variables.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/style-guide.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/documentation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/handling-operating-system-variation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/metaprogramming.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/multi-threading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/unicode-input.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/complex-and-rational-numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/embedding.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/distributed-computing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/strings.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/variables.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/faq.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/types.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/asynchronous-programming.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/methods.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/running-external-programs.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/getting-started.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/noteworthy-differences.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/mathematical-operations.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/integers-and-floating-point-numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/variables-and-scoping.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/functions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/calling-c-and-fortran-code.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/command-line-interface.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/stacktraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/control-flow.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/parallel-computing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/modules.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/code-loading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/networking-and-streams.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/interfaces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/workflow-tips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/conversion-and-promotion.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/profile.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/constructors.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/performance-tips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LibGit2.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LazyArtifacts.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/REPL.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Profile.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Statistics.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Mmap.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Random.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Downloads.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Logging.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Future.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Test.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/DelimitedFiles.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Sockets.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Artifacts.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SHA.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LinearAlgebra.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/UUIDs.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/CRC32c.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Tar.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/TOML.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Unicode.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/NetworkOptions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Serialization.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Libdl.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/FileWatching.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/InteractiveUtils.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Markdown.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/ArgTools.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Dates.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Printf.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SharedArrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Base64.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LibCURL.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Pkg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SparseArrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Distributed.html\n",
            "julia-1.9.3/share/doc/julia/html/en/index.html\n",
            "julia-1.9.3/share/doc/julia/html/en/search_index.js\n",
            "julia-1.9.3/share/doc/julia/html/en/NEWS.html\n",
            "julia-1.9.3/share/doc/julia/html/en/search.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/cartesian.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/object.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/subarrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/locks.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/linux.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/arm.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/freebsd.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/build.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/windows.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/macos.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/distributing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/gc.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/reflection.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/init.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/compiler.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/offset-arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/types.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/isbitsunionarrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/probes.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/valgrind.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/stdio.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/callconv.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/inference.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/debuggingtips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/functions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/ssair.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/llvm.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/gc-sa.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/require.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/EscapeAnalysis.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/eval.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/meta.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/sysimg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/pkgimg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/backtraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/ast.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/boundscheck.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/sanitizers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/\n",
            "julia-1.9.3/share/doc/julia/html/en/base/multi-threading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/collections.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/strings.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/base.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/parallel.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/iterators.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/sort.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/punctuation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/libc.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/stacktraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/io-network.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/constants.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/c.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/math.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/file.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/simd-types.html\n",
            "julia-1.9.3/share/man/\n",
            "julia-1.9.3/share/man/man1/\n",
            "julia-1.9.3/share/man/man1/julia.1\n",
            "julia-1.9.3/share/appdata/\n",
            "julia-1.9.3/share/appdata/julia.appdata.xml\n",
            "julia-1.9.3/share/applications/\n",
            "julia-1.9.3/share/applications/julia.desktop\n",
            "julia-1.9.3/share/julia/\n",
            "julia-1.9.3/share/julia/julia-config.jl\n",
            "julia-1.9.3/share/julia/base.cache\n",
            "julia-1.9.3/share/julia/cert.pem\n",
            "julia-1.9.3/share/julia/compiled/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KtHpY.so\n",
            "julia-1.9.3/share/julia/stdlib/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/src/SharedArrays.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/src/Statistics.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/src/libLLVM_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/src/LibCURL_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/src/Mmap.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/Logging.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/ConsoleLogger.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/src/dSFMT_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/src/LLD_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/IPAddr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/PipeServer.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/Sockets.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/addrinfo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/nettest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/TOML.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/print.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/values.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/toml_test.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/readme.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/error_printing.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/utils/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/utils/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/print.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/invalids.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/tune.json\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/Registry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/benchmarks.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/src/Artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/refresh_artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/hessenberg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/symmetriceigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lapack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/schur.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lq.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/uniformscaling.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/ldlt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/diagonal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/matmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/exceptions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/givens.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/structuredbroadcast.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/symmetric.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lbt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/generic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/triangular.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/tridiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/blas.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bidiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bunchkaufman.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/dense.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/factorization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/LinearAlgebra.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/qr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/special.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/cholesky.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/transpose.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bitarray.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/svd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/hessenberg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/ambiguous_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/trickyarithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lapack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/schur.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lq.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/eigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/uniformscaling.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/ldlt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/diagonal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/matmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/givens.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/structuredbroadcast.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/symmetric.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/pinv.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/testutils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/generic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/triangular.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/tridiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/blas.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/bidiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/bunchkaufman.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/dense.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/factorization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/qr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/special.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/cholesky.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/adjtrans.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/addmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/svd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/InteractiveUtils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/editless.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/macros.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/codeview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/clipboard.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/highlighting.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Versions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/API.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/argument_parsers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/REPLMode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/command_declarations.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/completions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/GitTools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/project.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/Registry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/registry_instance.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/HistoricalStdlibs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Operations.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/BinaryPlatforms_compat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/maxsum.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/fieldvalues.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/graphtype.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/versionweights.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/Resolve.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/PlatformEngines.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/MiniProgressBars.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/manifest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/CHANGELOG.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/LazilyInitializedFields/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/LazilyInitializedFields/LazilyInitializedFields.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/update.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/noproject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/noproject/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_path.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/ambiguous_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_tree_sha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/missing_entry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_repo_url.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/inconsistent_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_field.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/missing_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/inconsistent_dep2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_tree_sha2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/duplicate_deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/parse_error.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/string_pinned.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_pinned.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_repo_rev.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/bad_dep_name.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/not_unique_names.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/simple.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/misc.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolve.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/force_latest_compatible_version.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/unlisted_targets.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/targets_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/target_entry_twice.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_unlisted.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/repeated_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_version2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/deps_is_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_deps_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_uuid2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/parse_error.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_entry_not_a_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/repeated_extras_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/target_entry_not_a_list.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/simple.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/pkg.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/withcompat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/subdir.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/api.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/platformengines.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/NastyGenerator.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/extensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/repl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/coverage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/coverage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/new.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/sandbox.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/FakeTerminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/incorrect_sha256.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/doesnotexist.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/incorrect_gitsha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/no_gitsha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolve_utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project_manifest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolvedata.tar.gz\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/registry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/src/TestTargetCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/src/BigProject.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/src/SubModule2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/src/SubModule.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/src/RecursiveDep.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/src/RecursiveDep2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/src/Sandbox_PreserveTestDeps.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/src/TOML.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/src/ArtifactOverrideLoading.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/src/ExtraDirectDep.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/src/DependsOnExample.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/src/TestDepTrackingPath.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/src/SameNameDifferentUUID.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/src/Example.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/src/UnregisteredWithProject.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatExtras/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatExtras/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/src/Unpruned.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/src/OldOnly2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/src/OldOnly1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/src/BothOldAndNew.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/src/DirectDepWithoutCompatEntry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/src/NewOnly.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/src/PackageWithDependency.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTarget/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTarget/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/src/BuildProjectFixedDeps.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/src/TestSubgraphTrackingRepo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/src/TestDepTrackingRepo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/src/BasicTestTarget.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/src/SimplePackage.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/Project2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_module/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_module/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/JuliaArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/src/FailBuild.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/src/SubDir.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/src/AugmentedPlatform.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/platform_augmentation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/select_artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/src/BasicSandbox.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/src/x2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/src/A.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/src/C.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/src/D.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/src/Sandbox_PreservePreferences.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/LocalPreferences.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/src/x3.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/src/TestFailure.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/src/TestArguments.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/src/ArtifactInstallation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/src/Example.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/src/BasicCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/src/A.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/src/C.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/src/D.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/src/EmptyPackage.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Package.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/WeakCompat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Versions.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/WeakDeps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Package.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Versions.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/Registry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/ext/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/ext/OffsetArraysExt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/src/HasDepWithExtensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/src/TestDepCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/src/x1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/src/ActiveProjectInTestSubgraph.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/logo.png\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/custom.css\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/managing-packages.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/compatibility.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/environments.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/basedocs.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/glossary.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/getting-started.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/creating-packages.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/registries.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/artifacts.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/api.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/toml-files.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/NEWS-update.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/CODEOWNERS\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/workflows/test.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/Profile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/Allocs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/allocs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/src/CRC32c.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/src/MozillaCACerts_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/extract.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/Tar.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/header.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/create.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/data/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/data/LF10-fragment.tar\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/git_tools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/perf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/src/SuiteSparse_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/src/LazyArtifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/src/LibUV_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/src/UUIDs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/src/Printf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/src/OpenBLAS_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Downloads.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Easy.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Curl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Multi.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/json.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/src/Future.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/src/libblastrampoline_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/src/MbedTLS_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/src/Zlib_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/constants.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha3.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/SHA.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/base_functions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/common.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/hmac.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/constants.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/perf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/PULL_REQUEST_TEMPLATE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/CI.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/ISSUE_TEMPLATE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/src/MPFR_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/src/nghttp2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/decode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/encode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/Base64.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/buffer.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/LineEdit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/REPLCompletions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/latex_symbols.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/options.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/emoji_symbols.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/Terminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/MultiSelectMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/TerminalMenus.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/AbstractMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/Pager.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/util.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/RadioMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/REPL.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/docview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/lineedit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/replcompletions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/repl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/pager.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/old_multiselect_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/old_radio_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/radio_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/multiselect_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/dynamic_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/multiselect_with_skip_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/FakeTerminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/docview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/src/GMP_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/NetworkOptions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/ssh_options.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/ca_roots.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/verify_host.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/src/ArgTools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/process_messages.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/clusterserialize.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/managers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/messages.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/macros.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/cluster.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/pmap.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/remotecall.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/Distributed.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/workerpool.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/distributed_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/topology.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/splitrange.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/managers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/includefile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/ranges.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/query.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/periods.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/adjusters.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/Dates.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/rounding.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/arithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/conversions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/io.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/accessors.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/ranges.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/query.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/periods.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/adjusters.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/rounding.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/arithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/conversions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/io.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/accessors.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/src/Unicode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/misc.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/Random.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/XoshiroSimd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/Xoshiro.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/RNGs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/generation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/DSFMT.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/normal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/src/Libdl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/src/LLVMLibUnwind_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/src/Serialization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/src/LibSSH2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/src/DelimitedFiles.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/IPython/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/IPython/IPython.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/util.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/Common.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/inline.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/block.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Markdown.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/interp.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/Julia.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/latex.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/render.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/formatting.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/html.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/plain.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/rst.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/rich.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/table.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/GitHub.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/gen/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/gen/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_common_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_exports_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_curl_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/Mime_ext.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_defines_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/LibCURL.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/ssl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/src/LibUnwind_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/src/SuiteSparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/devcontainer.json\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/Dockerfile\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/src/p7zip_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/src/OpenLibm_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/src/CompilerSupportLibraries_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/pidfile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/FileWatching.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/pidfile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/generator.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/generator.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparsevector.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/higherorderfns.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-apple-darwin14.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-w64-mingw32.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/armv7l-linux-musleabihf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-unknown-freebsd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/armv7l-linux-gnueabihf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-w64-mingw32.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-apple-darwin20.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/powerpc64le-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/LibSuiteSparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/cholmod.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/spqr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/umfpack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/solvers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/linalg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/abstractsparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/SparseArrays.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparsematrix.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparseconvert.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/readonly.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/simplesmatrix.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsematrix_constructors_indexing.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsevector.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/fixed.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/ambiguous.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/forbidproperties.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/threads.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/higherorderfns.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/allowscalar.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/cholmod.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/linalg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/spqr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/umfpack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/matrices/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/matrices/stiffness_sym_indef\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/issues.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsematrix_ops.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/linalg_solvers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/solvers.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/backport.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/src/PCRE2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/src/LibGit2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/logging.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/Test.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/test_pop_testset_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/nothrow_testset.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/gitcredential.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/rebase.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/tag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/status.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/LibGit2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/merge.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/index.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/commit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/error.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/reference.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/repository.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/diff.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/blame.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/oid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/consts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/strarray.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/blob.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/callbacks.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/tree.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/remote.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/walker.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/signature.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2-helpers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/bad_ca_roots.pem\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/online-tests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid-passphrase.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/invalid.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid-passphrase\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/invalid\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/known_hosts\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/bad_ca_roots.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/online.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2-tests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/src/index.md\n",
            "julia-1.9.3/share/julia/test/\n",
            "julia-1.9.3/share/julia/test/depot/\n",
            "julia-1.9.3/share/julia/test/depot/packages/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/src/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/src/Baz.jl\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/src/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/vecelement.jl\n",
            "julia-1.9.3/share/julia/test/specificity.jl\n",
            "julia-1.9.3/share/julia/test/env.jl\n",
            "julia-1.9.3/share/julia/test/loading.jl\n",
            "julia-1.9.3/share/julia/test/manifest/\n",
            "julia-1.9.3/share/julia/test/manifest/v1.0/\n",
            "julia-1.9.3/share/julia/test/manifest/v1.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/manifest/v2.0/\n",
            "julia-1.9.3/share/julia/test/manifest/v2.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/sysinfo.jl\n",
            "julia-1.9.3/share/julia/test/version.jl\n",
            "julia-1.9.3/share/julia/test/meta.jl\n",
            "julia-1.9.3/share/julia/test/ranges.jl\n",
            "julia-1.9.3/share/julia/test/subtype.jl\n",
            "julia-1.9.3/share/julia/test/opaque_closure.jl\n",
            "julia-1.9.3/share/julia/test/reinterpretarray.jl\n",
            "julia-1.9.3/share/julia/test/osutils.jl\n",
            "julia-1.9.3/share/julia/test/deprecation_exec.jl\n",
            "julia-1.9.3/share/julia/test/triplequote.jl\n",
            "julia-1.9.3/share/julia/test/clangsa/\n",
            "julia-1.9.3/share/julia/test/clangsa/ImplicitAtomicsTest.c\n",
            "julia-1.9.3/share/julia/test/clangsa/.gitignore\n",
            "julia-1.9.3/share/julia/test/clangsa/GCPushPop.cpp\n",
            "julia-1.9.3/share/julia/test/clangsa/MissingRoots.c\n",
            "julia-1.9.3/share/julia/test/clangsa/lit.cfg.py\n",
            "julia-1.9.3/share/julia/test/clangsa/Makefile\n",
            "julia-1.9.3/share/julia/test/misc.jl\n",
            "julia-1.9.3/share/julia/test/ccall.jl\n",
            "julia-1.9.3/share/julia/test/.gitignore\n",
            "julia-1.9.3/share/julia/test/stack_overflow.jl\n",
            "julia-1.9.3/share/julia/test/backtrace.jl\n",
            "julia-1.9.3/share/julia/test/profile_spawnmany_exec.jl\n",
            "julia-1.9.3/share/julia/test/smallarrayshrink.jl\n",
            "julia-1.9.3/share/julia/test/project/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/src/SomePackage.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/ext/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/ext/Extension2.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/Extension.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/ExtensionFolder/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/ExtensionFolder/ExtensionFolder.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/src/HasDepWithExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/src/ExtDep2.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/src/ExtDep.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/deps/\n",
            "julia-1.9.3/share/julia/test/project/deps/Qux.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/src/Bar.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/SubFoo1.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/subdir/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/subdir/SubFoo2.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/threads_exec.jl\n",
            "julia-1.9.3/share/julia/test/iobuffer.jl\n",
            "julia-1.9.3/share/julia/test/strings/\n",
            "julia-1.9.3/share/julia/test/strings/search.jl\n",
            "julia-1.9.3/share/julia/test/strings/util.jl\n",
            "julia-1.9.3/share/julia/test/strings/types.jl\n",
            "julia-1.9.3/share/julia/test/strings/io.jl\n",
            "julia-1.9.3/share/julia/test/strings/basic.jl\n",
            "julia-1.9.3/share/julia/test/reduce.jl\n",
            "julia-1.9.3/share/julia/test/gcext/\n",
            "julia-1.9.3/share/julia/test/gcext/.gitignore\n",
            "julia-1.9.3/share/julia/test/gcext/gcext.c\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/src/\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/src/ForeignObjSerialization.jl\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/gcext-test.jl\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/src/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/src/Foreign.jl\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/deps/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/deps/foreignlib.c\n",
            "julia-1.9.3/share/julia/test/gcext/Makefile\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/src/\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/src/DependsOnForeign.jl\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/LocalTest.jl\n",
            "julia-1.9.3/share/julia/test/hashing.jl\n",
            "julia-1.9.3/share/julia/test/sorting.jl\n",
            "julia-1.9.3/share/julia/test/missing.jl\n",
            "julia-1.9.3/share/julia/test/interpreter.jl\n",
            "julia-1.9.3/share/julia/test/filesystem.jl\n",
            "julia-1.9.3/share/julia/test/functional.jl\n",
            "julia-1.9.3/share/julia/test/complex.jl\n",
            "julia-1.9.3/share/julia/test/bitset.jl\n",
            "julia-1.9.3/share/julia/test/docs.jl\n",
            "julia-1.9.3/share/julia/test/download_exec.jl\n",
            "julia-1.9.3/share/julia/test/ryu.jl\n",
            "julia-1.9.3/share/julia/test/sets.jl\n",
            "julia-1.9.3/share/julia/test/reducedim.jl\n",
            "julia-1.9.3/share/julia/test/math.jl\n",
            "julia-1.9.3/share/julia/test/mpfr.jl\n",
            "julia-1.9.3/share/julia/test/ordering.jl\n",
            "julia-1.9.3/share/julia/test/spawn.jl\n",
            "julia-1.9.3/share/julia/test/syntax.jl\n",
            "julia-1.9.3/share/julia/test/keywordargs.jl\n",
            "julia-1.9.3/share/julia/test/offsetarray.jl\n",
            "julia-1.9.3/share/julia/test/reflection.jl\n",
            "julia-1.9.3/share/julia/test/corelogging.jl\n",
            "julia-1.9.3/share/julia/test/asyncmap.jl\n",
            "julia-1.9.3/share/julia/test/dict.jl\n",
            "julia-1.9.3/share/julia/test/operators.jl\n",
            "julia-1.9.3/share/julia/test/namedtuple.jl\n",
            "julia-1.9.3/share/julia/test/choosetests.jl\n",
            "julia-1.9.3/share/julia/test/read.jl\n",
            "julia-1.9.3/share/julia/test/threadpool_latency.jl\n",
            "julia-1.9.3/share/julia/test/ambiguous.jl\n",
            "julia-1.9.3/share/julia/test/channels.jl\n",
            "julia-1.9.3/share/julia/test/exceptions.jl\n",
            "julia-1.9.3/share/julia/test/enums.jl\n",
            "julia-1.9.3/share/julia/test/threads.jl\n",
            "julia-1.9.3/share/julia/test/error.jl\n",
            "julia-1.9.3/share/julia/test/precompile.jl\n",
            "julia-1.9.3/share/julia/test/generic_map_tests.jl\n",
            "julia-1.9.3/share/julia/test/iostream.jl\n",
            "julia-1.9.3/share/julia/test/download.jl\n",
            "julia-1.9.3/share/julia/test/int.jl\n",
            "julia-1.9.3/share/julia/test/boundscheck_exec.jl\n",
            "julia-1.9.3/share/julia/test/goto.jl\n",
            "julia-1.9.3/share/julia/test/threadpool_use.jl\n",
            "julia-1.9.3/share/julia/test/boundscheck.jl\n",
            "julia-1.9.3/share/julia/test/stress.jl\n",
            "julia-1.9.3/share/julia/test/intrinsics.jl\n",
            "julia-1.9.3/share/julia/test/stress_fd_exec.jl\n",
            "julia-1.9.3/share/julia/test/mod2pi.jl\n",
            "julia-1.9.3/share/julia/test/worlds.jl\n",
            "julia-1.9.3/share/julia/test/arrayops.jl\n",
            "julia-1.9.3/share/julia/test/gmp.jl\n",
            "julia-1.9.3/share/julia/test/llvmcall2.jl\n",
            "julia-1.9.3/share/julia/test/unicode/\n",
            "julia-1.9.3/share/julia/test/unicode/utf8.jl\n",
            "julia-1.9.3/share/julia/test/subarray.jl\n",
            "julia-1.9.3/share/julia/test/broadcast.jl\n",
            "julia-1.9.3/share/julia/test/fastmath.jl\n",
            "julia-1.9.3/share/julia/test/rational.jl\n",
            "julia-1.9.3/share/julia/test/core.jl\n",
            "julia-1.9.3/share/julia/test/floatapprox.jl\n",
            "julia-1.9.3/share/julia/test/compiler/\n",
            "julia-1.9.3/share/julia/test/compiler/AbstractInterpreter.jl\n",
            "julia-1.9.3/share/julia/test/compiler/ssair.jl\n",
            "julia-1.9.3/share/julia/test/compiler/validation.jl\n",
            "julia-1.9.3/share/julia/test/compiler/datastructures.jl\n",
            "julia-1.9.3/share/julia/test/compiler/irutils.jl\n",
            "julia-1.9.3/share/julia/test/compiler/codegen.jl\n",
            "julia-1.9.3/share/julia/test/compiler/inline.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/EAUtils.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/local.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/interprocedural.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/setup.jl\n",
            "julia-1.9.3/share/julia/test/compiler/inference.jl\n",
            "julia-1.9.3/share/julia/test/compiler/effects.jl\n",
            "julia-1.9.3/share/julia/test/compiler/irpasses.jl\n",
            "julia-1.9.3/share/julia/test/compiler/interpreter_exec.jl\n",
            "julia-1.9.3/share/julia/test/compiler/contextual.jl\n",
            "julia-1.9.3/share/julia/test/client.jl\n",
            "julia-1.9.3/share/julia/test/regex.jl\n",
            "julia-1.9.3/share/julia/test/netload/\n",
            "julia-1.9.3/share/julia/test/netload/memtest.jl\n",
            "julia-1.9.3/share/julia/test/tuple.jl\n",
            "julia-1.9.3/share/julia/test/TestPkg/\n",
            "julia-1.9.3/share/julia/test/TestPkg/src/\n",
            "julia-1.9.3/share/julia/test/TestPkg/src/TestPkg.jl\n",
            "julia-1.9.3/share/julia/test/TestPkg/Project.toml\n",
            "julia-1.9.3/share/julia/test/TestPkg/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/intfuncs.jl\n",
            "julia-1.9.3/share/julia/test/file.jl\n",
            "julia-1.9.3/share/julia/test/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/test/simdloop.jl\n",
            "julia-1.9.3/share/julia/test/atexit.jl\n",
            "julia-1.9.3/share/julia/test/parse.jl\n",
            "julia-1.9.3/share/julia/test/test_sourcepath.jl\n",
            "julia-1.9.3/share/julia/test/floatfuncs.jl\n",
            "julia-1.9.3/share/julia/test/testdefs.jl\n",
            "julia-1.9.3/share/julia/test/rounding.jl\n",
            "julia-1.9.3/share/julia/test/char.jl\n",
            "julia-1.9.3/share/julia/test/cmdlineargs.jl\n",
            "julia-1.9.3/share/julia/test/numbers.jl\n",
            "julia-1.9.3/share/julia/test/some.jl\n",
            "julia-1.9.3/share/julia/test/copy.jl\n",
            "julia-1.9.3/share/julia/test/errorshow.jl\n",
            "julia-1.9.3/share/julia/test/secretbuffer.jl\n",
            "julia-1.9.3/share/julia/test/iterators.jl\n",
            "julia-1.9.3/share/julia/test/float16.jl\n",
            "julia-1.9.3/share/julia/test/runtests.jl\n",
            "julia-1.9.3/share/julia/test/checked.jl\n",
            "julia-1.9.3/share/julia/test/embedding/\n",
            "julia-1.9.3/share/julia/test/embedding/embedding.c\n",
            "julia-1.9.3/share/julia/test/embedding/.gitignore\n",
            "julia-1.9.3/share/julia/test/embedding/LocalModule.jl\n",
            "julia-1.9.3/share/julia/test/embedding/include_and_eval.jl\n",
            "julia-1.9.3/share/julia/test/embedding/embedding-test.jl\n",
            "julia-1.9.3/share/julia/test/embedding/Makefile\n",
            "julia-1.9.3/share/julia/test/staged.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/\n",
            "julia-1.9.3/share/julia/test/llvmpasses/late-lower-gc-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/final-lower-gc-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/.gitignore\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o0.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-pipeline.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/late-lower-gc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/float16.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/propagate-addrspace-non-zero.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-unsized.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/safepoint_stress.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/loopinfo.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/returnstwicegc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lit.cfg.py\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lower-handlers.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/gcroots.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lower-handlers-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o2-allocs.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-gcframe-addrspaces.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/fastmath.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/propagate-addrspace.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/muladd.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-pass.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/noinline.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/refinements.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/Makefile\n",
            "julia-1.9.3/share/julia/test/llvmpasses/fmf.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/simdloop.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/julia-licm.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/remove-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/aliasscopes.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/final-lower-gc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/cpu-features.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o2.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/llvmcall.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-gcframe.jl\n",
            "julia-1.9.3/share/julia/test/cartesian.jl\n",
            "julia-1.9.3/share/julia/test/print_process_affinity.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/\n",
            "julia-1.9.3/share/julia/test/testhelpers/Furlongs.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info.bad2\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/include_error.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/FakePTYs.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/withlocales.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/allocation_file.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/SizedArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info.bad\n",
            "julia-1.9.3/share/julia/test/testhelpers/InfiniteArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/ImmutableArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/Quaternions.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info\n",
            "julia-1.9.3/share/julia/test/testhelpers/llvmpasses.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/MacroCalls.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/PhysQuantities.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/arrayindexingtypes.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/OffsetArrays.jl\n",
            "julia-1.9.3/share/julia/test/stacktraces.jl\n",
            "julia-1.9.3/share/julia/test/testenv.jl\n",
            "julia-1.9.3/share/julia/test/abstractarray.jl\n",
            "julia-1.9.3/share/julia/test/euler.jl\n",
            "julia-1.9.3/share/julia/test/path.jl\n",
            "julia-1.9.3/share/julia/test/llvmcall.jl\n",
            "julia-1.9.3/share/julia/test/bitarray.jl\n",
            "julia-1.9.3/share/julia/test/atomics.jl\n",
            "julia-1.9.3/share/julia/test/combinatorics.jl\n",
            "julia-1.9.3/share/julia/test/show.jl\n",
            "julia-1.9.3/share/julia/test/test_exec.jl\n",
            "julia-1.9.3/share/julia/base/\n",
            "julia-1.9.3/share/julia/base/env.jl\n",
            "julia-1.9.3/share/julia/base/loading.jl\n",
            "julia-1.9.3/share/julia/base/Enums.jl\n",
            "julia-1.9.3/share/julia/base/sysinfo.jl\n",
            "julia-1.9.3/share/julia/base/version.jl\n",
            "julia-1.9.3/share/julia/base/meta.jl\n",
            "julia-1.9.3/share/julia/base/uuid.jl\n",
            "julia-1.9.3/share/julia/base/permuteddimsarray.jl\n",
            "julia-1.9.3/share/julia/base/uv_constants.jl\n",
            "julia-1.9.3/share/julia/base/timing.jl\n",
            "julia-1.9.3/share/julia/base/opaque_closure.jl\n",
            "julia-1.9.3/share/julia/base/iddict.jl\n",
            "julia-1.9.3/share/julia/base/reinterpretarray.jl\n",
            "julia-1.9.3/share/julia/base/views.jl\n",
            "julia-1.9.3/share/julia/base/sysimg.jl\n",
            "julia-1.9.3/share/julia/base/osutils.jl\n",
            "julia-1.9.3/share/julia/base/stat.jl\n",
            "julia-1.9.3/share/julia/base/float.jl\n",
            "julia-1.9.3/share/julia/base/.gitignore\n",
            "julia-1.9.3/share/julia/base/Base.jl\n",
            "julia-1.9.3/share/julia/base/threadcall.jl\n",
            "julia-1.9.3/share/julia/base/indices.jl\n",
            "julia-1.9.3/share/julia/base/errno_h.jl\n",
            "julia-1.9.3/share/julia/base/iobuffer.jl\n",
            "julia-1.9.3/share/julia/base/strings/\n",
            "julia-1.9.3/share/julia/base/strings/unicode.jl\n",
            "julia-1.9.3/share/julia/base/strings/substring.jl\n",
            "julia-1.9.3/share/julia/base/strings/strings.jl\n",
            "julia-1.9.3/share/julia/base/strings/search.jl\n",
            "julia-1.9.3/share/julia/base/strings/lazy.jl\n",
            "julia-1.9.3/share/julia/base/strings/string.jl\n",
            "julia-1.9.3/share/julia/base/strings/util.jl\n",
            "julia-1.9.3/share/julia/base/strings/io.jl\n",
            "julia-1.9.3/share/julia/base/strings/basic.jl\n",
            "julia-1.9.3/share/julia/base/reduce.jl\n",
            "julia-1.9.3/share/julia/base/boot.jl\n",
            "julia-1.9.3/share/julia/base/div.jl\n",
            "julia-1.9.3/share/julia/base/ntuple.jl\n",
            "julia-1.9.3/share/julia/base/hashing.jl\n",
            "julia-1.9.3/share/julia/base/missing.jl\n",
            "julia-1.9.3/share/julia/base/gcutils.jl\n",
            "julia-1.9.3/share/julia/base/filesystem.jl\n",
            "julia-1.9.3/share/julia/base/threads_overloads.jl\n",
            "julia-1.9.3/share/julia/base/pointer.jl\n",
            "julia-1.9.3/share/julia/base/file_constants.jl\n",
            "julia-1.9.3/share/julia/base/sort.jl\n",
            "julia-1.9.3/share/julia/base/arrayshow.jl\n",
            "julia-1.9.3/share/julia/base/cmd.jl\n",
            "julia-1.9.3/share/julia/base/complex.jl\n",
            "julia-1.9.3/share/julia/base/bitset.jl\n",
            "julia-1.9.3/share/julia/base/twiceprecision.jl\n",
            "julia-1.9.3/share/julia/base/features_h.jl\n",
            "julia-1.9.3/share/julia/base/task.jl\n",
            "julia-1.9.3/share/julia/base/reducedim.jl\n",
            "julia-1.9.3/share/julia/base/math.jl\n",
            "julia-1.9.3/share/julia/base/mpfr.jl\n",
            "julia-1.9.3/share/julia/base/generator.jl\n",
            "julia-1.9.3/share/julia/base/ordering.jl\n",
            "julia-1.9.3/share/julia/base/reflection.jl\n",
            "julia-1.9.3/share/julia/base/cpuid.jl\n",
            "julia-1.9.3/share/julia/base/shell.jl\n",
            "julia-1.9.3/share/julia/base/asyncmap.jl\n",
            "julia-1.9.3/share/julia/base/dict.jl\n",
            "julia-1.9.3/share/julia/base/operators.jl\n",
            "julia-1.9.3/share/julia/base/namedtuple.jl\n",
            "julia-1.9.3/share/julia/base/threadingconstructs.jl\n",
            "julia-1.9.3/share/julia/base/slicearray.jl\n",
            "julia-1.9.3/share/julia/base/abstractset.jl\n",
            "julia-1.9.3/share/julia/base/abstractarraymath.jl\n",
            "julia-1.9.3/share/julia/base/c.jl\n",
            "julia-1.9.3/share/julia/base/pair.jl\n",
            "julia-1.9.3/share/julia/base/channels.jl\n",
            "julia-1.9.3/share/julia/base/libdl.jl\n",
            "julia-1.9.3/share/julia/base/partr.jl\n",
            "julia-1.9.3/share/julia/base/condition.jl\n",
            "julia-1.9.3/share/julia/base/weakkeydict.jl\n",
            "julia-1.9.3/share/julia/base/threads.jl\n",
            "julia-1.9.3/share/julia/base/error.jl\n",
            "julia-1.9.3/share/julia/base/refvalue.jl\n",
            "julia-1.9.3/share/julia/base/asyncevent.jl\n",
            "julia-1.9.3/share/julia/base/deprecated.jl\n",
            "julia-1.9.3/share/julia/base/iostream.jl\n",
            "julia-1.9.3/share/julia/base/logging.jl\n",
            "julia-1.9.3/share/julia/base/deepcopy.jl\n",
            "julia-1.9.3/share/julia/base/range.jl\n",
            "julia-1.9.3/share/julia/base/baseext.jl\n",
            "julia-1.9.3/share/julia/base/initdefs.jl\n",
            "julia-1.9.3/share/julia/base/download.jl\n",
            "julia-1.9.3/share/julia/base/int.jl\n",
            "julia-1.9.3/share/julia/base/bool.jl\n",
            "julia-1.9.3/share/julia/base/arraymath.jl\n",
            "julia-1.9.3/share/julia/base/methodshow.jl\n",
            "julia-1.9.3/share/julia/base/libuv.jl\n",
            "julia-1.9.3/share/julia/base/multinverses.jl\n",
            "julia-1.9.3/share/julia/base/gmp.jl\n",
            "julia-1.9.3/share/julia/base/ctypes.jl\n",
            "julia-1.9.3/share/julia/base/subarray.jl\n",
            "julia-1.9.3/share/julia/base/ryu/\n",
            "julia-1.9.3/share/julia/base/ryu/utils.jl\n",
            "julia-1.9.3/share/julia/base/ryu/exp.jl\n",
            "julia-1.9.3/share/julia/base/ryu/fixed.jl\n",
            "julia-1.9.3/share/julia/base/ryu/LICENSE.md\n",
            "julia-1.9.3/share/julia/base/ryu/Ryu.jl\n",
            "julia-1.9.3/share/julia/base/ryu/shortest.jl\n",
            "julia-1.9.3/share/julia/base/broadcast.jl\n",
            "julia-1.9.3/share/julia/base/summarysize.jl\n",
            "julia-1.9.3/share/julia/base/fastmath.jl\n",
            "julia-1.9.3/share/julia/base/rational.jl\n",
            "julia-1.9.3/share/julia/base/promotion.jl\n",
            "julia-1.9.3/share/julia/base/pkgid.jl\n",
            "julia-1.9.3/share/julia/base/reshapedarray.jl\n",
            "julia-1.9.3/share/julia/base/abstractdict.jl\n",
            "julia-1.9.3/share/julia/base/process.jl\n",
            "julia-1.9.3/share/julia/base/compiler/\n",
            "julia-1.9.3/share/julia/base/compiler/typeinfer.jl\n",
            "julia-1.9.3/share/julia/base/compiler/bootstrap.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typelattice.jl\n",
            "julia-1.9.3/share/julia/base/compiler/stmtinfo.jl\n",
            "julia-1.9.3/share/julia/base/compiler/sort.jl\n",
            "julia-1.9.3/share/julia/base/compiler/validation.jl\n",
            "julia-1.9.3/share/julia/base/compiler/inferencestate.jl\n",
            "julia-1.9.3/share/julia/base/compiler/utilities.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/basicblock.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/irinterp.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/legacy.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/passes.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/ir.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/inlining.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/driver.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/EscapeAnalysis.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/disjoint_set.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/interprocedural.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/verify.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/domtree.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/heap.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/slot2ssa.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/show.jl\n",
            "julia-1.9.3/share/julia/base/compiler/tfuncs.jl\n",
            "julia-1.9.3/share/julia/base/compiler/cicache.jl\n",
            "julia-1.9.3/share/julia/base/compiler/abstractlattice.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typeutils.jl\n",
            "julia-1.9.3/share/julia/base/compiler/inferenceresult.jl\n",
            "julia-1.9.3/share/julia/base/compiler/parsing.jl\n",
            "julia-1.9.3/share/julia/base/compiler/types.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typelimits.jl\n",
            "julia-1.9.3/share/julia/base/compiler/abstractinterpretation.jl\n",
            "julia-1.9.3/share/julia/base/compiler/optimize.jl\n",
            "julia-1.9.3/share/julia/base/compiler/effects.jl\n",
            "julia-1.9.3/share/julia/base/compiler/compiler.jl\n",
            "julia-1.9.3/share/julia/base/compiler/methodtable.jl\n",
            "julia-1.9.3/share/julia/base/client.jl\n",
            "julia-1.9.3/share/julia/base/regex.jl\n",
            "julia-1.9.3/share/julia/base/pcre_h.jl\n",
            "julia-1.9.3/share/julia/base/options.jl\n",
            "julia-1.9.3/share/julia/base/version_git.jl\n",
            "julia-1.9.3/share/julia/base/multimedia.jl\n",
            "julia-1.9.3/share/julia/base/ttyhascolor.jl\n",
            "julia-1.9.3/share/julia/base/tuple.jl\n",
            "julia-1.9.3/share/julia/base/intfuncs.jl\n",
            "julia-1.9.3/share/julia/base/file.jl\n",
            "julia-1.9.3/share/julia/base/util.jl\n",
            "julia-1.9.3/share/julia/base/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/base/simdloop.jl\n",
            "julia-1.9.3/share/julia/base/stream.jl\n",
            "julia-1.9.3/share/julia/base/pcre.jl\n",
            "julia-1.9.3/share/julia/base/array.jl\n",
            "julia-1.9.3/share/julia/base/toml_parser.jl\n",
            "julia-1.9.3/share/julia/base/parse.jl\n",
            "julia-1.9.3/share/julia/base/mathconstants.jl\n",
            "julia-1.9.3/share/julia/base/floatfuncs.jl\n",
            "julia-1.9.3/share/julia/base/essentials.jl\n",
            "julia-1.9.3/share/julia/base/set.jl\n",
            "julia-1.9.3/share/julia/base/rounding.jl\n",
            "julia-1.9.3/share/julia/base/char.jl\n",
            "julia-1.9.3/share/julia/base/refpointer.jl\n",
            "julia-1.9.3/share/julia/base/Makefile\n",
            "julia-1.9.3/share/julia/base/some.jl\n",
            "julia-1.9.3/share/julia/base/errorshow.jl\n",
            "julia-1.9.3/share/julia/base/secretbuffer.jl\n",
            "julia-1.9.3/share/julia/base/iterators.jl\n",
            "julia-1.9.3/share/julia/base/linked_list.jl\n",
            "julia-1.9.3/share/julia/base/number.jl\n",
            "julia-1.9.3/share/julia/base/expr.jl\n",
            "julia-1.9.3/share/julia/base/lock.jl\n",
            "julia-1.9.3/share/julia/base/docs/\n",
            "julia-1.9.3/share/julia/base/docs/utils.jl\n",
            "julia-1.9.3/share/julia/base/docs/Docs.jl\n",
            "julia-1.9.3/share/julia/base/docs/core.jl\n",
            "julia-1.9.3/share/julia/base/docs/basedocs.jl\n",
            "julia-1.9.3/share/julia/base/docs/bindings.jl\n",
            "julia-1.9.3/share/julia/base/idset.jl\n",
            "julia-1.9.3/share/julia/base/multidimensional.jl\n",
            "julia-1.9.3/share/julia/base/checked.jl\n",
            "julia-1.9.3/share/julia/base/exports.jl\n",
            "julia-1.9.3/share/julia/base/linking.jl\n",
            "julia-1.9.3/share/julia/base/cartesian.jl\n",
            "julia-1.9.3/share/julia/base/traits.jl\n",
            "julia-1.9.3/share/julia/base/coreio.jl\n",
            "julia-1.9.3/share/julia/base/stacktraces.jl\n",
            "julia-1.9.3/share/julia/base/build_h.jl\n",
            "julia-1.9.3/share/julia/base/irrationals.jl\n",
            "julia-1.9.3/share/julia/base/abstractarray.jl\n",
            "julia-1.9.3/share/julia/base/accumulate.jl\n",
            "julia-1.9.3/share/julia/base/libc.jl\n",
            "julia-1.9.3/share/julia/base/special/\n",
            "julia-1.9.3/share/julia/base/special/log.jl\n",
            "julia-1.9.3/share/julia/base/special/exp.jl\n",
            "julia-1.9.3/share/julia/base/special/rem_pio2.jl\n",
            "julia-1.9.3/share/julia/base/special/hyperbolic.jl\n",
            "julia-1.9.3/share/julia/base/special/cbrt.jl\n",
            "julia-1.9.3/share/julia/base/special/trig.jl\n",
            "julia-1.9.3/share/julia/base/path.jl\n",
            "julia-1.9.3/share/julia/base/io.jl\n",
            "julia-1.9.3/share/julia/base/experimental.jl\n",
            "julia-1.9.3/share/julia/base/locks-mt.jl\n",
            "julia-1.9.3/share/julia/base/bitarray.jl\n",
            "julia-1.9.3/share/julia/base/atomics.jl\n",
            "julia-1.9.3/share/julia/base/combinatorics.jl\n",
            "julia-1.9.3/share/julia/base/show.jl\n",
            "julia-1.9.3/libexec/\n",
            "julia-1.9.3/libexec/julia/\n",
            "julia-1.9.3/libexec/julia/dsymutil\n",
            "julia-1.9.3/libexec/julia/7z\n",
            "julia-1.9.3/libexec/julia/lld\n",
            "julia-1.9.3/include/\n",
            "julia-1.9.3/include/julia/\n",
            "julia-1.9.3/include/julia/utf8.h\n",
            "julia-1.9.3/include/julia/htable.h\n",
            "julia-1.9.3/include/julia/strtod.h\n",
            "julia-1.9.3/include/julia/rle.h\n",
            "julia-1.9.3/include/julia/libsupport.h\n",
            "julia-1.9.3/include/julia/julia_gcext.h\n",
            "julia-1.9.3/include/julia/hashing.h\n",
            "julia-1.9.3/include/julia/utils.h\n",
            "julia-1.9.3/include/julia/arraylist.h\n",
            "julia-1.9.3/include/julia/bitvector.h\n",
            "julia-1.9.3/include/julia/julia_version.h\n",
            "julia-1.9.3/include/julia/MurmurHash3.h\n",
            "julia-1.9.3/include/julia/julia.h\n",
            "julia-1.9.3/include/julia/timefuncs.h\n",
            "julia-1.9.3/include/julia/ptrhash.h\n",
            "julia-1.9.3/include/julia/END.h\n",
            "julia-1.9.3/include/julia/uv/\n",
            "julia-1.9.3/include/julia/uv/linux.h\n",
            "julia-1.9.3/include/julia/uv/unix.h\n",
            "julia-1.9.3/include/julia/uv/errno.h\n",
            "julia-1.9.3/include/julia/uv/version.h\n",
            "julia-1.9.3/include/julia/uv/threadpool.h\n",
            "julia-1.9.3/include/julia/julia_threads.h\n",
            "julia-1.9.3/include/julia/julia_fasttls.h\n",
            "julia-1.9.3/include/julia/uv.h\n",
            "julia-1.9.3/include/julia/jloptions.h\n",
            "julia-1.9.3/include/julia/ENTRY.i387.h\n",
            "julia-1.9.3/include/julia/tzfile.h\n",
            "julia-1.9.3/include/julia/dtypes.h\n",
            "julia-1.9.3/include/julia/dirpath.h\n",
            "julia-1.9.3/include/julia/julia_locks.h\n",
            "julia-1.9.3/include/julia/analyzer_annotations.h\n",
            "julia-1.9.3/include/julia/julia_atomics.h\n",
            "julia-1.9.3/include/julia/platform.h\n",
            "julia-1.9.3/include/julia/ios.h\n",
            "julia-1.9.3/include/julia/julia_assert.h\n",
            "julia-1.9.3/include/julia/ENTRY.amd64.h\n",
            "julia-1.9.3/bin/\n",
            "julia-1.9.3/bin/julia\n",
            "julia-1.9.3/etc/\n",
            "julia-1.9.3/etc/julia/\n",
            "julia-1.9.3/etc/julia/startup.jl\n",
            "julia-1.9.3/LICENSE.md\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update -y\n",
        "!sudo apt upgrade -y\n",
        "!sudo apt install wget -y\n",
        "!wget https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz\n",
        "!tar -xvzf julia-1.9.3-linux-x86_64.tar.gz\n",
        "!sudo cp -r julia-1.9.3 /opt/\n",
        "!sudo ln -s /opt/julia-1.9.3/bin/julia /usr/local/bin/julia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install PySR\n",
        "\n",
        "---\n",
        "\n",
        "PySR is an useful tool, providing the most extensive authority\n",
        "\n",
        "for symbolic regression users, between pip-installable packages..\n",
        "\n",
        "\n",
        "공개된 기호적 회귀 패키지 중 가장 높은 자유도를 지닙니다.\n",
        "\n",
        "PySR need to be installed only once, **the very first time** you try this code."
      ],
      "metadata": {
        "id": "qWIsh2NxBdPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install julia\n",
        "!pip install pysr pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyC1i5oJFM-n",
        "outputId": "bb181b50-6f5d-42f1-a7ee-cffb345d2009"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting julia\n",
            "  Downloading julia-0.6.1-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: julia\n",
            "Successfully installed julia-0.6.1\n",
            "Collecting pysr\n",
            "  Downloading pysr-0.16.3-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.8-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from pysr) (1.12)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pysr) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.2.2)\n",
            "Requirement already satisfied: julia>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (0.6.1)\n",
            "Requirement already satisfied: click>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (8.1.7)\n",
            "Requirement already satisfied: setuptools>=50.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (67.7.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.1.1-py3-none-any.whl (763 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.21.0->pysr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.21.0->pysr) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->pysr) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.21.0->pysr) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.7.22)\n",
            "Installing collected packages: lightning-utilities, pysr, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.9.0 pysr-0.16.3 pytorch_lightning-2.0.8 torchmetrics-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] += \":/usr/local/bin/julia\""
      ],
      "metadata": {
        "id": "V3LNvr1PFOhO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pysr\n",
        "\n",
        "# We don't precompile in colab because compiled modules\n",
        "# are incompatible static Python libraries:\n",
        "pysr.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPeRsaORFlpW",
        "outputId": "f1f3b7aa-0e1a-4e4e-8a48-334722b65efb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Precompiling PyCall...\n",
            "Precompiling PyCall... DONE\n",
            "PyCall is installed and built successfully.\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:208: UserWarning: Your system's Python library is static (e.g., conda), so precompilation will be turned off. For a dynamic library, try using `pyenv` and installing with `--enable-shared`: https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#building-with---enable-shared.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:118: UserWarning: It is recommended to restart Python after installing PySR's dependencies, so that the Julia environment is properly initialized.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Import basics\n",
        "\n",
        "---\n",
        "\n",
        "Some packages need to be imported,,,"
      ],
      "metadata": {
        "id": "1KFM0G8SF1o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pysr import PySRRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "pM6uKN13F8QY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Mount Google Drive & Read Dataset\n",
        "\n",
        "---\n",
        "\n",
        "By mounting google drive, you can easily back-up your each processes.\n",
        "\n",
        "Caution: This code is very fragile. Please be patient."
      ],
      "metadata": {
        "id": "lXpaUovYF9UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p7XOFwrxGRS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# where is your dataset\n",
        "# file_path = '/content/drive/MyDrive/MyInput.xlsx'  # should be modified into your path\n",
        "\n",
        "file_path = 'MyInput.xlsx'  # should be modified into your path\n",
        "\n",
        "\n",
        "# read dataset\n",
        "data = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "upcrYPSrGVYY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Split dataset into Input&Output\n",
        "\n",
        "---\n",
        "\n",
        "This code assumes that your dataset has the same unit for the input data,\n",
        "\n",
        "and un-nondimensionalized output data.\n",
        "\n",
        "You can easily modify the code, from now on."
      ],
      "metadata": {
        "id": "Vn39PBOtGZXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import combinations\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "# Assuming the last column in your dataset is the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]/315 # y value nondim'ed herein.\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhXw66qaGeFc",
        "outputId": "2c4df4f9-8d3a-4a8a-d6b6-a57950f75b57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         TP   BF    TW  TF    HW\n",
            "0      44.5  100  10.0  14   200\n",
            "1      44.5  100  10.0  14   284\n",
            "2      44.5  100  10.0  14   300\n",
            "3      44.5  100  10.0  14   360\n",
            "4      44.5  100  10.0  14   425\n",
            "...     ...  ...   ...  ..   ...\n",
            "10493   9.5  200  28.0  30   500\n",
            "10494   9.5  200  28.0  30   460\n",
            "10495   9.5  200  28.0  30   700\n",
            "10496   9.5  200  28.0  30   800\n",
            "10497   9.5  200  28.0  30  1000\n",
            "\n",
            "[10498 rows x 5 columns]\n",
            "0        0.553074\n",
            "1        0.705244\n",
            "2        0.719511\n",
            "3        0.751525\n",
            "4        0.816629\n",
            "           ...   \n",
            "10493    0.793881\n",
            "10494    0.813152\n",
            "10495    0.705881\n",
            "10496    0.655486\n",
            "10497    0.585506\n",
            "Name: ULS, Length: 10498, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. generate nondimensionalized parameters\n",
        "\n",
        "---\n",
        "\n",
        "Implemented methods: ***Buckingham's Pi Theorem***\n",
        "\n",
        "i) define \"powers\"\n",
        "\n",
        "ii) generate combinations for \"powers\"\n",
        "\n",
        "iii) for sum(power)==0: generate nondimensionalized\n",
        "\n",
        "\n",
        "During each generation of nondim' parameters, its feature importance would be evaluated by RandomForestRegressor;\n",
        "\n",
        "thus only ***top_n*** of parameters would be remained.\n",
        "\n",
        "\n",
        "# **CAUTION: Don't Execute this cell more than once.**\n",
        "\n",
        "cell above must be executed previously."
      ],
      "metadata": {
        "id": "RvF1W5QeGfkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def create_dimensionless_parameters(df, y, drop_origin=True, top_n=6):\n",
        "    powers = [-1, -1/2, 0, 1/2, 1, 2] # you can modify here as your needs\n",
        "    columns = df.columns\n",
        "    result = pd.DataFrame()\n",
        "\n",
        "    # generate combinations of 'power', for you nondim' parameters.\n",
        "    combinations = itertools.product(powers, repeat=len(columns))\n",
        "    iters = 0\n",
        "\n",
        "    for idx, combo in enumerate(combinations):\n",
        "        if sum(combo) == 0:  # for 'sum to zeros' only\n",
        "            # Update naming convention\n",
        "            new_col_name = '_'.join([f\"{col}_p{str(p).replace('-', 'n').replace('.', 'd')}\" for col, p in zip(columns, combo)])\n",
        "            temp_result = df.apply(lambda row: prod_with_power(row, combo), axis=1)\n",
        "            result = result.copy()\n",
        "            result.loc[:, new_col_name] = temp_result\n",
        "\n",
        "            # between each iterations,\n",
        "            combined_df = pd.concat([df, result], axis=1)\n",
        "            if drop_origin:\n",
        "                training_df = combined_df.drop(columns=columns)\n",
        "            else:\n",
        "                training_df = combined_df\n",
        "\n",
        "            model = RandomForestRegressor(n_estimators=30)\n",
        "            model.fit(training_df, y)\n",
        "            feature_importances = model.feature_importances_\n",
        "\n",
        "            # maintain only (top_n) features\n",
        "            important_indices = feature_importances.argsort()[-top_n:][::-1]\n",
        "            important_features = training_df.columns[important_indices]\n",
        "\n",
        "            # print procedures\n",
        "            print(f\"Iteration {iters+1}\")\n",
        "            print(f\"Important features: {important_features.tolist()}\")\n",
        "\n",
        "            result = combined_df[important_features]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def prod_with_power(row, powers):\n",
        "    result = 1\n",
        "    for value, power in zip(row, powers):\n",
        "        result *= value**power\n",
        "    return result\n",
        "\n",
        "# Figure out the most important nondim' features\n",
        "X = create_dimensionless_parameters(X, y, drop_origin=True, top_n=10)\n",
        "X.to_csv('top_n_features.csv', index=False)\n",
        "print(X)\n"
      ],
      "metadata": {
        "id": "-QT5hs3rGiLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. RandomForestRegressor would pick out some number of best nondim' parameters for your dataset.\n",
        "\n",
        "---\n",
        "\n",
        "**Caution:** Random Forest Regression is alreay defined inside the *PySR*.\n",
        "\n",
        "Yet to print out, exclusive package of sklearn would be applied herein.\n",
        "\n",
        "Moreover, selected features by Random Forest Regression may *not represent the optimal* features for your training.\n",
        "\n",
        "However, such sets would be suboptimal, at least.\n",
        "\n",
        "Thus herein, you could define 'N', which will figure out the most important *N* features, among *top_n* features.\n",
        "\n",
        "Good Luck!"
      ],
      "metadata": {
        "id": "LSzgwcZeGqDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('top_n_features.csv')\n",
        "\n",
        "# Initialize and fit the Random Forest Regressor\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# get feature importances\n",
        "feature_importances = regressor.feature_importances_\n",
        "\n",
        "# print it out\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(f'Feature: {feature}, Importance: {importance}')\n",
        "\n",
        "# pick out the best 'N' parameters, with score.\n",
        "N = 6\n",
        "top_features = sorted(zip(X.columns, feature_importances), key=lambda x: x[1], reverse=True)[:N]\n",
        "print(f'Top {N} important features:')\n",
        "for feature, importance in top_features:\n",
        "    print(f'Feature: {feature}, Importance: {importance}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d53NVduL-eM",
        "outputId": "2a944d4d-48e5-4b70-eb93-7eb576fb487b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2, Importance: 0.36912851238814387\n",
            "Feature: TPp3_BFpn1_TWp0_TFpn1_HWpn1, Importance: 0.12064485320510256\n",
            "Feature: TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2, Importance: 0.1505048779038222\n",
            "Feature: TPpn2_BFp0_TWpn1_TFp0_HWp3, Importance: 0.09483178764841392\n",
            "Feature: TPpn1_BFp0_TWp0_TFp0d5_HWp0d5, Importance: 0.024535590101506948\n",
            "Feature: TPp3_BFp0_TWp0_TFpn2_HWpn1, Importance: 0.028325841115249027\n",
            "Feature: TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2, Importance: 0.0276508753043265\n",
            "Feature: TPpn1_BFp0_TWp0_TFp0_HWp1, Importance: 0.023814345185042402\n",
            "Feature: TPp0_BFpn1_TWp3_TFpn1_HWpn1, Importance: 0.020036394596694686\n",
            "Feature: TPp0d5_BFpn1_TWpn0d5_TFpn1_HWp2, Importance: 0.017425387465979648\n",
            "Feature: TPp0d5_BFp0_TWp0_TFp0_HWpn0d5, Importance: 0.015523521158666263\n",
            "Feature: TPp3_BFp0_TWpn2_TFp0_HWpn1, Importance: 0.01617332391642722\n",
            "Feature: TPp2_BFpn2_TWp0_TFp0_HWp0, Importance: 0.01689229969599252\n",
            "Feature: TPp1_BFp0_TWp0_TFp0_HWpn1, Importance: 0.015266930217747207\n",
            "Feature: TPpn2_BFp0d5_TWp0_TFp0d5_HWp1, Importance: 0.013624810180254873\n",
            "Feature: TPpn2_BFp0_TWp2_TFp0_HWp0, Importance: 0.01127059246153245\n",
            "Feature: TPp3_BFpn1_TWpn0d5_TFpn0d5_HWpn1, Importance: 0.010896692184509338\n",
            "Feature: TPp0d5_BFp0_TWpn0d5_TFp0_HWp0, Importance: 0.009957584020405459\n",
            "Feature: TPp1_BFp0_TWpn1_TFp0_HWp0, Importance: 0.009816483239903657\n",
            "Feature: TPp3_BFp1_TWpn2_TFp0_HWpn2, Importance: 0.0036792980102791275\n",
            "Top 6 important features:\n",
            "Feature: TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2, Importance: 0.36912851238814387\n",
            "Feature: TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2, Importance: 0.1505048779038222\n",
            "Feature: TPp3_BFpn1_TWp0_TFpn1_HWpn1, Importance: 0.12064485320510256\n",
            "Feature: TPpn2_BFp0_TWpn1_TFp0_HWp3, Importance: 0.09483178764841392\n",
            "Feature: TPp3_BFp0_TWp0_TFpn2_HWpn1, Importance: 0.028325841115249027\n",
            "Feature: TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2, Importance: 0.0276508753043265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Show the best parameter set\n",
        "\n",
        "---\n",
        "\n",
        "Meanwhile, there could be NaN values, somehow.\n",
        "\n",
        "Drop NaN values here."
      ],
      "metadata": {
        "id": "LaXVOixrMDHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Parameter Set for YOU\n",
        "\n",
        "selected_features = [feature for feature, _ in top_features]\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# find out rows with NaN values\n",
        "drop_indices = X_selected.dropna().index\n",
        "\n",
        "# drop NaN\n",
        "X_selected = X_selected.loc[drop_indices]\n",
        "y = y.loc[drop_indices]\n",
        "\n",
        "print(X_selected)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQprtuwMfRl",
        "outputId": "fb54fa10-b07c-4036-e86f-03b8f76adc34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2  TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2  \\\n",
            "0                            0.041840                       23.900335   \n",
            "1                            0.020750                       48.192635   \n",
            "2                            0.018596                       53.775754   \n",
            "3                            0.012914                       77.437085   \n",
            "4                            0.009266                      107.924950   \n",
            "...                               ...                             ...   \n",
            "10493                        0.000349                     2867.308418   \n",
            "10494                        0.000412                     2426.889845   \n",
            "10495                        0.000178                     5619.924500   \n",
            "10496                        0.000136                     7340.309551   \n",
            "10497                        0.000087                    11469.233673   \n",
            "\n",
            "       TPp3_BFpn1_TWp0_TFpn1_HWpn1  TPpn2_BFp0_TWpn1_TFp0_HWp3  \\\n",
            "0                         0.314718                  403.989395   \n",
            "1                         0.221633                 1156.737988   \n",
            "2                         0.209812                 1363.464209   \n",
            "3                         0.174844                 2356.066153   \n",
            "4                         0.148103                 3876.562303   \n",
            "...                            ...                         ...   \n",
            "10493                     0.000286                49465.769687   \n",
            "10494                     0.000311                38518.401266   \n",
            "10495                     0.000204               135734.072022   \n",
            "10496                     0.000179               202611.792639   \n",
            "10497                     0.000143               395726.157499   \n",
            "\n",
            "       TPp3_BFp0_TWp0_TFpn2_HWpn1  TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2  \n",
            "0                        2.247988                        59.962535  \n",
            "1                        1.583090                       120.908456  \n",
            "2                        1.498659                       134.915704  \n",
            "3                        1.248882                       194.278614  \n",
            "4                        1.057877                       270.768323  \n",
            "...                           ...                              ...  \n",
            "10493                    0.001905                       204.835477  \n",
            "10494                    0.002071                       173.372747  \n",
            "10495                    0.001361                       401.477534  \n",
            "10496                    0.001191                       524.378820  \n",
            "10497                    0.000953                       819.341907  \n",
            "\n",
            "[10498 rows x 6 columns]\n",
            "0        0.553074\n",
            "1        0.705244\n",
            "2        0.719511\n",
            "3        0.751525\n",
            "4        0.816629\n",
            "           ...   \n",
            "10493    0.793881\n",
            "10494    0.813152\n",
            "10495    0.705881\n",
            "10496    0.655486\n",
            "10497    0.585506\n",
            "Name: ULS, Length: 10498, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Chapter.2 Generate model by NAS\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Cn1qZpQ3RBLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Tensorflow\n",
        "\n",
        "---\n",
        "\n",
        "Basic Requirments would be fulfilled herein."
      ],
      "metadata": {
        "id": "HT2VOpnMMwOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install scikit-optimize\n",
        "\n",
        "# Import Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import json\n",
        "#-----------------------------------------------------------\n",
        "# Add the required libraries for Bayesian optimization\n",
        "import skopt\n",
        "    # Caution : please open your scikit-optimize package,\n",
        "    # and then replace every 'np.int' into 'int', in 'transformer.py'\n",
        "    # Anaconda\\Lib\\site-packages\\skopt\\space\\transformers.py\n",
        "from skopt import gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOnCGrUeRLgJ",
        "outputId": "2302e721-6cec-4936-bd89-ea4ec1449efe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.9.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.9.5 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Engage your GPU\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PaBDv2hRRUA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Does GPU Works?\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "#-----------------------------------------------------------\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "print(device_lib.list_local_devices())\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g66TEU4zRR3U",
        "outputId": "16bea857-d20a-4512-b0cf-83ecc8765ae2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1091014522144463102\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 40161050624\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14213526378031958282\n",
            "physical_device_desc: \"device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Split Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "C07r1Om1Rk_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#-----------------------------------------------------------\n",
        "X_clean = X_selected.values\n",
        "y_clean = y.values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.2, random_state=7)\n",
        "\n",
        "# Reshaping data\n",
        "input_data_train = [X_train[:, i].reshape(-1, 1) for i in range(X_train.shape[1])]\n",
        "input_data_val = [X_val[:, i].reshape(-1, 1) for i in range(X_val.shape[1])]\n",
        "\n",
        "print(X_train, y_train)\n",
        "print(X_val, y_val)\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpZKYnL2RlG1",
        "outputId": "16d37e6f-167b-4d49-da02-ead3a5cd4c3c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.51773715e-02 3.97182049e+01 3.90092330e-02 3.78698225e+02\n",
            "  3.54629390e-01 2.48069469e+01]\n",
            " [3.86392688e-03 2.58804069e+02 1.59064901e-02 4.95539297e+03\n",
            "  7.23022276e-02 1.73947203e+02]\n",
            " [5.04413749e-03 1.98249949e+02 1.12679989e-02 3.60472842e+03\n",
            "  1.40849986e-01 7.54585952e+01]\n",
            " ...\n",
            " [2.68249714e-03 3.72786977e+02 5.15090543e-03 8.94777500e+03\n",
            "  7.35843633e-02 1.42581011e+02]\n",
            " [2.95014733e-03 3.38966122e+02 4.00550568e-02 1.29276606e+04\n",
            "  2.27585550e-01 4.29056975e+02]\n",
            " [4.28449753e-04 2.33399598e+03 9.49342561e-04 6.80470914e+04\n",
            "  6.98046000e-03 4.19325273e+02]] [0.86033048 0.81743365 0.92112127 ... 0.76684381 0.88360667 0.67025587]\n",
            "[[5.34785694e-04 1.86990791e+03 1.32560386e-03 4.96612245e+04\n",
            "  6.62801932e-03 4.61749056e+02]\n",
            " [6.05415405e-05 1.65175843e+04 1.42895833e-04 8.20765364e+05\n",
            "  9.52638889e-04 1.69937581e+03]\n",
            " [1.92093675e-03 5.20579347e+02 2.88471639e-02 2.40543502e+04\n",
            "  1.69689199e-01 6.36679155e+02]\n",
            " ...\n",
            " [1.10895826e-02 9.01747192e+01 6.53869048e-02 2.04497041e+03\n",
            "  5.83811650e-01 1.12962894e+02]\n",
            " [2.98922383e-03 3.34535002e+02 1.83585677e-02 9.23404332e+03\n",
            "  1.22390451e-01 2.42285230e+02]\n",
            " [3.60135858e-03 2.77672989e+02 4.23150660e-02 1.28304039e+04\n",
            "  4.35596268e-01 4.11304330e+02]] [0.69768508 0.49199587 0.85335365 ... 0.86095365 0.96188571 0.9130381 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Definitions by TensorFlow\n",
        "\n",
        "---\n",
        "\n",
        "![15658638.png](data:image/png;base64,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)\n",
        "\n",
        "a) Early Stopping\n",
        "\n",
        "b) Create Model = (N, 1) + (1, 1)"
      ],
      "metadata": {
        "id": "tC20megQRlQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate earlyStopping callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#-----------------------------------------------------------\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function : Create SumNET\n",
        "#-----------------------------------------------------------\n",
        "class SumNet:\n",
        "    def __init__(self, layer_nodes, learning_rate, activation, dropout_rate, optimizer, loss_function):\n",
        "        self.model_g = self.create_sumnet_g(layer_nodes, activation, dropout_rate)\n",
        "        self.model_f = self.create_sumnet_f(layer_nodes, activation, dropout_rate)\n",
        "        self.model = self.build_model(layer_nodes, learning_rate, activation, dropout_rate, optimizer, loss_function)\n",
        "\n",
        "    def create_sumnet_g(self, layer_nodes, activation, dropout_rate):\n",
        "        model_g_inputs = [tf.keras.layers.Input(shape=(1,)) for _ in range(N)]\n",
        "        x = tf.keras.layers.Concatenate()(model_g_inputs)\n",
        "\n",
        "        for nodes in layer_nodes:\n",
        "            x = tf.keras.layers.Dense(nodes, activation=activation)(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "        model_g_output = tf.keras.layers.Dense(1)(x)\n",
        "        return tf.keras.Model(inputs=model_g_inputs, outputs=model_g_output)\n",
        "\n",
        "    def create_sumnet_f(self, layer_nodes, activation, dropout_rate):\n",
        "        model_f_input = tf.keras.layers.Input(shape=(1,))\n",
        "        x = model_f_input\n",
        "\n",
        "        for nodes in layer_nodes:\n",
        "            x = tf.keras.layers.Dense(nodes, activation=activation)(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "        model_f_output = tf.keras.layers.Dense(1)(x)\n",
        "        return tf.keras.Model(inputs=model_f_input, outputs=model_f_output)\n",
        "\n",
        "    def build_model(self, layer_nodes, learning_rate, activation, dropout_rate, optimizer, loss_function):\n",
        "        inputs = [tf.keras.layers.Input(shape=(1,)) for _ in range(N)]\n",
        "        g_out = self.model_g(inputs)\n",
        "        f_out = self.model_f(g_out)\n",
        "        outputs = f_out\n",
        "\n",
        "        sumnet_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        opt = None\n",
        "        if optimizer == 'adam':\n",
        "            opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        elif optimizer == 'sgd':\n",
        "            opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "        sumnet_model.compile(optimizer=opt, loss=loss_function, metrics=['mse'])\n",
        "        return sumnet_model\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# Function: show plot\n",
        "#-----------------------------------------------------------\n",
        "def show_plot(params, val_mse, epoch_rate, predicted_performance, toshow=False):\n",
        "    if toshow==True:\n",
        "        plt.plot(np.arange(int(params['epochs']*epoch_rate)), val_mse, label='Actual')\n",
        "        plt.axhline(y=predicted_performance, color='r', linestyle='dashed', label='Predicted')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Validation MSE')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "id": "6GQ_Q-JDRlYA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search space could be defined by your own here.\n",
        "\n",
        "Recommended Options:\n",
        "\n",
        "*   Activation Function - ReLu\n",
        "\n",
        "*   Optimizer - Adam"
      ],
      "metadata": {
        "id": "hDUzVPDVRlgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search space\n",
        "#-----------------------------------------------------------\n",
        "    # Define the hyperparameter search space\n",
        "    # Caution: this\n",
        "max_layers = 2\n",
        "layer_nodes_space = [Integer(64, 256, name=f'layer_{i+1}_nodes') for i in range(max_layers)]\n",
        "space = [\n",
        "    Integer(1, max_layers, name='number_of_layers'),\n",
        "    *layer_nodes_space,\n",
        "    Integer(16, 256, name='batch_size'),\n",
        "    Categorical([200], name='epochs'),\n",
        "    Real(1e-6, 1e-1, \"log-uniform\", name='learning_rate'),\n",
        "    Categorical(['relu'], name='activation'),\n",
        "    Categorical(['huber','mae','logcosh'], name='loss_function'),\n",
        "    Categorical(['adam'], name='optimizer'),\n",
        "    Real(0, 0.5, name='dropout_rate')\n",
        "]\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function: Print Hyperparameters\n",
        "#-----------------------------------------------------------\n",
        "def print_model(params, layer_nodes):\n",
        "    print(\"----------------------------------------\")\n",
        "    print(\"Model Specifications:\")\n",
        "    print(f\"Number of Layers: {params['number_of_layers']}\")\n",
        "    print(f\"Layer Nodes: {layer_nodes}\")\n",
        "    print(f\"Learning Rate: {params['learning_rate']}\")\n",
        "    print(f\"Activation Function: {params['activation']}\")\n",
        "    print(f\"Loss Function: {params['loss_function']}\")\n",
        "    print(f\"Optimizer: {params['optimizer']}\")\n",
        "    print(f\"Epochs: {params['epochs']}\")\n",
        "    print(f\"Dropout Rate: {params['dropout_rate']}\")\n",
        "    print(f\"Batch Size: {params['batch_size']}\")\n",
        "    print(\"----------------------------------------\")\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function: SVR Trainer\n",
        "from sklearn.svm import NuSVR\n",
        "from sklearn.svm import SVR\n",
        "from skopt.sampler import Lhs\n",
        "from joblib import dump\n",
        "#-----------------------------------------------------------\n",
        "# Function: Model Performance Estimation Strategy\n",
        "    # by nu-SVR, would predict model performance\n",
        "def predict_final_performance(val_loss, model=None, total_epochs=None):\n",
        "    x_pred = np.array(val_loss).reshape(1,-1)\n",
        "    prediction = model.predict(x_pred)\n",
        "    return prediction\n",
        "\n",
        "def pretrain_Estimator(X, y, model=None):\n",
        "    if model is None:\n",
        "        model = NuSVR(kernel='rbf', nu=0.5, gamma=0.1, C=100)\n",
        "    model.fit(X, y)\n",
        "    dump(model, 'estimator.joblib')\n",
        "    return model\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "id": "zl5xGmSaRlmz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Train NuSVR\n",
        "\n",
        "---\n",
        "\n",
        "*n_samples* of models would be randomly generated, and trained herein.\n",
        "\n",
        "From its 25% learning curve and final val_loss,\n",
        "\n",
        "NuSVR would get trained thus it'll be a useful estimator for your Bayesian Optimization with Gaussian Process."
      ],
      "metadata": {
        "id": "d4sDGWzdSBq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVR - from random samples\n",
        "    # models: 25% learning curve - final_val_loss\n",
        "#-----------------------------------------------------------\n",
        "    # Create a sampler\n",
        "sampler = Lhs(lhs_type=\"classic\", criterion=None)\n",
        "    # Sample \"n_samples\" points from the search space\n",
        "samples = sampler.generate(space, n_samples=50)\n",
        "    # Convert samples to list of dictionaries\n",
        "random_datasets = [{dim.name: sample[i] for i, dim in enumerate(space)} for sample in samples]\n",
        "    # Initialize the lists to store the results\n",
        "val_losses_25pct = []\n",
        "final_val_losses = []\n",
        "\n",
        "iters = 0\n",
        "    # Train each model and record the results\n",
        "for params in random_datasets:\n",
        "        # Create and compile the model\n",
        "    number_of_layers = params['number_of_layers']\n",
        "    layer_nodes = [params[f'layer_{i+1}_nodes'] for i in range(number_of_layers)]\n",
        "\n",
        "    f_g_net = SumNet(\n",
        "        layer_nodes=layer_nodes,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        activation=params['activation'],\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        optimizer=params['optimizer'],\n",
        "        loss_function=params['loss_function']\n",
        "    )\n",
        "\n",
        "    print(\"\\n****Iteration number {} started****\\n\".format(iters+1))\n",
        "\n",
        "    iters=iters+1\n",
        "        # Train the model\n",
        "    history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                        epochs=int(params['epochs']*0.25),\n",
        "                        batch_size=params['batch_size'],\n",
        "                        validation_data=(input_data_val, y_val), verbose=1)\n",
        "\n",
        "        # Record the 25% val_loss\n",
        "    val_losses_25pct.append(history.history['val_loss'])\n",
        "\n",
        "    # Continue training to 100%\n",
        "    history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                        epochs=params['epochs'],\n",
        "                        batch_size=params['batch_size'],\n",
        "                        validation_data=(input_data_val, y_val),\n",
        "                        verbose=2, callbacks=[early_stopping],\n",
        "                        initial_epoch=int(params['epochs']*0.25))\n",
        "\n",
        "    # Record the final val_loss\n",
        "    final_val_losses.append(history.history['val_loss'][-1])\n",
        "\n",
        "# Train the NuSVR model\n",
        "Learning_Curve_train = np.array(val_losses_25pct)\n",
        "Model_Performance_train = np.array(final_val_losses)\n",
        "\n",
        "estimator = pretrain_Estimator(\n",
        "    Learning_Curve_train,\n",
        "    Model_Performance_train)\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBx_FmuzSBx_",
        "outputId": "20c221b0-31a4-4382-ada9-43fb057f0cb0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "52/52 - 0s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0033 - 202ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 202ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0016 - val_mse: 0.0033 - 199ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0020 - val_mse: 0.0040 - 205ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0016 - val_mse: 0.0032 - 203ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 201ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 207ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 200ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0033 - 200ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0016 - val_mse: 0.0033 - 203ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0016 - val_mse: 0.0033 - 200ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "52/52 - 0s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032 - 201ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032 - 202ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0035 - 201ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 201ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0017 - val_mse: 0.0033 - 202ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "52/52 - 0s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032 - 204ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032 - 200ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0033 - 203ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 200ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032 - 200ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "52/52 - 0s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0017 - val_mse: 0.0033 - 206ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0034 - 209ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "52/52 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0018 - val_mse: 0.0035 - 204ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 200ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 201ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0033 - 209ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "52/52 - 0s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0017 - val_mse: 0.0034 - 222ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 34 started****\n",
            "\n",
            "Epoch 1/50\n",
            "68/68 [==============================] - 2s 7ms/step - loss: 437.0059 - mse: 2500651.5000 - val_loss: 0.3878 - val_mse: 0.9693\n",
            "Epoch 2/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 159.9251 - mse: 317670.5938 - val_loss: 1.5883 - val_mse: 18.1333\n",
            "Epoch 3/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 70.2702 - mse: 64747.8281 - val_loss: 1.3257 - val_mse: 14.7397\n",
            "Epoch 4/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 30.1501 - mse: 11108.7764 - val_loss: 0.0378 - val_mse: 0.0793\n",
            "Epoch 5/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 15.1862 - mse: 3506.4512 - val_loss: 0.0933 - val_mse: 0.2472\n",
            "Epoch 6/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 6.1986 - mse: 498.9811 - val_loss: 0.0563 - val_mse: 0.1266\n",
            "Epoch 7/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.0353 - mse: 204.8492 - val_loss: 0.0246 - val_mse: 0.0541\n",
            "Epoch 8/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0541 - mse: 21.8286 - val_loss: 0.0074 - val_mse: 0.0149\n",
            "Epoch 9/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5290 - mse: 5.9219 - val_loss: 0.0051 - val_mse: 0.0102\n",
            "Epoch 10/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.6293 - mse: 10.5783 - val_loss: 0.0126 - val_mse: 0.0255\n",
            "Epoch 11/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.3560 - mse: 3.9944 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 12/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.3240 - mse: 3.2066 - val_loss: 0.0076 - val_mse: 0.0154\n",
            "Epoch 13/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.6152 - mse: 9.6626 - val_loss: 0.0110 - val_mse: 0.0223\n",
            "Epoch 14/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.3733 - mse: 3.6350 - val_loss: 0.0086 - val_mse: 0.0174\n",
            "Epoch 15/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1603 - mse: 0.8947 - val_loss: 0.0061 - val_mse: 0.0123\n",
            "Epoch 16/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1969 - mse: 1.4511 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 17/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1601 - mse: 1.3190 - val_loss: 0.0051 - val_mse: 0.0103\n",
            "Epoch 18/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1417 - mse: 0.9992 - val_loss: 0.0041 - val_mse: 0.0083\n",
            "Epoch 19/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0987 - mse: 0.4657 - val_loss: 0.0054 - val_mse: 0.0108\n",
            "Epoch 20/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1188 - mse: 0.7250 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 21/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1308 - mse: 0.7822 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 22/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1671 - mse: 0.9957 - val_loss: 0.0045 - val_mse: 0.0090\n",
            "Epoch 23/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.2160 - mse: 1.6450 - val_loss: 0.0150 - val_mse: 0.0315\n",
            "Epoch 24/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1327 - mse: 0.9649 - val_loss: 0.0037 - val_mse: 0.0075\n",
            "Epoch 25/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0827 - mse: 0.4456 - val_loss: 0.0035 - val_mse: 0.0071\n",
            "Epoch 26/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1513 - mse: 1.1192 - val_loss: 0.0034 - val_mse: 0.0067\n",
            "Epoch 27/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0994 - mse: 0.4855 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 28/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0724 - mse: 0.3149 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 29/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1761 - mse: 1.4411 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 30/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0744 - mse: 0.3424 - val_loss: 0.0068 - val_mse: 0.0137\n",
            "Epoch 31/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0554 - mse: 0.2264 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 32/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.1410 - mse: 0.9323 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 33/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0656 - mse: 0.3381 - val_loss: 0.0034 - val_mse: 0.0069\n",
            "Epoch 34/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0295 - mse: 0.0888 - val_loss: 0.0033 - val_mse: 0.0067\n",
            "Epoch 35/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0416 - mse: 0.1598 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 36/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0607 - val_loss: 0.0089 - val_mse: 0.0182\n",
            "Epoch 37/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0505 - mse: 0.2540 - val_loss: 0.0082 - val_mse: 0.0165\n",
            "Epoch 38/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0358 - mse: 0.1320 - val_loss: 0.0058 - val_mse: 0.0115\n",
            "Epoch 39/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0261 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 40/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0379 - mse: 0.1518 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 41/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0719 - mse: 0.3881 - val_loss: 0.1188 - val_mse: 0.3897\n",
            "Epoch 42/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.1631 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 43/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0029 - val_mse: 0.0058\n",
            "Epoch 44/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 45/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 46/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 47/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 48/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0061 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 49/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 50/50\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0024 - val_mse: 0.0047\n",
            "Epoch 51/200\n",
            "68/68 - 0s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0024 - val_mse: 0.0048 - 317ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "68/68 - 0s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0023 - val_mse: 0.0046 - 253ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "68/68 - 0s - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0023 - val_mse: 0.0046 - 256ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "68/68 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046 - 256ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0023 - val_mse: 0.0046 - 255ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "68/68 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0045 - 252ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0045 - 253ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044 - 251ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0021 - val_mse: 0.0042 - 255ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0022 - val_mse: 0.0044 - 250ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044 - 250ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0021 - val_mse: 0.0043 - 252ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0021 - val_mse: 0.0042 - 264ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0022 - val_mse: 0.0043 - 244ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0021 - val_mse: 0.0041 - 252ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0020 - val_mse: 0.0041 - 256ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0040 - 260ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0043 - 252ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0020 - val_mse: 0.0040 - 253ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0040 - 251ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0041 - 257ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 251ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0040 - 254ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 253ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0040 - 257ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0019 - val_mse: 0.0039 - 250ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042 - 252ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0039 - 258ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0039 - 264ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0039 - 254ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0040 - 254ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0039 - 259ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0040 - 260ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0042 - 261ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 261ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 252ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0021 - val_mse: 0.0042 - 255ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0039 - 249ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0040 - 251ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 249ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0039 - 250ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0046 - 252ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0020 - val_mse: 0.0040 - 251ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 254ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0019 - val_mse: 0.0039 - 247ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0040 - 248ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 251ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0020 - val_mse: 0.0041 - 251ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "68/68 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0019 - val_mse: 0.0038 - 249ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 250ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0039 - 247ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0021 - val_mse: 0.0042 - 248ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0039 - 254ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0019 - val_mse: 0.0038 - 254ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0039 - 257ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "68/68 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 257ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 253ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "68/68 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0032 - val_mse: 0.0065 - 258ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "68/68 - 0s - loss: 1.7008 - mse: 101.1689 - val_loss: 0.0097 - val_mse: 0.0195 - 252ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "68/68 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "68/68 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0082 - val_mse: 0.0166 - 257ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "68/68 - 0s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0176 - 262ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "68/68 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0081 - val_mse: 0.0163 - 259ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "68/68 - 0s - loss: 0.0082 - mse: 0.0166 - val_loss: 0.0072 - val_mse: 0.0146 - 252ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "68/68 - 0s - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0067 - val_mse: 0.0134 - 250ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "68/68 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0060 - val_mse: 0.0120 - 251ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "68/68 - 0s - loss: 0.0070 - mse: 0.0142 - val_loss: 0.0060 - val_mse: 0.0121 - 252ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "68/68 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0053 - val_mse: 0.0107 - 248ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "68/68 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0055 - val_mse: 0.0111 - 252ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "68/68 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0056 - val_mse: 0.0112 - 252ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "68/68 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0051 - val_mse: 0.0102 - 250ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "68/68 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0052 - val_mse: 0.0105 - 252ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "68/68 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0053 - val_mse: 0.0107 - 250ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "68/68 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0052 - val_mse: 0.0104 - 255ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "68/68 - 0s - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0054 - val_mse: 0.0109 - 258ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "68/68 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0059 - val_mse: 0.0119 - 257ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "68/68 - 0s - loss: 0.0064 - mse: 0.0130 - val_loss: 0.0053 - val_mse: 0.0105 - 261ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "68/68 - 0s - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0053 - val_mse: 0.0106 - 256ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "68/68 - 0s - loss: 0.0062 - mse: 0.0125 - val_loss: 0.0049 - val_mse: 0.0099 - 267ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 35 started****\n",
            "\n",
            "Epoch 1/50\n",
            "44/44 [==============================] - 2s 9ms/step - loss: 246.5913 - mse: 1088173.3750 - val_loss: 1.6109 - val_mse: 15.6158\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 15.2531 - mse: 3637.2795 - val_loss: 0.0329 - val_mse: 0.0675\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9554 - mse: 69.1773 - val_loss: 0.0510 - val_mse: 0.1186\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.4649 - mse: 6.7275 - val_loss: 0.0094 - val_mse: 0.0194\n",
            "Epoch 5/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.1310 - mse: 0.6886 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 6/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.1833 - mse: 1.2340 - val_loss: 0.0052 - val_mse: 0.0105\n",
            "Epoch 7/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0744 - mse: 0.3088 - val_loss: 0.0064 - val_mse: 0.0129\n",
            "Epoch 8/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.1689 - mse: 1.0681 - val_loss: 0.0259 - val_mse: 0.0588\n",
            "Epoch 9/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.1328 - mse: 0.7317 - val_loss: 0.0268 - val_mse: 0.0599\n",
            "Epoch 10/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0566 - mse: 0.2192 - val_loss: 0.0083 - val_mse: 0.0170\n",
            "Epoch 11/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0417 - mse: 0.1355 - val_loss: 0.0156 - val_mse: 0.0327\n",
            "Epoch 12/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0309 - mse: 0.1443 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 13/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0483 - val_loss: 0.0036 - val_mse: 0.0073\n",
            "Epoch 14/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0126 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 15/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0119 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 16/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0167 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 17/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 0.0121 - val_loss: 0.0040 - val_mse: 0.0081\n",
            "Epoch 18/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0103 - val_loss: 0.0029 - val_mse: 0.0059\n",
            "Epoch 19/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0109 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 20/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0029 - val_mse: 0.0059\n",
            "Epoch 21/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0029 - val_mse: 0.0058\n",
            "Epoch 22/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 23/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 24/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 25/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 26/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 27/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 28/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0027 - val_mse: 0.0055\n",
            "Epoch 29/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 30/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 31/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 32/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0063 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 33/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 34/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 35/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0061 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "Epoch 36/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0059 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "Epoch 37/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0049\n",
            "Epoch 38/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0023 - val_mse: 0.0047\n",
            "Epoch 39/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 40/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 41/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 42/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 43/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0022 - val_mse: 0.0045\n",
            "Epoch 44/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 45/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 46/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 47/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0021 - val_mse: 0.0043\n",
            "Epoch 48/50\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0045\n",
            "Epoch 49/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 50/50\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0021 - val_mse: 0.0043\n",
            "Epoch 51/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0021 - val_mse: 0.0042 - 251ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "44/44 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0044 - 185ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0021 - val_mse: 0.0041 - 178ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "44/44 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0021 - val_mse: 0.0042 - 175ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0041 - 180ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0021 - val_mse: 0.0041 - 176ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0041 - 176ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0040 - 178ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0040 - 176ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 177ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0042 - 179ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0041 - 176ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0041 - 175ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0041 - 179ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0040 - 176ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0025 - val_mse: 0.0049 - 177ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "44/44 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0020 - val_mse: 0.0040 - 175ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0039 - 180ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0040 - 181ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0039 - 177ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0040 - 174ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0039 - 178ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0039 - 177ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 178ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0021 - val_mse: 0.0043 - 174ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 176ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0039 - 174ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0040 - 177ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "44/44 - 0s - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0022 - val_mse: 0.0045 - 174ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0020 - val_mse: 0.0040 - 178ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0040 - 179ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0042 - 173ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0023 - val_mse: 0.0047 - 174ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0019 - val_mse: 0.0039 - 175ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0039 - 176ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0023 - val_mse: 0.0046 - 176ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0042 - 174ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 176ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0039 - 178ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0038 - 182ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0018 - val_mse: 0.0037 - 176ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0041 - 188ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "44/44 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0045 - 173ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "44/44 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0039 - 175ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0038 - 176ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0039 - 174ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0018 - val_mse: 0.0037 - 187ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "44/44 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0039 - 176ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "44/44 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0020 - val_mse: 0.0041 - 175ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "44/44 - 0s - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0028 - val_mse: 0.0056 - 176ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "44/44 - 0s - loss: 4.1517 - mse: 1157.6492 - val_loss: 0.0083 - val_mse: 0.0167 - 178ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "44/44 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0083 - val_mse: 0.0167 - 176ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0167 - 189ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0167 - 176ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0167 - 174ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 175ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 176ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0167 - 184ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 181ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 175ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 178ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 179ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 178ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0167 - 195ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 182ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 182ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 185ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 186ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 178ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 177ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 180ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0168 - 180ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "44/44 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 179ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 180ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 180ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 175ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "44/44 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 183ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 36 started****\n",
            "\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 3s 11ms/step - loss: 381.8831 - mse: 1625158.2500 - val_loss: 26.0594 - val_mse: 3575.5776\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 290.7170 - mse: 1041559.3125 - val_loss: 8.5603 - val_mse: 438.3653\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 224.6669 - mse: 688942.3125 - val_loss: 5.7507 - val_mse: 213.6511\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 183.2268 - mse: 411608.3125 - val_loss: 4.6561 - val_mse: 147.9493\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 140.1212 - mse: 204435.6875 - val_loss: 6.4679 - val_mse: 272.5792\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 118.0045 - mse: 165775.2500 - val_loss: 2.1645 - val_mse: 38.2632\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 101.0839 - mse: 121635.6641 - val_loss: 3.2286 - val_mse: 80.1948\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 88.2326 - mse: 114109.7500 - val_loss: 1.4573 - val_mse: 9.6407\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 73.7010 - mse: 62629.7500 - val_loss: 0.2984 - val_mse: 0.7066\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 64.6848 - mse: 57664.2188 - val_loss: 0.2175 - val_mse: 0.4878\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 55.8162 - mse: 41510.8867 - val_loss: 0.1931 - val_mse: 0.4215\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 45.8355 - mse: 23841.5215 - val_loss: 0.2779 - val_mse: 0.6466\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 42.3878 - mse: 20556.8945 - val_loss: 1.0646 - val_mse: 6.9406\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 38.4103 - mse: 18494.0664 - val_loss: 0.6151 - val_mse: 2.4438\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 33.5828 - mse: 15097.8965 - val_loss: 0.1640 - val_mse: 0.3493\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 29.8402 - mse: 11351.7031 - val_loss: 0.5876 - val_mse: 2.3025\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 26.7770 - mse: 9046.8076 - val_loss: 0.1807 - val_mse: 0.3865\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 23.2669 - mse: 6647.9536 - val_loss: 0.1707 - val_mse: 0.4047\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 20.0124 - mse: 4821.4126 - val_loss: 0.2159 - val_mse: 0.6098\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 17.9257 - mse: 4105.3706 - val_loss: 0.2403 - val_mse: 0.7409\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 18.0192 - mse: 4315.3652 - val_loss: 0.2355 - val_mse: 0.7169\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 14.9807 - mse: 2706.1868 - val_loss: 0.2321 - val_mse: 0.6961\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 13.7991 - mse: 2567.3125 - val_loss: 0.1589 - val_mse: 0.3584\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 13.2226 - mse: 2615.3025 - val_loss: 0.1714 - val_mse: 0.4057\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 11.4500 - mse: 2193.1169 - val_loss: 0.1825 - val_mse: 0.4583\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 10.2172 - mse: 1529.3173 - val_loss: 0.1917 - val_mse: 0.4995\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 9.4575 - mse: 1467.2734 - val_loss: 0.1650 - val_mse: 0.3949\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 7.9583 - mse: 846.2922 - val_loss: 0.1733 - val_mse: 0.4392\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 7.5675 - mse: 844.9821 - val_loss: 0.1775 - val_mse: 0.4643\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 7.2871 - mse: 833.6867 - val_loss: 0.1323 - val_mse: 0.2946\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 6.7220 - mse: 1294.7833 - val_loss: 0.1209 - val_mse: 0.2632\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 5.8857 - mse: 658.4045 - val_loss: 0.1278 - val_mse: 0.2880\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 5.2603 - mse: 443.8108 - val_loss: 0.1015 - val_mse: 0.2142\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4.7343 - mse: 345.3054 - val_loss: 0.0996 - val_mse: 0.2107\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 4.3895 - mse: 396.7489 - val_loss: 0.0817 - val_mse: 0.1696\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4.3461 - mse: 464.1524 - val_loss: 0.0720 - val_mse: 0.1490\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 3.8808 - mse: 330.9838 - val_loss: 0.0457 - val_mse: 0.0935\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 3.4342 - mse: 256.0308 - val_loss: 0.0137 - val_mse: 0.0275\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 3.0800 - mse: 194.7395 - val_loss: 0.0256 - val_mse: 0.0521\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2.8943 - mse: 285.8584 - val_loss: 0.0316 - val_mse: 0.0644\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2.7888 - mse: 274.0113 - val_loss: 0.0221 - val_mse: 0.0449\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2.4718 - mse: 191.8232 - val_loss: 0.0219 - val_mse: 0.0446\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2.1741 - mse: 131.9357 - val_loss: 0.0106 - val_mse: 0.0215\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.9741 - mse: 134.6454 - val_loss: 0.0078 - val_mse: 0.0156\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1.8268 - mse: 76.6722 - val_loss: 0.0075 - val_mse: 0.0151\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.7966 - mse: 100.7098 - val_loss: 0.0064 - val_mse: 0.0130\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.6148 - mse: 100.9858 - val_loss: 0.0069 - val_mse: 0.0138\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.4478 - mse: 82.1850 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1.3355 - mse: 63.5031 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1.3517 - mse: 62.6918 - val_loss: 0.0119 - val_mse: 0.0240\n",
            "Epoch 51/200\n",
            "37/37 - 0s - loss: 1.1112 - mse: 41.0385 - val_loss: 0.0079 - val_mse: 0.0159 - 245ms/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "37/37 - 0s - loss: 1.3521 - mse: 91.2370 - val_loss: 0.0043 - val_mse: 0.0086 - 182ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "37/37 - 0s - loss: 1.0289 - mse: 52.7050 - val_loss: 0.0067 - val_mse: 0.0134 - 179ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "37/37 - 0s - loss: 1.0368 - mse: 101.8671 - val_loss: 0.0046 - val_mse: 0.0093 - 181ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "37/37 - 0s - loss: 0.8779 - mse: 42.3096 - val_loss: 0.0062 - val_mse: 0.0124 - 190ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "37/37 - 0s - loss: 0.9500 - mse: 108.5515 - val_loss: 0.0043 - val_mse: 0.0087 - 178ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "37/37 - 0s - loss: 0.9734 - mse: 101.7927 - val_loss: 0.0070 - val_mse: 0.0140 - 176ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "37/37 - 0s - loss: 0.8100 - mse: 29.5772 - val_loss: 0.0079 - val_mse: 0.0159 - 178ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "37/37 - 0s - loss: 0.6583 - mse: 21.4479 - val_loss: 0.0040 - val_mse: 0.0079 - 184ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "37/37 - 0s - loss: 0.6704 - mse: 33.9739 - val_loss: 0.0035 - val_mse: 0.0070 - 183ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "37/37 - 0s - loss: 0.6198 - mse: 27.0306 - val_loss: 0.0046 - val_mse: 0.0092 - 185ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "37/37 - 0s - loss: 0.6339 - mse: 24.0405 - val_loss: 0.0034 - val_mse: 0.0068 - 182ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "37/37 - 0s - loss: 0.5606 - mse: 27.3893 - val_loss: 0.0076 - val_mse: 0.0153 - 180ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "37/37 - 0s - loss: 0.5760 - mse: 27.9403 - val_loss: 0.0040 - val_mse: 0.0080 - 178ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "37/37 - 0s - loss: 0.5431 - mse: 24.9858 - val_loss: 0.0055 - val_mse: 0.0110 - 176ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "37/37 - 0s - loss: 0.4680 - mse: 14.2061 - val_loss: 0.0037 - val_mse: 0.0074 - 185ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "37/37 - 0s - loss: 0.4546 - mse: 16.2781 - val_loss: 0.0039 - val_mse: 0.0079 - 174ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "37/37 - 0s - loss: 0.4962 - mse: 34.0762 - val_loss: 0.0050 - val_mse: 0.0100 - 174ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "37/37 - 0s - loss: 0.4375 - mse: 17.4163 - val_loss: 0.0039 - val_mse: 0.0078 - 172ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "37/37 - 0s - loss: 0.5617 - mse: 38.0323 - val_loss: 0.0060 - val_mse: 0.0121 - 174ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "37/37 - 0s - loss: 0.3852 - mse: 11.8275 - val_loss: 0.0041 - val_mse: 0.0082 - 175ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "37/37 - 0s - loss: 0.3780 - mse: 12.8423 - val_loss: 0.0040 - val_mse: 0.0080 - 174ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "37/37 - 0s - loss: 0.4080 - mse: 39.4690 - val_loss: 0.0040 - val_mse: 0.0080 - 172ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "37/37 - 0s - loss: 0.3085 - mse: 10.6946 - val_loss: 0.0052 - val_mse: 0.0104 - 176ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "37/37 - 0s - loss: 0.3945 - mse: 16.7851 - val_loss: 0.0075 - val_mse: 0.0152 - 176ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "37/37 - 0s - loss: 0.2608 - mse: 6.3483 - val_loss: 0.0048 - val_mse: 0.0097 - 175ms/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "37/37 - 0s - loss: 0.3372 - mse: 13.1928 - val_loss: 0.0074 - val_mse: 0.0150 - 176ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "37/37 - 0s - loss: 0.2758 - mse: 17.8173 - val_loss: 0.0069 - val_mse: 0.0138 - 176ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "37/37 - 0s - loss: 0.3436 - mse: 15.6470 - val_loss: 0.0083 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "37/37 - 0s - loss: 0.3003 - mse: 15.4675 - val_loss: 0.0073 - val_mse: 0.0148 - 175ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "37/37 - 0s - loss: 0.3240 - mse: 20.3459 - val_loss: 0.0051 - val_mse: 0.0103 - 172ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "37/37 - 0s - loss: 0.2563 - mse: 9.5093 - val_loss: 0.0040 - val_mse: 0.0080 - 176ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "37/37 - 0s - loss: 0.2028 - mse: 4.5092 - val_loss: 0.0051 - val_mse: 0.0102 - 178ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "37/37 - 0s - loss: 0.1986 - mse: 4.8879 - val_loss: 0.0040 - val_mse: 0.0080 - 171ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "37/37 - 0s - loss: 0.1999 - mse: 4.9872 - val_loss: 0.0044 - val_mse: 0.0089 - 173ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "37/37 - 0s - loss: 0.2145 - mse: 5.8647 - val_loss: 0.0038 - val_mse: 0.0077 - 176ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "37/37 - 0s - loss: 0.2235 - mse: 5.8851 - val_loss: 0.0040 - val_mse: 0.0080 - 175ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "37/37 - 0s - loss: 0.1647 - mse: 3.7432 - val_loss: 0.0043 - val_mse: 0.0086 - 174ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "37/37 - 0s - loss: 0.1790 - mse: 4.0171 - val_loss: 0.0038 - val_mse: 0.0077 - 174ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "37/37 - 0s - loss: 0.1705 - mse: 4.9982 - val_loss: 0.0050 - val_mse: 0.0101 - 170ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "37/37 - 0s - loss: 0.1893 - mse: 5.0348 - val_loss: 0.0049 - val_mse: 0.0098 - 174ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "37/37 - 0s - loss: 0.2030 - mse: 6.2177 - val_loss: 0.0059 - val_mse: 0.0119 - 187ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 37 started****\n",
            "\n",
            "Epoch 1/50\n",
            "39/39 [==============================] - 2s 9ms/step - loss: 133.7016 - mse: 248551.8906 - val_loss: 1.1090 - val_mse: 10.9645\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.3838 - mse: 24.7733 - val_loss: 0.2418 - val_mse: 0.6403\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.3036 - mse: 1.9416 - val_loss: 0.1678 - val_mse: 0.3595\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2136 - mse: 0.9933 - val_loss: 0.1403 - val_mse: 0.2973\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2165 - mse: 6.6105 - val_loss: 0.1231 - val_mse: 0.2586\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1382 - mse: 0.6498 - val_loss: 0.0934 - val_mse: 0.1945\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1248 - mse: 1.0954 - val_loss: 0.0729 - val_mse: 0.1507\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1125 - mse: 0.8180 - val_loss: 0.0564 - val_mse: 0.1160\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1261 - mse: 4.2830 - val_loss: 0.0474 - val_mse: 0.0970\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1191 - mse: 5.5408 - val_loss: 0.0340 - val_mse: 0.0693\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1613 - mse: 16.8000 - val_loss: 0.0261 - val_mse: 0.0530\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0679 - mse: 0.8719 - val_loss: 0.0206 - val_mse: 0.0418\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1086 - mse: 3.3198 - val_loss: 0.0166 - val_mse: 0.0335\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1238 - mse: 5.7377 - val_loss: 0.0137 - val_mse: 0.0276\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1201 - mse: 14.4593 - val_loss: 0.0116 - val_mse: 0.0234\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0508 - mse: 0.9860 - val_loss: 0.0099 - val_mse: 0.0200\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0586 - mse: 0.7568 - val_loss: 0.0094 - val_mse: 0.0189\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0496 - mse: 2.3565 - val_loss: 0.0081 - val_mse: 0.0162\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0654 - mse: 2.2542 - val_loss: 0.0075 - val_mse: 0.0151\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1130 - mse: 2.5700 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0410 - mse: 0.2896 - val_loss: 0.0073 - val_mse: 0.0148\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0729 - mse: 1.3292 - val_loss: 0.0071 - val_mse: 0.0143\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0687 - mse: 1.8927 - val_loss: 0.0081 - val_mse: 0.0163\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0630 - mse: 0.8560 - val_loss: 0.0078 - val_mse: 0.0158\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1139 - mse: 4.8253 - val_loss: 0.0061 - val_mse: 0.0123\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0928 - mse: 2.5593 - val_loss: 0.0078 - val_mse: 0.0156\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1190 - mse: 9.6664 - val_loss: 0.0076 - val_mse: 0.0152\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0676 - mse: 1.2486 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1256 - mse: 6.2479 - val_loss: 0.0071 - val_mse: 0.0143\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0460 - mse: 0.6151 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0568 - mse: 0.7115 - val_loss: 0.0091 - val_mse: 0.0187\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0527 - mse: 1.0230 - val_loss: 0.0066 - val_mse: 0.0132\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0925 - mse: 2.0521 - val_loss: 0.0072 - val_mse: 0.0146\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0709 - mse: 1.3163 - val_loss: 0.0095 - val_mse: 0.0193\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0857 - mse: 1.9326 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1152 - mse: 1.7008 - val_loss: 0.0055 - val_mse: 0.0110\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0834 - mse: 3.3958 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0385 - mse: 0.2615 - val_loss: 0.0047 - val_mse: 0.0093\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0651 - mse: 1.5906 - val_loss: 0.0066 - val_mse: 0.0134\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0741 - mse: 2.3992 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0446 - mse: 0.9643 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0706 - mse: 3.1621 - val_loss: 0.0065 - val_mse: 0.0131\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0682 - mse: 2.2160 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0655 - mse: 0.9274 - val_loss: 0.0050 - val_mse: 0.0101\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1084 - mse: 2.5039 - val_loss: 0.0364 - val_mse: 0.0871\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0950 - mse: 2.1545 - val_loss: 0.0071 - val_mse: 0.0143\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0367 - mse: 0.7506 - val_loss: 0.0072 - val_mse: 0.0146\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0849 - mse: 1.7438 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0587 - mse: 0.7111 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0730 - mse: 4.2604 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 51/200\n",
            "39/39 - 0s - loss: 0.0382 - mse: 1.2837 - val_loss: 0.0044 - val_mse: 0.0088 - 221ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "39/39 - 0s - loss: 0.0650 - mse: 1.7667 - val_loss: 0.0047 - val_mse: 0.0094 - 174ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "39/39 - 0s - loss: 0.1242 - mse: 3.4868 - val_loss: 0.0041 - val_mse: 0.0081 - 168ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "39/39 - 0s - loss: 0.1076 - mse: 2.4795 - val_loss: 0.0057 - val_mse: 0.0115 - 162ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "39/39 - 0s - loss: 0.1110 - mse: 9.6888 - val_loss: 0.0059 - val_mse: 0.0118 - 161ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "39/39 - 0s - loss: 0.0678 - mse: 1.5263 - val_loss: 0.0054 - val_mse: 0.0109 - 163ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "39/39 - 0s - loss: 0.0461 - mse: 0.4798 - val_loss: 0.0062 - val_mse: 0.0124 - 161ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "39/39 - 0s - loss: 0.1020 - mse: 3.8406 - val_loss: 0.0051 - val_mse: 0.0102 - 167ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "39/39 - 0s - loss: 0.0537 - mse: 0.6697 - val_loss: 0.0044 - val_mse: 0.0089 - 165ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "39/39 - 0s - loss: 0.0691 - mse: 0.8568 - val_loss: 0.0077 - val_mse: 0.0156 - 162ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "39/39 - 0s - loss: 0.0745 - mse: 1.4207 - val_loss: 0.0049 - val_mse: 0.0098 - 165ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "39/39 - 0s - loss: 0.1236 - mse: 3.8409 - val_loss: 0.0047 - val_mse: 0.0095 - 166ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "39/39 - 0s - loss: 0.1264 - mse: 2.8871 - val_loss: 0.0066 - val_mse: 0.0132 - 168ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "39/39 - 0s - loss: 0.0859 - mse: 1.4318 - val_loss: 0.0057 - val_mse: 0.0115 - 182ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "39/39 - 0s - loss: 0.1058 - mse: 2.3565 - val_loss: 0.0049 - val_mse: 0.0098 - 161ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "39/39 - 0s - loss: 0.0626 - mse: 0.5148 - val_loss: 0.0054 - val_mse: 0.0108 - 160ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "39/39 - 0s - loss: 0.1298 - mse: 17.2314 - val_loss: 0.0048 - val_mse: 0.0096 - 156ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "39/39 - 0s - loss: 0.0648 - mse: 0.6887 - val_loss: 0.0047 - val_mse: 0.0095 - 158ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "39/39 - 0s - loss: 0.0671 - mse: 0.8374 - val_loss: 0.0044 - val_mse: 0.0088 - 160ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "39/39 - 0s - loss: 0.0904 - mse: 2.9264 - val_loss: 0.0061 - val_mse: 0.0122 - 158ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "39/39 - 0s - loss: 0.0986 - mse: 1.5533 - val_loss: 0.0038 - val_mse: 0.0076 - 163ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "39/39 - 0s - loss: 0.0458 - mse: 0.6775 - val_loss: 0.0075 - val_mse: 0.0150 - 159ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "39/39 - 0s - loss: 0.0536 - mse: 0.7839 - val_loss: 0.0063 - val_mse: 0.0126 - 157ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "39/39 - 0s - loss: 0.0497 - mse: 0.3010 - val_loss: 0.0048 - val_mse: 0.0097 - 158ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "39/39 - 0s - loss: 0.0579 - mse: 0.6511 - val_loss: 0.0044 - val_mse: 0.0089 - 161ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "39/39 - 0s - loss: 0.2608 - mse: 11.4005 - val_loss: 0.0149 - val_mse: 0.0310 - 160ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "39/39 - 0s - loss: 0.0865 - mse: 1.1272 - val_loss: 0.0066 - val_mse: 0.0132 - 159ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "39/39 - 0s - loss: 0.0761 - mse: 0.9081 - val_loss: 0.0041 - val_mse: 0.0083 - 158ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "39/39 - 0s - loss: 0.0737 - mse: 0.7933 - val_loss: 0.0038 - val_mse: 0.0076 - 159ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "39/39 - 0s - loss: 0.0746 - mse: 1.0562 - val_loss: 0.0044 - val_mse: 0.0089 - 159ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "39/39 - 0s - loss: 0.0892 - mse: 2.0201 - val_loss: 0.0088 - val_mse: 0.0177 - 159ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "39/39 - 0s - loss: 0.0589 - mse: 0.7749 - val_loss: 0.0060 - val_mse: 0.0121 - 160ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "39/39 - 0s - loss: 0.1023 - mse: 7.7109 - val_loss: 0.0037 - val_mse: 0.0075 - 163ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "39/39 - 0s - loss: 0.0506 - mse: 0.4176 - val_loss: 0.0058 - val_mse: 0.0116 - 161ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "39/39 - 0s - loss: 0.0915 - mse: 1.2538 - val_loss: 0.0067 - val_mse: 0.0135 - 160ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "39/39 - 0s - loss: 0.0515 - mse: 0.7418 - val_loss: 0.0045 - val_mse: 0.0091 - 163ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "39/39 - 0s - loss: 0.0879 - mse: 5.9031 - val_loss: 0.0049 - val_mse: 0.0098 - 159ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "39/39 - 0s - loss: 0.1021 - mse: 4.0037 - val_loss: 0.0035 - val_mse: 0.0070 - 160ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "39/39 - 0s - loss: 0.1067 - mse: 4.2593 - val_loss: 0.0046 - val_mse: 0.0093 - 161ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "39/39 - 0s - loss: 0.1247 - mse: 7.5785 - val_loss: 0.0157 - val_mse: 0.0328 - 159ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "39/39 - 0s - loss: 0.1261 - mse: 6.2140 - val_loss: 0.0031 - val_mse: 0.0062 - 165ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "39/39 - 0s - loss: 0.1592 - mse: 4.7815 - val_loss: 0.0059 - val_mse: 0.0119 - 160ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "39/39 - 0s - loss: 0.1611 - mse: 7.1870 - val_loss: 0.0041 - val_mse: 0.0082 - 161ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "39/39 - 0s - loss: 0.1293 - mse: 1.5756 - val_loss: 0.0130 - val_mse: 0.0272 - 160ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "39/39 - 0s - loss: 0.0659 - mse: 0.9421 - val_loss: 0.0064 - val_mse: 0.0129 - 161ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "39/39 - 0s - loss: 0.0844 - mse: 3.2328 - val_loss: 0.0063 - val_mse: 0.0127 - 163ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "39/39 - 0s - loss: 0.0955 - mse: 1.3703 - val_loss: 0.0048 - val_mse: 0.0097 - 161ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "39/39 - 0s - loss: 0.0659 - mse: 0.5675 - val_loss: 0.0041 - val_mse: 0.0082 - 160ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "39/39 - 0s - loss: 0.0933 - mse: 2.8544 - val_loss: 0.0056 - val_mse: 0.0114 - 160ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "39/39 - 0s - loss: 0.1023 - mse: 2.3241 - val_loss: 0.0040 - val_mse: 0.0081 - 162ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "39/39 - 0s - loss: 0.0917 - mse: 3.6198 - val_loss: 0.0028 - val_mse: 0.0056 - 165ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "39/39 - 0s - loss: 0.0879 - mse: 2.8063 - val_loss: 0.0384 - val_mse: 0.0885 - 159ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "39/39 - 0s - loss: 0.0856 - mse: 4.0602 - val_loss: 0.0116 - val_mse: 0.0238 - 158ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "39/39 - 0s - loss: 0.0773 - mse: 1.2662 - val_loss: 0.0109 - val_mse: 0.0223 - 160ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "39/39 - 0s - loss: 0.0632 - mse: 1.9087 - val_loss: 0.0058 - val_mse: 0.0116 - 160ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "39/39 - 0s - loss: 0.1453 - mse: 2.4860 - val_loss: 0.0038 - val_mse: 0.0076 - 159ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "39/39 - 0s - loss: 0.0775 - mse: 1.5280 - val_loss: 0.0052 - val_mse: 0.0105 - 162ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "39/39 - 0s - loss: 0.1699 - mse: 20.4119 - val_loss: 0.0221 - val_mse: 0.0476 - 161ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "39/39 - 0s - loss: 0.1595 - mse: 4.3262 - val_loss: 0.0035 - val_mse: 0.0071 - 159ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "39/39 - 0s - loss: 0.0962 - mse: 1.8104 - val_loss: 0.0055 - val_mse: 0.0111 - 161ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "39/39 - 0s - loss: 0.1284 - mse: 5.1421 - val_loss: 0.0078 - val_mse: 0.0159 - 162ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "39/39 - 0s - loss: 0.0978 - mse: 2.2837 - val_loss: 0.0041 - val_mse: 0.0083 - 161ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "39/39 - 0s - loss: 0.0754 - mse: 1.1997 - val_loss: 0.0059 - val_mse: 0.0119 - 161ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "39/39 - 0s - loss: 0.0840 - mse: 1.5780 - val_loss: 0.0080 - val_mse: 0.0163 - 162ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "39/39 - 0s - loss: 0.0973 - mse: 1.0702 - val_loss: 0.0110 - val_mse: 0.0223 - 162ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "39/39 - 0s - loss: 0.0893 - mse: 2.3496 - val_loss: 0.0050 - val_mse: 0.0100 - 161ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "39/39 - 0s - loss: 0.0852 - mse: 0.8101 - val_loss: 0.0587 - val_mse: 0.1486 - 162ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "39/39 - 0s - loss: 0.1468 - mse: 2.8074 - val_loss: 0.0083 - val_mse: 0.0167 - 160ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "39/39 - 0s - loss: 0.0718 - mse: 0.6598 - val_loss: 0.0058 - val_mse: 0.0117 - 158ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "39/39 - 0s - loss: 0.0515 - mse: 0.6134 - val_loss: 0.0056 - val_mse: 0.0113 - 162ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "39/39 - 0s - loss: 0.0834 - mse: 6.2156 - val_loss: 0.0055 - val_mse: 0.0110 - 161ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "39/39 - 0s - loss: 0.1383 - mse: 5.2063 - val_loss: 0.0035 - val_mse: 0.0069 - 158ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "39/39 - 0s - loss: 0.0423 - mse: 0.2992 - val_loss: 0.0044 - val_mse: 0.0088 - 161ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "39/39 - 0s - loss: 0.0883 - mse: 1.2204 - val_loss: 0.0029 - val_mse: 0.0058 - 160ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "39/39 - 0s - loss: 0.1133 - mse: 4.0575 - val_loss: 0.0092 - val_mse: 0.0185 - 161ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "39/39 - 0s - loss: 0.0651 - mse: 0.6715 - val_loss: 0.0045 - val_mse: 0.0090 - 170ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "39/39 - 0s - loss: 0.0767 - mse: 2.9683 - val_loss: 0.0054 - val_mse: 0.0108 - 165ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "39/39 - 0s - loss: 0.0776 - mse: 0.9774 - val_loss: 0.0079 - val_mse: 0.0163 - 163ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "39/39 - 0s - loss: 0.0968 - mse: 6.9269 - val_loss: 0.0096 - val_mse: 0.0196 - 165ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "39/39 - 0s - loss: 0.0989 - mse: 3.3400 - val_loss: 0.0129 - val_mse: 0.0269 - 164ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "39/39 - 0s - loss: 0.1067 - mse: 1.9345 - val_loss: 0.0035 - val_mse: 0.0069 - 173ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 38 started****\n",
            "\n",
            "Epoch 1/50\n",
            "70/70 [==============================] - 4s 17ms/step - loss: 96.4927 - mse: 466960.0625 - val_loss: 0.4128 - val_mse: 0.1936\n",
            "Epoch 2/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.8423 - mse: 28.0985 - val_loss: 0.1019 - val_mse: 0.0153\n",
            "Epoch 3/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.3586 - mse: 9.9122 - val_loss: 0.0909 - val_mse: 0.0117\n",
            "Epoch 4/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.2465 - mse: 3.1873 - val_loss: 0.0952 - val_mse: 0.0126\n",
            "Epoch 5/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.2024 - mse: 2.3057 - val_loss: 0.1051 - val_mse: 0.0168\n",
            "Epoch 6/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1601 - mse: 1.1527 - val_loss: 0.1048 - val_mse: 0.0166\n",
            "Epoch 7/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1486 - mse: 2.3279 - val_loss: 0.0809 - val_mse: 0.0093\n",
            "Epoch 8/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1371 - mse: 0.6393 - val_loss: 0.0896 - val_mse: 0.0108\n",
            "Epoch 9/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1425 - mse: 1.7774 - val_loss: 0.1100 - val_mse: 0.0188\n",
            "Epoch 10/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1266 - mse: 0.3354 - val_loss: 0.1051 - val_mse: 0.0169\n",
            "Epoch 11/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1142 - mse: 0.0841 - val_loss: 0.1058 - val_mse: 0.0171\n",
            "Epoch 12/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1130 - mse: 0.0789 - val_loss: 0.0921 - val_mse: 0.0117\n",
            "Epoch 13/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1061 - mse: 0.0462 - val_loss: 0.0776 - val_mse: 0.0086\n",
            "Epoch 14/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1204 - mse: 0.1011 - val_loss: 0.1055 - val_mse: 0.0170\n",
            "Epoch 15/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1100 - mse: 0.2434 - val_loss: 0.1050 - val_mse: 0.0168\n",
            "Epoch 16/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1091 - mse: 0.1314 - val_loss: 0.0973 - val_mse: 0.0133\n",
            "Epoch 17/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0992 - mse: 0.0265 - val_loss: 0.0743 - val_mse: 0.0079\n",
            "Epoch 18/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1080 - mse: 0.0441 - val_loss: 0.0928 - val_mse: 0.0117\n",
            "Epoch 19/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1062 - mse: 0.1679 - val_loss: 0.0784 - val_mse: 0.0085\n",
            "Epoch 20/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0956 - mse: 0.0242 - val_loss: 0.0712 - val_mse: 0.0073\n",
            "Epoch 21/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0927 - mse: 0.0177 - val_loss: 0.0717 - val_mse: 0.0074\n",
            "Epoch 22/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0986 - mse: 0.1435 - val_loss: 0.0702 - val_mse: 0.0071\n",
            "Epoch 23/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1190 - mse: 0.0892 - val_loss: 0.0870 - val_mse: 0.0110\n",
            "Epoch 24/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0985 - mse: 0.0307 - val_loss: 0.0780 - val_mse: 0.0087\n",
            "Epoch 25/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0941 - mse: 0.0260 - val_loss: 0.0805 - val_mse: 0.0091\n",
            "Epoch 26/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0912 - mse: 0.0440 - val_loss: 0.0681 - val_mse: 0.0067\n",
            "Epoch 27/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1016 - mse: 0.6106 - val_loss: 0.0699 - val_mse: 0.0071\n",
            "Epoch 28/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0874 - mse: 0.0241 - val_loss: 0.0662 - val_mse: 0.0064\n",
            "Epoch 29/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0874 - mse: 0.0213 - val_loss: 0.0663 - val_mse: 0.0063\n",
            "Epoch 30/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0897 - mse: 0.0232 - val_loss: 0.0937 - val_mse: 0.0125\n",
            "Epoch 31/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1126 - mse: 0.0897 - val_loss: 0.0823 - val_mse: 0.0096\n",
            "Epoch 32/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0918 - mse: 0.0249 - val_loss: 0.0721 - val_mse: 0.0073\n",
            "Epoch 33/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0867 - mse: 0.0144 - val_loss: 0.0703 - val_mse: 0.0070\n",
            "Epoch 34/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0816 - mse: 0.0114 - val_loss: 0.0737 - val_mse: 0.0077\n",
            "Epoch 35/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0834 - mse: 0.0123 - val_loss: 0.0710 - val_mse: 0.0073\n",
            "Epoch 36/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0838 - mse: 0.0166 - val_loss: 0.0702 - val_mse: 0.0071\n",
            "Epoch 37/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0806 - mse: 0.0104 - val_loss: 0.0666 - val_mse: 0.0064\n",
            "Epoch 38/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0843 - mse: 0.0156 - val_loss: 0.0703 - val_mse: 0.0070\n",
            "Epoch 39/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0809 - mse: 0.0111 - val_loss: 0.0690 - val_mse: 0.0072\n",
            "Epoch 40/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0812 - mse: 0.0110 - val_loss: 0.0708 - val_mse: 0.0071\n",
            "Epoch 41/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0812 - mse: 0.0113 - val_loss: 0.0676 - val_mse: 0.0065\n",
            "Epoch 42/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0800 - mse: 0.0106 - val_loss: 0.0684 - val_mse: 0.0066\n",
            "Epoch 43/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0789 - mse: 0.0105 - val_loss: 0.0649 - val_mse: 0.0062\n",
            "Epoch 44/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0868 - mse: 0.0192 - val_loss: 0.0729 - val_mse: 0.0076\n",
            "Epoch 45/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0826 - mse: 0.0169 - val_loss: 0.0642 - val_mse: 0.0061\n",
            "Epoch 46/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0820 - mse: 0.0132 - val_loss: 0.0689 - val_mse: 0.0068\n",
            "Epoch 47/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0845 - mse: 0.0919 - val_loss: 0.0688 - val_mse: 0.0067\n",
            "Epoch 48/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0807 - mse: 0.0198 - val_loss: 0.0696 - val_mse: 0.0072\n",
            "Epoch 49/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0807 - mse: 0.0106 - val_loss: 0.0662 - val_mse: 0.0063\n",
            "Epoch 50/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0809 - mse: 0.0118 - val_loss: 0.0661 - val_mse: 0.0064\n",
            "Epoch 51/200\n",
            "70/70 - 0s - loss: 0.0800 - mse: 0.0108 - val_loss: 0.0673 - val_mse: 0.0065 - 387ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "70/70 - 0s - loss: 0.0809 - mse: 0.0108 - val_loss: 0.0732 - val_mse: 0.0078 - 304ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "70/70 - 0s - loss: 0.0808 - mse: 0.0115 - val_loss: 0.0658 - val_mse: 0.0062 - 308ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "70/70 - 0s - loss: 0.0791 - mse: 0.0099 - val_loss: 0.0635 - val_mse: 0.0060 - 320ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "70/70 - 0s - loss: 0.0813 - mse: 0.0128 - val_loss: 0.0690 - val_mse: 0.0070 - 305ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "70/70 - 0s - loss: 0.0812 - mse: 0.0112 - val_loss: 0.0731 - val_mse: 0.0078 - 312ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "70/70 - 0s - loss: 0.0799 - mse: 0.0103 - val_loss: 0.0700 - val_mse: 0.0071 - 324ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "70/70 - 0s - loss: 0.0824 - mse: 0.0210 - val_loss: 0.0685 - val_mse: 0.0067 - 310ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "70/70 - 0s - loss: 0.0785 - mse: 0.0104 - val_loss: 0.0681 - val_mse: 0.0067 - 315ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "70/70 - 0s - loss: 0.0780 - mse: 0.0097 - val_loss: 0.0644 - val_mse: 0.0062 - 318ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "70/70 - 0s - loss: 0.0782 - mse: 0.0104 - val_loss: 0.0654 - val_mse: 0.0062 - 318ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "70/70 - 0s - loss: 0.0797 - mse: 0.0229 - val_loss: 0.0661 - val_mse: 0.0064 - 306ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "70/70 - 0s - loss: 0.0789 - mse: 0.0101 - val_loss: 0.0644 - val_mse: 0.0061 - 316ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "70/70 - 0s - loss: 0.0792 - mse: 0.0099 - val_loss: 0.0623 - val_mse: 0.0057 - 301ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "70/70 - 0s - loss: 0.0773 - mse: 0.0101 - val_loss: 0.0706 - val_mse: 0.0074 - 303ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "70/70 - 0s - loss: 0.0764 - mse: 0.0095 - val_loss: 0.0625 - val_mse: 0.0058 - 303ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "70/70 - 0s - loss: 0.0783 - mse: 0.0234 - val_loss: 0.0643 - val_mse: 0.0059 - 305ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "70/70 - 0s - loss: 0.0760 - mse: 0.0096 - val_loss: 0.0600 - val_mse: 0.0054 - 304ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "70/70 - 0s - loss: 0.0774 - mse: 0.0099 - val_loss: 0.0712 - val_mse: 0.0072 - 304ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "70/70 - 0s - loss: 0.0790 - mse: 0.0101 - val_loss: 0.0619 - val_mse: 0.0057 - 303ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "70/70 - 0s - loss: 0.0797 - mse: 0.0189 - val_loss: 0.0661 - val_mse: 0.0063 - 301ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "70/70 - 0s - loss: 0.0795 - mse: 0.0103 - val_loss: 0.0652 - val_mse: 0.0061 - 304ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "70/70 - 0s - loss: 0.0772 - mse: 0.0098 - val_loss: 0.0629 - val_mse: 0.0058 - 306ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "70/70 - 0s - loss: 0.0768 - mse: 0.0094 - val_loss: 0.0692 - val_mse: 0.0071 - 301ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "70/70 - 0s - loss: 0.0788 - mse: 0.0158 - val_loss: 0.0789 - val_mse: 0.0090 - 304ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "70/70 - 0s - loss: 0.0820 - mse: 0.0127 - val_loss: 0.0766 - val_mse: 0.0084 - 306ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "70/70 - 0s - loss: 0.0844 - mse: 0.0140 - val_loss: 0.0651 - val_mse: 0.0061 - 305ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "70/70 - 0s - loss: 0.0904 - mse: 0.0953 - val_loss: 0.0703 - val_mse: 0.0072 - 304ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "70/70 - 0s - loss: 0.0864 - mse: 0.0119 - val_loss: 0.0691 - val_mse: 0.0069 - 302ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "70/70 - 0s - loss: 0.0853 - mse: 0.0115 - val_loss: 0.0716 - val_mse: 0.0073 - 305ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "70/70 - 0s - loss: 0.0855 - mse: 0.0117 - val_loss: 0.0677 - val_mse: 0.0065 - 307ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "70/70 - 0s - loss: 0.1375 - mse: 7.8603 - val_loss: 0.1050 - val_mse: 0.0169 - 305ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "70/70 - 0s - loss: 0.1154 - mse: 0.1505 - val_loss: 0.1024 - val_mse: 0.0159 - 305ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "70/70 - 0s - loss: 0.1057 - mse: 0.0358 - val_loss: 0.0935 - val_mse: 0.0130 - 303ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "70/70 - 0s - loss: 0.1037 - mse: 0.2181 - val_loss: 0.0942 - val_mse: 0.0127 - 302ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "70/70 - 0s - loss: 0.0969 - mse: 0.0148 - val_loss: 0.0894 - val_mse: 0.0117 - 304ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "70/70 - 0s - loss: 0.0974 - mse: 0.0146 - val_loss: 0.0854 - val_mse: 0.0108 - 303ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "70/70 - 0s - loss: 0.0985 - mse: 0.0533 - val_loss: 0.0957 - val_mse: 0.0134 - 301ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "70/70 - 0s - loss: 0.0959 - mse: 0.0155 - val_loss: 0.0817 - val_mse: 0.0100 - 304ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "70/70 - 0s - loss: 0.0904 - mse: 0.0125 - val_loss: 0.0717 - val_mse: 0.0079 - 302ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "70/70 - 0s - loss: 0.0964 - mse: 0.0154 - val_loss: 0.0872 - val_mse: 0.0117 - 299ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "70/70 - 0s - loss: 0.0960 - mse: 0.0152 - val_loss: 0.0784 - val_mse: 0.0093 - 305ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "70/70 - 0s - loss: 0.0982 - mse: 0.0222 - val_loss: 0.0980 - val_mse: 0.0142 - 306ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "70/70 - 0s - loss: 0.1005 - mse: 0.0188 - val_loss: 0.0959 - val_mse: 0.0137 - 312ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "70/70 - 0s - loss: 0.0968 - mse: 0.0143 - val_loss: 0.0790 - val_mse: 0.0094 - 312ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "70/70 - 0s - loss: 0.1749 - mse: 5.8317 - val_loss: 0.1051 - val_mse: 0.0168 - 319ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "70/70 - 0s - loss: 0.1110 - mse: 0.1037 - val_loss: 0.1047 - val_mse: 0.0167 - 321ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "70/70 - 0s - loss: 0.1072 - mse: 0.0178 - val_loss: 0.1047 - val_mse: 0.0167 - 328ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 39 started****\n",
            "\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 2s 6ms/step - loss: 1450.3955 - mse: 10979796.0000 - val_loss: 1293.0332 - val_mse: 8480450.0000\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1279.8186 - mse: 8889210.0000 - val_loss: 1118.3948 - val_mse: 6347675.0000\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1090.5013 - mse: 6465300.0000 - val_loss: 960.6985 - val_mse: 4686519.0000\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 921.5126 - mse: 4703557.5000 - val_loss: 815.6292 - val_mse: 3380262.0000\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 791.5624 - mse: 3508149.5000 - val_loss: 682.2479 - val_mse: 2367121.5000\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 649.5223 - mse: 2410170.5000 - val_loss: 559.0717 - val_mse: 1591256.5000\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 535.6209 - mse: 1775344.0000 - val_loss: 450.4719 - val_mse: 1034029.8125\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 442.5174 - mse: 1275771.2500 - val_loss: 349.4661 - val_mse: 623214.3125\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 362.3519 - mse: 865380.8750 - val_loss: 262.3275 - val_mse: 351992.9062\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 280.8684 - mse: 542098.2500 - val_loss: 189.7244 - val_mse: 184769.7500\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 237.9053 - mse: 399984.5938 - val_loss: 131.4924 - val_mse: 89243.8594\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 214.4810 - mse: 367674.1250 - val_loss: 84.1705 - val_mse: 36922.0508\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 189.6812 - mse: 284439.1562 - val_loss: 46.5464 - val_mse: 11518.3213\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 176.0104 - mse: 276477.7188 - val_loss: 18.3651 - val_mse: 1897.4595\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 168.4033 - mse: 250257.0156 - val_loss: 4.1924 - val_mse: 118.5866\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 167.9179 - mse: 270460.9688 - val_loss: 0.7175 - val_mse: 4.1369\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 153.7273 - mse: 236293.5312 - val_loss: 0.3559 - val_mse: 0.7118\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 152.9349 - mse: 205297.3125 - val_loss: 0.6335 - val_mse: 1.5763\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 155.2864 - mse: 249239.2812 - val_loss: 0.3480 - val_mse: 0.8348\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 147.0585 - mse: 222834.6875 - val_loss: 0.3007 - val_mse: 0.6042\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 140.7144 - mse: 182315.7969 - val_loss: 0.3804 - val_mse: 1.0277\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 138.4365 - mse: 183527.6719 - val_loss: 0.5837 - val_mse: 2.6903\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 134.0774 - mse: 181091.7812 - val_loss: 0.8417 - val_mse: 2.7517\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 122.6623 - mse: 136281.4219 - val_loss: 0.4030 - val_mse: 1.1816\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 119.0674 - mse: 132227.9219 - val_loss: 0.6582 - val_mse: 1.7095\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 110.9818 - mse: 113166.7969 - val_loss: 0.4395 - val_mse: 0.9010\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 104.9662 - mse: 95751.4297 - val_loss: 0.4841 - val_mse: 1.8021\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 102.0693 - mse: 118954.0078 - val_loss: 1.1101 - val_mse: 4.9600\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 93.4520 - mse: 82145.5469 - val_loss: 0.4899 - val_mse: 1.8596\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 92.8322 - mse: 95690.6094 - val_loss: 0.5080 - val_mse: 1.1117\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 81.3149 - mse: 68518.9375 - val_loss: 0.4246 - val_mse: 0.8668\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 73.3294 - mse: 52834.1250 - val_loss: 0.6127 - val_mse: 3.0440\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 67.0090 - mse: 47232.4180 - val_loss: 0.3350 - val_mse: 0.8040\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 64.6012 - mse: 44881.1641 - val_loss: 0.2859 - val_mse: 0.5722\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 53.8072 - mse: 30319.8672 - val_loss: 0.2867 - val_mse: 0.5734\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 48.0581 - mse: 31207.4844 - val_loss: 0.2919 - val_mse: 0.5837\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 40.1203 - mse: 18699.8262 - val_loss: 0.2797 - val_mse: 0.5603\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 36.0635 - mse: 16556.0488 - val_loss: 0.2825 - val_mse: 0.5651\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 27.3845 - mse: 8577.3525 - val_loss: 0.2849 - val_mse: 0.5913\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 22.6669 - mse: 7875.9409 - val_loss: 0.2953 - val_mse: 0.5906\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 19.1672 - mse: 5427.8853 - val_loss: 0.2742 - val_mse: 0.5484\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 17.0446 - mse: 4412.6216 - val_loss: 0.2931 - val_mse: 0.5861\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 15.6592 - mse: 4378.1436 - val_loss: 0.2907 - val_mse: 0.5814\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 14.5627 - mse: 3752.4075 - val_loss: 0.2690 - val_mse: 0.5380\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 13.9487 - mse: 2836.0708 - val_loss: 0.2471 - val_mse: 0.4942\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 14.0395 - mse: 2923.5471 - val_loss: 0.2378 - val_mse: 0.4756\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 15.0237 - mse: 4055.6213 - val_loss: 0.2221 - val_mse: 0.4441\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 14.0514 - mse: 3028.7520 - val_loss: 0.2189 - val_mse: 0.4378\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 14.8905 - mse: 4456.6260 - val_loss: 0.2078 - val_mse: 0.4157\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 14.5946 - mse: 3894.2456 - val_loss: 0.2226 - val_mse: 0.4452\n",
            "Epoch 51/200\n",
            "104/104 - 0s - loss: 14.0353 - mse: 3794.0010 - val_loss: 0.2167 - val_mse: 0.4334 - 458ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "104/104 - 0s - loss: 14.4052 - mse: 3584.8652 - val_loss: 0.2360 - val_mse: 0.4721 - 384ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "104/104 - 0s - loss: 14.6495 - mse: 4145.1611 - val_loss: 0.2056 - val_mse: 0.4112 - 383ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "104/104 - 0s - loss: 14.7665 - mse: 4146.5830 - val_loss: 0.1914 - val_mse: 0.3829 - 394ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "104/104 - 0s - loss: 14.0064 - mse: 3072.7354 - val_loss: 0.1894 - val_mse: 0.3787 - 385ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "104/104 - 0s - loss: 14.1328 - mse: 2991.0945 - val_loss: 0.2067 - val_mse: 0.4134 - 384ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "104/104 - 0s - loss: 14.0444 - mse: 3271.0366 - val_loss: 0.1998 - val_mse: 0.3995 - 382ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "104/104 - 0s - loss: 15.1581 - mse: 4002.3186 - val_loss: 0.1969 - val_mse: 0.3938 - 379ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "104/104 - 0s - loss: 14.4941 - mse: 3531.4534 - val_loss: 0.1942 - val_mse: 0.3883 - 381ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "104/104 - 0s - loss: 13.5810 - mse: 3165.5574 - val_loss: 0.2066 - val_mse: 0.4132 - 382ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "104/104 - 0s - loss: 13.9346 - mse: 3336.5647 - val_loss: 0.1944 - val_mse: 0.3889 - 379ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "104/104 - 0s - loss: 13.8100 - mse: 3737.4587 - val_loss: 0.1991 - val_mse: 0.3982 - 382ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "104/104 - 0s - loss: 13.8136 - mse: 3206.3608 - val_loss: 0.1819 - val_mse: 0.3639 - 389ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "104/104 - 0s - loss: 13.9494 - mse: 3951.2170 - val_loss: 0.1838 - val_mse: 0.3677 - 377ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "104/104 - 0s - loss: 14.1689 - mse: 3992.3948 - val_loss: 0.1703 - val_mse: 0.3405 - 379ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "104/104 - 0s - loss: 13.6314 - mse: 2839.1221 - val_loss: 0.1685 - val_mse: 0.3371 - 386ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "104/104 - 0s - loss: 14.0714 - mse: 3587.3298 - val_loss: 0.1725 - val_mse: 0.3450 - 380ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "104/104 - 0s - loss: 14.1671 - mse: 3903.7791 - val_loss: 0.1726 - val_mse: 0.3452 - 377ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "104/104 - 0s - loss: 13.4541 - mse: 2927.0215 - val_loss: 0.1782 - val_mse: 0.3564 - 377ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "104/104 - 0s - loss: 14.3305 - mse: 3996.8098 - val_loss: 0.1784 - val_mse: 0.3568 - 378ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "104/104 - 0s - loss: 14.2286 - mse: 3503.4812 - val_loss: 0.1716 - val_mse: 0.3432 - 380ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "104/104 - 0s - loss: 14.9219 - mse: 4278.1646 - val_loss: 0.1639 - val_mse: 0.3279 - 383ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "104/104 - 0s - loss: 14.1589 - mse: 3485.3135 - val_loss: 0.1606 - val_mse: 0.3212 - 384ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "104/104 - 0s - loss: 14.3276 - mse: 3873.8267 - val_loss: 0.1701 - val_mse: 0.3402 - 378ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "104/104 - 0s - loss: 13.9500 - mse: 2868.0623 - val_loss: 0.1719 - val_mse: 0.3438 - 380ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "104/104 - 0s - loss: 14.7492 - mse: 5191.2197 - val_loss: 0.1608 - val_mse: 0.3216 - 377ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "104/104 - 0s - loss: 14.2632 - mse: 4287.9492 - val_loss: 0.1544 - val_mse: 0.3089 - 386ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "104/104 - 0s - loss: 14.1267 - mse: 3480.2185 - val_loss: 0.1563 - val_mse: 0.3126 - 385ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "104/104 - 0s - loss: 14.3466 - mse: 3230.5413 - val_loss: 0.1535 - val_mse: 0.3070 - 390ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "104/104 - 0s - loss: 12.8463 - mse: 2580.9390 - val_loss: 0.1476 - val_mse: 0.2953 - 396ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "104/104 - 0s - loss: 15.5308 - mse: 5486.6958 - val_loss: 0.1545 - val_mse: 0.3091 - 397ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "104/104 - 0s - loss: 13.2262 - mse: 2642.9619 - val_loss: 0.1461 - val_mse: 0.2921 - 398ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "104/104 - 0s - loss: 13.4765 - mse: 2773.7212 - val_loss: 0.1483 - val_mse: 0.2967 - 383ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "104/104 - 0s - loss: 14.3066 - mse: 4179.2788 - val_loss: 0.1321 - val_mse: 0.2642 - 387ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "104/104 - 0s - loss: 14.6389 - mse: 4937.6592 - val_loss: 0.1327 - val_mse: 0.2653 - 381ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "104/104 - 0s - loss: 13.2531 - mse: 2785.6206 - val_loss: 0.1398 - val_mse: 0.2797 - 383ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "104/104 - 0s - loss: 14.3011 - mse: 3740.3428 - val_loss: 0.1202 - val_mse: 0.2403 - 389ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "104/104 - 0s - loss: 14.7721 - mse: 3918.1428 - val_loss: 0.1264 - val_mse: 0.2529 - 381ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "104/104 - 0s - loss: 14.3754 - mse: 4464.2769 - val_loss: 0.1179 - val_mse: 0.2358 - 383ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "104/104 - 0s - loss: 13.7408 - mse: 2883.4829 - val_loss: 0.1273 - val_mse: 0.2547 - 378ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "104/104 - 0s - loss: 13.7005 - mse: 3542.9329 - val_loss: 0.1246 - val_mse: 0.2492 - 392ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "104/104 - 0s - loss: 13.4987 - mse: 2962.2493 - val_loss: 0.1102 - val_mse: 0.2204 - 385ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "104/104 - 0s - loss: 13.0784 - mse: 2441.5007 - val_loss: 0.1250 - val_mse: 0.2499 - 386ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "104/104 - 0s - loss: 13.6040 - mse: 3294.2756 - val_loss: 0.1244 - val_mse: 0.2488 - 395ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "104/104 - 0s - loss: 13.5015 - mse: 2956.9038 - val_loss: 0.1224 - val_mse: 0.2449 - 384ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "104/104 - 0s - loss: 13.7539 - mse: 3524.3394 - val_loss: 0.1211 - val_mse: 0.2422 - 382ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "104/104 - 0s - loss: 13.1205 - mse: 3006.6614 - val_loss: 0.1185 - val_mse: 0.2370 - 392ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "104/104 - 0s - loss: 12.7733 - mse: 2527.1626 - val_loss: 0.1141 - val_mse: 0.2282 - 380ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "104/104 - 0s - loss: 15.0108 - mse: 4754.9248 - val_loss: 0.1120 - val_mse: 0.2239 - 386ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "104/104 - 0s - loss: 14.1629 - mse: 4452.6338 - val_loss: 0.1039 - val_mse: 0.2078 - 386ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "104/104 - 0s - loss: 12.8939 - mse: 2533.4009 - val_loss: 0.1096 - val_mse: 0.2193 - 383ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "104/104 - 0s - loss: 13.2309 - mse: 2654.2002 - val_loss: 0.1118 - val_mse: 0.2236 - 400ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "104/104 - 0s - loss: 13.1277 - mse: 2397.9556 - val_loss: 0.1060 - val_mse: 0.2120 - 381ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "104/104 - 0s - loss: 13.6964 - mse: 3027.0713 - val_loss: 0.0994 - val_mse: 0.1989 - 381ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "104/104 - 0s - loss: 13.0957 - mse: 6977.7158 - val_loss: 0.1052 - val_mse: 0.2104 - 379ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "104/104 - 0s - loss: 12.8362 - mse: 2500.3716 - val_loss: 0.0956 - val_mse: 0.1912 - 381ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "104/104 - 0s - loss: 13.2261 - mse: 3714.9668 - val_loss: 0.0974 - val_mse: 0.1949 - 379ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "104/104 - 0s - loss: 13.3459 - mse: 4482.7632 - val_loss: 0.0991 - val_mse: 0.1982 - 384ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "104/104 - 0s - loss: 13.2840 - mse: 3198.0491 - val_loss: 0.0931 - val_mse: 0.1861 - 395ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "104/104 - 0s - loss: 13.7014 - mse: 3615.2090 - val_loss: 0.1032 - val_mse: 0.2064 - 389ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "104/104 - 0s - loss: 13.5888 - mse: 2979.5432 - val_loss: 0.0887 - val_mse: 0.1774 - 388ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "104/104 - 0s - loss: 13.2546 - mse: 3176.1379 - val_loss: 0.0968 - val_mse: 0.1936 - 397ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "104/104 - 0s - loss: 13.6820 - mse: 3357.1191 - val_loss: 0.0913 - val_mse: 0.1827 - 395ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "104/104 - 0s - loss: 12.9802 - mse: 2279.8508 - val_loss: 0.0902 - val_mse: 0.1803 - 377ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "104/104 - 0s - loss: 13.5079 - mse: 3657.9873 - val_loss: 0.0815 - val_mse: 0.1629 - 383ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "104/104 - 0s - loss: 13.7614 - mse: 2808.4080 - val_loss: 0.0826 - val_mse: 0.1652 - 376ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "104/104 - 0s - loss: 12.5095 - mse: 2943.2048 - val_loss: 0.0899 - val_mse: 0.1799 - 378ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "104/104 - 0s - loss: 13.1910 - mse: 2662.9958 - val_loss: 0.0834 - val_mse: 0.1667 - 380ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "104/104 - 0s - loss: 13.2722 - mse: 3088.3933 - val_loss: 0.0876 - val_mse: 0.1753 - 379ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "104/104 - 0s - loss: 13.9398 - mse: 4255.4077 - val_loss: 0.0795 - val_mse: 0.1589 - 385ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "104/104 - 0s - loss: 12.9037 - mse: 2745.5452 - val_loss: 0.0757 - val_mse: 0.1515 - 383ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "104/104 - 0s - loss: 14.4849 - mse: 9404.9521 - val_loss: 0.0815 - val_mse: 0.1630 - 378ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "104/104 - 0s - loss: 13.0817 - mse: 3017.9199 - val_loss: 0.0762 - val_mse: 0.1524 - 380ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "104/104 - 0s - loss: 13.3802 - mse: 3101.3145 - val_loss: 0.0741 - val_mse: 0.1481 - 380ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "104/104 - 0s - loss: 14.3583 - mse: 5290.7207 - val_loss: 0.0710 - val_mse: 0.1421 - 383ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "104/104 - 0s - loss: 13.2482 - mse: 3037.9985 - val_loss: 0.0780 - val_mse: 0.1560 - 382ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "104/104 - 0s - loss: 13.2363 - mse: 2522.0901 - val_loss: 0.0749 - val_mse: 0.1499 - 377ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "104/104 - 0s - loss: 13.6346 - mse: 3310.7703 - val_loss: 0.0720 - val_mse: 0.1439 - 382ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "104/104 - 0s - loss: 12.7912 - mse: 3999.3193 - val_loss: 0.0618 - val_mse: 0.1236 - 385ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "104/104 - 0s - loss: 12.2209 - mse: 2261.2488 - val_loss: 0.0707 - val_mse: 0.1414 - 379ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "104/104 - 0s - loss: 14.1061 - mse: 3443.0396 - val_loss: 0.0685 - val_mse: 0.1370 - 382ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "104/104 - 0s - loss: 13.3231 - mse: 3118.1384 - val_loss: 0.0652 - val_mse: 0.1305 - 377ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "104/104 - 0s - loss: 12.7202 - mse: 2865.5730 - val_loss: 0.0625 - val_mse: 0.1249 - 385ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "104/104 - 0s - loss: 13.5746 - mse: 3077.2849 - val_loss: 0.0644 - val_mse: 0.1288 - 388ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "104/104 - 0s - loss: 13.2373 - mse: 3571.0723 - val_loss: 0.0615 - val_mse: 0.1229 - 384ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "104/104 - 0s - loss: 13.3716 - mse: 2954.8162 - val_loss: 0.0605 - val_mse: 0.1210 - 379ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "104/104 - 0s - loss: 13.4285 - mse: 3350.3396 - val_loss: 0.0613 - val_mse: 0.1226 - 378ms/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "104/104 - 0s - loss: 12.7516 - mse: 2992.0486 - val_loss: 0.0629 - val_mse: 0.1259 - 383ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "104/104 - 0s - loss: 13.4616 - mse: 3432.3403 - val_loss: 0.0616 - val_mse: 0.1232 - 394ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "104/104 - 0s - loss: 13.0906 - mse: 2820.2800 - val_loss: 0.0593 - val_mse: 0.1186 - 389ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "104/104 - 0s - loss: 12.6540 - mse: 2587.5981 - val_loss: 0.0625 - val_mse: 0.1250 - 385ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "104/104 - 0s - loss: 13.6669 - mse: 3010.1521 - val_loss: 0.0509 - val_mse: 0.1018 - 403ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "104/104 - 0s - loss: 13.3179 - mse: 3714.7410 - val_loss: 0.0664 - val_mse: 0.1328 - 399ms/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "104/104 - 0s - loss: 12.7671 - mse: 2623.8196 - val_loss: 0.0515 - val_mse: 0.1030 - 404ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "104/104 - 0s - loss: 12.9039 - mse: 3366.9507 - val_loss: 0.0495 - val_mse: 0.0990 - 382ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "104/104 - 0s - loss: 13.3279 - mse: 2657.8472 - val_loss: 0.0535 - val_mse: 0.1071 - 378ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "104/104 - 0s - loss: 13.3698 - mse: 3758.9709 - val_loss: 0.0519 - val_mse: 0.1038 - 381ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "104/104 - 0s - loss: 13.2308 - mse: 3048.7861 - val_loss: 0.0506 - val_mse: 0.1013 - 384ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "104/104 - 0s - loss: 13.0480 - mse: 3485.6816 - val_loss: 0.0497 - val_mse: 0.0994 - 390ms/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "104/104 - 0s - loss: 14.1549 - mse: 3501.3408 - val_loss: 0.0500 - val_mse: 0.1001 - 381ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "104/104 - 0s - loss: 13.8130 - mse: 3338.7832 - val_loss: 0.0456 - val_mse: 0.0913 - 380ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "104/104 - 0s - loss: 13.9984 - mse: 4808.3589 - val_loss: 0.0482 - val_mse: 0.0965 - 377ms/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "104/104 - 0s - loss: 13.4878 - mse: 4094.9626 - val_loss: 0.0447 - val_mse: 0.0894 - 382ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "104/104 - 0s - loss: 12.2610 - mse: 2379.2737 - val_loss: 0.0449 - val_mse: 0.0898 - 380ms/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "104/104 - 0s - loss: 13.7945 - mse: 4184.4873 - val_loss: 0.0439 - val_mse: 0.0878 - 383ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "104/104 - 0s - loss: 11.8834 - mse: 2024.6777 - val_loss: 0.0439 - val_mse: 0.0877 - 383ms/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "104/104 - 0s - loss: 12.2316 - mse: 2509.6040 - val_loss: 0.0408 - val_mse: 0.0815 - 387ms/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "104/104 - 0s - loss: 13.5679 - mse: 3252.8789 - val_loss: 0.0453 - val_mse: 0.0906 - 379ms/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "104/104 - 0s - loss: 12.8408 - mse: 3028.2830 - val_loss: 0.0499 - val_mse: 0.0999 - 382ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "104/104 - 0s - loss: 12.7348 - mse: 2554.2690 - val_loss: 0.0383 - val_mse: 0.0767 - 382ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "104/104 - 0s - loss: 12.9404 - mse: 2945.4639 - val_loss: 0.0373 - val_mse: 0.0745 - 384ms/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "104/104 - 0s - loss: 12.8754 - mse: 2824.6958 - val_loss: 0.0383 - val_mse: 0.0766 - 381ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "104/104 - 0s - loss: 13.0670 - mse: 2995.4011 - val_loss: 0.0351 - val_mse: 0.0703 - 382ms/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "104/104 - 0s - loss: 13.2996 - mse: 3626.0378 - val_loss: 0.0385 - val_mse: 0.0771 - 382ms/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "104/104 - 0s - loss: 13.1841 - mse: 2905.0950 - val_loss: 0.0348 - val_mse: 0.0696 - 385ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "104/104 - 0s - loss: 12.6706 - mse: 2563.5593 - val_loss: 0.0328 - val_mse: 0.0656 - 383ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "104/104 - 0s - loss: 13.4781 - mse: 3259.0569 - val_loss: 0.0320 - val_mse: 0.0640 - 383ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "104/104 - 0s - loss: 12.3553 - mse: 2711.6504 - val_loss: 0.0328 - val_mse: 0.0655 - 381ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "104/104 - 0s - loss: 11.6187 - mse: 1756.0515 - val_loss: 0.0327 - val_mse: 0.0653 - 383ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "104/104 - 0s - loss: 11.9604 - mse: 2006.4756 - val_loss: 0.0315 - val_mse: 0.0629 - 389ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "104/104 - 0s - loss: 12.9017 - mse: 3055.6067 - val_loss: 0.0383 - val_mse: 0.0765 - 390ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "104/104 - 0s - loss: 12.1979 - mse: 2058.5076 - val_loss: 0.0288 - val_mse: 0.0576 - 398ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "104/104 - 0s - loss: 13.5549 - mse: 3547.4111 - val_loss: 0.0285 - val_mse: 0.0569 - 390ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "104/104 - 0s - loss: 12.6018 - mse: 2670.0837 - val_loss: 0.0315 - val_mse: 0.0630 - 398ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "104/104 - 0s - loss: 12.4981 - mse: 2599.9692 - val_loss: 0.0278 - val_mse: 0.0555 - 398ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "104/104 - 0s - loss: 12.3642 - mse: 3009.0532 - val_loss: 0.0333 - val_mse: 0.0667 - 379ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "104/104 - 0s - loss: 10.9702 - mse: 1541.9927 - val_loss: 0.0289 - val_mse: 0.0577 - 376ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "104/104 - 0s - loss: 12.9752 - mse: 3839.4377 - val_loss: 0.0304 - val_mse: 0.0608 - 384ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "104/104 - 0s - loss: 13.1627 - mse: 3213.0820 - val_loss: 0.0250 - val_mse: 0.0501 - 386ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "104/104 - 0s - loss: 12.3677 - mse: 2806.2676 - val_loss: 0.0258 - val_mse: 0.0516 - 379ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "104/104 - 0s - loss: 12.4146 - mse: 3115.0930 - val_loss: 0.0293 - val_mse: 0.0586 - 389ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "104/104 - 0s - loss: 12.5898 - mse: 3103.7075 - val_loss: 0.0250 - val_mse: 0.0500 - 381ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "104/104 - 0s - loss: 13.0226 - mse: 3292.9907 - val_loss: 0.0251 - val_mse: 0.0503 - 379ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "104/104 - 0s - loss: 12.4619 - mse: 2456.8362 - val_loss: 0.0251 - val_mse: 0.0503 - 380ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "104/104 - 0s - loss: 12.5318 - mse: 2689.1724 - val_loss: 0.0239 - val_mse: 0.0478 - 383ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "104/104 - 0s - loss: 12.7651 - mse: 2903.4856 - val_loss: 0.0298 - val_mse: 0.0597 - 390ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "104/104 - 0s - loss: 13.2069 - mse: 4833.3540 - val_loss: 0.0220 - val_mse: 0.0441 - 382ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "104/104 - 0s - loss: 12.9332 - mse: 2826.7622 - val_loss: 0.0221 - val_mse: 0.0443 - 378ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "104/104 - 0s - loss: 12.4751 - mse: 2400.6948 - val_loss: 0.0261 - val_mse: 0.0522 - 386ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "104/104 - 0s - loss: 13.3363 - mse: 2868.3359 - val_loss: 0.0220 - val_mse: 0.0440 - 382ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "104/104 - 0s - loss: 12.4207 - mse: 2292.7300 - val_loss: 0.0205 - val_mse: 0.0410 - 379ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "104/104 - 0s - loss: 12.7772 - mse: 2569.4377 - val_loss: 0.0233 - val_mse: 0.0467 - 389ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "104/104 - 0s - loss: 12.4043 - mse: 2641.2102 - val_loss: 0.0203 - val_mse: 0.0406 - 386ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "104/104 - 0s - loss: 12.6242 - mse: 2779.6758 - val_loss: 0.0204 - val_mse: 0.0408 - 382ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "104/104 - 0s - loss: 12.0665 - mse: 2127.8887 - val_loss: 0.0204 - val_mse: 0.0408 - 381ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "104/104 - 0s - loss: 12.9701 - mse: 2914.9504 - val_loss: 0.0190 - val_mse: 0.0380 - 382ms/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "104/104 - 0s - loss: 12.7695 - mse: 3292.4609 - val_loss: 0.0182 - val_mse: 0.0365 - 399ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "104/104 - 0s - loss: 11.9714 - mse: 2639.6826 - val_loss: 0.0178 - val_mse: 0.0357 - 390ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "104/104 - 0s - loss: 11.8265 - mse: 2407.1509 - val_loss: 0.0176 - val_mse: 0.0351 - 387ms/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "104/104 - 0s - loss: 12.1345 - mse: 2702.3154 - val_loss: 0.0187 - val_mse: 0.0374 - 382ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 40 started****\n",
            "\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 7ms/step - loss: 1138.0977 - mse: 160422288.0000 - val_loss: 0.1169 - val_mse: 0.0201\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1207 - mse: 0.0223 - val_loss: 0.1348 - val_mse: 0.0288\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1138 - mse: 0.0199 - val_loss: 0.1057 - val_mse: 0.0171\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1066 - val_mse: 0.0175\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1050 - val_mse: 0.0167\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1058 - val_mse: 0.0172\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1054 - val_mse: 0.0170\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1052 - val_mse: 0.0169\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1054 - val_mse: 0.0168\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0168\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1058 - val_mse: 0.0172\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0167\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1061 - val_mse: 0.0170\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0167\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0168\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1056 - val_mse: 0.0171\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1078 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1073 - mse: 0.0174 - val_loss: 0.1055 - val_mse: 0.0169\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1049 - val_mse: 0.0167\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1049 - val_mse: 0.0167\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1082 - mse: 0.0177 - val_loss: 0.1059 - val_mse: 0.0170\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1061 - val_mse: 0.0173\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1087 - mse: 0.0179 - val_loss: 0.1094 - val_mse: 0.0179\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1062 - val_mse: 0.0173\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1082 - mse: 0.0177 - val_loss: 0.1055 - val_mse: 0.0170\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1078 - mse: 0.0176 - val_loss: 0.1065 - val_mse: 0.0171\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1089 - mse: 0.0180 - val_loss: 0.1050 - val_mse: 0.0167\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1084 - mse: 0.0178 - val_loss: 0.1060 - val_mse: 0.0172\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1056 - val_mse: 0.0169\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1060 - val_mse: 0.0172\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1087 - val_mse: 0.0183\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1081 - mse: 0.0178 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 0.1076 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0167\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1074 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1053 - val_mse: 0.0169\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1074 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1079 - mse: 0.0177 - val_loss: 0.1049 - val_mse: 0.0167\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1071 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1062 - val_mse: 0.0173\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1093 - val_mse: 0.0185\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1051 - val_mse: 0.0169\n",
            "Epoch 51/200\n",
            "67/67 - 0s - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1047 - val_mse: 0.0167 - 326ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "67/67 - 0s - loss: 0.1073 - mse: 0.0174 - val_loss: 0.1057 - val_mse: 0.0169 - 251ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "67/67 - 0s - loss: 0.1073 - mse: 0.0174 - val_loss: 0.1052 - val_mse: 0.0169 - 254ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "67/67 - 0s - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167 - 252ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "67/67 - 0s - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1056 - val_mse: 0.0169 - 250ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "67/67 - 0s - loss: 0.1073 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0167 - 250ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "67/67 - 0s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1054 - val_mse: 0.0170 - 251ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "67/67 - 0s - loss: 0.1087 - mse: 0.0180 - val_loss: 0.1058 - val_mse: 0.0171 - 252ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "67/67 - 0s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1114 - val_mse: 0.0185 - 250ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "67/67 - 0s - loss: 0.1098 - mse: 0.0183 - val_loss: 0.1052 - val_mse: 0.0169 - 250ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "67/67 - 0s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167 - 247ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "67/67 - 0s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1068 - val_mse: 0.0176 - 250ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "67/67 - 0s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1055 - val_mse: 0.0170 - 251ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "67/67 - 0s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1062 - val_mse: 0.0173 - 252ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "67/67 - 0s - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1050 - val_mse: 0.0167 - 250ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "67/67 - 0s - loss: 0.1076 - mse: 0.0176 - val_loss: 0.1048 - val_mse: 0.0167 - 248ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "67/67 - 0s - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1051 - val_mse: 0.0168 - 248ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "67/67 - 0s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0167 - 249ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "67/67 - 0s - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0167 - 248ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "67/67 - 0s - loss: 0.1078 - mse: 0.0177 - val_loss: 0.1051 - val_mse: 0.0168 - 247ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "67/67 - 0s - loss: 0.1073 - mse: 0.0174 - val_loss: 0.1051 - val_mse: 0.0168 - 249ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "67/67 - 0s - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1058 - val_mse: 0.0171 - 251ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "67/67 - 0s - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167 - 250ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "67/67 - 0s - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1174 - val_mse: 0.0202 - 253ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "67/67 - 0s - loss: 0.1084 - mse: 0.0177 - val_loss: 0.1060 - val_mse: 0.0172 - 251ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "67/67 - 0s - loss: 0.1075 - mse: 0.0175 - val_loss: 0.1069 - val_mse: 0.0176 - 253ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "67/67 - 0s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167 - 252ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "67/67 - 0s - loss: 0.1096 - mse: 0.0183 - val_loss: 0.1053 - val_mse: 0.0168 - 253ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "67/67 - 0s - loss: 0.1074 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0167 - 252ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "67/67 - 0s - loss: 0.1082 - mse: 0.0177 - val_loss: 0.1175 - val_mse: 0.0218 - 277ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "67/67 - 0s - loss: 0.1096 - mse: 0.0182 - val_loss: 0.1047 - val_mse: 0.0167 - 264ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 41 started****\n",
            "\n",
            "Epoch 1/50\n",
            "54/54 [==============================] - 2s 8ms/step - loss: 271.2125 - mse: 2487048.2500 - val_loss: 0.1591 - val_mse: 0.5263\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 3.9186 - mse: 486.3896 - val_loss: 0.4345 - val_mse: 2.1619\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.2208 - mse: 4.7451 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0600 - mse: 0.2026 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0346 - mse: 0.1321 - val_loss: 0.0052 - val_mse: 0.0106\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.1061 - val_loss: 0.0036 - val_mse: 0.0073\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0457 - val_loss: 0.0040 - val_mse: 0.0081\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0236 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0180 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.1144 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0269 - mse: 0.0833 - val_loss: 0.0062 - val_mse: 0.0127\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0454 - val_loss: 0.0035 - val_mse: 0.0069\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0089 - val_loss: 0.0034 - val_mse: 0.0068\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0470 - val_loss: 0.0083 - val_mse: 0.0168\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0279 - val_loss: 0.0033 - val_mse: 0.0067\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0075 - val_loss: 0.0030 - val_mse: 0.0059\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0071 - val_loss: 0.0029 - val_mse: 0.0059\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0029 - val_mse: 0.0058\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0027 - val_mse: 0.0055\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0063 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0063 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0061 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0027 - val_mse: 0.0053\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0026 - val_mse: 0.0051\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0059 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 51/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0025 - val_mse: 0.0049 - 267ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0024 - val_mse: 0.0049 - 213ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0055 - val_loss: 0.0024 - val_mse: 0.0047 - 213ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0024 - val_mse: 0.0047 - 210ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0024 - val_mse: 0.0047 - 207ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0047 - 209ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0023 - val_mse: 0.0047 - 211ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0047 - 208ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0047 - 207ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0047 - 207ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0046 - 207ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0023 - val_mse: 0.0045 - 209ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0045 - 210ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0045 - 211ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0023 - val_mse: 0.0046 - 208ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "54/54 - 0s - loss: 0.0027 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0046 - 204ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0045 - 210ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0047 - 207ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0045 - 210ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0023 - val_mse: 0.0045 - 207ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0024 - val_mse: 0.0048 - 208ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0023 - val_mse: 0.0046 - 209ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 213ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 211ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0023 - val_mse: 0.0045 - 208ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 209ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 209ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0043 - 211ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0045 - 206ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044 - 206ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0023 - val_mse: 0.0047 - 209ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0044 - 207ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0045 - 207ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0044 - 209ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0022 - val_mse: 0.0044 - 206ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0023 - val_mse: 0.0045 - 206ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0021 - val_mse: 0.0043 - 210ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0044 - 206ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0043 - 209ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0044 - 206ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0043 - 215ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0023 - val_mse: 0.0046 - 207ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0043 - 208ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042 - 213ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042 - 218ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0022 - val_mse: 0.0043 - 218ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0022 - val_mse: 0.0044 - 214ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0043 - 215ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0043 - 215ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0022 - val_mse: 0.0045 - 226ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0041 - 221ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0021 - val_mse: 0.0041 - 216ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0042 - 216ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0041 - 210ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042 - 219ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042 - 207ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0042 - 207ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0022 - val_mse: 0.0044 - 207ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0042 - 206ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0041 - 223ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0041 - 209ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0040 - 210ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0041 - 206ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0039 - 211ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0021 - val_mse: 0.0042 - 208ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0041 - 209ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0023 - val_mse: 0.0046 - 208ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0040 - 206ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0020 - val_mse: 0.0040 - 225ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0022 - val_mse: 0.0044 - 210ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0040 - 208ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0039 - 208ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0041 - 207ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0039 - 211ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0039 - 206ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0039 - 210ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0039 - 207ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0021 - val_mse: 0.0041 - 206ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0039 - 209ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0038 - 208ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0022 - val_mse: 0.0044 - 206ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0020 - val_mse: 0.0040 - 209ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0038 - 207ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0021 - val_mse: 0.0042 - 211ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0020 - val_mse: 0.0039 - 205ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0037 - 209ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0039 - 206ms/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0018 - val_mse: 0.0037 - 212ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0038 - 210ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0020 - val_mse: 0.0041 - 208ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0024 - val_mse: 0.0047 - 207ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0025 - val_mse: 0.0050 - 210ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0038 - 207ms/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0020 - val_mse: 0.0039 - 211ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0023 - val_mse: 0.0046 - 206ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0039 - 206ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0038 - 211ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0021 - val_mse: 0.0042 - 209ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0037 - 207ms/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0035 - 209ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0019 - val_mse: 0.0038 - 216ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0036 - 213ms/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 213ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0037 - 219ms/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0039 - 215ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0019 - val_mse: 0.0038 - 216ms/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0034 - 216ms/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0020 - val_mse: 0.0040 - 218ms/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "54/54 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0031 - val_mse: 0.0063 - 218ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0018 - val_mse: 0.0036 - 214ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0041 - 208ms/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0036 - 209ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 208ms/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0019 - val_mse: 0.0037 - 210ms/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0035 - 211ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0036 - 209ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0037 - 208ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0034 - 207ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0017 - val_mse: 0.0035 - 206ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0017 - val_mse: 0.0034 - 207ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0019 - val_mse: 0.0038 - 206ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0035 - 209ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 206ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "54/54 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0019 - val_mse: 0.0038 - 209ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0019 - val_mse: 0.0039 - 208ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0034 - 210ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0037 - 215ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0034 - 210ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 208ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0039 - 206ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0017 - val_mse: 0.0033 - 209ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0034 - 211ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0018 - val_mse: 0.0035 - 208ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0018 - val_mse: 0.0036 - 211ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0018 - val_mse: 0.0036 - 208ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0034 - 222ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "54/54 - 0s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0018 - val_mse: 0.0036 - 207ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 208ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0036 - 208ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0018 - val_mse: 0.0036 - 207ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0019 - val_mse: 0.0038 - 220ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0035 - 209ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0020 - val_mse: 0.0040 - 208ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "54/54 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0037 - 210ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "54/54 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0041 - 231ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "54/54 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0017 - val_mse: 0.0034 - 254ms/epoch - 5ms/step\n",
            "Epoch 197/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0020 - val_mse: 0.0041 - 224ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0038 - 226ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0034 - 219ms/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "54/54 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0016 - val_mse: 0.0033 - 224ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 42 started****\n",
            "\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - 3s 11ms/step - loss: 123.2235 - mse: 185963.2344 - val_loss: 5.7122 - val_mse: 202.2830\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 95.1988 - mse: 124927.0156 - val_loss: 1.2440 - val_mse: 2.3403\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 77.0603 - mse: 72216.1875 - val_loss: 1.2196 - val_mse: 1.9243\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 69.1880 - mse: 55535.4844 - val_loss: 0.5615 - val_mse: 0.4547\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 56.3903 - mse: 33310.0938 - val_loss: 1.4951 - val_mse: 11.5591\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 51.7259 - mse: 33684.6250 - val_loss: 1.6391 - val_mse: 14.4487\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 44.0852 - mse: 20867.9355 - val_loss: 1.1321 - val_mse: 5.6694\n",
            "Epoch 8/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 39.9884 - mse: 16328.7471 - val_loss: 0.4897 - val_mse: 0.2631\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 35.7479 - mse: 16703.8711 - val_loss: 0.6148 - val_mse: 0.3906\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 32.8920 - mse: 13527.2822 - val_loss: 1.0004 - val_mse: 1.7743\n",
            "Epoch 11/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 29.7001 - mse: 10130.2930 - val_loss: 0.5540 - val_mse: 0.6231\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 26.7798 - mse: 9485.3682 - val_loss: 0.3924 - val_mse: 0.2339\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 24.1715 - mse: 7173.9985 - val_loss: 0.6294 - val_mse: 0.5035\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 22.8197 - mse: 6737.7544 - val_loss: 0.5123 - val_mse: 0.2906\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 20.5084 - mse: 5327.2461 - val_loss: 1.0262 - val_mse: 2.1288\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 18.4386 - mse: 4288.4639 - val_loss: 0.4079 - val_mse: 0.1762\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 16.8086 - mse: 3374.9148 - val_loss: 0.6313 - val_mse: 1.5298\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 15.2976 - mse: 2691.5154 - val_loss: 0.3891 - val_mse: 0.3286\n",
            "Epoch 19/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 14.0938 - mse: 2232.7678 - val_loss: 0.3163 - val_mse: 0.1444\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 13.2133 - mse: 2136.2998 - val_loss: 0.4496 - val_mse: 0.5891\n",
            "Epoch 21/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 12.6834 - mse: 2036.5166 - val_loss: 0.3142 - val_mse: 0.1493\n",
            "Epoch 22/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 12.0842 - mse: 1723.7114 - val_loss: 1.1787 - val_mse: 4.2535\n",
            "Epoch 23/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 10.8295 - mse: 1428.9625 - val_loss: 0.2806 - val_mse: 0.1060\n",
            "Epoch 24/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 9.9941 - mse: 1278.2893 - val_loss: 0.3078 - val_mse: 0.1647\n",
            "Epoch 25/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 8.9890 - mse: 1196.5248 - val_loss: 0.5637 - val_mse: 0.5936\n",
            "Epoch 26/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 8.7944 - mse: 902.1198 - val_loss: 0.4454 - val_mse: 0.6455\n",
            "Epoch 27/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 8.3851 - mse: 817.5755 - val_loss: 0.6275 - val_mse: 0.8167\n",
            "Epoch 28/50\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 7.5727 - mse: 629.4452 - val_loss: 0.6481 - val_mse: 0.9196\n",
            "Epoch 29/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 7.1000 - mse: 565.9124 - val_loss: 1.1333 - val_mse: 4.1739\n",
            "Epoch 30/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 6.9006 - mse: 599.4019 - val_loss: 0.2960 - val_mse: 0.1155\n",
            "Epoch 31/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 6.7425 - mse: 650.5208 - val_loss: 0.6858 - val_mse: 1.1159\n",
            "Epoch 32/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 5.8643 - mse: 387.5916 - val_loss: 0.9825 - val_mse: 2.8329\n",
            "Epoch 33/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 5.6191 - mse: 370.8495 - val_loss: 0.8682 - val_mse: 2.0261\n",
            "Epoch 34/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 5.5202 - mse: 404.9645 - val_loss: 0.9378 - val_mse: 2.4490\n",
            "Epoch 35/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 5.0993 - mse: 331.1016 - val_loss: 0.9658 - val_mse: 2.6976\n",
            "Epoch 36/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 4.9207 - mse: 332.2370 - val_loss: 0.3331 - val_mse: 0.1241\n",
            "Epoch 37/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 4.3014 - mse: 223.8098 - val_loss: 0.6162 - val_mse: 0.7838\n",
            "Epoch 38/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 4.0910 - mse: 187.2015 - val_loss: 0.6537 - val_mse: 0.9233\n",
            "Epoch 39/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 3.9151 - mse: 198.5943 - val_loss: 0.5346 - val_mse: 0.5264\n",
            "Epoch 40/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 3.7930 - mse: 206.8533 - val_loss: 0.4879 - val_mse: 0.3934\n",
            "Epoch 41/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 3.4045 - mse: 141.8410 - val_loss: 0.3327 - val_mse: 0.1329\n",
            "Epoch 42/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 3.1963 - mse: 142.0217 - val_loss: 0.4514 - val_mse: 0.3878\n",
            "Epoch 43/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 3.0401 - mse: 123.8918 - val_loss: 0.3289 - val_mse: 0.1364\n",
            "Epoch 44/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.8283 - mse: 104.0876 - val_loss: 0.2627 - val_mse: 0.0930\n",
            "Epoch 45/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.7612 - mse: 129.0861 - val_loss: 0.2124 - val_mse: 0.0605\n",
            "Epoch 46/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.5293 - mse: 71.5037 - val_loss: 0.1641 - val_mse: 0.0394\n",
            "Epoch 47/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.5322 - mse: 82.6831 - val_loss: 0.2372 - val_mse: 0.0749\n",
            "Epoch 48/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.3104 - mse: 72.1380 - val_loss: 0.1357 - val_mse: 0.0280\n",
            "Epoch 49/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.9757 - mse: 41.2421 - val_loss: 0.0954 - val_mse: 0.0146\n",
            "Epoch 50/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.1053 - mse: 60.2736 - val_loss: 0.1535 - val_mse: 0.0356\n",
            "Epoch 51/200\n",
            "35/35 - 0s - loss: 1.8917 - mse: 44.6235 - val_loss: 0.0781 - val_mse: 0.0103 - 230ms/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "35/35 - 0s - loss: 1.8175 - mse: 48.3069 - val_loss: 0.1495 - val_mse: 0.0337 - 165ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "35/35 - 0s - loss: 1.5985 - mse: 28.8033 - val_loss: 0.0852 - val_mse: 0.0121 - 165ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "35/35 - 0s - loss: 1.5539 - mse: 35.9671 - val_loss: 0.0834 - val_mse: 0.0114 - 167ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "35/35 - 0s - loss: 1.4672 - mse: 35.1876 - val_loss: 0.0811 - val_mse: 0.0114 - 188ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "35/35 - 0s - loss: 1.3982 - mse: 28.7709 - val_loss: 0.1030 - val_mse: 0.0160 - 169ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "35/35 - 0s - loss: 1.2315 - mse: 20.8033 - val_loss: 0.1151 - val_mse: 0.0208 - 166ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "35/35 - 0s - loss: 1.3467 - mse: 36.3053 - val_loss: 0.1029 - val_mse: 0.0165 - 169ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "35/35 - 0s - loss: 1.2229 - mse: 19.4173 - val_loss: 0.1022 - val_mse: 0.0154 - 169ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "35/35 - 0s - loss: 1.0746 - mse: 17.3469 - val_loss: 0.0995 - val_mse: 0.0152 - 171ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "35/35 - 0s - loss: 1.0282 - mse: 15.2284 - val_loss: 0.0778 - val_mse: 0.0093 - 176ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "35/35 - 0s - loss: 0.9712 - mse: 14.1761 - val_loss: 0.1174 - val_mse: 0.0209 - 171ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "35/35 - 0s - loss: 0.8932 - mse: 12.6702 - val_loss: 0.0972 - val_mse: 0.0136 - 172ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "35/35 - 0s - loss: 0.8466 - mse: 13.0141 - val_loss: 0.0835 - val_mse: 0.0102 - 173ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "35/35 - 0s - loss: 0.7520 - mse: 9.3562 - val_loss: 0.1209 - val_mse: 0.0214 - 176ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "35/35 - 0s - loss: 0.7194 - mse: 8.5632 - val_loss: 0.0808 - val_mse: 0.0093 - 184ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "35/35 - 0s - loss: 0.6735 - mse: 8.3469 - val_loss: 0.0803 - val_mse: 0.0093 - 167ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "35/35 - 0s - loss: 0.6207 - mse: 5.9433 - val_loss: 0.1179 - val_mse: 0.0202 - 165ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "35/35 - 0s - loss: 0.5879 - mse: 5.2395 - val_loss: 0.1021 - val_mse: 0.0143 - 164ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "35/35 - 0s - loss: 0.5588 - mse: 4.6036 - val_loss: 0.1180 - val_mse: 0.0205 - 168ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "35/35 - 0s - loss: 0.5280 - mse: 4.9607 - val_loss: 0.0795 - val_mse: 0.0090 - 168ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "35/35 - 0s - loss: 0.5122 - mse: 4.2465 - val_loss: 0.0740 - val_mse: 0.0078 - 191ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "35/35 - 0s - loss: 0.4555 - mse: 3.4410 - val_loss: 0.0994 - val_mse: 0.0135 - 170ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "35/35 - 0s - loss: 0.4423 - mse: 5.3681 - val_loss: 0.0783 - val_mse: 0.0086 - 165ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "35/35 - 0s - loss: 0.3858 - mse: 2.5832 - val_loss: 0.0806 - val_mse: 0.0091 - 166ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "35/35 - 0s - loss: 0.3498 - mse: 1.7986 - val_loss: 0.0774 - val_mse: 0.0084 - 167ms/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "35/35 - 0s - loss: 0.3849 - mse: 2.9538 - val_loss: 0.0740 - val_mse: 0.0077 - 168ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "35/35 - 0s - loss: 0.3494 - mse: 2.4556 - val_loss: 0.0878 - val_mse: 0.0102 - 179ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "35/35 - 0s - loss: 0.3357 - mse: 2.5874 - val_loss: 0.0721 - val_mse: 0.0073 - 168ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "35/35 - 0s - loss: 0.3186 - mse: 1.7704 - val_loss: 0.1033 - val_mse: 0.0151 - 163ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "35/35 - 0s - loss: 0.3344 - mse: 3.7689 - val_loss: 0.0734 - val_mse: 0.0075 - 164ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "35/35 - 0s - loss: 0.2506 - mse: 0.8204 - val_loss: 0.0702 - val_mse: 0.0069 - 167ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "35/35 - 0s - loss: 0.2503 - mse: 0.9658 - val_loss: 0.0724 - val_mse: 0.0073 - 163ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "35/35 - 0s - loss: 0.2650 - mse: 1.7305 - val_loss: 0.0752 - val_mse: 0.0079 - 170ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "35/35 - 0s - loss: 0.2403 - mse: 1.2319 - val_loss: 0.0682 - val_mse: 0.0065 - 166ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "35/35 - 0s - loss: 0.2238 - mse: 1.1866 - val_loss: 0.0682 - val_mse: 0.0065 - 162ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "35/35 - 0s - loss: 0.2122 - mse: 1.0965 - val_loss: 0.0687 - val_mse: 0.0066 - 163ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "35/35 - 0s - loss: 0.2054 - mse: 0.6554 - val_loss: 0.0671 - val_mse: 0.0064 - 165ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "35/35 - 0s - loss: 0.1951 - mse: 0.9741 - val_loss: 0.0681 - val_mse: 0.0065 - 163ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "35/35 - 0s - loss: 0.1895 - mse: 0.7034 - val_loss: 0.0683 - val_mse: 0.0066 - 180ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "35/35 - 0s - loss: 0.1897 - mse: 1.8015 - val_loss: 0.0663 - val_mse: 0.0063 - 167ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "35/35 - 0s - loss: 0.1708 - mse: 0.5241 - val_loss: 0.0647 - val_mse: 0.0060 - 167ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "35/35 - 0s - loss: 0.1765 - mse: 0.7728 - val_loss: 0.0690 - val_mse: 0.0067 - 165ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "35/35 - 0s - loss: 0.1772 - mse: 1.4010 - val_loss: 0.0654 - val_mse: 0.0061 - 163ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "35/35 - 0s - loss: 0.1630 - mse: 0.8921 - val_loss: 0.0635 - val_mse: 0.0059 - 167ms/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "35/35 - 0s - loss: 0.1572 - mse: 0.6225 - val_loss: 0.0657 - val_mse: 0.0062 - 168ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "35/35 - 0s - loss: 0.1409 - mse: 0.2709 - val_loss: 0.0645 - val_mse: 0.0060 - 163ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "35/35 - 0s - loss: 0.1432 - mse: 0.2900 - val_loss: 0.0642 - val_mse: 0.0060 - 163ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "35/35 - 0s - loss: 0.1355 - mse: 0.4260 - val_loss: 0.0706 - val_mse: 0.0070 - 166ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "35/35 - 0s - loss: 0.1404 - mse: 0.3585 - val_loss: 0.0625 - val_mse: 0.0058 - 167ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "35/35 - 0s - loss: 0.1312 - mse: 0.2456 - val_loss: 0.0691 - val_mse: 0.0067 - 165ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "35/35 - 0s - loss: 0.1413 - mse: 0.3929 - val_loss: 0.0675 - val_mse: 0.0065 - 172ms/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "35/35 - 0s - loss: 0.1150 - mse: 0.1288 - val_loss: 0.0741 - val_mse: 0.0076 - 162ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "35/35 - 0s - loss: 0.1227 - mse: 0.1646 - val_loss: 0.0622 - val_mse: 0.0057 - 170ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "35/35 - 0s - loss: 0.1206 - mse: 0.1693 - val_loss: 0.0660 - val_mse: 0.0063 - 167ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "35/35 - 0s - loss: 0.1284 - mse: 0.3802 - val_loss: 0.0650 - val_mse: 0.0061 - 164ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "35/35 - 0s - loss: 0.1262 - mse: 0.5865 - val_loss: 0.0710 - val_mse: 0.0070 - 164ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "35/35 - 0s - loss: 0.1146 - mse: 0.1756 - val_loss: 0.0636 - val_mse: 0.0059 - 167ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "35/35 - 0s - loss: 0.1122 - mse: 0.1275 - val_loss: 0.0624 - val_mse: 0.0057 - 167ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "35/35 - 0s - loss: 0.1194 - mse: 0.2840 - val_loss: 0.0745 - val_mse: 0.0077 - 164ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "35/35 - 0s - loss: 0.1133 - mse: 0.4136 - val_loss: 0.0645 - val_mse: 0.0060 - 169ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "35/35 - 0s - loss: 0.1147 - mse: 0.4045 - val_loss: 0.0631 - val_mse: 0.0059 - 165ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "35/35 - 0s - loss: 0.1085 - mse: 0.1212 - val_loss: 0.0628 - val_mse: 0.0059 - 169ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "35/35 - 0s - loss: 0.1145 - mse: 0.2309 - val_loss: 0.0664 - val_mse: 0.0064 - 170ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "35/35 - 0s - loss: 0.1139 - mse: 0.2705 - val_loss: 0.0621 - val_mse: 0.0058 - 168ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "35/35 - 0s - loss: 0.1097 - mse: 0.1486 - val_loss: 0.0626 - val_mse: 0.0058 - 164ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "35/35 - 0s - loss: 0.1088 - mse: 0.2424 - val_loss: 0.0719 - val_mse: 0.0072 - 165ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "35/35 - 0s - loss: 0.1073 - mse: 0.4430 - val_loss: 0.0646 - val_mse: 0.0061 - 164ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "35/35 - 0s - loss: 0.1072 - mse: 0.2848 - val_loss: 0.0648 - val_mse: 0.0061 - 163ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "35/35 - 0s - loss: 0.1145 - mse: 0.6490 - val_loss: 0.0639 - val_mse: 0.0060 - 164ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "35/35 - 0s - loss: 0.0966 - mse: 0.0628 - val_loss: 0.0627 - val_mse: 0.0058 - 164ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "35/35 - 0s - loss: 0.0984 - mse: 0.0944 - val_loss: 0.0666 - val_mse: 0.0063 - 165ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "35/35 - 0s - loss: 0.0978 - mse: 0.1127 - val_loss: 0.0652 - val_mse: 0.0062 - 166ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "35/35 - 0s - loss: 0.0994 - mse: 0.1467 - val_loss: 0.0627 - val_mse: 0.0058 - 163ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "35/35 - 0s - loss: 0.0997 - mse: 0.1828 - val_loss: 0.0636 - val_mse: 0.0059 - 176ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "35/35 - 0s - loss: 0.0940 - mse: 0.0493 - val_loss: 0.0692 - val_mse: 0.0068 - 175ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "35/35 - 0s - loss: 0.1021 - mse: 0.2271 - val_loss: 0.0628 - val_mse: 0.0058 - 165ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "35/35 - 0s - loss: 0.0972 - mse: 0.0708 - val_loss: 0.0650 - val_mse: 0.0061 - 168ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "35/35 - 0s - loss: 0.1033 - mse: 0.7060 - val_loss: 0.0677 - val_mse: 0.0066 - 171ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "35/35 - 0s - loss: 0.0948 - mse: 0.0973 - val_loss: 0.0658 - val_mse: 0.0063 - 166ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "35/35 - 0s - loss: 0.0969 - mse: 0.1924 - val_loss: 0.0624 - val_mse: 0.0057 - 167ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "35/35 - 0s - loss: 0.0865 - mse: 0.0466 - val_loss: 0.0620 - val_mse: 0.0057 - 177ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "35/35 - 0s - loss: 0.0899 - mse: 0.1694 - val_loss: 0.0623 - val_mse: 0.0057 - 172ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "35/35 - 0s - loss: 0.0921 - mse: 0.1407 - val_loss: 0.0731 - val_mse: 0.0074 - 173ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "35/35 - 0s - loss: 0.0902 - mse: 0.0786 - val_loss: 0.0631 - val_mse: 0.0059 - 171ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "35/35 - 0s - loss: 0.0863 - mse: 0.0271 - val_loss: 0.0702 - val_mse: 0.0070 - 172ms/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "35/35 - 0s - loss: 0.0863 - mse: 0.0410 - val_loss: 0.0659 - val_mse: 0.0063 - 166ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "35/35 - 0s - loss: 0.0862 - mse: 0.0420 - val_loss: 0.0623 - val_mse: 0.0058 - 161ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "35/35 - 0s - loss: 0.0912 - mse: 0.2210 - val_loss: 0.0689 - val_mse: 0.0067 - 165ms/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "35/35 - 0s - loss: 0.0850 - mse: 0.0531 - val_loss: 0.0620 - val_mse: 0.0057 - 168ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "35/35 - 0s - loss: 0.0858 - mse: 0.0312 - val_loss: 0.0673 - val_mse: 0.0065 - 164ms/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "35/35 - 0s - loss: 0.0877 - mse: 0.0575 - val_loss: 0.0627 - val_mse: 0.0058 - 164ms/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "35/35 - 0s - loss: 0.0901 - mse: 0.1274 - val_loss: 0.0652 - val_mse: 0.0062 - 163ms/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "35/35 - 0s - loss: 0.0852 - mse: 0.0391 - val_loss: 0.0746 - val_mse: 0.0077 - 165ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "35/35 - 0s - loss: 0.0857 - mse: 0.0434 - val_loss: 0.0626 - val_mse: 0.0058 - 164ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "35/35 - 0s - loss: 0.0892 - mse: 0.0877 - val_loss: 0.0623 - val_mse: 0.0058 - 166ms/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "35/35 - 0s - loss: 0.0879 - mse: 0.0510 - val_loss: 0.0663 - val_mse: 0.0064 - 163ms/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "35/35 - 0s - loss: 0.0869 - mse: 0.0827 - val_loss: 0.0656 - val_mse: 0.0062 - 163ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "35/35 - 0s - loss: 0.0825 - mse: 0.0285 - val_loss: 0.0638 - val_mse: 0.0059 - 166ms/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "35/35 - 0s - loss: 0.0904 - mse: 0.0581 - val_loss: 0.0676 - val_mse: 0.0066 - 168ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "35/35 - 0s - loss: 0.0837 - mse: 0.0703 - val_loss: 0.0794 - val_mse: 0.0087 - 163ms/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "35/35 - 0s - loss: 0.0788 - mse: 0.0162 - val_loss: 0.0734 - val_mse: 0.0075 - 163ms/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "35/35 - 0s - loss: 0.0858 - mse: 0.1086 - val_loss: 0.0674 - val_mse: 0.0065 - 162ms/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "35/35 - 0s - loss: 0.0834 - mse: 0.0589 - val_loss: 0.0622 - val_mse: 0.0058 - 165ms/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "35/35 - 0s - loss: 0.0809 - mse: 0.0264 - val_loss: 0.0679 - val_mse: 0.0066 - 166ms/epoch - 5ms/step\n",
            "Epoch 156/200\n",
            "35/35 - 0s - loss: 0.0865 - mse: 0.1140 - val_loss: 0.0667 - val_mse: 0.0064 - 172ms/epoch - 5ms/step\n",
            "Epoch 157/200\n",
            "35/35 - 0s - loss: 0.0828 - mse: 0.0501 - val_loss: 0.0678 - val_mse: 0.0066 - 164ms/epoch - 5ms/step\n",
            "Epoch 158/200\n",
            "35/35 - 0s - loss: 0.0821 - mse: 0.0683 - val_loss: 0.0667 - val_mse: 0.0064 - 163ms/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "35/35 - 0s - loss: 0.0810 - mse: 0.0487 - val_loss: 0.0626 - val_mse: 0.0058 - 164ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "35/35 - 0s - loss: 0.0812 - mse: 0.0278 - val_loss: 0.0664 - val_mse: 0.0063 - 164ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "35/35 - 0s - loss: 0.0804 - mse: 0.0430 - val_loss: 0.0635 - val_mse: 0.0059 - 163ms/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "35/35 - 0s - loss: 0.0876 - mse: 0.0819 - val_loss: 0.0801 - val_mse: 0.0088 - 165ms/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "35/35 - 0s - loss: 0.0828 - mse: 0.0430 - val_loss: 0.0660 - val_mse: 0.0063 - 171ms/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "35/35 - 0s - loss: 0.0789 - mse: 0.0205 - val_loss: 0.0662 - val_mse: 0.0063 - 164ms/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "35/35 - 0s - loss: 0.0799 - mse: 0.0223 - val_loss: 0.0690 - val_mse: 0.0069 - 165ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "35/35 - 0s - loss: 0.0821 - mse: 0.0358 - val_loss: 0.0620 - val_mse: 0.0057 - 165ms/epoch - 5ms/step\n",
            "Epoch 167/200\n",
            "35/35 - 0s - loss: 0.0776 - mse: 0.0211 - val_loss: 0.0625 - val_mse: 0.0058 - 167ms/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "35/35 - 0s - loss: 0.0759 - mse: 0.0104 - val_loss: 0.0670 - val_mse: 0.0064 - 165ms/epoch - 5ms/step\n",
            "Epoch 169/200\n",
            "35/35 - 0s - loss: 0.0889 - mse: 0.1863 - val_loss: 0.0638 - val_mse: 0.0060 - 166ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "35/35 - 0s - loss: 0.0795 - mse: 0.0400 - val_loss: 0.0624 - val_mse: 0.0057 - 178ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 43 started****\n",
            "\n",
            "Epoch 1/50\n",
            "34/34 [==============================] - 3s 12ms/step - loss: 132.2379 - mse: 255663.9375 - val_loss: 17.7856 - val_mse: 1812.3401\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.2641 - mse: 5178.1426 - val_loss: 0.4501 - val_mse: 2.3888\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 9.8237 - mse: 1227.4406 - val_loss: 2.2711 - val_mse: 32.4295\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7.1430 - mse: 700.5240 - val_loss: 0.1541 - val_mse: 0.4491\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 5.5684 - mse: 492.7393 - val_loss: 0.1177 - val_mse: 0.3172\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4.0436 - mse: 266.0031 - val_loss: 0.0944 - val_mse: 0.2533\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2.7771 - mse: 127.6879 - val_loss: 0.6632 - val_mse: 3.8544\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2.0521 - mse: 61.5572 - val_loss: 0.1405 - val_mse: 0.3419\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1.4861 - mse: 36.4637 - val_loss: 0.0830 - val_mse: 0.1920\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.8848 - mse: 14.5455 - val_loss: 0.0985 - val_mse: 0.2343\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.7032 - mse: 12.8149 - val_loss: 0.0686 - val_mse: 0.1460\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.4409 - mse: 4.5940 - val_loss: 0.0667 - val_mse: 0.1450\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.2856 - mse: 4.3794 - val_loss: 0.0433 - val_mse: 0.0886\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.1888 - mse: 2.1511 - val_loss: 0.0367 - val_mse: 0.0748\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.1255 - mse: 1.5534 - val_loss: 0.0260 - val_mse: 0.0527\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0676 - mse: 0.5254 - val_loss: 0.0184 - val_mse: 0.0373\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0543 - mse: 0.4609 - val_loss: 0.0135 - val_mse: 0.0272\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0361 - mse: 0.1960 - val_loss: 0.0103 - val_mse: 0.0207\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0281 - mse: 0.1372 - val_loss: 0.0086 - val_mse: 0.0173\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0249 - mse: 0.1660 - val_loss: 0.0068 - val_mse: 0.0137\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0352 - mse: 0.6214 - val_loss: 0.0061 - val_mse: 0.0122\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0207 - mse: 0.1597 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0220 - mse: 0.2376 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0124 - mse: 0.0658 - val_loss: 0.0053 - val_mse: 0.0106\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0907 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0204 - mse: 0.3152 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0607 - val_loss: 0.0045 - val_mse: 0.0090\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0476 - val_loss: 0.0048 - val_mse: 0.0097\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.1063 - val_loss: 0.0047 - val_mse: 0.0095\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0408 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0843 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0562 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0081 - mse: 0.0280 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0544 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0073 - mse: 0.0199 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0120 - mse: 0.1191 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0064 - mse: 0.0135 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0110 - mse: 0.2066 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0193 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0089 - mse: 0.0517 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0797 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 0.0119 - val_loss: 0.0051 - val_mse: 0.0101\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0065 - mse: 0.0170 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0947 - val_loss: 0.0051 - val_mse: 0.0103\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0072 - mse: 0.0212 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0076 - mse: 0.0222 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0063 - mse: 0.0131 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0063 - mse: 0.0149 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0090 - mse: 0.0553 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 51/200\n",
            "34/34 - 0s - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0046 - val_mse: 0.0093 - 225ms/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "34/34 - 0s - loss: 0.0110 - mse: 0.2122 - val_loss: 0.0044 - val_mse: 0.0088 - 165ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0195 - val_loss: 0.0044 - val_mse: 0.0089 - 162ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0171 - val_loss: 0.0043 - val_mse: 0.0087 - 165ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0125 - val_loss: 0.0052 - val_mse: 0.0104 - 164ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0173 - val_loss: 0.0044 - val_mse: 0.0088 - 162ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0136 - val_loss: 0.0054 - val_mse: 0.0109 - 161ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0131 - val_loss: 0.0046 - val_mse: 0.0092 - 164ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "34/34 - 0s - loss: 0.0076 - mse: 0.0602 - val_loss: 0.0053 - val_mse: 0.0106 - 164ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "34/34 - 0s - loss: 0.0094 - mse: 0.0908 - val_loss: 0.0046 - val_mse: 0.0091 - 164ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "34/34 - 0s - loss: 0.0064 - mse: 0.0150 - val_loss: 0.0049 - val_mse: 0.0098 - 164ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "34/34 - 0s - loss: 0.0060 - mse: 0.0128 - val_loss: 0.0056 - val_mse: 0.0112 - 163ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "34/34 - 0s - loss: 0.0071 - mse: 0.0200 - val_loss: 0.0043 - val_mse: 0.0086 - 163ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "34/34 - 0s - loss: 0.0081 - mse: 0.0438 - val_loss: 0.0042 - val_mse: 0.0085 - 167ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "34/34 - 0s - loss: 0.0082 - mse: 0.0355 - val_loss: 0.0043 - val_mse: 0.0087 - 160ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "34/34 - 0s - loss: 0.0072 - mse: 0.0216 - val_loss: 0.0047 - val_mse: 0.0093 - 169ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "34/34 - 0s - loss: 0.0063 - mse: 0.0131 - val_loss: 0.0048 - val_mse: 0.0096 - 164ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0149 - val_loss: 0.0063 - val_mse: 0.0127 - 163ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "34/34 - 0s - loss: 0.0071 - mse: 0.0260 - val_loss: 0.0044 - val_mse: 0.0089 - 161ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "34/34 - 0s - loss: 0.0075 - mse: 0.0322 - val_loss: 0.0049 - val_mse: 0.0097 - 162ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0148 - val_loss: 0.0045 - val_mse: 0.0089 - 162ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "34/34 - 0s - loss: 0.0077 - mse: 0.0242 - val_loss: 0.0043 - val_mse: 0.0087 - 163ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "34/34 - 0s - loss: 0.0084 - mse: 0.0280 - val_loss: 0.0079 - val_mse: 0.0160 - 163ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "34/34 - 0s - loss: 0.0069 - mse: 0.0198 - val_loss: 0.0045 - val_mse: 0.0090 - 171ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0137 - val_loss: 0.0051 - val_mse: 0.0102 - 167ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "34/34 - 0s - loss: 0.0088 - mse: 0.0497 - val_loss: 0.0043 - val_mse: 0.0087 - 162ms/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0118 - val_loss: 0.0050 - val_mse: 0.0101 - 166ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0044 - val_mse: 0.0088 - 169ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0112 - val_loss: 0.0054 - val_mse: 0.0109 - 165ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0051 - val_mse: 0.0102 - 166ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0129 - val_loss: 0.0042 - val_mse: 0.0085 - 175ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "34/34 - 0s - loss: 0.0060 - mse: 0.0121 - val_loss: 0.0045 - val_mse: 0.0090 - 175ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0050 - val_mse: 0.0100 - 170ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0251 - val_loss: 0.0043 - val_mse: 0.0085 - 168ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "34/34 - 0s - loss: 0.0076 - mse: 0.0369 - val_loss: 0.0057 - val_mse: 0.0114 - 169ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0116 - val_loss: 0.0044 - val_mse: 0.0089 - 168ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0119 - val_loss: 0.0052 - val_mse: 0.0105 - 166ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0136 - val_loss: 0.0048 - val_mse: 0.0095 - 165ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0118 - val_loss: 0.0048 - val_mse: 0.0097 - 163ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "34/34 - 0s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0042 - val_mse: 0.0085 - 175ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "34/34 - 0s - loss: 0.0053 - mse: 0.0106 - val_loss: 0.0052 - val_mse: 0.0104 - 164ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0155 - val_loss: 0.0043 - val_mse: 0.0086 - 167ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0153 - val_loss: 0.0060 - val_mse: 0.0120 - 164ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0119 - val_loss: 0.0048 - val_mse: 0.0096 - 161ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "34/34 - 0s - loss: 0.0053 - mse: 0.0108 - val_loss: 0.0047 - val_mse: 0.0094 - 163ms/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0268 - val_loss: 0.0042 - val_mse: 0.0084 - 177ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0134 - val_loss: 0.0060 - val_mse: 0.0120 - 163ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0118 - val_loss: 0.0044 - val_mse: 0.0088 - 163ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0157 - val_loss: 0.0072 - val_mse: 0.0145 - 163ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "34/34 - 0s - loss: 0.0063 - mse: 0.0128 - val_loss: 0.0054 - val_mse: 0.0109 - 163ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0139 - val_loss: 0.0043 - val_mse: 0.0086 - 163ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "34/34 - 0s - loss: 0.0080 - mse: 0.0218 - val_loss: 0.0060 - val_mse: 0.0120 - 170ms/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086 - 161ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0124 - val_loss: 0.0049 - val_mse: 0.0098 - 162ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "34/34 - 0s - loss: 0.0054 - mse: 0.0110 - val_loss: 0.0043 - val_mse: 0.0086 - 162ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0121 - val_loss: 0.0047 - val_mse: 0.0094 - 165ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0131 - val_loss: 0.0044 - val_mse: 0.0088 - 162ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0112 - val_loss: 0.0062 - val_mse: 0.0125 - 162ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "34/34 - 0s - loss: 0.0098 - mse: 0.1467 - val_loss: 0.0056 - val_mse: 0.0112 - 163ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0053 - val_mse: 0.0107 - 164ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0047 - val_mse: 0.0095 - 161ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0142 - val_loss: 0.0045 - val_mse: 0.0090 - 163ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "34/34 - 0s - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0065 - val_mse: 0.0130 - 160ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0135 - val_loss: 0.0043 - val_mse: 0.0085 - 173ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0049 - val_mse: 0.0098 - 164ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "34/34 - 0s - loss: 0.0093 - mse: 0.0755 - val_loss: 0.0063 - val_mse: 0.0126 - 166ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0138 - val_loss: 0.0050 - val_mse: 0.0100 - 165ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "34/34 - 0s - loss: 0.0054 - mse: 0.0110 - val_loss: 0.0048 - val_mse: 0.0096 - 165ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0132 - val_loss: 0.0043 - val_mse: 0.0086 - 161ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "34/34 - 0s - loss: 0.0061 - mse: 0.0161 - val_loss: 0.0042 - val_mse: 0.0084 - 169ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0048 - val_mse: 0.0097 - 161ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0132 - val_loss: 0.0048 - val_mse: 0.0097 - 162ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0140 - val_loss: 0.0044 - val_mse: 0.0089 - 159ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0121 - val_loss: 0.0043 - val_mse: 0.0087 - 162ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "34/34 - 0s - loss: 0.0055 - mse: 0.0110 - val_loss: 0.0043 - val_mse: 0.0085 - 161ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0152 - val_loss: 0.0043 - val_mse: 0.0086 - 161ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0125 - val_loss: 0.0049 - val_mse: 0.0098 - 165ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "34/34 - 0s - loss: 0.0053 - mse: 0.0107 - val_loss: 0.0068 - val_mse: 0.0137 - 161ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0135 - val_loss: 0.0055 - val_mse: 0.0111 - 161ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "34/34 - 0s - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0048 - val_mse: 0.0096 - 161ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "34/34 - 0s - loss: 0.0071 - mse: 0.0420 - val_loss: 0.0045 - val_mse: 0.0091 - 174ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0118 - val_loss: 0.0042 - val_mse: 0.0085 - 165ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0122 - val_loss: 0.0057 - val_mse: 0.0115 - 169ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "34/34 - 0s - loss: 0.0059 - mse: 0.0124 - val_loss: 0.0076 - val_mse: 0.0153 - 161ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0142 - val_loss: 0.0069 - val_mse: 0.0139 - 161ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0145 - val_loss: 0.0056 - val_mse: 0.0112 - 165ms/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "34/34 - 0s - loss: 0.0057 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086 - 161ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "34/34 - 0s - loss: 0.0063 - mse: 0.0128 - val_loss: 0.0077 - val_mse: 0.0155 - 160ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "34/34 - 0s - loss: 0.0071 - mse: 0.0183 - val_loss: 0.0045 - val_mse: 0.0092 - 161ms/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0042 - val_mse: 0.0085 - 164ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "34/34 - 0s - loss: 0.0060 - mse: 0.0121 - val_loss: 0.0051 - val_mse: 0.0103 - 160ms/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "34/34 - 0s - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0043 - val_mse: 0.0087 - 161ms/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "34/34 - 0s - loss: 0.0087 - mse: 0.0177 - val_loss: 0.0083 - val_mse: 0.0167 - 162ms/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "34/34 - 0s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0083 - val_mse: 0.0167 - 163ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "34/34 - 0s - loss: 0.0084 - mse: 0.0170 - val_loss: 0.0083 - val_mse: 0.0167 - 169ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "34/34 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0083 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "34/34 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0170 - 169ms/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "34/34 - 0s - loss: 0.0086 - mse: 0.0174 - val_loss: 0.0083 - val_mse: 0.0167 - 165ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "34/34 - 0s - loss: 0.0103 - mse: 0.0455 - val_loss: 0.0083 - val_mse: 0.0167 - 169ms/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "34/34 - 0s - loss: 0.0086 - mse: 0.0174 - val_loss: 0.0083 - val_mse: 0.0167 - 173ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 44 started****\n",
            "\n",
            "Epoch 1/50\n",
            "187/187 [==============================] - 3s 5ms/step - loss: 616.0077 - mse: 133198664.0000 - val_loss: 0.0088 - val_mse: 0.0176\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0173\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0089 - val_mse: 0.0178\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0088 - val_mse: 0.0175\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0093 - val_mse: 0.0185\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0088 - val_mse: 0.0176\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0096 - val_mse: 0.0191\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0087 - val_mse: 0.0173\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0091 - val_mse: 0.0182\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0088 - val_mse: 0.0175\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0108 - val_mse: 0.0216\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0090 - val_mse: 0.0181\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0172\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 51/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0169 - 701ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 641ms/epoch - 3ms/step\n",
            "Epoch 53/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0094 - val_mse: 0.0189 - 642ms/epoch - 3ms/step\n",
            "Epoch 54/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0171 - 636ms/epoch - 3ms/step\n",
            "Epoch 55/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0170 - 638ms/epoch - 3ms/step\n",
            "Epoch 56/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 644ms/epoch - 3ms/step\n",
            "Epoch 57/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0169 - 639ms/epoch - 3ms/step\n",
            "Epoch 58/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0093 - val_mse: 0.0186 - 640ms/epoch - 3ms/step\n",
            "Epoch 59/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0088 - val_mse: 0.0175 - 648ms/epoch - 3ms/step\n",
            "Epoch 60/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 637ms/epoch - 3ms/step\n",
            "Epoch 61/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 649ms/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 645ms/epoch - 3ms/step\n",
            "Epoch 63/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0094 - val_mse: 0.0187 - 652ms/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0169 - 655ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0171 - 672ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0175 - 669ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0090 - val_mse: 0.0180 - 636ms/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0172 - 639ms/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0169 - 638ms/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0089 - val_mse: 0.0177 - 646ms/epoch - 3ms/step\n",
            "Epoch 71/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0168 - 647ms/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 645ms/epoch - 3ms/step\n",
            "Epoch 73/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0169 - 644ms/epoch - 3ms/step\n",
            "Epoch 74/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0169 - 643ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0085 - val_mse: 0.0171 - 645ms/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 642ms/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 655ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 647ms/epoch - 3ms/step\n",
            "Epoch 79/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 646ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0102 - val_mse: 0.0204 - 645ms/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0099 - val_mse: 0.0197 - 655ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 661ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 660ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0088 - val_mse: 0.0175 - 672ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0092 - val_mse: 0.0184 - 639ms/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0172 - 637ms/epoch - 3ms/step\n",
            "Epoch 87/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 640ms/epoch - 3ms/step\n",
            "Epoch 88/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0169 - 647ms/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169 - 648ms/epoch - 3ms/step\n",
            "Epoch 90/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 638ms/epoch - 3ms/step\n",
            "Epoch 91/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 646ms/epoch - 3ms/step\n",
            "Epoch 92/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 643ms/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 641ms/epoch - 3ms/step\n",
            "Epoch 94/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168 - 651ms/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0090 - val_mse: 0.0179 - 641ms/epoch - 3ms/step\n",
            "Epoch 96/200\n",
            "187/187 - 1s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0086 - val_mse: 0.0172 - 642ms/epoch - 3ms/step\n",
            "Epoch 97/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0113 - val_mse: 0.0225 - 647ms/epoch - 3ms/step\n",
            "Epoch 98/200\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0088 - val_mse: 0.0177 - 637ms/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172 - 648ms/epoch - 3ms/step\n",
            "Epoch 100/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 655ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0090 - val_mse: 0.0179 - 661ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 669ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "187/187 - 1s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0088 - val_mse: 0.0176 - 659ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178 - 642ms/epoch - 3ms/step\n",
            "Epoch 105/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172 - 639ms/epoch - 3ms/step\n",
            "Epoch 106/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0090 - val_mse: 0.0179 - 640ms/epoch - 3ms/step\n",
            "Epoch 107/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0170 - 641ms/epoch - 3ms/step\n",
            "Epoch 108/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0089 - val_mse: 0.0179 - 639ms/epoch - 3ms/step\n",
            "Epoch 109/200\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0089 - val_mse: 0.0179 - 639ms/epoch - 3ms/step\n",
            "\n",
            "****Iteration number 45 started****\n",
            "\n",
            "Epoch 1/50\n",
            "39/39 [==============================] - 3s 10ms/step - loss: 1239.4988 - mse: 16878676.0000 - val_loss: 255.4826 - val_mse: 327194.1562\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1246.9697 - mse: 17068408.0000 - val_loss: 213.0050 - val_mse: 227334.8594\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1226.2346 - mse: 18477890.0000 - val_loss: 177.0699 - val_mse: 157023.7812\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1139.9437 - mse: 15170571.0000 - val_loss: 146.0646 - val_mse: 106789.0078\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1123.2623 - mse: 13821034.0000 - val_loss: 118.5782 - val_mse: 70334.1094\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1079.4004 - mse: 14966561.0000 - val_loss: 92.1680 - val_mse: 42461.6406\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1108.0861 - mse: 14902318.0000 - val_loss: 66.2996 - val_mse: 21952.3145\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1031.6960 - mse: 13123969.0000 - val_loss: 48.4166 - val_mse: 11694.0654\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1050.3854 - mse: 12551458.0000 - val_loss: 31.4217 - val_mse: 4909.9072\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 961.9548 - mse: 9990112.0000 - val_loss: 18.0212 - val_mse: 1604.5150\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 966.8750 - mse: 11077858.0000 - val_loss: 4.8108 - val_mse: 109.9054\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 938.9712 - mse: 9531610.0000 - val_loss: 6.9680 - val_mse: 299.4418\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 945.2747 - mse: 10707148.0000 - val_loss: 16.8082 - val_mse: 1578.3164\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 878.6462 - mse: 8341699.5000 - val_loss: 25.5842 - val_mse: 3542.3540\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 843.5413 - mse: 8345331.5000 - val_loss: 32.0428 - val_mse: 5480.1475\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 867.8249 - mse: 8369793.0000 - val_loss: 38.6037 - val_mse: 7873.7173\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 848.2179 - mse: 9530497.0000 - val_loss: 43.6827 - val_mse: 10020.4697\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 847.7175 - mse: 8889189.0000 - val_loss: 48.5300 - val_mse: 12308.3125\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 798.3864 - mse: 8156722.0000 - val_loss: 52.0483 - val_mse: 14114.2305\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 842.0139 - mse: 8837080.0000 - val_loss: 53.8339 - val_mse: 15073.2480\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 784.6544 - mse: 8401323.0000 - val_loss: 56.2189 - val_mse: 16407.1992\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 786.7256 - mse: 6944184.0000 - val_loss: 57.9332 - val_mse: 17398.2930\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 764.6102 - mse: 6715984.0000 - val_loss: 59.8086 - val_mse: 18516.2129\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 805.3669 - mse: 8715994.0000 - val_loss: 62.8430 - val_mse: 20395.0156\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 801.8801 - mse: 7543689.0000 - val_loss: 62.9114 - val_mse: 20417.9160\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 785.5440 - mse: 6802131.5000 - val_loss: 63.9101 - val_mse: 21040.9121\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 763.2663 - mse: 6608382.0000 - val_loss: 64.3786 - val_mse: 21324.3613\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 765.8548 - mse: 7774241.5000 - val_loss: 63.1793 - val_mse: 20529.9121\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 741.4521 - mse: 6734390.5000 - val_loss: 60.3938 - val_mse: 18764.4043\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 716.9049 - mse: 6320867.0000 - val_loss: 59.4062 - val_mse: 18152.7246\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 718.9554 - mse: 5597249.0000 - val_loss: 58.7294 - val_mse: 17740.2324\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 719.3301 - mse: 6425865.0000 - val_loss: 58.7089 - val_mse: 17724.9805\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 737.3675 - mse: 7159117.5000 - val_loss: 57.7078 - val_mse: 17128.9121\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 666.2976 - mse: 4593307.5000 - val_loss: 56.0475 - val_mse: 16168.5352\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 706.5859 - mse: 5876188.5000 - val_loss: 55.8076 - val_mse: 16031.9961\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 681.6304 - mse: 5532825.0000 - val_loss: 54.8798 - val_mse: 15506.8047\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 716.3030 - mse: 6147987.5000 - val_loss: 52.5919 - val_mse: 14254.4541\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 693.3377 - mse: 5460393.0000 - val_loss: 50.5140 - val_mse: 13154.9092\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 698.9995 - mse: 6042418.5000 - val_loss: 49.2591 - val_mse: 12516.5996\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 682.2457 - mse: 7772731.5000 - val_loss: 47.0391 - val_mse: 11424.7080\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 688.4276 - mse: 5834496.5000 - val_loss: 45.6082 - val_mse: 10744.1191\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 669.8002 - mse: 4793246.5000 - val_loss: 43.9963 - val_mse: 10004.1162\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 690.5860 - mse: 5019388.5000 - val_loss: 42.4281 - val_mse: 9305.4395\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 676.3506 - mse: 5949955.5000 - val_loss: 41.1729 - val_mse: 8762.7344\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 660.8830 - mse: 5798174.5000 - val_loss: 39.9896 - val_mse: 8264.1826\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 694.4490 - mse: 6460574.5000 - val_loss: 38.2429 - val_mse: 7558.6860\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 678.0183 - mse: 5560296.0000 - val_loss: 36.3792 - val_mse: 6842.5176\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 671.8877 - mse: 6205699.0000 - val_loss: 34.4982 - val_mse: 6157.5542\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 655.5937 - mse: 4855745.5000 - val_loss: 33.2459 - val_mse: 5720.1289\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 650.3135 - mse: 5997186.0000 - val_loss: 32.3605 - val_mse: 5416.9736\n",
            "Epoch 51/200\n",
            "39/39 - 0s - loss: 667.7247 - mse: 5550007.5000 - val_loss: 31.7935 - val_mse: 5225.3682 - 249ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "39/39 - 0s - loss: 645.6351 - mse: 4564031.5000 - val_loss: 31.1505 - val_mse: 5014.7622 - 186ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "39/39 - 0s - loss: 667.4066 - mse: 5702470.0000 - val_loss: 30.9850 - val_mse: 4961.2617 - 189ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "39/39 - 0s - loss: 641.0273 - mse: 4889713.0000 - val_loss: 29.4267 - val_mse: 4473.7720 - 188ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "39/39 - 0s - loss: 621.9785 - mse: 4392068.5000 - val_loss: 28.6175 - val_mse: 4228.3506 - 186ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "39/39 - 0s - loss: 615.2764 - mse: 5130095.5000 - val_loss: 26.6148 - val_mse: 3655.6765 - 183ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "39/39 - 0s - loss: 637.3653 - mse: 4908299.5000 - val_loss: 25.4875 - val_mse: 3350.7114 - 184ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "39/39 - 0s - loss: 619.2053 - mse: 4445057.5000 - val_loss: 25.4356 - val_mse: 3334.0105 - 184ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "39/39 - 0s - loss: 638.6337 - mse: 5418820.0000 - val_loss: 25.6261 - val_mse: 3381.0488 - 185ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "39/39 - 0s - loss: 602.0413 - mse: 3771454.0000 - val_loss: 25.5517 - val_mse: 3360.6709 - 181ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "39/39 - 0s - loss: 592.1384 - mse: 4162327.0000 - val_loss: 25.0732 - val_mse: 3233.8699 - 185ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "39/39 - 0s - loss: 611.8702 - mse: 4473978.0000 - val_loss: 24.0207 - val_mse: 2966.3359 - 184ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "39/39 - 0s - loss: 637.4705 - mse: 4664992.0000 - val_loss: 23.2380 - val_mse: 2773.2573 - 183ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "39/39 - 0s - loss: 625.7703 - mse: 5252925.5000 - val_loss: 23.1737 - val_mse: 2758.5815 - 183ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "39/39 - 0s - loss: 629.2358 - mse: 5398289.5000 - val_loss: 23.1492 - val_mse: 2750.2129 - 185ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "39/39 - 0s - loss: 606.8372 - mse: 4731497.0000 - val_loss: 23.9894 - val_mse: 2951.7522 - 181ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "39/39 - 0s - loss: 628.3481 - mse: 5007423.0000 - val_loss: 24.1356 - val_mse: 2988.1272 - 182ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "39/39 - 0s - loss: 620.0361 - mse: 5062477.0000 - val_loss: 23.7368 - val_mse: 2890.2529 - 181ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "39/39 - 0s - loss: 616.3586 - mse: 4594916.5000 - val_loss: 25.0499 - val_mse: 3216.5481 - 182ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "39/39 - 0s - loss: 590.6625 - mse: 4190101.7500 - val_loss: 25.1710 - val_mse: 3246.7371 - 180ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "39/39 - 0s - loss: 578.5490 - mse: 4026232.0000 - val_loss: 24.2704 - val_mse: 3018.7439 - 183ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "39/39 - 0s - loss: 619.5211 - mse: 4654715.5000 - val_loss: 24.1056 - val_mse: 2979.8989 - 185ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "39/39 - 0s - loss: 609.7348 - mse: 4635884.0000 - val_loss: 23.6207 - val_mse: 2863.9705 - 182ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "39/39 - 0s - loss: 634.0748 - mse: 5694600.5000 - val_loss: 22.9995 - val_mse: 2715.4385 - 188ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "39/39 - 0s - loss: 598.9816 - mse: 5099734.5000 - val_loss: 22.7045 - val_mse: 2644.9482 - 191ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "39/39 - 0s - loss: 578.2011 - mse: 4035679.5000 - val_loss: 22.6097 - val_mse: 2622.2095 - 190ms/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "39/39 - 0s - loss: 580.6714 - mse: 4143306.0000 - val_loss: 22.2688 - val_mse: 2542.6235 - 193ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "39/39 - 0s - loss: 593.4685 - mse: 4353162.0000 - val_loss: 22.8059 - val_mse: 2666.9939 - 188ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "39/39 - 0s - loss: 581.6980 - mse: 4530325.0000 - val_loss: 22.2770 - val_mse: 2545.7769 - 183ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "39/39 - 0s - loss: 595.0604 - mse: 4187088.0000 - val_loss: 22.9614 - val_mse: 2702.7612 - 187ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "39/39 - 0s - loss: 568.7509 - mse: 3628022.2500 - val_loss: 22.3247 - val_mse: 2555.4968 - 186ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "39/39 - 0s - loss: 581.8644 - mse: 3903139.5000 - val_loss: 20.5209 - val_mse: 2161.2043 - 192ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "39/39 - 0s - loss: 583.0196 - mse: 4604313.0000 - val_loss: 19.9142 - val_mse: 2036.2092 - 195ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "39/39 - 0s - loss: 604.6555 - mse: 5541718.5000 - val_loss: 19.5168 - val_mse: 1956.1851 - 192ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "39/39 - 0s - loss: 561.4425 - mse: 3625924.7500 - val_loss: 20.3123 - val_mse: 2119.0183 - 184ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "39/39 - 0s - loss: 561.7570 - mse: 3633812.2500 - val_loss: 20.0489 - val_mse: 2067.5469 - 182ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "39/39 - 0s - loss: 589.7640 - mse: 4193405.0000 - val_loss: 19.6857 - val_mse: 1992.4882 - 180ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "39/39 - 0s - loss: 561.1453 - mse: 3447538.7500 - val_loss: 20.6401 - val_mse: 2192.3386 - 186ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "39/39 - 0s - loss: 568.5378 - mse: 5057926.0000 - val_loss: 21.5719 - val_mse: 2395.3074 - 181ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "39/39 - 0s - loss: 589.0735 - mse: 4563466.0000 - val_loss: 20.8814 - val_mse: 2246.0876 - 179ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "39/39 - 0s - loss: 581.6771 - mse: 4131630.0000 - val_loss: 20.1318 - val_mse: 2092.8577 - 184ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "39/39 - 0s - loss: 557.6443 - mse: 4391132.5000 - val_loss: 20.7413 - val_mse: 2228.0593 - 183ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "39/39 - 0s - loss: 575.3402 - mse: 4200503.5000 - val_loss: 20.5810 - val_mse: 2194.1499 - 183ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "39/39 - 0s - loss: 576.3871 - mse: 4203155.5000 - val_loss: 20.9965 - val_mse: 2284.2031 - 184ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "39/39 - 0s - loss: 545.7407 - mse: 3330596.5000 - val_loss: 18.9798 - val_mse: 1869.3765 - 188ms/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "39/39 - 0s - loss: 538.5529 - mse: 3413048.0000 - val_loss: 19.5950 - val_mse: 1992.0770 - 181ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "39/39 - 0s - loss: 553.2051 - mse: 3805082.7500 - val_loss: 19.4854 - val_mse: 1971.2012 - 182ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "39/39 - 0s - loss: 526.3806 - mse: 3539256.5000 - val_loss: 19.8592 - val_mse: 2047.1040 - 180ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "39/39 - 0s - loss: 496.7690 - mse: 2684213.5000 - val_loss: 18.0226 - val_mse: 1689.1206 - 195ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "39/39 - 0s - loss: 548.9727 - mse: 3859184.0000 - val_loss: 17.2638 - val_mse: 1551.7384 - 185ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "39/39 - 0s - loss: 546.7263 - mse: 4000276.2500 - val_loss: 17.5147 - val_mse: 1597.2278 - 182ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "39/39 - 0s - loss: 514.9698 - mse: 3104764.0000 - val_loss: 17.5329 - val_mse: 1600.4868 - 181ms/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "39/39 - 0s - loss: 519.2226 - mse: 2915831.7500 - val_loss: 16.3423 - val_mse: 1391.9846 - 185ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "39/39 - 0s - loss: 511.1177 - mse: 2707065.2500 - val_loss: 14.8812 - val_mse: 1154.0310 - 193ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "39/39 - 0s - loss: 526.3500 - mse: 3715535.5000 - val_loss: 15.3770 - val_mse: 1231.7993 - 181ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "39/39 - 0s - loss: 525.9160 - mse: 3259189.2500 - val_loss: 15.5620 - val_mse: 1260.7068 - 182ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "39/39 - 0s - loss: 511.3335 - mse: 2813873.5000 - val_loss: 16.0839 - val_mse: 1346.2115 - 185ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "39/39 - 0s - loss: 531.4710 - mse: 3356020.0000 - val_loss: 15.3826 - val_mse: 1233.6732 - 182ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "39/39 - 0s - loss: 508.5173 - mse: 3042683.2500 - val_loss: 15.5017 - val_mse: 1253.9277 - 178ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "39/39 - 0s - loss: 513.7756 - mse: 3060320.7500 - val_loss: 15.7377 - val_mse: 1292.9554 - 192ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "39/39 - 0s - loss: 520.5654 - mse: 3266243.2500 - val_loss: 15.8713 - val_mse: 1313.0637 - 182ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "39/39 - 0s - loss: 506.0871 - mse: 2822101.7500 - val_loss: 16.7705 - val_mse: 1462.0100 - 180ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "39/39 - 0s - loss: 520.7009 - mse: 3422009.5000 - val_loss: 16.7278 - val_mse: 1450.8972 - 182ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "39/39 - 0s - loss: 528.0474 - mse: 3130038.2500 - val_loss: 16.6992 - val_mse: 1442.1913 - 180ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "39/39 - 0s - loss: 510.2960 - mse: 2916555.2500 - val_loss: 16.4506 - val_mse: 1397.5598 - 184ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "39/39 - 0s - loss: 497.1602 - mse: 2836640.0000 - val_loss: 16.8219 - val_mse: 1460.4609 - 182ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "39/39 - 0s - loss: 509.2005 - mse: 2875393.7500 - val_loss: 17.2732 - val_mse: 1540.9717 - 181ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "39/39 - 0s - loss: 521.5568 - mse: 3781417.2500 - val_loss: 16.4921 - val_mse: 1404.8187 - 183ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "39/39 - 0s - loss: 519.5571 - mse: 3729493.0000 - val_loss: 16.5481 - val_mse: 1413.2560 - 179ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "39/39 - 0s - loss: 494.8146 - mse: 2907749.0000 - val_loss: 16.2520 - val_mse: 1361.8439 - 184ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "39/39 - 0s - loss: 498.3216 - mse: 2730518.0000 - val_loss: 16.3232 - val_mse: 1373.6849 - 200ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "39/39 - 0s - loss: 487.6322 - mse: 2447245.7500 - val_loss: 16.1987 - val_mse: 1351.8048 - 184ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "39/39 - 0s - loss: 493.1965 - mse: 3038211.5000 - val_loss: 16.7355 - val_mse: 1442.3429 - 185ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "39/39 - 0s - loss: 494.3481 - mse: 3001840.5000 - val_loss: 16.7897 - val_mse: 1451.3864 - 183ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "39/39 - 0s - loss: 503.5073 - mse: 3608959.0000 - val_loss: 16.3653 - val_mse: 1379.2230 - 182ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "39/39 - 0s - loss: 477.6154 - mse: 2731594.5000 - val_loss: 15.2927 - val_mse: 1204.8547 - 183ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "39/39 - 0s - loss: 478.1826 - mse: 2561050.5000 - val_loss: 14.6553 - val_mse: 1107.4998 - 182ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "39/39 - 0s - loss: 490.7755 - mse: 3176468.0000 - val_loss: 15.2062 - val_mse: 1191.1929 - 181ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "39/39 - 0s - loss: 508.6111 - mse: 3118520.5000 - val_loss: 14.2307 - val_mse: 1043.4020 - 184ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "39/39 - 0s - loss: 483.2126 - mse: 2667094.2500 - val_loss: 13.8907 - val_mse: 993.9343 - 184ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "39/39 - 0s - loss: 475.6641 - mse: 2717542.0000 - val_loss: 13.5024 - val_mse: 939.8083 - 184ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "39/39 - 0s - loss: 491.2850 - mse: 3161018.0000 - val_loss: 13.9333 - val_mse: 1000.6984 - 184ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "39/39 - 0s - loss: 489.2266 - mse: 2945759.7500 - val_loss: 14.9829 - val_mse: 1156.7556 - 181ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "39/39 - 0s - loss: 467.4604 - mse: 2610730.2500 - val_loss: 15.1140 - val_mse: 1177.2085 - 181ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "39/39 - 0s - loss: 470.2078 - mse: 2793004.0000 - val_loss: 16.2092 - val_mse: 1351.7373 - 181ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "39/39 - 0s - loss: 472.9225 - mse: 2509069.7500 - val_loss: 16.8829 - val_mse: 1462.7223 - 180ms/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "39/39 - 0s - loss: 478.2239 - mse: 2951090.2500 - val_loss: 16.1713 - val_mse: 1342.0199 - 184ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "39/39 - 0s - loss: 432.7494 - mse: 2102829.0000 - val_loss: 16.2337 - val_mse: 1353.1028 - 185ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "39/39 - 0s - loss: 468.9146 - mse: 3112172.2500 - val_loss: 16.5342 - val_mse: 1402.4550 - 190ms/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "39/39 - 0s - loss: 466.7374 - mse: 2476698.7500 - val_loss: 17.0284 - val_mse: 1487.1362 - 186ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "39/39 - 0s - loss: 485.1190 - mse: 3297142.5000 - val_loss: 16.5258 - val_mse: 1399.7338 - 183ms/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "39/39 - 0s - loss: 454.4159 - mse: 2564562.2500 - val_loss: 15.9434 - val_mse: 1301.1342 - 186ms/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "39/39 - 0s - loss: 452.6170 - mse: 2591568.7500 - val_loss: 15.4038 - val_mse: 1214.5541 - 186ms/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "39/39 - 0s - loss: 462.1316 - mse: 2705341.5000 - val_loss: 15.4209 - val_mse: 1217.1458 - 186ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "39/39 - 0s - loss: 478.1954 - mse: 2883905.2500 - val_loss: 15.8008 - val_mse: 1277.7928 - 192ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "39/39 - 0s - loss: 458.0977 - mse: 2854785.5000 - val_loss: 14.6322 - val_mse: 1096.8104 - 204ms/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "39/39 - 0s - loss: 432.1718 - mse: 2315468.0000 - val_loss: 15.2620 - val_mse: 1192.6807 - 197ms/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "39/39 - 0s - loss: 438.1171 - mse: 2409429.5000 - val_loss: 14.3781 - val_mse: 1059.1781 - 193ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "39/39 - 0s - loss: 462.0039 - mse: 2377253.7500 - val_loss: 12.8465 - val_mse: 845.3267 - 189ms/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "39/39 - 0s - loss: 451.1043 - mse: 2322866.2500 - val_loss: 13.3529 - val_mse: 915.3753 - 185ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "39/39 - 0s - loss: 443.4612 - mse: 2387104.0000 - val_loss: 14.8303 - val_mse: 1131.8975 - 184ms/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "39/39 - 0s - loss: 431.4439 - mse: 2260243.2500 - val_loss: 15.4333 - val_mse: 1228.3735 - 182ms/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "39/39 - 0s - loss: 464.5965 - mse: 2947507.2500 - val_loss: 15.4969 - val_mse: 1240.3434 - 182ms/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "39/39 - 0s - loss: 447.8758 - mse: 2322635.0000 - val_loss: 14.7109 - val_mse: 1119.6418 - 180ms/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "39/39 - 0s - loss: 442.6349 - mse: 2504261.5000 - val_loss: 14.2234 - val_mse: 1047.1631 - 180ms/epoch - 5ms/step\n",
            "Epoch 156/200\n",
            "39/39 - 0s - loss: 441.0658 - mse: 2585531.0000 - val_loss: 13.7038 - val_mse: 971.7134 - 185ms/epoch - 5ms/step\n",
            "Epoch 157/200\n",
            "39/39 - 0s - loss: 444.3800 - mse: 2242306.0000 - val_loss: 13.4551 - val_mse: 935.3851 - 179ms/epoch - 5ms/step\n",
            "Epoch 158/200\n",
            "39/39 - 0s - loss: 438.9043 - mse: 2389235.7500 - val_loss: 13.7452 - val_mse: 973.1644 - 182ms/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "39/39 - 0s - loss: 460.8938 - mse: 2688007.7500 - val_loss: 13.6837 - val_mse: 963.5845 - 185ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "39/39 - 0s - loss: 437.4144 - mse: 2394774.5000 - val_loss: 15.7035 - val_mse: 1266.2189 - 182ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "39/39 - 0s - loss: 412.5427 - mse: 2076142.7500 - val_loss: 16.1438 - val_mse: 1330.5968 - 179ms/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "39/39 - 0s - loss: 423.6812 - mse: 2188653.2500 - val_loss: 16.4196 - val_mse: 1373.3357 - 184ms/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "39/39 - 0s - loss: 423.2831 - mse: 2064422.2500 - val_loss: 15.8378 - val_mse: 1276.0055 - 180ms/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "39/39 - 0s - loss: 434.4059 - mse: 2380234.7500 - val_loss: 16.1048 - val_mse: 1319.3114 - 186ms/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "39/39 - 0s - loss: 427.9000 - mse: 2293220.7500 - val_loss: 16.8775 - val_mse: 1448.4447 - 183ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "39/39 - 0s - loss: 439.1712 - mse: 2451444.7500 - val_loss: 16.6842 - val_mse: 1414.3086 - 183ms/epoch - 5ms/step\n",
            "Epoch 167/200\n",
            "39/39 - 0s - loss: 426.3609 - mse: 2053206.3750 - val_loss: 16.7837 - val_mse: 1430.2212 - 182ms/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "39/39 - 0s - loss: 409.8284 - mse: 2061109.6250 - val_loss: 16.8730 - val_mse: 1445.5017 - 180ms/epoch - 5ms/step\n",
            "Epoch 169/200\n",
            "39/39 - 0s - loss: 427.2519 - mse: 2290580.2500 - val_loss: 16.1293 - val_mse: 1320.1379 - 182ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "39/39 - 0s - loss: 410.2762 - mse: 1985950.3750 - val_loss: 14.8688 - val_mse: 1119.7177 - 185ms/epoch - 5ms/step\n",
            "Epoch 171/200\n",
            "39/39 - 0s - loss: 415.2781 - mse: 2117976.5000 - val_loss: 14.1875 - val_mse: 1019.0247 - 185ms/epoch - 5ms/step\n",
            "Epoch 172/200\n",
            "39/39 - 0s - loss: 418.9303 - mse: 2317006.5000 - val_loss: 12.5976 - val_mse: 801.4363 - 191ms/epoch - 5ms/step\n",
            "Epoch 173/200\n",
            "39/39 - 0s - loss: 427.8854 - mse: 2613970.7500 - val_loss: 13.6473 - val_mse: 941.4346 - 188ms/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "39/39 - 0s - loss: 401.6216 - mse: 1855306.8750 - val_loss: 13.8491 - val_mse: 969.4023 - 194ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "39/39 - 0s - loss: 409.2236 - mse: 2101509.7500 - val_loss: 14.5665 - val_mse: 1073.3468 - 197ms/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "39/39 - 0s - loss: 409.0236 - mse: 2760050.5000 - val_loss: 15.6438 - val_mse: 1238.3210 - 186ms/epoch - 5ms/step\n",
            "Epoch 177/200\n",
            "39/39 - 0s - loss: 397.9140 - mse: 1888365.0000 - val_loss: 16.4487 - val_mse: 1369.7207 - 181ms/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "39/39 - 0s - loss: 423.0776 - mse: 2519502.2500 - val_loss: 15.9357 - val_mse: 1284.6763 - 182ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "39/39 - 0s - loss: 394.8654 - mse: 1791998.3750 - val_loss: 15.7260 - val_mse: 1252.7458 - 181ms/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "39/39 - 0s - loss: 400.1440 - mse: 1902088.1250 - val_loss: 15.2409 - val_mse: 1177.1533 - 182ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "39/39 - 0s - loss: 387.5055 - mse: 1642190.2500 - val_loss: 15.1383 - val_mse: 1161.4302 - 184ms/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "39/39 - 0s - loss: 398.9789 - mse: 1739727.3750 - val_loss: 15.3201 - val_mse: 1189.7372 - 186ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "39/39 - 0s - loss: 402.4978 - mse: 1832285.5000 - val_loss: 16.5567 - val_mse: 1390.1206 - 185ms/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "39/39 - 0s - loss: 391.5610 - mse: 1962539.2500 - val_loss: 17.8203 - val_mse: 1611.1858 - 187ms/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "39/39 - 0s - loss: 390.3781 - mse: 1732761.6250 - val_loss: 18.0752 - val_mse: 1657.8246 - 198ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "39/39 - 0s - loss: 378.3562 - mse: 1681573.0000 - val_loss: 18.1839 - val_mse: 1677.8564 - 194ms/epoch - 5ms/step\n",
            "Epoch 187/200\n",
            "39/39 - 0s - loss: 367.6659 - mse: 1574957.1250 - val_loss: 18.3402 - val_mse: 1706.9525 - 190ms/epoch - 5ms/step\n",
            "Epoch 188/200\n",
            "39/39 - 0s - loss: 380.7685 - mse: 1633700.8750 - val_loss: 17.7051 - val_mse: 1589.8309 - 190ms/epoch - 5ms/step\n",
            "Epoch 189/200\n",
            "39/39 - 0s - loss: 376.2112 - mse: 1635666.6250 - val_loss: 17.3400 - val_mse: 1525.6387 - 186ms/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "39/39 - 0s - loss: 386.5897 - mse: 1791940.1250 - val_loss: 16.9589 - val_mse: 1458.0302 - 187ms/epoch - 5ms/step\n",
            "Epoch 191/200\n",
            "39/39 - 0s - loss: 386.9447 - mse: 1768268.8750 - val_loss: 16.6135 - val_mse: 1398.4961 - 183ms/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "39/39 - 0s - loss: 383.6995 - mse: 1942147.7500 - val_loss: 14.5762 - val_mse: 1075.2448 - 185ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "39/39 - 0s - loss: 387.6977 - mse: 1863051.8750 - val_loss: 15.3325 - val_mse: 1190.9583 - 185ms/epoch - 5ms/step\n",
            "Epoch 194/200\n",
            "39/39 - 0s - loss: 387.8506 - mse: 1900815.3750 - val_loss: 14.8647 - val_mse: 1118.7521 - 183ms/epoch - 5ms/step\n",
            "Epoch 195/200\n",
            "39/39 - 0s - loss: 372.6079 - mse: 1780392.1250 - val_loss: 13.1410 - val_mse: 873.9521 - 185ms/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "39/39 - 0s - loss: 381.4247 - mse: 1681138.3750 - val_loss: 12.6682 - val_mse: 812.8316 - 186ms/epoch - 5ms/step\n",
            "Epoch 197/200\n",
            "39/39 - 0s - loss: 385.1541 - mse: 2084843.7500 - val_loss: 12.3571 - val_mse: 774.1900 - 202ms/epoch - 5ms/step\n",
            "Epoch 198/200\n",
            "39/39 - 0s - loss: 358.6851 - mse: 1521179.3750 - val_loss: 11.5406 - val_mse: 675.1346 - 189ms/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "39/39 - 0s - loss: 379.1335 - mse: 1727247.7500 - val_loss: 12.0699 - val_mse: 737.8495 - 184ms/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "39/39 - 0s - loss: 360.4042 - mse: 1428145.3750 - val_loss: 12.3231 - val_mse: 769.5228 - 182ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 46 started****\n",
            "\n",
            "Epoch 1/50\n",
            "83/83 [==============================] - 2s 6ms/step - loss: 123.5740 - mse: 207850.8594 - val_loss: 9.5693 - val_mse: 458.4315\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 37.6526 - mse: 19339.0938 - val_loss: 0.1189 - val_mse: 0.3576\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 14.0804 - mse: 2633.5571 - val_loss: 1.5643 - val_mse: 16.8243\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 5.9420 - mse: 491.4145 - val_loss: 1.2374 - val_mse: 12.4569\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 2.5389 - mse: 137.0166 - val_loss: 0.1759 - val_mse: 0.6694\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - mse: 14.6509 - val_loss: 0.0468 - val_mse: 0.1076\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4890 - mse: 6.7581 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3511 - mse: 4.4798 - val_loss: 0.1235 - val_mse: 0.4016\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.1595 - mse: 1.1309 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0640 - mse: 0.2886 - val_loss: 0.0136 - val_mse: 0.0285\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0479 - mse: 0.2191 - val_loss: 0.0036 - val_mse: 0.0073\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0532 - mse: 0.2685 - val_loss: 0.0507 - val_mse: 0.1280\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0486 - mse: 0.2902 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0741 - val_loss: 0.0065 - val_mse: 0.0132\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0314 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0124 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0971 - mse: 0.4461 - val_loss: 0.0048 - val_mse: 0.0097\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0152 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0112 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0389 - mse: 0.1610 - val_loss: 0.0882 - val_mse: 0.2480\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0494 - mse: 0.1645 - val_loss: 0.0049 - val_mse: 0.0099\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0027 - val_mse: 0.0055\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0244 - val_loss: 0.0055 - val_mse: 0.0111\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0102 - val_loss: 0.0027 - val_mse: 0.0055\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0069 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0061 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0059 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0023 - val_mse: 0.0047\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0045\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0021 - val_mse: 0.0043\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0022 - val_mse: 0.0044\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0039\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 51/200\n",
            "83/83 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0019 - val_mse: 0.0038 - 370ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0018 - val_mse: 0.0037 - 302ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "83/83 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0038 - 300ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0037 - 301ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0022 - val_mse: 0.0044 - 299ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0035 - 304ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0019 - val_mse: 0.0039 - 308ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0034 - 305ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0036 - 302ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0035 - 303ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0035 - 307ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0018 - val_mse: 0.0036 - 306ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0019 - val_mse: 0.0037 - 306ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0019 - val_mse: 0.0037 - 300ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0032 - val_mse: 0.0065 - 305ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0018 - val_mse: 0.0035 - 307ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 311ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "83/83 - 0s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0033 - val_mse: 0.0066 - 307ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0034 - 314ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 317ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "83/83 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0037 - 316ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "83/83 - 0s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0019 - val_mse: 0.0038 - 304ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0042 - 302ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0019 - val_mse: 0.0038 - 302ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0019 - val_mse: 0.0039 - 306ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0019 - val_mse: 0.0039 - 305ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "83/83 - 0s - loss: 0.6387 - mse: 38.4494 - val_loss: 1.7046 - val_mse: 22.3266 - 302ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "83/83 - 0s - loss: 0.9318 - mse: 84.4694 - val_loss: 0.0030 - val_mse: 0.0060 - 303ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "83/83 - 0s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0025 - val_mse: 0.0050 - 304ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "83/83 - 0s - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0019 - val_mse: 0.0039 - 304ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "83/83 - 0s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0018 - val_mse: 0.0037 - 304ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "83/83 - 0s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0017 - val_mse: 0.0035 - 304ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "83/83 - 0s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0018 - val_mse: 0.0036 - 306ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "83/83 - 0s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0018 - val_mse: 0.0035 - 307ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0018 - val_mse: 0.0035 - 303ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0034 - 303ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0034 - 305ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0017 - val_mse: 0.0035 - 308ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0034 - 306ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0035 - 304ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0034 - 305ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 305ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0033 - 307ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 308ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 309ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 304ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 306ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 312ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0033 - 304ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 304ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 302ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 298ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0036 - 313ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 313ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0033 - 314ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 327ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 325ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 320ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 323ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 325ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 312ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 315ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 314ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 305ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 306ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 321ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0033 - 306ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0031 - 309ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 311ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 308ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 310ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 312ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 310ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0036 - 307ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0035 - 310ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0031 - 317ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0031 - 311ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 314ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 310ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 313ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 313ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 302ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 310ms/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 306ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0033 - 307ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0034 - 300ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0031 - 309ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 307ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 313ms/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 311ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 312ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0035 - 313ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "83/83 - 0s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 325ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0036 - 322ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0015 - val_mse: 0.0031 - 318ms/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0035 - 305ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 309ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 306ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 304ms/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 308ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 305ms/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0016 - val_mse: 0.0032 - 306ms/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 304ms/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0034 - 304ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 306ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032 - 303ms/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0031 - 318ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 305ms/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0035 - 306ms/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0031 - 319ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 312ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 316ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 327ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 318ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0031 - 333ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0035 - 314ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0019 - val_mse: 0.0038 - 312ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 314ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0015 - val_mse: 0.0031 - 308ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 326ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0033 - 312ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0031 - 313ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032 - 311ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0015 - val_mse: 0.0031 - 311ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0019 - val_mse: 0.0037 - 312ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0016 - val_mse: 0.0033 - 328ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0020 - val_mse: 0.0041 - 319ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 321ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 320ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0031 - 322ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0035 - 325ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0031 - 317ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0034 - 310ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0018 - val_mse: 0.0036 - 309ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 308ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033 - 310ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 311ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0016 - val_mse: 0.0032 - 309ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0034 - 308ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0033 - 310ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0034 - 310ms/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 313ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0017 - val_mse: 0.0033 - 302ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "83/83 - 0s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0032 - 302ms/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "83/83 - 0s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0016 - val_mse: 0.0031 - 298ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 47 started****\n",
            "\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 3s 23ms/step - loss: 431.4014 - mse: 2086241.1250 - val_loss: 1.1666 - val_mse: 12.4785\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 254.9255 - mse: 795978.6250 - val_loss: 1.5980 - val_mse: 21.0410\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 175.3787 - mse: 360055.0938 - val_loss: 0.2083 - val_mse: 0.5656\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 107.4191 - mse: 137572.3125 - val_loss: 0.4296 - val_mse: 2.1896\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 71.1381 - mse: 48412.8516 - val_loss: 0.6170 - val_mse: 3.3320\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 49.8145 - mse: 31622.4629 - val_loss: 0.0833 - val_mse: 0.1791\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 34.8858 - mse: 16410.1680 - val_loss: 0.1173 - val_mse: 0.2919\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 21.0924 - mse: 5058.2788 - val_loss: 0.1130 - val_mse: 0.3404\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 14.1946 - mse: 2822.4053 - val_loss: 0.0538 - val_mse: 0.1228\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.4049 - mse: 918.2838 - val_loss: 0.0221 - val_mse: 0.0451\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.1844 - mse: 395.9649 - val_loss: 0.0233 - val_mse: 0.0482\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1211 - mse: 163.0799 - val_loss: 0.0176 - val_mse: 0.0356\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.5815 - mse: 43.9136 - val_loss: 0.0129 - val_mse: 0.0259\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.8830 - mse: 18.4849 - val_loss: 0.0109 - val_mse: 0.0219\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5052 - mse: 6.2983 - val_loss: 0.0090 - val_mse: 0.0181\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3007 - mse: 2.4271 - val_loss: 0.0103 - val_mse: 0.0208\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2742 - mse: 2.7568 - val_loss: 0.0077 - val_mse: 0.0155\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3722 - mse: 4.2471 - val_loss: 0.0081 - val_mse: 0.0165\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3455 - mse: 2.9871 - val_loss: 0.0089 - val_mse: 0.0186\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3475 - mse: 2.8983 - val_loss: 0.0075 - val_mse: 0.0152\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6398 - mse: 8.8285 - val_loss: 0.0075 - val_mse: 0.0155\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2382 - mse: 1.7725 - val_loss: 0.0107 - val_mse: 0.0216\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1960 - mse: 1.9048 - val_loss: 0.0067 - val_mse: 0.0135\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2589 - mse: 2.2643 - val_loss: 0.0058 - val_mse: 0.0117\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1672 - mse: 1.0048 - val_loss: 0.0076 - val_mse: 0.0153\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1411 - mse: 0.8200 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1850 - mse: 1.3439 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2585 - mse: 2.1790 - val_loss: 0.0058 - val_mse: 0.0118\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2798 - mse: 2.1922 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1743 - mse: 1.1022 - val_loss: 0.0056 - val_mse: 0.0114\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1679 - mse: 1.1893 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2652 - mse: 2.2423 - val_loss: 0.0067 - val_mse: 0.0135\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.4124 - mse: 3.7853 - val_loss: 0.0135 - val_mse: 0.0295\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1762 - mse: 1.2352 - val_loss: 0.0081 - val_mse: 0.0164\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1403 - mse: 1.0173 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.4075 - mse: 4.2901 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2621 - mse: 1.9864 - val_loss: 0.0067 - val_mse: 0.0134\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1185 - mse: 0.6563 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1779 - mse: 1.1759 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0958 - mse: 0.4895 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1096 - mse: 0.5264 - val_loss: 0.0068 - val_mse: 0.0138\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1206 - mse: 0.6739 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0856 - mse: 0.4006 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3253 - mse: 2.8278 - val_loss: 0.0275 - val_mse: 0.0653\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1690 - mse: 1.3463 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0821 - mse: 0.3794 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0938 - mse: 0.4935 - val_loss: 0.0040 - val_mse: 0.0081\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1472 - mse: 0.8981 - val_loss: 0.0086 - val_mse: 0.0173\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1379 - mse: 0.7500 - val_loss: 0.0087 - val_mse: 0.0176\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1341 - mse: 0.8989 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 51/200\n",
            "45/45 - 0s - loss: 0.2090 - mse: 1.7688 - val_loss: 0.0036 - val_mse: 0.0072 - 273ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "45/45 - 0s - loss: 0.2211 - mse: 1.8526 - val_loss: 0.0047 - val_mse: 0.0094 - 190ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "45/45 - 0s - loss: 0.1315 - mse: 0.7386 - val_loss: 0.0055 - val_mse: 0.0110 - 190ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "45/45 - 0s - loss: 0.1543 - mse: 0.9708 - val_loss: 0.0037 - val_mse: 0.0074 - 191ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "45/45 - 0s - loss: 0.1693 - mse: 1.1298 - val_loss: 0.0081 - val_mse: 0.0164 - 194ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "45/45 - 0s - loss: 0.0891 - mse: 0.4351 - val_loss: 0.0055 - val_mse: 0.0110 - 192ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "45/45 - 0s - loss: 0.1053 - mse: 0.5473 - val_loss: 0.0062 - val_mse: 0.0124 - 192ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "45/45 - 0s - loss: 0.0727 - mse: 0.3333 - val_loss: 0.0085 - val_mse: 0.0171 - 191ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "45/45 - 0s - loss: 0.3222 - mse: 3.3440 - val_loss: 0.0036 - val_mse: 0.0072 - 195ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "45/45 - 0s - loss: 0.1387 - mse: 0.8144 - val_loss: 0.0066 - val_mse: 0.0133 - 192ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "45/45 - 0s - loss: 0.0977 - mse: 0.5272 - val_loss: 0.0048 - val_mse: 0.0097 - 193ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "45/45 - 0s - loss: 0.0817 - mse: 0.4250 - val_loss: 0.0038 - val_mse: 0.0077 - 193ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "45/45 - 0s - loss: 0.0936 - mse: 0.4786 - val_loss: 0.0040 - val_mse: 0.0080 - 191ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "45/45 - 0s - loss: 0.1299 - mse: 0.6960 - val_loss: 0.0039 - val_mse: 0.0078 - 191ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "45/45 - 0s - loss: 0.1866 - mse: 1.3307 - val_loss: 0.0072 - val_mse: 0.0145 - 193ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "45/45 - 0s - loss: 0.1477 - mse: 0.8552 - val_loss: 0.0044 - val_mse: 0.0087 - 190ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "45/45 - 0s - loss: 0.0838 - mse: 0.4427 - val_loss: 0.0052 - val_mse: 0.0104 - 196ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "45/45 - 0s - loss: 0.0904 - mse: 0.4951 - val_loss: 0.0044 - val_mse: 0.0088 - 191ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "45/45 - 0s - loss: 0.2176 - mse: 1.8031 - val_loss: 0.0051 - val_mse: 0.0104 - 193ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "45/45 - 0s - loss: 0.1255 - mse: 0.7998 - val_loss: 0.0085 - val_mse: 0.0172 - 203ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "45/45 - 0s - loss: 0.0545 - mse: 0.2057 - val_loss: 0.0045 - val_mse: 0.0091 - 198ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "45/45 - 0s - loss: 0.0652 - mse: 0.2931 - val_loss: 0.0053 - val_mse: 0.0105 - 195ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "45/45 - 0s - loss: 0.0561 - mse: 0.2279 - val_loss: 0.0047 - val_mse: 0.0094 - 197ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "45/45 - 0s - loss: 0.1486 - mse: 1.0597 - val_loss: 0.0035 - val_mse: 0.0070 - 197ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "45/45 - 0s - loss: 0.0910 - mse: 0.4786 - val_loss: 0.0060 - val_mse: 0.0121 - 196ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "45/45 - 0s - loss: 0.0844 - mse: 0.4531 - val_loss: 0.0034 - val_mse: 0.0068 - 200ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "45/45 - 0s - loss: 0.1093 - mse: 0.5927 - val_loss: 0.0040 - val_mse: 0.0081 - 203ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "45/45 - 0s - loss: 0.2132 - mse: 1.5230 - val_loss: 0.0082 - val_mse: 0.0165 - 198ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "45/45 - 0s - loss: 0.0754 - mse: 0.3599 - val_loss: 0.0041 - val_mse: 0.0082 - 201ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "45/45 - 0s - loss: 0.1266 - mse: 0.7867 - val_loss: 0.0086 - val_mse: 0.0174 - 194ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "45/45 - 0s - loss: 0.0425 - mse: 0.1577 - val_loss: 0.0038 - val_mse: 0.0076 - 192ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "45/45 - 0s - loss: 0.1385 - mse: 0.7492 - val_loss: 0.0040 - val_mse: 0.0080 - 195ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "45/45 - 0s - loss: 0.0802 - mse: 0.3478 - val_loss: 0.0073 - val_mse: 0.0148 - 192ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "45/45 - 0s - loss: 0.0834 - mse: 0.4719 - val_loss: 0.0069 - val_mse: 0.0139 - 194ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "45/45 - 0s - loss: 0.0309 - mse: 0.1034 - val_loss: 0.0041 - val_mse: 0.0082 - 192ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "45/45 - 0s - loss: 0.0306 - mse: 0.1016 - val_loss: 0.0039 - val_mse: 0.0079 - 197ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "45/45 - 0s - loss: 0.0680 - mse: 0.3120 - val_loss: 0.0034 - val_mse: 0.0069 - 192ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "45/45 - 0s - loss: 0.1223 - mse: 0.6629 - val_loss: 0.0039 - val_mse: 0.0079 - 191ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "45/45 - 0s - loss: 0.0671 - mse: 0.3608 - val_loss: 0.0053 - val_mse: 0.0105 - 195ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "45/45 - 0s - loss: 0.0720 - mse: 0.3448 - val_loss: 0.0085 - val_mse: 0.0172 - 193ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "45/45 - 0s - loss: 0.0561 - mse: 0.2356 - val_loss: 0.0038 - val_mse: 0.0076 - 194ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "45/45 - 0s - loss: 0.0359 - mse: 0.1238 - val_loss: 0.0067 - val_mse: 0.0134 - 197ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "45/45 - 0s - loss: 0.0313 - mse: 0.1303 - val_loss: 0.0078 - val_mse: 0.0156 - 196ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "45/45 - 0s - loss: 0.0465 - mse: 0.2115 - val_loss: 0.0066 - val_mse: 0.0133 - 191ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "45/45 - 0s - loss: 0.0607 - mse: 0.3149 - val_loss: 0.0036 - val_mse: 0.0072 - 199ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "45/45 - 0s - loss: 0.1979 - mse: 1.4859 - val_loss: 0.0039 - val_mse: 0.0078 - 192ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "45/45 - 0s - loss: 0.0701 - mse: 0.3216 - val_loss: 0.0032 - val_mse: 0.0063 - 195ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "45/45 - 0s - loss: 0.0605 - mse: 0.2945 - val_loss: 0.0037 - val_mse: 0.0074 - 188ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "45/45 - 0s - loss: 0.0984 - mse: 0.4760 - val_loss: 0.0084 - val_mse: 0.0168 - 189ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "45/45 - 0s - loss: 0.0359 - mse: 0.1303 - val_loss: 0.0043 - val_mse: 0.0086 - 191ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "45/45 - 0s - loss: 0.0400 - mse: 0.1626 - val_loss: 0.0072 - val_mse: 0.0144 - 192ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "45/45 - 0s - loss: 0.0223 - mse: 0.0734 - val_loss: 0.0077 - val_mse: 0.0156 - 188ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "45/45 - 0s - loss: 0.0210 - mse: 0.0592 - val_loss: 0.0037 - val_mse: 0.0075 - 202ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "45/45 - 0s - loss: 0.0193 - mse: 0.0541 - val_loss: 0.0084 - val_mse: 0.0169 - 188ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "45/45 - 0s - loss: 0.0346 - mse: 0.1199 - val_loss: 0.0084 - val_mse: 0.0169 - 195ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "45/45 - 0s - loss: 0.0554 - mse: 0.2607 - val_loss: 0.0032 - val_mse: 0.0065 - 191ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "45/45 - 0s - loss: 0.0478 - mse: 0.1943 - val_loss: 0.0030 - val_mse: 0.0061 - 196ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "45/45 - 0s - loss: 0.0511 - mse: 0.1937 - val_loss: 0.0060 - val_mse: 0.0120 - 201ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "45/45 - 0s - loss: 0.0505 - mse: 0.2148 - val_loss: 0.0052 - val_mse: 0.0105 - 192ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "45/45 - 0s - loss: 0.0470 - mse: 0.2222 - val_loss: 0.0056 - val_mse: 0.0112 - 191ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "45/45 - 0s - loss: 0.0993 - mse: 0.5464 - val_loss: 0.0045 - val_mse: 0.0090 - 191ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "45/45 - 0s - loss: 0.0698 - mse: 0.3603 - val_loss: 0.0071 - val_mse: 0.0143 - 189ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "45/45 - 0s - loss: 0.0229 - mse: 0.0696 - val_loss: 0.0052 - val_mse: 0.0104 - 190ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "45/45 - 0s - loss: 0.0133 - mse: 0.0336 - val_loss: 0.0056 - val_mse: 0.0113 - 198ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "45/45 - 0s - loss: 0.0140 - mse: 0.0363 - val_loss: 0.0036 - val_mse: 0.0073 - 199ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "45/45 - 0s - loss: 0.0186 - mse: 0.0519 - val_loss: 0.0045 - val_mse: 0.0091 - 192ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "45/45 - 0s - loss: 0.0161 - mse: 0.0441 - val_loss: 0.0050 - val_mse: 0.0100 - 192ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "45/45 - 0s - loss: 0.0362 - mse: 0.1386 - val_loss: 0.0037 - val_mse: 0.0073 - 193ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "45/45 - 0s - loss: 0.0268 - mse: 0.0822 - val_loss: 0.0048 - val_mse: 0.0096 - 197ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "45/45 - 0s - loss: 0.0314 - mse: 0.1119 - val_loss: 0.0036 - val_mse: 0.0072 - 193ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "45/45 - 0s - loss: 0.1215 - mse: 0.6851 - val_loss: 0.0050 - val_mse: 0.0101 - 192ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "45/45 - 0s - loss: 0.1011 - mse: 0.6816 - val_loss: 0.0053 - val_mse: 0.0105 - 195ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "45/45 - 0s - loss: 0.0171 - mse: 0.0502 - val_loss: 0.0058 - val_mse: 0.0116 - 193ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "45/45 - 0s - loss: 0.0173 - mse: 0.0492 - val_loss: 0.0036 - val_mse: 0.0073 - 203ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "45/45 - 0s - loss: 0.0152 - mse: 0.0403 - val_loss: 0.0066 - val_mse: 0.0133 - 190ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "45/45 - 0s - loss: 0.0185 - mse: 0.0575 - val_loss: 0.0037 - val_mse: 0.0075 - 191ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "45/45 - 0s - loss: 0.0615 - mse: 0.3095 - val_loss: 0.0075 - val_mse: 0.0151 - 189ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "45/45 - 0s - loss: 0.0190 - mse: 0.0600 - val_loss: 0.0078 - val_mse: 0.0158 - 193ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "45/45 - 0s - loss: 0.0193 - mse: 0.0569 - val_loss: 0.0048 - val_mse: 0.0096 - 200ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "45/45 - 0s - loss: 0.0198 - mse: 0.0755 - val_loss: 0.0033 - val_mse: 0.0067 - 194ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "45/45 - 0s - loss: 0.0410 - mse: 0.1631 - val_loss: 0.0038 - val_mse: 0.0076 - 201ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "45/45 - 0s - loss: 0.0150 - mse: 0.0419 - val_loss: 0.0078 - val_mse: 0.0157 - 193ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "45/45 - 0s - loss: 0.0126 - mse: 0.0316 - val_loss: 0.0050 - val_mse: 0.0100 - 196ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "45/45 - 0s - loss: 0.0137 - mse: 0.0340 - val_loss: 0.0055 - val_mse: 0.0111 - 198ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "45/45 - 0s - loss: 0.0106 - mse: 0.0242 - val_loss: 0.0036 - val_mse: 0.0072 - 194ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "45/45 - 0s - loss: 0.0148 - mse: 0.0416 - val_loss: 0.0050 - val_mse: 0.0100 - 197ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "45/45 - 0s - loss: 0.0112 - mse: 0.0282 - val_loss: 0.0083 - val_mse: 0.0168 - 204ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 48 started****\n",
            "\n",
            "Epoch 1/50\n",
            "51/51 [==============================] - 2s 8ms/step - loss: 2833.6943 - mse: 46372720.0000 - val_loss: 2650.5989 - val_mse: 35657404.0000\n",
            "Epoch 2/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2797.5828 - mse: 44459036.0000 - val_loss: 2614.0820 - val_mse: 34682280.0000\n",
            "Epoch 3/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2776.3591 - mse: 45249920.0000 - val_loss: 2576.6553 - val_mse: 33696988.0000\n",
            "Epoch 4/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 2762.0249 - mse: 44250804.0000 - val_loss: 2539.8420 - val_mse: 32741606.0000\n",
            "Epoch 5/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2679.2996 - mse: 41793096.0000 - val_loss: 2502.6140 - val_mse: 31789414.0000\n",
            "Epoch 6/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2638.2131 - mse: 39323088.0000 - val_loss: 2466.1614 - val_mse: 30870670.0000\n",
            "Epoch 7/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2548.2795 - mse: 37049948.0000 - val_loss: 2431.4788 - val_mse: 30008954.0000\n",
            "Epoch 8/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 2565.3276 - mse: 39021164.0000 - val_loss: 2395.6443 - val_mse: 29131568.0000\n",
            "Epoch 9/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 2529.0454 - mse: 36256244.0000 - val_loss: 2359.5288 - val_mse: 28260346.0000\n",
            "Epoch 10/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2528.2695 - mse: 37981328.0000 - val_loss: 2324.2302 - val_mse: 27421594.0000\n",
            "Epoch 11/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2470.0376 - mse: 35735632.0000 - val_loss: 2288.9407 - val_mse: 26595746.0000\n",
            "Epoch 12/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2451.1094 - mse: 35913432.0000 - val_loss: 2254.2068 - val_mse: 25795158.0000\n",
            "Epoch 13/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 2401.7212 - mse: 34243380.0000 - val_loss: 2218.5522 - val_mse: 24986014.0000\n",
            "Epoch 14/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2386.4685 - mse: 32939328.0000 - val_loss: 2185.3882 - val_mse: 24245082.0000\n",
            "Epoch 15/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2310.5723 - mse: 30431072.0000 - val_loss: 2150.7402 - val_mse: 23482790.0000\n",
            "Epoch 16/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2247.8655 - mse: 28975350.0000 - val_loss: 2116.5781 - val_mse: 22743148.0000\n",
            "Epoch 17/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2245.2817 - mse: 29550408.0000 - val_loss: 2083.0566 - val_mse: 22028834.0000\n",
            "Epoch 18/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2255.5676 - mse: 31195300.0000 - val_loss: 2049.8254 - val_mse: 21331940.0000\n",
            "Epoch 19/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2154.2883 - mse: 28081580.0000 - val_loss: 2016.4111 - val_mse: 20642556.0000\n",
            "Epoch 20/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2184.1582 - mse: 28830862.0000 - val_loss: 1982.3688 - val_mse: 19951760.0000\n",
            "Epoch 21/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 2105.7036 - mse: 26247116.0000 - val_loss: 1949.7949 - val_mse: 19301782.0000\n",
            "Epoch 22/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2121.4050 - mse: 28675956.0000 - val_loss: 1916.6508 - val_mse: 18651500.0000\n",
            "Epoch 23/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2061.6443 - mse: 25675742.0000 - val_loss: 1883.7825 - val_mse: 18017578.0000\n",
            "Epoch 24/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1998.1858 - mse: 24236774.0000 - val_loss: 1852.0647 - val_mse: 17416254.0000\n",
            "Epoch 25/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 2004.7543 - mse: 24529030.0000 - val_loss: 1819.8469 - val_mse: 16815920.0000\n",
            "Epoch 26/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1991.5173 - mse: 24993740.0000 - val_loss: 1788.4707 - val_mse: 16241328.0000\n",
            "Epoch 27/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1943.8566 - mse: 23459292.0000 - val_loss: 1757.5809 - val_mse: 15685409.0000\n",
            "Epoch 28/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1883.3805 - mse: 21388054.0000 - val_loss: 1726.5106 - val_mse: 15136040.0000\n",
            "Epoch 29/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1868.4182 - mse: 21889062.0000 - val_loss: 1695.6265 - val_mse: 14599599.0000\n",
            "Epoch 30/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1801.7983 - mse: 20632744.0000 - val_loss: 1664.9692 - val_mse: 14076683.0000\n",
            "Epoch 31/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1791.1179 - mse: 19802418.0000 - val_loss: 1634.4329 - val_mse: 13565323.0000\n",
            "Epoch 32/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1791.1019 - mse: 20464258.0000 - val_loss: 1603.0779 - val_mse: 13050062.0000\n",
            "Epoch 33/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1782.1842 - mse: 20805096.0000 - val_loss: 1573.3149 - val_mse: 12570203.0000\n",
            "Epoch 34/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1746.8311 - mse: 19316062.0000 - val_loss: 1542.5211 - val_mse: 12083182.0000\n",
            "Epoch 35/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1724.7520 - mse: 19831956.0000 - val_loss: 1512.3048 - val_mse: 11614614.0000\n",
            "Epoch 36/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1683.5299 - mse: 18366786.0000 - val_loss: 1483.3254 - val_mse: 11173950.0000\n",
            "Epoch 37/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1639.2230 - mse: 16373689.0000 - val_loss: 1454.0082 - val_mse: 10736830.0000\n",
            "Epoch 38/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1598.7820 - mse: 16156974.0000 - val_loss: 1425.4464 - val_mse: 10319324.0000\n",
            "Epoch 39/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1552.5558 - mse: 15610950.0000 - val_loss: 1397.2573 - val_mse: 9915387.0000\n",
            "Epoch 40/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1553.9244 - mse: 14891701.0000 - val_loss: 1368.4019 - val_mse: 9510247.0000\n",
            "Epoch 41/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1563.0424 - mse: 16450084.0000 - val_loss: 1340.5200 - val_mse: 9126821.0000\n",
            "Epoch 42/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1509.7843 - mse: 14557514.0000 - val_loss: 1312.0347 - val_mse: 8743217.0000\n",
            "Epoch 43/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1492.1340 - mse: 14528895.0000 - val_loss: 1283.4823 - val_mse: 8366957.5000\n",
            "Epoch 44/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1470.2540 - mse: 14173625.0000 - val_loss: 1255.3623 - val_mse: 8004507.0000\n",
            "Epoch 45/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1445.1990 - mse: 14691560.0000 - val_loss: 1227.3918 - val_mse: 7651931.0000\n",
            "Epoch 46/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1410.4152 - mse: 13596418.0000 - val_loss: 1200.8411 - val_mse: 7324578.5000\n",
            "Epoch 47/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1435.0671 - mse: 13810808.0000 - val_loss: 1172.2380 - val_mse: 6979956.5000\n",
            "Epoch 48/50\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 1359.9313 - mse: 12165714.0000 - val_loss: 1145.5322 - val_mse: 6665657.5000\n",
            "Epoch 49/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1345.3347 - mse: 12191700.0000 - val_loss: 1119.4661 - val_mse: 6365871.5000\n",
            "Epoch 50/50\n",
            "51/51 [==============================] - 0s 5ms/step - loss: 1327.4019 - mse: 11833795.0000 - val_loss: 1092.2657 - val_mse: 6060406.0000\n",
            "Epoch 51/200\n",
            "51/51 - 0s - loss: 1284.1605 - mse: 11080544.0000 - val_loss: 1065.0995 - val_mse: 5762800.0000 - 267ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "51/51 - 0s - loss: 1294.3840 - mse: 11135486.0000 - val_loss: 1038.0753 - val_mse: 5474177.5000 - 203ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "51/51 - 0s - loss: 1243.9180 - mse: 9941322.0000 - val_loss: 1011.6086 - val_mse: 5198696.5000 - 206ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "51/51 - 0s - loss: 1261.8873 - mse: 11855880.0000 - val_loss: 986.1470 - val_mse: 4940398.5000 - 204ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "51/51 - 0s - loss: 1199.9060 - mse: 9889438.0000 - val_loss: 959.7896 - val_mse: 4679926.5000 - 201ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "51/51 - 0s - loss: 1208.9454 - mse: 10192089.0000 - val_loss: 934.6338 - val_mse: 4437905.5000 - 203ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "51/51 - 0s - loss: 1146.7012 - mse: 9018776.0000 - val_loss: 910.0563 - val_mse: 4207660.5000 - 202ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "51/51 - 0s - loss: 1143.8931 - mse: 9186838.0000 - val_loss: 884.5140 - val_mse: 3974864.7500 - 223ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "51/51 - 0s - loss: 1140.3875 - mse: 9670911.0000 - val_loss: 860.9483 - val_mse: 3765960.0000 - 209ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "51/51 - 0s - loss: 1107.2881 - mse: 8725788.0000 - val_loss: 837.3760 - val_mse: 3562631.5000 - 203ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "51/51 - 0s - loss: 1126.5798 - mse: 9683813.0000 - val_loss: 813.2827 - val_mse: 3360648.0000 - 205ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "51/51 - 0s - loss: 1078.7356 - mse: 8247215.5000 - val_loss: 789.7324 - val_mse: 3168908.7500 - 207ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "51/51 - 0s - loss: 1050.1372 - mse: 7592856.0000 - val_loss: 765.7371 - val_mse: 2979324.5000 - 205ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "51/51 - 0s - loss: 1059.5287 - mse: 8786325.0000 - val_loss: 743.0914 - val_mse: 2805775.0000 - 205ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "51/51 - 0s - loss: 1013.9366 - mse: 7285400.5000 - val_loss: 721.3074 - val_mse: 2643741.7500 - 206ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "51/51 - 0s - loss: 1016.7310 - mse: 7864611.5000 - val_loss: 699.1083 - val_mse: 2483568.7500 - 203ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "51/51 - 0s - loss: 1017.6371 - mse: 8057908.5000 - val_loss: 676.5822 - val_mse: 2326152.0000 - 202ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "51/51 - 0s - loss: 950.7372 - mse: 6499057.0000 - val_loss: 655.5999 - val_mse: 2184165.2500 - 204ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "51/51 - 0s - loss: 955.5449 - mse: 6671086.5000 - val_loss: 635.2167 - val_mse: 2050508.5000 - 203ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "51/51 - 0s - loss: 964.5852 - mse: 7084442.0000 - val_loss: 614.0709 - val_mse: 1916307.0000 - 204ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "51/51 - 0s - loss: 934.6999 - mse: 6406747.0000 - val_loss: 593.2135 - val_mse: 1788384.8750 - 209ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "51/51 - 0s - loss: 944.2546 - mse: 6911185.0000 - val_loss: 572.2102 - val_mse: 1664033.2500 - 210ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "51/51 - 0s - loss: 888.7241 - mse: 6229880.0000 - val_loss: 551.7479 - val_mse: 1547187.7500 - 212ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "51/51 - 0s - loss: 894.0204 - mse: 6349308.5000 - val_loss: 531.4533 - val_mse: 1435498.7500 - 207ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "51/51 - 0s - loss: 885.6894 - mse: 5847990.0000 - val_loss: 511.9840 - val_mse: 1332289.7500 - 205ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "51/51 - 0s - loss: 878.7911 - mse: 6272383.5000 - val_loss: 492.5518 - val_mse: 1233108.5000 - 208ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "51/51 - 0s - loss: 859.0613 - mse: 6040165.5000 - val_loss: 471.9031 - val_mse: 1131922.1250 - 209ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "51/51 - 0s - loss: 823.1906 - mse: 5425524.5000 - val_loss: 451.5038 - val_mse: 1036209.1250 - 208ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "51/51 - 0s - loss: 842.5269 - mse: 6021696.5000 - val_loss: 432.4746 - val_mse: 950737.3125 - 206ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "51/51 - 0s - loss: 819.0411 - mse: 5508560.0000 - val_loss: 413.8084 - val_mse: 870465.0000 - 207ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "51/51 - 0s - loss: 833.5189 - mse: 5762512.5000 - val_loss: 395.5339 - val_mse: 795307.0625 - 212ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "51/51 - 0s - loss: 804.4333 - mse: 5549765.0000 - val_loss: 376.5080 - val_mse: 720663.5625 - 210ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "51/51 - 0s - loss: 802.2711 - mse: 5327904.0000 - val_loss: 358.5459 - val_mse: 653566.5000 - 211ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "51/51 - 0s - loss: 790.7778 - mse: 5167153.0000 - val_loss: 340.6308 - val_mse: 589910.0625 - 208ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "51/51 - 0s - loss: 775.6902 - mse: 5129553.5000 - val_loss: 322.5257 - val_mse: 528890.2500 - 208ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "51/51 - 0s - loss: 764.4656 - mse: 5139025.0000 - val_loss: 306.3257 - val_mse: 477115.1875 - 207ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "51/51 - 0s - loss: 765.0284 - mse: 4996916.5000 - val_loss: 290.9136 - val_mse: 430331.9688 - 215ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "51/51 - 0s - loss: 761.2677 - mse: 5175400.0000 - val_loss: 274.0395 - val_mse: 381877.0625 - 210ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "51/51 - 0s - loss: 747.2469 - mse: 4686979.5000 - val_loss: 256.2095 - val_mse: 333821.5625 - 210ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "51/51 - 0s - loss: 727.1608 - mse: 4599301.5000 - val_loss: 239.8703 - val_mse: 292618.6562 - 210ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "51/51 - 0s - loss: 738.5906 - mse: 4788197.0000 - val_loss: 224.3162 - val_mse: 255916.8281 - 217ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "51/51 - 0s - loss: 739.4123 - mse: 5033109.5000 - val_loss: 209.2115 - val_mse: 222627.1250 - 210ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "51/51 - 0s - loss: 708.6436 - mse: 4379270.0000 - val_loss: 193.8274 - val_mse: 191104.9844 - 209ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "51/51 - 0s - loss: 710.0349 - mse: 4703023.0000 - val_loss: 178.4734 - val_mse: 162041.7031 - 210ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "51/51 - 0s - loss: 718.4703 - mse: 4637991.5000 - val_loss: 165.0255 - val_mse: 138554.4844 - 210ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "51/51 - 0s - loss: 694.3586 - mse: 4301965.5000 - val_loss: 151.1544 - val_mse: 116254.1719 - 209ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "51/51 - 0s - loss: 683.0256 - mse: 4306269.5000 - val_loss: 137.1789 - val_mse: 95762.3203 - 217ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "51/51 - 0s - loss: 680.0331 - mse: 4471078.0000 - val_loss: 122.2992 - val_mse: 76126.4141 - 214ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "51/51 - 0s - loss: 680.6342 - mse: 4357444.5000 - val_loss: 109.5587 - val_mse: 61101.8711 - 219ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "51/51 - 0s - loss: 692.5613 - mse: 4867270.0000 - val_loss: 96.5405 - val_mse: 47453.7500 - 217ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "51/51 - 0s - loss: 694.4697 - mse: 4637196.5000 - val_loss: 85.8212 - val_mse: 37509.0117 - 206ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "51/51 - 0s - loss: 669.6544 - mse: 4527414.5000 - val_loss: 74.6264 - val_mse: 28369.5957 - 205ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "51/51 - 0s - loss: 648.3286 - mse: 3941821.0000 - val_loss: 62.8985 - val_mse: 20161.2617 - 208ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "51/51 - 0s - loss: 655.3241 - mse: 4138552.0000 - val_loss: 51.0845 - val_mse: 13306.1162 - 208ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "51/51 - 0s - loss: 635.3892 - mse: 4217917.0000 - val_loss: 38.2092 - val_mse: 7450.8770 - 207ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "51/51 - 0s - loss: 652.9881 - mse: 4396581.5000 - val_loss: 28.3374 - val_mse: 4103.0234 - 206ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "51/51 - 0s - loss: 632.2077 - mse: 3812842.2500 - val_loss: 18.6458 - val_mse: 1780.1794 - 207ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "51/51 - 0s - loss: 621.5305 - mse: 3895201.2500 - val_loss: 10.4122 - val_mse: 557.2986 - 206ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "51/51 - 0s - loss: 633.8107 - mse: 3771824.5000 - val_loss: 1.0091 - val_mse: 5.3704 - 207ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "51/51 - 0s - loss: 646.3163 - mse: 4328892.5000 - val_loss: 0.2186 - val_mse: 0.4853 - 205ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "51/51 - 0s - loss: 623.5099 - mse: 3791983.5000 - val_loss: 0.2171 - val_mse: 0.4792 - 204ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "51/51 - 0s - loss: 623.2773 - mse: 4207680.0000 - val_loss: 0.2500 - val_mse: 0.5462 - 204ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "51/51 - 0s - loss: 617.7067 - mse: 3966460.0000 - val_loss: 0.2371 - val_mse: 0.5658 - 200ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "51/51 - 0s - loss: 642.6572 - mse: 4302211.5000 - val_loss: 0.2183 - val_mse: 0.4762 - 200ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "51/51 - 0s - loss: 624.7394 - mse: 3675907.2500 - val_loss: 0.2605 - val_mse: 0.5703 - 202ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "51/51 - 0s - loss: 649.6042 - mse: 3949521.2500 - val_loss: 0.2156 - val_mse: 0.4705 - 209ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "51/51 - 0s - loss: 637.9682 - mse: 4148451.0000 - val_loss: 0.2153 - val_mse: 0.4700 - 207ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "51/51 - 0s - loss: 607.6529 - mse: 3650704.7500 - val_loss: 0.2853 - val_mse: 0.8206 - 204ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "51/51 - 0s - loss: 621.0950 - mse: 3644546.2500 - val_loss: 0.2701 - val_mse: 0.7346 - 206ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "51/51 - 0s - loss: 588.4033 - mse: 3231747.7500 - val_loss: 0.2244 - val_mse: 0.4897 - 201ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "51/51 - 0s - loss: 629.3134 - mse: 3914339.0000 - val_loss: 0.2886 - val_mse: 0.8409 - 201ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "51/51 - 0s - loss: 606.2072 - mse: 3375821.7500 - val_loss: 0.2282 - val_mse: 0.4979 - 204ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "51/51 - 0s - loss: 620.9654 - mse: 3916845.5000 - val_loss: 0.4308 - val_mse: 1.1261 - 202ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "51/51 - 0s - loss: 614.5031 - mse: 4256980.5000 - val_loss: 0.2146 - val_mse: 0.4703 - 202ms/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "51/51 - 0s - loss: 609.6316 - mse: 3574261.7500 - val_loss: 0.2548 - val_mse: 0.5571 - 200ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "51/51 - 0s - loss: 606.6005 - mse: 3518936.2500 - val_loss: 0.2150 - val_mse: 0.4725 - 213ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "51/51 - 0s - loss: 621.4474 - mse: 4167660.5000 - val_loss: 0.2145 - val_mse: 0.4701 - 204ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "51/51 - 0s - loss: 612.4099 - mse: 3538926.7500 - val_loss: 0.2146 - val_mse: 0.4681 - 203ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "51/51 - 0s - loss: 607.3242 - mse: 3656355.2500 - val_loss: 0.3798 - val_mse: 1.4696 - 212ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "51/51 - 0s - loss: 618.9518 - mse: 4142725.5000 - val_loss: 0.3918 - val_mse: 1.5637 - 214ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "51/51 - 0s - loss: 609.3122 - mse: 3398151.2500 - val_loss: 0.2215 - val_mse: 0.4830 - 209ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "51/51 - 0s - loss: 616.7047 - mse: 3908231.5000 - val_loss: 0.2276 - val_mse: 0.4964 - 203ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "51/51 - 0s - loss: 591.3465 - mse: 3477805.2500 - val_loss: 0.4171 - val_mse: 1.7721 - 201ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "51/51 - 0s - loss: 571.7910 - mse: 3407535.2500 - val_loss: 0.2859 - val_mse: 0.6333 - 200ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "51/51 - 0s - loss: 576.0496 - mse: 3267108.0000 - val_loss: 0.3615 - val_mse: 0.8622 - 208ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "51/51 - 0s - loss: 597.7423 - mse: 3265478.7500 - val_loss: 0.2606 - val_mse: 0.6870 - 199ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "51/51 - 0s - loss: 583.6802 - mse: 3721656.2500 - val_loss: 0.3224 - val_mse: 1.0583 - 197ms/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "51/51 - 0s - loss: 584.7753 - mse: 3332463.7500 - val_loss: 0.2232 - val_mse: 0.4868 - 200ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "51/51 - 0s - loss: 588.6109 - mse: 3717393.7500 - val_loss: 0.5221 - val_mse: 1.5624 - 202ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "51/51 - 0s - loss: 553.9590 - mse: 3231791.0000 - val_loss: 0.2164 - val_mse: 0.4716 - 200ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "51/51 - 0s - loss: 581.0887 - mse: 3332368.7500 - val_loss: 0.2496 - val_mse: 0.6317 - 205ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "51/51 - 0s - loss: 590.6176 - mse: 3320495.2500 - val_loss: 0.4513 - val_mse: 2.0750 - 201ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "51/51 - 0s - loss: 583.6018 - mse: 3283714.5000 - val_loss: 0.2341 - val_mse: 0.5574 - 200ms/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "51/51 - 0s - loss: 584.2574 - mse: 3522207.5000 - val_loss: 0.2234 - val_mse: 0.5104 - 201ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "51/51 - 0s - loss: 577.8251 - mse: 3140485.2500 - val_loss: 0.2634 - val_mse: 0.7045 - 213ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "51/51 - 0s - loss: 565.9570 - mse: 3068865.5000 - val_loss: 0.2333 - val_mse: 0.5547 - 202ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "51/51 - 0s - loss: 565.4531 - mse: 3245337.7500 - val_loss: 0.2128 - val_mse: 0.4671 - 205ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "51/51 - 0s - loss: 574.5137 - mse: 3358139.7500 - val_loss: 0.6169 - val_mse: 2.1142 - 206ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "51/51 - 0s - loss: 577.4505 - mse: 3499910.5000 - val_loss: 0.2483 - val_mse: 0.6275 - 206ms/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "51/51 - 0s - loss: 589.0005 - mse: 3515654.2500 - val_loss: 0.4322 - val_mse: 1.9100 - 203ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "51/51 - 0s - loss: 556.4680 - mse: 3023703.7500 - val_loss: 0.2152 - val_mse: 0.4782 - 208ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "51/51 - 0s - loss: 556.4749 - mse: 3025729.0000 - val_loss: 0.2942 - val_mse: 0.8846 - 213ms/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "51/51 - 0s - loss: 560.2905 - mse: 3278533.0000 - val_loss: 0.2865 - val_mse: 0.6356 - 206ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "51/51 - 0s - loss: 566.2020 - mse: 3038970.0000 - val_loss: 0.3128 - val_mse: 1.0021 - 209ms/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "51/51 - 0s - loss: 546.4999 - mse: 2765904.2500 - val_loss: 0.2449 - val_mse: 0.5343 - 212ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "51/51 - 0s - loss: 569.2999 - mse: 3549854.0000 - val_loss: 0.2630 - val_mse: 0.5764 - 215ms/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "51/51 - 0s - loss: 563.0585 - mse: 3459705.5000 - val_loss: 0.4077 - val_mse: 1.7063 - 216ms/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "51/51 - 0s - loss: 540.2534 - mse: 2828704.2500 - val_loss: 0.6431 - val_mse: 2.2904 - 207ms/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "51/51 - 0s - loss: 543.9226 - mse: 3138237.5000 - val_loss: 0.6778 - val_mse: 4.5304 - 203ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "51/51 - 0s - loss: 555.9962 - mse: 3166151.0000 - val_loss: 0.6279 - val_mse: 2.1929 - 206ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "51/51 - 0s - loss: 556.5782 - mse: 2921006.0000 - val_loss: 0.5493 - val_mse: 3.0472 - 203ms/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "51/51 - 0s - loss: 540.5392 - mse: 2762361.7500 - val_loss: 0.4603 - val_mse: 1.2675 - 202ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "51/51 - 0s - loss: 520.0420 - mse: 2638759.5000 - val_loss: 0.2118 - val_mse: 0.4611 - 202ms/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "51/51 - 0s - loss: 536.7708 - mse: 3026909.0000 - val_loss: 0.2511 - val_mse: 0.6469 - 199ms/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "51/51 - 0s - loss: 559.9204 - mse: 3176191.5000 - val_loss: 0.2097 - val_mse: 0.4567 - 210ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "51/51 - 0s - loss: 542.9048 - mse: 3268115.2500 - val_loss: 0.3000 - val_mse: 0.9263 - 203ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "51/51 - 0s - loss: 533.8407 - mse: 2830441.5000 - val_loss: 0.5398 - val_mse: 2.9517 - 200ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "51/51 - 0s - loss: 525.1488 - mse: 2958726.5000 - val_loss: 0.2620 - val_mse: 0.5740 - 203ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "51/51 - 0s - loss: 526.7467 - mse: 3166902.5000 - val_loss: 0.2393 - val_mse: 0.5214 - 200ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "51/51 - 0s - loss: 535.5263 - mse: 2894666.7500 - val_loss: 0.2804 - val_mse: 0.8102 - 206ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "51/51 - 0s - loss: 521.4657 - mse: 2767941.7500 - val_loss: 0.2479 - val_mse: 0.6334 - 200ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "51/51 - 0s - loss: 515.3668 - mse: 2458744.0000 - val_loss: 0.3950 - val_mse: 0.9931 - 201ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "51/51 - 0s - loss: 534.1091 - mse: 2953225.2500 - val_loss: 0.2637 - val_mse: 0.7173 - 206ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "51/51 - 0s - loss: 504.5030 - mse: 2538491.7500 - val_loss: 0.2549 - val_mse: 0.6707 - 205ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "51/51 - 0s - loss: 503.4642 - mse: 2317920.7500 - val_loss: 0.2142 - val_mse: 0.4800 - 205ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "51/51 - 0s - loss: 509.2209 - mse: 2482644.0000 - val_loss: 0.5301 - val_mse: 2.8583 - 202ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "51/51 - 0s - loss: 530.1564 - mse: 2914592.7500 - val_loss: 0.3031 - val_mse: 0.9518 - 205ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "51/51 - 0s - loss: 519.5817 - mse: 2660280.2500 - val_loss: 0.2169 - val_mse: 0.4720 - 205ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "51/51 - 0s - loss: 513.3968 - mse: 2641201.2500 - val_loss: 0.2075 - val_mse: 0.4542 - 203ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "51/51 - 0s - loss: 513.6387 - mse: 2668455.0000 - val_loss: 0.3209 - val_mse: 0.7363 - 204ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "51/51 - 0s - loss: 490.9765 - mse: 2327957.0000 - val_loss: 0.3897 - val_mse: 1.5758 - 201ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "51/51 - 0s - loss: 503.5811 - mse: 2577282.0000 - val_loss: 0.4117 - val_mse: 1.0632 - 204ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "51/51 - 0s - loss: 507.4069 - mse: 2868665.0000 - val_loss: 0.7865 - val_mse: 3.3792 - 202ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "51/51 - 0s - loss: 482.6032 - mse: 2257967.5000 - val_loss: 0.2815 - val_mse: 0.6239 - 204ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "51/51 - 0s - loss: 509.5597 - mse: 2677702.7500 - val_loss: 0.4246 - val_mse: 1.8674 - 203ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "51/51 - 0s - loss: 458.1687 - mse: 2143314.0000 - val_loss: 0.3386 - val_mse: 1.1948 - 201ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "51/51 - 0s - loss: 463.4643 - mse: 2017881.1250 - val_loss: 0.2246 - val_mse: 0.5285 - 207ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "51/51 - 0s - loss: 500.7505 - mse: 2636611.2500 - val_loss: 0.3680 - val_mse: 1.4117 - 202ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "51/51 - 0s - loss: 528.1083 - mse: 3040449.7500 - val_loss: 0.2194 - val_mse: 0.5063 - 204ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "51/51 - 0s - loss: 488.2202 - mse: 2384311.2500 - val_loss: 0.2453 - val_mse: 0.5346 - 201ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "51/51 - 0s - loss: 481.3148 - mse: 2218884.0000 - val_loss: 0.7511 - val_mse: 5.5154 - 201ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "51/51 - 0s - loss: 485.5424 - mse: 2342358.5000 - val_loss: 0.2906 - val_mse: 0.8817 - 201ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "51/51 - 0s - loss: 473.3204 - mse: 2435250.2500 - val_loss: 0.2900 - val_mse: 0.8786 - 205ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "51/51 - 0s - loss: 480.1951 - mse: 2332698.7500 - val_loss: 0.6254 - val_mse: 3.9263 - 203ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "51/51 - 0s - loss: 462.4625 - mse: 2057610.3750 - val_loss: 0.4377 - val_mse: 1.1801 - 200ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "51/51 - 0s - loss: 484.3719 - mse: 2320342.5000 - val_loss: 0.2470 - val_mse: 0.6391 - 204ms/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "51/51 - 0s - loss: 489.8817 - mse: 2281455.0000 - val_loss: 0.3544 - val_mse: 1.3158 - 204ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "51/51 - 0s - loss: 484.9702 - mse: 2214364.2500 - val_loss: 0.2223 - val_mse: 0.5220 - 201ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "51/51 - 0s - loss: 460.2336 - mse: 2088500.2500 - val_loss: 0.2333 - val_mse: 0.5073 - 203ms/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "51/51 - 0s - loss: 484.9019 - mse: 2360132.2500 - val_loss: 0.5193 - val_mse: 2.7682 - 200ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 49 started****\n",
            "\n",
            "Epoch 1/50\n",
            "140/140 [==============================] - 3s 5ms/step - loss: 94.3074 - mse: 142028.3594 - val_loss: 1.4136 - val_mse: 11.0680\n",
            "Epoch 2/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 29.7644 - mse: 11382.3115 - val_loss: 0.1308 - val_mse: 0.2896\n",
            "Epoch 3/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 30.5484 - mse: 12689.1182 - val_loss: 0.3044 - val_mse: 1.2859\n",
            "Epoch 4/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 27.2949 - mse: 10329.4268 - val_loss: 0.0689 - val_mse: 0.1419\n",
            "Epoch 5/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 27.1952 - mse: 8685.9453 - val_loss: 0.3709 - val_mse: 1.4148\n",
            "Epoch 6/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 25.8586 - mse: 8400.9014 - val_loss: 0.0733 - val_mse: 0.1513\n",
            "Epoch 7/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 24.7668 - mse: 7222.3438 - val_loss: 0.8342 - val_mse: 6.8350\n",
            "Epoch 8/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 24.2989 - mse: 7118.3130 - val_loss: 0.0283 - val_mse: 0.0579\n",
            "Epoch 9/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 24.2440 - mse: 7051.3882 - val_loss: 0.3592 - val_mse: 1.6998\n",
            "Epoch 10/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 23.0897 - mse: 6674.5967 - val_loss: 0.0258 - val_mse: 0.0528\n",
            "Epoch 11/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 22.6693 - mse: 7458.3735 - val_loss: 0.5171 - val_mse: 3.0141\n",
            "Epoch 12/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 21.0535 - mse: 5154.5527 - val_loss: 0.3328 - val_mse: 1.5818\n",
            "Epoch 13/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 20.4906 - mse: 5958.3730 - val_loss: 0.0571 - val_mse: 0.1612\n",
            "Epoch 14/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 20.5911 - mse: 6501.7598 - val_loss: 0.7567 - val_mse: 5.9605\n",
            "Epoch 15/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 18.6175 - mse: 4457.5562 - val_loss: 0.0277 - val_mse: 0.0581\n",
            "Epoch 16/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 18.6742 - mse: 4450.9688 - val_loss: 0.7375 - val_mse: 5.4574\n",
            "Epoch 17/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 16.8650 - mse: 3519.1294 - val_loss: 0.3625 - val_mse: 1.8906\n",
            "Epoch 18/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 16.8423 - mse: 3859.2871 - val_loss: 0.5586 - val_mse: 3.3754\n",
            "Epoch 19/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 16.0397 - mse: 3586.9077 - val_loss: 0.2808 - val_mse: 1.1780\n",
            "Epoch 20/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 15.6152 - mse: 3558.9285 - val_loss: 0.0753 - val_mse: 0.1943\n",
            "Epoch 21/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 13.0930 - mse: 1988.3025 - val_loss: 0.0701 - val_mse: 0.2065\n",
            "Epoch 22/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 13.3777 - mse: 2137.8274 - val_loss: 0.0854 - val_mse: 0.2257\n",
            "Epoch 23/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 13.2242 - mse: 2232.1880 - val_loss: 0.4663 - val_mse: 2.7694\n",
            "Epoch 24/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 12.6671 - mse: 1921.6586 - val_loss: 0.6779 - val_mse: 4.4466\n",
            "Epoch 25/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 12.4093 - mse: 1965.8179 - val_loss: 0.1508 - val_mse: 0.4642\n",
            "Epoch 26/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 11.4365 - mse: 1772.8047 - val_loss: 0.0121 - val_mse: 0.0260\n",
            "Epoch 27/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 10.9852 - mse: 1637.8344 - val_loss: 0.0564 - val_mse: 0.1339\n",
            "Epoch 28/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 10.7746 - mse: 1662.0894 - val_loss: 0.0607 - val_mse: 0.1435\n",
            "Epoch 29/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 9.8166 - mse: 1458.1910 - val_loss: 0.0399 - val_mse: 0.0875\n",
            "Epoch 30/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 9.7184 - mse: 1172.4314 - val_loss: 0.0772 - val_mse: 0.2390\n",
            "Epoch 31/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 9.1543 - mse: 1225.6307 - val_loss: 0.6185 - val_mse: 4.4108\n",
            "Epoch 32/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 8.4738 - mse: 1020.2416 - val_loss: 0.2079 - val_mse: 0.7330\n",
            "Epoch 33/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 8.3559 - mse: 1047.9476 - val_loss: 0.8438 - val_mse: 7.0327\n",
            "Epoch 34/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 7.7544 - mse: 1024.4843 - val_loss: 1.5477 - val_mse: 18.5891\n",
            "Epoch 35/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 7.2523 - mse: 686.1819 - val_loss: 0.1802 - val_mse: 0.6909\n",
            "Epoch 36/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.7688 - mse: 585.8165 - val_loss: 0.1563 - val_mse: 0.5086\n",
            "Epoch 37/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.9081 - mse: 635.0839 - val_loss: 0.2215 - val_mse: 0.9396\n",
            "Epoch 38/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.0020 - mse: 446.0278 - val_loss: 0.3161 - val_mse: 1.5695\n",
            "Epoch 39/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8871 - mse: 506.7664 - val_loss: 0.0479 - val_mse: 0.1108\n",
            "Epoch 40/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5397 - mse: 490.4946 - val_loss: 0.0459 - val_mse: 0.1205\n",
            "Epoch 41/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.2022 - mse: 371.4316 - val_loss: 0.0219 - val_mse: 0.0462\n",
            "Epoch 42/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7357 - mse: 319.5396 - val_loss: 0.0161 - val_mse: 0.0358\n",
            "Epoch 43/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9085 - mse: 338.1833 - val_loss: 0.0591 - val_mse: 0.1668\n",
            "Epoch 44/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4319 - mse: 314.9591 - val_loss: 1.0524 - val_mse: 10.1173\n",
            "Epoch 45/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1889 - mse: 240.7729 - val_loss: 0.2524 - val_mse: 0.9971\n",
            "Epoch 46/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0418 - mse: 257.0613 - val_loss: 0.0510 - val_mse: 0.1136\n",
            "Epoch 47/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8825 - mse: 237.4086 - val_loss: 0.0204 - val_mse: 0.0415\n",
            "Epoch 48/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.3681 - mse: 155.6092 - val_loss: 0.1526 - val_mse: 0.5795\n",
            "Epoch 49/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.2258 - mse: 155.6407 - val_loss: 0.0507 - val_mse: 0.1178\n",
            "Epoch 50/50\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.0733 - mse: 160.7017 - val_loss: 0.2562 - val_mse: 1.0247\n",
            "Epoch 51/200\n",
            "140/140 - 1s - loss: 3.0068 - mse: 135.5223 - val_loss: 0.0079 - val_mse: 0.0164 - 549ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "140/140 - 0s - loss: 2.5831 - mse: 103.1531 - val_loss: 0.0082 - val_mse: 0.0171 - 496ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "140/140 - 0s - loss: 2.4735 - mse: 101.4614 - val_loss: 0.1848 - val_mse: 0.7206 - 495ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "140/140 - 0s - loss: 2.3839 - mse: 84.0725 - val_loss: 0.0052 - val_mse: 0.0104 - 495ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "140/140 - 0s - loss: 2.2825 - mse: 88.8306 - val_loss: 0.0050 - val_mse: 0.0101 - 499ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "140/140 - 0s - loss: 2.0734 - mse: 70.7011 - val_loss: 0.0069 - val_mse: 0.0142 - 488ms/epoch - 3ms/step\n",
            "Epoch 57/200\n",
            "140/140 - 0s - loss: 1.8614 - mse: 52.3661 - val_loss: 0.2032 - val_mse: 0.8389 - 498ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "140/140 - 0s - loss: 1.7025 - mse: 47.3927 - val_loss: 0.0204 - val_mse: 0.0479 - 497ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "140/140 - 0s - loss: 1.7470 - mse: 55.7783 - val_loss: 0.0407 - val_mse: 0.1075 - 493ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "140/140 - 0s - loss: 1.5927 - mse: 44.4440 - val_loss: 0.0557 - val_mse: 0.1543 - 491ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "140/140 - 0s - loss: 1.4899 - mse: 36.1749 - val_loss: 0.0353 - val_mse: 0.0885 - 491ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "140/140 - 0s - loss: 1.3566 - mse: 31.7651 - val_loss: 0.0194 - val_mse: 0.0441 - 486ms/epoch - 3ms/step\n",
            "Epoch 63/200\n",
            "140/140 - 0s - loss: 1.3358 - mse: 37.2735 - val_loss: 0.0768 - val_mse: 0.2255 - 492ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "140/140 - 1s - loss: 1.1473 - mse: 25.9214 - val_loss: 0.0108 - val_mse: 0.0229 - 510ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "140/140 - 1s - loss: 1.0807 - mse: 19.8759 - val_loss: 0.0873 - val_mse: 0.2313 - 503ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "140/140 - 1s - loss: 0.9375 - mse: 14.4455 - val_loss: 0.0211 - val_mse: 0.0441 - 508ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "140/140 - 1s - loss: 0.9055 - mse: 17.4087 - val_loss: 0.0878 - val_mse: 0.2346 - 520ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "140/140 - 1s - loss: 0.8337 - mse: 14.6049 - val_loss: 0.0180 - val_mse: 0.0405 - 514ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "140/140 - 0s - loss: 0.7581 - mse: 12.9733 - val_loss: 0.0531 - val_mse: 0.1258 - 481ms/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "140/140 - 0s - loss: 0.7176 - mse: 9.6416 - val_loss: 0.0110 - val_mse: 0.0236 - 498ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "140/140 - 0s - loss: 0.6532 - mse: 7.8394 - val_loss: 0.0156 - val_mse: 0.0347 - 486ms/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "140/140 - 1s - loss: 0.5905 - mse: 7.9865 - val_loss: 0.0525 - val_mse: 0.1415 - 507ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "140/140 - 0s - loss: 0.5044 - mse: 5.9548 - val_loss: 0.0141 - val_mse: 0.0312 - 496ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "140/140 - 0s - loss: 0.5480 - mse: 7.3955 - val_loss: 0.0081 - val_mse: 0.0162 - 489ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "140/140 - 0s - loss: 0.4749 - mse: 6.7543 - val_loss: 0.0070 - val_mse: 0.0140 - 488ms/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "140/140 - 0s - loss: 0.4310 - mse: 4.5930 - val_loss: 0.0167 - val_mse: 0.0345 - 500ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "140/140 - 0s - loss: 0.3429 - mse: 3.1869 - val_loss: 0.0310 - val_mse: 0.0681 - 487ms/epoch - 3ms/step\n",
            "Epoch 78/200\n",
            "140/140 - 0s - loss: 0.3278 - mse: 2.9241 - val_loss: 0.0255 - val_mse: 0.0547 - 490ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "140/140 - 0s - loss: 0.2983 - mse: 3.1602 - val_loss: 0.0085 - val_mse: 0.0179 - 484ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "140/140 - 0s - loss: 0.2680 - mse: 2.2643 - val_loss: 0.0119 - val_mse: 0.0242 - 486ms/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "140/140 - 0s - loss: 0.2348 - mse: 1.8008 - val_loss: 0.0250 - val_mse: 0.0593 - 487ms/epoch - 3ms/step\n",
            "Epoch 82/200\n",
            "140/140 - 0s - loss: 0.2207 - mse: 1.5942 - val_loss: 0.0119 - val_mse: 0.0257 - 491ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "140/140 - 0s - loss: 0.2331 - mse: 1.5759 - val_loss: 0.0097 - val_mse: 0.0196 - 483ms/epoch - 3ms/step\n",
            "Epoch 84/200\n",
            "140/140 - 0s - loss: 0.1916 - mse: 1.3453 - val_loss: 0.0230 - val_mse: 0.0485 - 491ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "140/140 - 0s - loss: 0.1556 - mse: 1.0910 - val_loss: 0.0427 - val_mse: 0.0974 - 496ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 50 started****\n",
            "\n",
            "Epoch 1/50\n",
            "36/36 [==============================] - 3s 11ms/step - loss: 1023.8104 - mse: 29313490.0000 - val_loss: 0.8913 - val_mse: 2.3982\n",
            "Epoch 2/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.8312 - mse: 329.5769 - val_loss: 0.3675 - val_mse: 0.1586\n",
            "Epoch 3/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4005 - mse: 26.8814 - val_loss: 0.0817 - val_mse: 0.0114\n",
            "Epoch 4/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1468 - mse: 1.9666 - val_loss: 0.0757 - val_mse: 0.0086\n",
            "Epoch 5/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1780 - mse: 2.1203 - val_loss: 0.1590 - val_mse: 0.0604\n",
            "Epoch 6/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1231 - mse: 0.0845 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 7/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1125 - mse: 0.0334 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 8/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1144 - mse: 0.2065 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 9/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1078 - mse: 0.0224 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 10/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1071 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 11/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1099 - mse: 0.0504 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 12/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1125 - mse: 0.0882 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 13/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1096 - mse: 0.0336 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 14/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1076 - mse: 0.0203 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 15/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1121 - mse: 0.1011 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 16/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1097 - mse: 0.0829 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 17/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1106 - mse: 0.0578 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 18/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1116 - mse: 0.1885 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 19/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1142 - mse: 0.2848 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 20/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1085 - mse: 0.0285 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 21/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1083 - mse: 0.0325 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 22/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 23/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1076 - mse: 0.0191 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 24/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1127 - mse: 0.1576 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 25/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1078 - mse: 0.0228 - val_loss: 0.1051 - val_mse: 0.0169\n",
            "Epoch 26/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1067 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 27/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1066 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 28/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1155 - mse: 0.5153 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 29/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1054 - mse: 0.0845 - val_loss: 0.0800 - val_mse: 0.0091\n",
            "Epoch 30/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0977 - mse: 0.1866 - val_loss: 0.0755 - val_mse: 0.0095\n",
            "Epoch 31/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1003 - mse: 0.0210 - val_loss: 0.0850 - val_mse: 0.0103\n",
            "Epoch 32/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0984 - mse: 0.0420 - val_loss: 0.1160 - val_mse: 0.0223\n",
            "Epoch 33/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1062 - mse: 0.0510 - val_loss: 0.0849 - val_mse: 0.0098\n",
            "Epoch 34/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1110 - mse: 0.0610 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 35/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1075 - mse: 0.0214 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 36/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1068 - mse: 0.0172 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 37/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1126 - mse: 0.1451 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 38/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1071 - mse: 0.0176 - val_loss: 0.1048 - val_mse: 0.0168\n",
            "Epoch 39/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1114 - mse: 0.1849 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 40/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1080 - mse: 0.0293 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 41/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 42/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1069 - mse: 0.0175 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 43/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1105 - mse: 0.0620 - val_loss: 0.1048 - val_mse: 0.0167\n",
            "Epoch 44/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0168\n",
            "Epoch 45/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 46/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168\n",
            "Epoch 47/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1070 - mse: 0.0178 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 48/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1069 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167\n",
            "Epoch 49/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0168\n",
            "Epoch 50/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1052 - val_mse: 0.0169\n",
            "Epoch 51/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 184ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "36/36 - 0s - loss: 0.1073 - mse: 0.0187 - val_loss: 0.1048 - val_mse: 0.0168 - 180ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "36/36 - 0s - loss: 0.1067 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 177ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167 - 194ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 183ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "36/36 - 0s - loss: 0.1151 - mse: 0.5758 - val_loss: 0.1048 - val_mse: 0.0167 - 176ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168 - 181ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 182ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0175 - val_loss: 0.1051 - val_mse: 0.0169 - 183ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0168 - 184ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 184ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "36/36 - 0s - loss: 0.1197 - mse: 1.0965 - val_loss: 0.1047 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "36/36 - 0s - loss: 0.1072 - mse: 0.0191 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "36/36 - 0s - loss: 0.1072 - mse: 0.0178 - val_loss: 0.1048 - val_mse: 0.0167 - 173ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0168 - 172ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "36/36 - 0s - loss: 0.1140 - mse: 0.4344 - val_loss: 0.1049 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0176 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168 - 172ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "36/36 - 0s - loss: 0.1077 - mse: 0.0230 - val_loss: 0.1049 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "36/36 - 0s - loss: 0.1076 - mse: 0.0227 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0172 - val_loss: 0.1049 - val_mse: 0.0168 - 172ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167 - 176ms/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1050 - val_mse: 0.0168 - 172ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "36/36 - 0s - loss: 0.1072 - mse: 0.0179 - val_loss: 0.1047 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0169 - 174ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 176ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0172 - val_loss: 0.1051 - val_mse: 0.0169 - 172ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1058 - val_mse: 0.0171 - 173ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168 - 173ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0176 - val_loss: 0.1048 - val_mse: 0.0168 - 174ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0167 - 178ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 177ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0175 - val_loss: 0.1047 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 173ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "36/36 - 0s - loss: 0.1078 - mse: 0.0248 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1051 - val_mse: 0.0169 - 169ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "36/36 - 0s - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1049 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168 - 172ms/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1052 - val_mse: 0.0169 - 172ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 177ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1052 - val_mse: 0.0169 - 173ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 173ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 169ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0168 - 170ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "36/36 - 0s - loss: 0.1095 - mse: 0.0818 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "36/36 - 0s - loss: 0.1067 - mse: 0.0172 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 173ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "36/36 - 0s - loss: 0.1067 - mse: 0.0172 - val_loss: 0.1049 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 176ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1050 - val_mse: 0.0168 - 182ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0168 - 179ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167 - 174ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 180ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "36/36 - 0s - loss: 0.1073 - mse: 0.0184 - val_loss: 0.1048 - val_mse: 0.0167 - 182ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 175ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "36/36 - 0s - loss: 0.1067 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 177ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168 - 180ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 180ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "36/36 - 0s - loss: 0.1090 - mse: 0.0216 - val_loss: 0.1048 - val_mse: 0.0167 - 180ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "36/36 - 0s - loss: 0.1079 - mse: 0.0199 - val_loss: 0.1050 - val_mse: 0.0168 - 179ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "36/36 - 0s - loss: 0.1083 - mse: 0.0365 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 172ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "36/36 - 0s - loss: 0.1073 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "36/36 - 0s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "36/36 - 0s - loss: 0.1068 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 171ms/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "36/36 - 0s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 170ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "36/36 - 0s - loss: 0.1082 - mse: 0.0350 - val_loss: 0.1047 - val_mse: 0.0167 - 180ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Define Objective Function\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YcPCoGr7SDUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Objective Function\n",
        "from joblib import load\n",
        "estimator = load('estimator.joblib')\n",
        "#-----------------------------------------------------------\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    # User Input for Performance estimation\n",
        "    threshold=0.00015\n",
        "    epoch_rate=0.25 # When the model to be estimated\n",
        "    #-------------------------------------------------------\n",
        "\n",
        "    number_of_layers = params['number_of_layers']\n",
        "    layer_nodes = [params[f'layer_{i+1}_nodes'] for i in range(number_of_layers)]\n",
        "\n",
        "    f_g_net = SumNet(\n",
        "        layer_nodes=layer_nodes,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        activation=params['activation'],\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        optimizer=params['optimizer'],\n",
        "        loss_function=params['loss_function']\n",
        "    )\n",
        "\n",
        "    # Print the model structure\n",
        "    print_model(params, layer_nodes)\n",
        "\n",
        "    val_mse = []\n",
        "    for epoch in range(params['epochs']):\n",
        "        history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                            epochs=1,\n",
        "                            batch_size=params['batch_size'],\n",
        "                            validation_data=(input_data_val, y_val),\n",
        "                            callbacks=[early_stopping],verbose=2)\n",
        "        val_mse.append(history.history['val_mse'][-1])\n",
        "\n",
        "        if epoch == int(params['epochs'] * epoch_rate-1):\n",
        "            predicted_performance = predict_final_performance(val_mse, estimator)\n",
        "            print(\"\\nPredicted Performance: {}\\n\".format(predicted_performance))\n",
        "\n",
        "            # Plot actual vs. predicted learning curve\n",
        "            #show_plot(params, val_mse, epoch_rate, predicted_performance, toshow=False)\n",
        "\n",
        "            if predicted_performance >= threshold:\n",
        "                break\n",
        "\n",
        "    return val_mse[-1]\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "id": "tN781_I6SDb8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Run BOwGP\n",
        "\n",
        "---\n",
        "\n",
        "But each model's performance would be estimated by NuSVR,\n",
        "we've trained right before above."
      ],
      "metadata": {
        "id": "lIDSxiT2SEcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN: Run Bayesian optimization\n",
        "import time\n",
        "#-----------------------------------------------------------\n",
        "    # n_calls : iterations for iptimization\n",
        "    # Recommand : n_calls might be large enough, dependent to Search Space\n",
        "n_calls = 100\n",
        "res_gp = gp_minimize(objective, dimensions=space, n_calls=n_calls, random_state=7, verbose=True)\n",
        "\n",
        "    # Extract and print the best parameters\n",
        "best_params = res_gp.x\n",
        "print(\"\\nBest parameters:\", best_params)\n",
        "print(\"Best MSE:\", res_gp.fun)\n",
        "\n",
        "    # Convert results to DataFrame and save as CSV\n",
        "results_df = pd.DataFrame(res_gp.x_iters, columns=[dimension.name for dimension in space])\n",
        "results_df['MSE'] = res_gp.func_vals\n",
        "\n",
        "    # Optionally, add a column to indicate which configurations are better than a certain threshold\n",
        "result_threshold = 0.005  # adjust this value as needed\n",
        "results_df['is_better_than_threshold'] = results_df['MSE'] < result_threshold\n",
        "\n",
        "    # Save to CSV\n",
        "results_df.to_csv(\"NAS_Result_{}.csv\".format(\n",
        "    time.strftime('%Y_%m_%d_%H_%M', time.localtime(time.time()))\n",
        "    ), index=False)\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2TO8Q82SEkm",
        "outputId": "58a39eec-3431-44b6-9b45-ddbbefd0620f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [125]\n",
            "Learning Rate: 2.0861916134275696e-05\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2638823974103853\n",
            "Batch Size: 125\n",
            "----------------------------------------\n",
            "68/68 - 2s - loss: 803.1269 - mse: 6736523.0000 - val_loss: 559.6815 - val_mse: 1588138.0000 - 2s/epoch - 31ms/step\n",
            "68/68 - 0s - loss: 624.0599 - mse: 4183620.2500 - val_loss: 392.2914 - val_mse: 782321.5625 - 317ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 520.7646 - mse: 3289979.2500 - val_loss: 270.4424 - val_mse: 373273.0938 - 318ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 437.8654 - mse: 2566342.2500 - val_loss: 179.8778 - val_mse: 166148.6250 - 321ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 364.1915 - mse: 1602831.5000 - val_loss: 121.2511 - val_mse: 76150.3828 - 325ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 336.7155 - mse: 1318536.6250 - val_loss: 78.8929 - val_mse: 32696.3242 - 325ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 308.4160 - mse: 1128906.8750 - val_loss: 47.8106 - val_mse: 12420.5830 - 343ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 293.1777 - mse: 1251037.2500 - val_loss: 26.8247 - val_mse: 4100.1162 - 333ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 288.1248 - mse: 1088459.0000 - val_loss: 13.0664 - val_mse: 1066.6403 - 342ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 261.4105 - mse: 729856.5625 - val_loss: 5.8275 - val_mse: 246.0268 - 325ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 257.2234 - mse: 751786.1875 - val_loss: 2.5244 - val_mse: 55.0186 - 328ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 270.0370 - mse: 1023856.0000 - val_loss: 0.2406 - val_mse: 0.5275 - 326ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 258.9482 - mse: 766085.3125 - val_loss: 0.2954 - val_mse: 0.8447 - 326ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 255.4873 - mse: 695767.4375 - val_loss: 0.2245 - val_mse: 0.5134 - 328ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 255.9772 - mse: 809262.1875 - val_loss: 0.2414 - val_mse: 0.5844 - 326ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 246.3447 - mse: 743456.5625 - val_loss: 0.2461 - val_mse: 0.6052 - 332ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 246.9791 - mse: 690020.6875 - val_loss: 0.2804 - val_mse: 0.6189 - 335ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 252.5002 - mse: 699305.6875 - val_loss: 0.2303 - val_mse: 0.5054 - 335ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 241.8306 - mse: 573574.6250 - val_loss: 0.2350 - val_mse: 0.5622 - 333ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 266.6737 - mse: 981941.8750 - val_loss: 0.3335 - val_mse: 0.7669 - 338ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 233.8858 - mse: 623218.0625 - val_loss: 0.2405 - val_mse: 0.5957 - 334ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 233.1582 - mse: 660415.5625 - val_loss: 0.4976 - val_mse: 2.4154 - 327ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 240.8527 - mse: 693266.5625 - val_loss: 0.2085 - val_mse: 0.4573 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 231.6205 - mse: 700414.3750 - val_loss: 0.2846 - val_mse: 0.8399 - 325ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 232.5291 - mse: 641005.5625 - val_loss: 0.3888 - val_mse: 1.5587 - 346ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 246.5954 - mse: 739149.6250 - val_loss: 0.5838 - val_mse: 1.8816 - 342ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 233.2964 - mse: 633382.5625 - val_loss: 1.5897 - val_mse: 12.5087 - 337ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 224.2549 - mse: 605923.4375 - val_loss: 1.1550 - val_mse: 6.8546 - 371ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 232.4310 - mse: 674438.9375 - val_loss: 0.4297 - val_mse: 1.1548 - 342ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 221.8874 - mse: 573195.8125 - val_loss: 0.4339 - val_mse: 1.1832 - 336ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 219.3962 - mse: 533990.5625 - val_loss: 0.5433 - val_mse: 3.0289 - 333ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 223.4632 - mse: 556257.1875 - val_loss: 0.4370 - val_mse: 2.0234 - 329ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 220.4795 - mse: 631956.9375 - val_loss: 0.2410 - val_mse: 0.6531 - 325ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 208.4696 - mse: 478488.7812 - val_loss: 0.1823 - val_mse: 0.4001 - 317ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 217.7614 - mse: 600912.1250 - val_loss: 0.3978 - val_mse: 1.7051 - 318ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 211.0410 - mse: 627070.0000 - val_loss: 0.9731 - val_mse: 8.5988 - 323ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 200.7367 - mse: 465319.1562 - val_loss: 0.3741 - val_mse: 1.5351 - 313ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 214.6262 - mse: 544416.8125 - val_loss: 0.2310 - val_mse: 0.6289 - 308ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 210.6252 - mse: 509110.6875 - val_loss: 0.2220 - val_mse: 0.5890 - 313ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 212.5995 - mse: 566956.8125 - val_loss: 0.2180 - val_mse: 0.5729 - 313ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 210.0634 - mse: 514332.5312 - val_loss: 0.8422 - val_mse: 6.7313 - 314ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 209.2951 - mse: 550753.0000 - val_loss: 0.3858 - val_mse: 1.6738 - 318ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 215.5821 - mse: 573301.5625 - val_loss: 0.2419 - val_mse: 0.7076 - 309ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 209.4115 - mse: 559860.2500 - val_loss: 0.4829 - val_mse: 1.4832 - 316ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 194.0003 - mse: 415284.8125 - val_loss: 0.1953 - val_mse: 0.4186 - 316ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 198.8448 - mse: 450443.9062 - val_loss: 0.1590 - val_mse: 0.3396 - 319ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 197.5100 - mse: 463458.0938 - val_loss: 0.2281 - val_mse: 0.6520 - 321ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 191.3439 - mse: 475536.4375 - val_loss: 0.5582 - val_mse: 1.9736 - 313ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 195.7632 - mse: 522081.1875 - val_loss: 0.3369 - val_mse: 0.8598 - 314ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 187.2753 - mse: 416072.6875 - val_loss: 1.0566 - val_mse: 6.2641 - 316ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 23.6204\n",
            "Function value obtained: 6.2641\n",
            "Current minimum: 6.2641\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 139]\n",
            "Learning Rate: 0.002952282261438963\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.375381363930363\n",
            "Batch Size: 178\n",
            "----------------------------------------\n",
            "48/48 - 3s - loss: 223.3406 - mse: 1222285.2500 - val_loss: 0.9257 - val_mse: 2.6114 - 3s/epoch - 57ms/step\n",
            "48/48 - 0s - loss: 18.8768 - mse: 5400.7705 - val_loss: 0.5610 - val_mse: 0.3229 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 6.1693 - mse: 485.1204 - val_loss: 0.1931 - val_mse: 0.0527 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 3.1203 - mse: 157.3625 - val_loss: 0.1518 - val_mse: 0.0337 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.7974 - mse: 73.2515 - val_loss: 0.1080 - val_mse: 0.0190 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.1551 - mse: 59.1500 - val_loss: 0.0679 - val_mse: 0.0067 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.6992 - mse: 22.1167 - val_loss: 0.0919 - val_mse: 0.0112 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.5487 - mse: 20.9377 - val_loss: 0.0738 - val_mse: 0.0081 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.4365 - mse: 14.8756 - val_loss: 0.0896 - val_mse: 0.0108 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3768 - mse: 17.3533 - val_loss: 0.0829 - val_mse: 0.0092 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2819 - mse: 3.8731 - val_loss: 0.1145 - val_mse: 0.0203 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2589 - mse: 5.3405 - val_loss: 0.0804 - val_mse: 0.0088 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2041 - mse: 1.2160 - val_loss: 0.0940 - val_mse: 0.0119 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2017 - mse: 2.0831 - val_loss: 0.0753 - val_mse: 0.0080 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1696 - mse: 1.0244 - val_loss: 0.0879 - val_mse: 0.0103 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1881 - mse: 2.6394 - val_loss: 0.0703 - val_mse: 0.0072 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1577 - mse: 0.5845 - val_loss: 0.0718 - val_mse: 0.0076 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1500 - mse: 0.6556 - val_loss: 0.0708 - val_mse: 0.0074 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1621 - mse: 0.9423 - val_loss: 0.0720 - val_mse: 0.0076 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1217 - mse: 0.1860 - val_loss: 0.0699 - val_mse: 0.0072 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1348 - mse: 0.3907 - val_loss: 0.0711 - val_mse: 0.0074 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1388 - mse: 0.5830 - val_loss: 0.0847 - val_mse: 0.0098 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1306 - mse: 0.7375 - val_loss: 0.0701 - val_mse: 0.0072 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1324 - mse: 0.8906 - val_loss: 0.0732 - val_mse: 0.0077 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1178 - mse: 0.3143 - val_loss: 0.0786 - val_mse: 0.0084 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1432 - mse: 5.1741 - val_loss: 0.0695 - val_mse: 0.0072 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1188 - mse: 0.1394 - val_loss: 0.0721 - val_mse: 0.0077 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1125 - mse: 0.3299 - val_loss: 0.0710 - val_mse: 0.0074 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1017 - mse: 0.0715 - val_loss: 0.0704 - val_mse: 0.0071 - 312ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0987 - mse: 0.1055 - val_loss: 0.0719 - val_mse: 0.0073 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1194 - mse: 1.5020 - val_loss: 0.0721 - val_mse: 0.0074 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1077 - mse: 0.2223 - val_loss: 0.0744 - val_mse: 0.0077 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1415 - mse: 10.9338 - val_loss: 0.0775 - val_mse: 0.0083 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1164 - mse: 0.9779 - val_loss: 0.0809 - val_mse: 0.0091 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1038 - mse: 0.2729 - val_loss: 0.0872 - val_mse: 0.0102 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0970 - mse: 0.0875 - val_loss: 0.0986 - val_mse: 0.0131 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1021 - mse: 0.0887 - val_loss: 0.0707 - val_mse: 0.0072 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1018 - mse: 0.4351 - val_loss: 0.0784 - val_mse: 0.0083 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0999 - mse: 0.1305 - val_loss: 0.0697 - val_mse: 0.0070 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0923 - mse: 0.0580 - val_loss: 0.0689 - val_mse: 0.0070 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0920 - mse: 0.0340 - val_loss: 0.0809 - val_mse: 0.0089 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0967 - mse: 0.3295 - val_loss: 0.0743 - val_mse: 0.0077 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0925 - mse: 0.0836 - val_loss: 0.0676 - val_mse: 0.0067 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0881 - mse: 0.0324 - val_loss: 0.0722 - val_mse: 0.0073 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0970 - mse: 0.9779 - val_loss: 0.0738 - val_mse: 0.0077 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0952 - mse: 0.0709 - val_loss: 0.0700 - val_mse: 0.0071 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0868 - mse: 0.0301 - val_loss: 0.0678 - val_mse: 0.0067 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0892 - mse: 0.0195 - val_loss: 0.0681 - val_mse: 0.0068 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0907 - mse: 0.1048 - val_loss: 0.0669 - val_mse: 0.0067 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1012 - mse: 0.3634 - val_loss: 0.0723 - val_mse: 0.0077 - 279ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [-0.02783504]\n",
            "\n",
            "48/48 - 0s - loss: 0.0882 - mse: 0.0313 - val_loss: 0.0686 - val_mse: 0.0068 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0851 - mse: 0.0180 - val_loss: 0.0658 - val_mse: 0.0064 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0886 - mse: 0.0623 - val_loss: 0.0725 - val_mse: 0.0075 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0815 - mse: 0.0194 - val_loss: 0.0658 - val_mse: 0.0064 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0848 - mse: 0.0469 - val_loss: 0.0662 - val_mse: 0.0064 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0859 - mse: 0.0791 - val_loss: 0.0668 - val_mse: 0.0065 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0920 - mse: 0.0435 - val_loss: 0.0719 - val_mse: 0.0075 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0898 - mse: 0.1926 - val_loss: 0.0706 - val_mse: 0.0070 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0893 - mse: 0.2147 - val_loss: 0.0769 - val_mse: 0.0082 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0845 - mse: 0.0158 - val_loss: 0.0741 - val_mse: 0.0079 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0907 - mse: 0.2359 - val_loss: 0.0673 - val_mse: 0.0066 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0811 - mse: 0.0133 - val_loss: 0.0651 - val_mse: 0.0063 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0833 - mse: 0.1067 - val_loss: 0.0917 - val_mse: 0.0116 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0899 - mse: 0.0290 - val_loss: 0.0674 - val_mse: 0.0067 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0821 - mse: 0.0181 - val_loss: 0.0658 - val_mse: 0.0064 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0809 - mse: 0.0279 - val_loss: 0.0673 - val_mse: 0.0066 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0840 - mse: 0.1937 - val_loss: 0.0661 - val_mse: 0.0064 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0804 - mse: 0.0172 - val_loss: 0.0661 - val_mse: 0.0063 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0779 - mse: 0.0130 - val_loss: 0.0651 - val_mse: 0.0063 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0788 - mse: 0.0178 - val_loss: 0.0643 - val_mse: 0.0061 - 305ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0800 - mse: 0.1252 - val_loss: 0.0644 - val_mse: 0.0062 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0850 - mse: 0.0559 - val_loss: 0.0671 - val_mse: 0.0066 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0857 - mse: 0.3357 - val_loss: 0.0723 - val_mse: 0.0075 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0797 - mse: 0.0163 - val_loss: 0.0666 - val_mse: 0.0065 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0775 - mse: 0.0108 - val_loss: 0.0668 - val_mse: 0.0065 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0804 - mse: 0.0147 - val_loss: 0.0662 - val_mse: 0.0063 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0768 - mse: 0.0115 - val_loss: 0.0660 - val_mse: 0.0064 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0826 - mse: 0.0495 - val_loss: 0.0639 - val_mse: 0.0061 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0776 - mse: 0.0233 - val_loss: 0.0673 - val_mse: 0.0066 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0796 - mse: 0.0127 - val_loss: 0.0673 - val_mse: 0.0066 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0790 - mse: 0.0121 - val_loss: 0.0722 - val_mse: 0.0074 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0761 - mse: 0.0104 - val_loss: 0.0654 - val_mse: 0.0063 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0770 - mse: 0.0112 - val_loss: 0.0667 - val_mse: 0.0063 - 271ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0773 - mse: 0.0117 - val_loss: 0.0625 - val_mse: 0.0058 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0772 - mse: 0.0130 - val_loss: 0.0645 - val_mse: 0.0061 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0770 - mse: 0.0184 - val_loss: 0.0646 - val_mse: 0.0061 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0738 - mse: 0.0097 - val_loss: 0.0635 - val_mse: 0.0059 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0800 - mse: 0.0128 - val_loss: 0.0649 - val_mse: 0.0061 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0746 - mse: 0.0095 - val_loss: 0.0739 - val_mse: 0.0076 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0818 - mse: 0.0304 - val_loss: 0.0698 - val_mse: 0.0068 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0801 - mse: 0.0207 - val_loss: 0.0671 - val_mse: 0.0066 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0769 - mse: 0.0108 - val_loss: 0.0653 - val_mse: 0.0061 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0737 - mse: 0.0103 - val_loss: 0.0638 - val_mse: 0.0061 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0785 - mse: 0.0127 - val_loss: 0.0780 - val_mse: 0.0096 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0828 - mse: 0.0148 - val_loss: 0.0674 - val_mse: 0.0066 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0763 - mse: 0.0116 - val_loss: 0.0651 - val_mse: 0.0062 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0757 - mse: 0.0157 - val_loss: 0.0647 - val_mse: 0.0061 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0749 - mse: 0.0131 - val_loss: 0.0651 - val_mse: 0.0062 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0748 - mse: 0.0146 - val_loss: 0.0646 - val_mse: 0.0061 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0745 - mse: 0.0090 - val_loss: 0.0675 - val_mse: 0.0066 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0758 - mse: 0.0097 - val_loss: 0.0674 - val_mse: 0.0071 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0764 - mse: 0.0142 - val_loss: 0.0657 - val_mse: 0.0065 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0870 - mse: 0.0295 - val_loss: 0.0705 - val_mse: 0.0073 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0793 - mse: 0.0137 - val_loss: 0.0693 - val_mse: 0.0071 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0787 - mse: 0.0214 - val_loss: 0.0651 - val_mse: 0.0062 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0762 - mse: 0.0095 - val_loss: 0.0663 - val_mse: 0.0064 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0752 - mse: 0.0192 - val_loss: 0.0635 - val_mse: 0.0060 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0743 - mse: 0.0106 - val_loss: 0.0663 - val_mse: 0.0063 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0797 - mse: 0.2386 - val_loss: 0.0652 - val_mse: 0.0062 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0743 - mse: 0.0104 - val_loss: 0.0687 - val_mse: 0.0068 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0749 - mse: 0.0101 - val_loss: 0.0672 - val_mse: 0.0066 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0726 - mse: 0.0086 - val_loss: 0.0616 - val_mse: 0.0057 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0730 - mse: 0.0086 - val_loss: 0.0627 - val_mse: 0.0058 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0753 - mse: 0.0244 - val_loss: 0.0611 - val_mse: 0.0056 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0753 - mse: 0.0101 - val_loss: 0.0639 - val_mse: 0.0059 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0736 - mse: 0.0099 - val_loss: 0.0633 - val_mse: 0.0059 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0732 - mse: 0.0089 - val_loss: 0.0644 - val_mse: 0.0062 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0724 - mse: 0.0085 - val_loss: 0.0622 - val_mse: 0.0057 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0747 - mse: 0.0223 - val_loss: 0.0646 - val_mse: 0.0060 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0730 - mse: 0.0088 - val_loss: 0.0658 - val_mse: 0.0063 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0722 - mse: 0.0083 - val_loss: 0.0618 - val_mse: 0.0057 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0741 - mse: 0.0092 - val_loss: 0.0619 - val_mse: 0.0057 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0729 - mse: 0.0086 - val_loss: 0.0623 - val_mse: 0.0058 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0739 - mse: 0.0101 - val_loss: 0.0627 - val_mse: 0.0058 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0771 - mse: 0.1560 - val_loss: 0.0614 - val_mse: 0.0056 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0725 - mse: 0.0106 - val_loss: 0.0624 - val_mse: 0.0058 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0701 - mse: 0.0077 - val_loss: 0.0583 - val_mse: 0.0053 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0714 - mse: 0.0086 - val_loss: 0.0632 - val_mse: 0.0059 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0721 - mse: 0.0084 - val_loss: 0.0598 - val_mse: 0.0053 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0725 - mse: 0.0087 - val_loss: 0.0625 - val_mse: 0.0058 - 271ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0715 - mse: 0.0087 - val_loss: 0.0609 - val_mse: 0.0056 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0721 - mse: 0.0109 - val_loss: 0.0597 - val_mse: 0.0053 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0809 - mse: 0.0810 - val_loss: 0.0652 - val_mse: 0.0062 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0733 - mse: 0.0085 - val_loss: 0.0650 - val_mse: 0.0063 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0713 - mse: 0.0081 - val_loss: 0.0602 - val_mse: 0.0054 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0704 - mse: 0.0080 - val_loss: 0.0671 - val_mse: 0.0067 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0746 - mse: 0.0090 - val_loss: 0.0588 - val_mse: 0.0051 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0711 - mse: 0.0087 - val_loss: 0.0589 - val_mse: 0.0051 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0703 - mse: 0.0083 - val_loss: 0.0535 - val_mse: 0.0046 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0747 - mse: 0.0145 - val_loss: 0.0597 - val_mse: 0.0054 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0725 - mse: 0.0090 - val_loss: 0.0678 - val_mse: 0.0068 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0709 - mse: 0.0086 - val_loss: 0.0581 - val_mse: 0.0055 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0696 - mse: 0.0081 - val_loss: 0.0557 - val_mse: 0.0050 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0676 - mse: 0.0076 - val_loss: 0.0546 - val_mse: 0.0045 - 271ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0695 - mse: 0.0083 - val_loss: 0.0580 - val_mse: 0.0050 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0688 - mse: 0.0081 - val_loss: 0.0553 - val_mse: 0.0048 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0712 - mse: 0.0106 - val_loss: 0.0549 - val_mse: 0.0046 - 270ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0673 - mse: 0.0074 - val_loss: 0.0523 - val_mse: 0.0044 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0677 - mse: 0.0082 - val_loss: 0.0529 - val_mse: 0.0045 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0677 - mse: 0.0077 - val_loss: 0.0529 - val_mse: 0.0044 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0671 - mse: 0.0090 - val_loss: 0.0540 - val_mse: 0.0044 - 269ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0688 - mse: 0.0229 - val_loss: 0.0550 - val_mse: 0.0047 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0666 - mse: 0.0082 - val_loss: 0.0532 - val_mse: 0.0043 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0687 - mse: 0.0081 - val_loss: 0.0601 - val_mse: 0.0052 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0693 - mse: 0.0080 - val_loss: 0.0561 - val_mse: 0.0047 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0684 - mse: 0.0080 - val_loss: 0.0522 - val_mse: 0.0042 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0685 - mse: 0.0083 - val_loss: 0.0508 - val_mse: 0.0041 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0683 - mse: 0.0077 - val_loss: 0.0532 - val_mse: 0.0045 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0676 - mse: 0.0074 - val_loss: 0.0532 - val_mse: 0.0043 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0679 - mse: 0.0077 - val_loss: 0.0549 - val_mse: 0.0045 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0674 - mse: 0.0075 - val_loss: 0.0523 - val_mse: 0.0042 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0682 - mse: 0.0076 - val_loss: 0.0546 - val_mse: 0.0049 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0678 - mse: 0.0118 - val_loss: 0.0533 - val_mse: 0.0043 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0670 - mse: 0.0077 - val_loss: 0.0550 - val_mse: 0.0046 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0662 - mse: 0.0076 - val_loss: 0.0545 - val_mse: 0.0045 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0686 - mse: 0.0080 - val_loss: 0.0575 - val_mse: 0.0054 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0682 - mse: 0.0083 - val_loss: 0.0546 - val_mse: 0.0047 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0663 - mse: 0.0073 - val_loss: 0.0510 - val_mse: 0.0041 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0675 - mse: 0.0079 - val_loss: 0.0520 - val_mse: 0.0042 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0665 - mse: 0.0081 - val_loss: 0.0547 - val_mse: 0.0046 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0661 - mse: 0.0075 - val_loss: 0.0560 - val_mse: 0.0048 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0679 - mse: 0.0211 - val_loss: 0.0575 - val_mse: 0.0052 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0659 - mse: 0.0076 - val_loss: 0.0545 - val_mse: 0.0046 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0643 - mse: 0.0068 - val_loss: 0.0592 - val_mse: 0.0053 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0677 - mse: 0.0093 - val_loss: 0.0560 - val_mse: 0.0050 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0691 - mse: 0.0085 - val_loss: 0.0517 - val_mse: 0.0042 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0650 - mse: 0.0073 - val_loss: 0.0524 - val_mse: 0.0042 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0641 - mse: 0.0070 - val_loss: 0.0512 - val_mse: 0.0041 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0653 - mse: 0.0074 - val_loss: 0.0509 - val_mse: 0.0039 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0658 - mse: 0.0074 - val_loss: 0.0519 - val_mse: 0.0043 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0669 - mse: 0.0112 - val_loss: 0.0555 - val_mse: 0.0049 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0672 - mse: 0.0082 - val_loss: 0.0548 - val_mse: 0.0047 - 273ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0666 - mse: 0.0075 - val_loss: 0.0506 - val_mse: 0.0039 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0663 - mse: 0.0075 - val_loss: 0.0502 - val_mse: 0.0039 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0658 - mse: 0.0076 - val_loss: 0.0485 - val_mse: 0.0037 - 271ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0634 - mse: 0.0069 - val_loss: 0.0507 - val_mse: 0.0039 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0651 - mse: 0.0105 - val_loss: 0.0501 - val_mse: 0.0040 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0652 - mse: 0.0073 - val_loss: 0.0518 - val_mse: 0.0041 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0649 - mse: 0.0093 - val_loss: 0.0507 - val_mse: 0.0039 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0649 - mse: 0.0071 - val_loss: 0.0509 - val_mse: 0.0040 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0638 - mse: 0.0069 - val_loss: 0.0526 - val_mse: 0.0042 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0651 - mse: 0.0072 - val_loss: 0.0509 - val_mse: 0.0040 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0649 - mse: 0.0077 - val_loss: 0.0490 - val_mse: 0.0037 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0645 - mse: 0.0073 - val_loss: 0.0506 - val_mse: 0.0039 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0640 - mse: 0.0070 - val_loss: 0.0500 - val_mse: 0.0039 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0636 - mse: 0.0068 - val_loss: 0.0520 - val_mse: 0.0041 - 271ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0643 - mse: 0.0070 - val_loss: 0.0478 - val_mse: 0.0036 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0651 - mse: 0.0073 - val_loss: 0.0490 - val_mse: 0.0038 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0637 - mse: 0.0077 - val_loss: 0.0491 - val_mse: 0.0039 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0645 - mse: 0.0071 - val_loss: 0.0496 - val_mse: 0.0037 - 303ms/epoch - 6ms/step\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 76.4681\n",
            "Function value obtained: 0.0037\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [227]\n",
            "Learning Rate: 0.000175440144708574\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.050236985850517016\n",
            "Batch Size: 206\n",
            "----------------------------------------\n",
            "41/41 - 2s - loss: 25.4090 - mse: 7918.8760 - val_loss: 0.3123 - val_mse: 0.8464 - 2s/epoch - 52ms/step\n",
            "41/41 - 0s - loss: 19.4956 - mse: 4996.6782 - val_loss: 0.6650 - val_mse: 2.7986 - 234ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 20.4469 - mse: 5329.4551 - val_loss: 0.2402 - val_mse: 0.5234 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 19.7432 - mse: 5113.8281 - val_loss: 0.8479 - val_mse: 4.4930 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 20.1928 - mse: 7094.8110 - val_loss: 0.2115 - val_mse: 0.5161 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 19.2619 - mse: 4833.3179 - val_loss: 0.1207 - val_mse: 0.2589 - 229ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 18.1293 - mse: 4628.7549 - val_loss: 0.0823 - val_mse: 0.1715 - 234ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 18.0319 - mse: 4936.3047 - val_loss: 0.0894 - val_mse: 0.1854 - 239ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 17.6056 - mse: 4091.5894 - val_loss: 0.2484 - val_mse: 0.6695 - 230ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 18.1519 - mse: 5172.4014 - val_loss: 0.0747 - val_mse: 0.1540 - 229ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 16.9547 - mse: 4532.4839 - val_loss: 0.7994 - val_mse: 6.3676 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 16.3360 - mse: 3487.7488 - val_loss: 0.2586 - val_mse: 0.8024 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 16.3517 - mse: 3959.3811 - val_loss: 0.3451 - val_mse: 1.6524 - 230ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 15.0161 - mse: 2704.4863 - val_loss: 0.0255 - val_mse: 0.0520 - 244ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 15.3572 - mse: 3472.9563 - val_loss: 0.0223 - val_mse: 0.0452 - 234ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 15.8561 - mse: 3766.0684 - val_loss: 0.0274 - val_mse: 0.0556 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 14.9520 - mse: 3244.8247 - val_loss: 0.2480 - val_mse: 0.9965 - 243ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 14.0570 - mse: 2338.5745 - val_loss: 0.0325 - val_mse: 0.0689 - 233ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 13.3711 - mse: 2509.1431 - val_loss: 0.0141 - val_mse: 0.0286 - 230ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 13.5958 - mse: 2564.8003 - val_loss: 0.1581 - val_mse: 0.5162 - 245ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 13.2050 - mse: 2553.0696 - val_loss: 0.0066 - val_mse: 0.0133 - 240ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 13.6700 - mse: 2844.5576 - val_loss: 0.2147 - val_mse: 0.8324 - 233ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 13.0466 - mse: 2442.5132 - val_loss: 0.0077 - val_mse: 0.0155 - 230ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 12.0954 - mse: 2006.7047 - val_loss: 0.4506 - val_mse: 2.4872 - 235ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 12.3686 - mse: 2111.7161 - val_loss: 0.0064 - val_mse: 0.0130 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 11.7219 - mse: 1981.5574 - val_loss: 0.0292 - val_mse: 0.0637 - 237ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 11.9994 - mse: 2145.4062 - val_loss: 0.3638 - val_mse: 1.7508 - 256ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 11.8115 - mse: 2351.5984 - val_loss: 0.0682 - val_mse: 0.1836 - 229ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 11.0856 - mse: 1699.5308 - val_loss: 0.0319 - val_mse: 0.0697 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 10.6403 - mse: 1560.5248 - val_loss: 0.0053 - val_mse: 0.0105 - 243ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 10.7059 - mse: 1687.3156 - val_loss: 0.0067 - val_mse: 0.0135 - 238ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 10.7557 - mse: 1715.5343 - val_loss: 0.0113 - val_mse: 0.0228 - 229ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 9.9666 - mse: 1515.1476 - val_loss: 0.0526 - val_mse: 0.1400 - 235ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 9.6421 - mse: 1163.1379 - val_loss: 0.0626 - val_mse: 0.1784 - 225ms/epoch - 5ms/step\n",
            "41/41 - 0s - loss: 9.5184 - mse: 1338.9926 - val_loss: 0.0098 - val_mse: 0.0208 - 227ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 9.1204 - mse: 986.2859 - val_loss: 0.0133 - val_mse: 0.0289 - 232ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 9.0868 - mse: 1084.2697 - val_loss: 0.1983 - val_mse: 0.7976 - 226ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 8.8559 - mse: 1237.4742 - val_loss: 0.0188 - val_mse: 0.0425 - 227ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 9.0151 - mse: 1199.3887 - val_loss: 0.0088 - val_mse: 0.0177 - 233ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 8.5136 - mse: 927.0526 - val_loss: 0.0356 - val_mse: 0.0800 - 228ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 8.5504 - mse: 1106.8884 - val_loss: 0.0423 - val_mse: 0.1112 - 225ms/epoch - 5ms/step\n",
            "41/41 - 0s - loss: 7.7370 - mse: 786.8154 - val_loss: 0.0056 - val_mse: 0.0115 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 8.0107 - mse: 955.9481 - val_loss: 0.0163 - val_mse: 0.0333 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 7.4706 - mse: 730.5458 - val_loss: 0.0206 - val_mse: 0.0476 - 223ms/epoch - 5ms/step\n",
            "41/41 - 0s - loss: 7.5728 - mse: 780.7548 - val_loss: 0.0077 - val_mse: 0.0154 - 233ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 7.4896 - mse: 798.9742 - val_loss: 0.0425 - val_mse: 0.0938 - 230ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 7.3019 - mse: 884.6125 - val_loss: 0.0061 - val_mse: 0.0122 - 224ms/epoch - 5ms/step\n",
            "41/41 - 0s - loss: 6.8358 - mse: 762.1434 - val_loss: 0.3648 - val_mse: 1.6680 - 231ms/epoch - 6ms/step\n",
            "41/41 - 0s - loss: 6.7325 - mse: 647.2874 - val_loss: 0.2177 - val_mse: 0.9673 - 225ms/epoch - 5ms/step\n",
            "41/41 - 0s - loss: 6.6381 - mse: 605.8407 - val_loss: 0.1674 - val_mse: 0.6557 - 228ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.74899275]\n",
            "\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 17.9609\n",
            "Function value obtained: 0.6557\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [182]\n",
            "Learning Rate: 0.00017081636474245977\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.04175405000464217\n",
            "Batch Size: 100\n",
            "----------------------------------------\n",
            "84/84 - 2s - loss: 121.7737 - mse: 216910.4219 - val_loss: 3.2655 - val_mse: 72.4647 - 2s/epoch - 26ms/step\n",
            "84/84 - 0s - loss: 39.0700 - mse: 20378.3691 - val_loss: 0.4384 - val_mse: 1.5601 - 360ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 21.3718 - mse: 6435.8979 - val_loss: 0.4543 - val_mse: 1.0434 - 361ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 20.2144 - mse: 5084.8911 - val_loss: 0.4503 - val_mse: 1.1857 - 364ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 19.4369 - mse: 4686.5894 - val_loss: 0.1354 - val_mse: 0.2801 - 365ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 19.1659 - mse: 4972.6631 - val_loss: 0.1524 - val_mse: 0.3047 - 369ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 21.0654 - mse: 6772.8750 - val_loss: 0.1425 - val_mse: 0.3693 - 376ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 19.5434 - mse: 5698.4551 - val_loss: 0.0841 - val_mse: 0.1699 - 374ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 18.7963 - mse: 4819.6846 - val_loss: 0.0465 - val_mse: 0.0931 - 377ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 18.8452 - mse: 5133.5850 - val_loss: 0.0836 - val_mse: 0.1793 - 364ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 17.8170 - mse: 3898.3430 - val_loss: 0.4933 - val_mse: 2.9479 - 374ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 18.3258 - mse: 4762.6719 - val_loss: 0.0151 - val_mse: 0.0302 - 357ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 18.0020 - mse: 4330.5278 - val_loss: 0.0748 - val_mse: 0.1662 - 360ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 18.1419 - mse: 4781.6328 - val_loss: 0.0465 - val_mse: 0.0969 - 362ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 17.0498 - mse: 3631.2422 - val_loss: 0.0241 - val_mse: 0.0487 - 364ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 16.8847 - mse: 4369.3389 - val_loss: 0.0136 - val_mse: 0.0272 - 368ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 16.8893 - mse: 4764.6577 - val_loss: 0.0248 - val_mse: 0.0496 - 360ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 17.5834 - mse: 6509.8784 - val_loss: 0.0198 - val_mse: 0.0395 - 373ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 16.6543 - mse: 4769.3477 - val_loss: 0.0236 - val_mse: 0.0474 - 360ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 15.5956 - mse: 3378.3079 - val_loss: 0.0061 - val_mse: 0.0123 - 373ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 15.3296 - mse: 3339.6099 - val_loss: 0.0674 - val_mse: 0.1548 - 357ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 14.2870 - mse: 2778.0764 - val_loss: 0.4533 - val_mse: 2.3870 - 358ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 15.7700 - mse: 4425.9854 - val_loss: 0.3288 - val_mse: 1.3707 - 354ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 14.3299 - mse: 2588.7551 - val_loss: 0.0051 - val_mse: 0.0102 - 358ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 14.5400 - mse: 3196.0112 - val_loss: 0.0524 - val_mse: 0.1196 - 361ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 13.2004 - mse: 2649.9395 - val_loss: 0.1816 - val_mse: 0.5478 - 363ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 13.1213 - mse: 2618.4563 - val_loss: 0.0583 - val_mse: 0.1457 - 364ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 13.3459 - mse: 2393.7046 - val_loss: 0.1017 - val_mse: 0.2494 - 364ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 13.1857 - mse: 2619.9519 - val_loss: 0.0125 - val_mse: 0.0250 - 366ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 12.8138 - mse: 2365.3679 - val_loss: 0.0395 - val_mse: 0.0902 - 366ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 12.4483 - mse: 2656.9502 - val_loss: 0.2520 - val_mse: 0.8666 - 362ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 11.8440 - mse: 1909.3459 - val_loss: 0.0113 - val_mse: 0.0226 - 376ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 11.1029 - mse: 1521.2817 - val_loss: 0.0911 - val_mse: 0.2164 - 376ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 11.2462 - mse: 1575.1476 - val_loss: 0.0063 - val_mse: 0.0125 - 372ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 10.9807 - mse: 1663.7823 - val_loss: 0.0137 - val_mse: 0.0274 - 382ms/epoch - 5ms/step\n",
            "84/84 - 0s - loss: 10.5960 - mse: 1706.0718 - val_loss: 0.1381 - val_mse: 0.3717 - 376ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 10.0168 - mse: 1305.4308 - val_loss: 0.0795 - val_mse: 0.1854 - 372ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 10.0737 - mse: 1750.1284 - val_loss: 0.1990 - val_mse: 0.6824 - 365ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 10.8343 - mse: 1769.3710 - val_loss: 0.0561 - val_mse: 0.1196 - 371ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 9.6423 - mse: 1273.9084 - val_loss: 0.0086 - val_mse: 0.0171 - 370ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 9.1210 - mse: 1290.5192 - val_loss: 0.0276 - val_mse: 0.0578 - 367ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 9.4244 - mse: 1114.2548 - val_loss: 0.4690 - val_mse: 2.2527 - 366ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 8.7959 - mse: 1095.8196 - val_loss: 0.0271 - val_mse: 0.0545 - 371ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 8.2959 - mse: 810.0768 - val_loss: 0.0278 - val_mse: 0.0556 - 372ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 8.5576 - mse: 1004.2324 - val_loss: 0.0178 - val_mse: 0.0356 - 370ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 8.4912 - mse: 1403.0522 - val_loss: 0.0104 - val_mse: 0.0207 - 370ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 7.7264 - mse: 793.9405 - val_loss: 0.1062 - val_mse: 0.2907 - 368ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 7.8458 - mse: 969.7607 - val_loss: 0.0051 - val_mse: 0.0103 - 370ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 7.8679 - mse: 871.8343 - val_loss: 0.0708 - val_mse: 0.1597 - 374ms/epoch - 4ms/step\n",
            "84/84 - 0s - loss: 7.3639 - mse: 721.4273 - val_loss: 0.0160 - val_mse: 0.0321 - 359ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 24.6767\n",
            "Function value obtained: 0.0321\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [124, 118]\n",
            "Learning Rate: 0.00012410409969188736\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.15016953804483282\n",
            "Batch Size: 237\n",
            "----------------------------------------\n",
            "36/36 - 3s - loss: 175.1255 - mse: 367107.5312 - val_loss: 16.6232 - val_mse: 1232.0751 - 3s/epoch - 79ms/step\n",
            "36/36 - 0s - loss: 126.7425 - mse: 204551.4844 - val_loss: 10.1620 - val_mse: 555.0032 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 101.1621 - mse: 127991.8438 - val_loss: 4.4686 - val_mse: 73.4334 - 249ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 90.1738 - mse: 101027.2188 - val_loss: 5.0521 - val_mse: 98.3267 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 73.8155 - mse: 64266.4258 - val_loss: 0.6949 - val_mse: 0.4964 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 69.3596 - mse: 55202.1875 - val_loss: 3.4029 - val_mse: 37.9259 - 244ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 61.7243 - mse: 49765.6680 - val_loss: 3.1610 - val_mse: 38.5470 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 53.1290 - mse: 35219.0508 - val_loss: 1.2094 - val_mse: 2.0115 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 46.0403 - mse: 21650.7402 - val_loss: 1.7207 - val_mse: 8.6624 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 40.4995 - mse: 18535.6816 - val_loss: 0.7025 - val_mse: 0.5821 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 41.8420 - mse: 21359.4375 - val_loss: 0.6088 - val_mse: 0.3836 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 34.7343 - mse: 15497.1357 - val_loss: 0.5021 - val_mse: 0.2817 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 30.4180 - mse: 9845.6904 - val_loss: 1.1696 - val_mse: 2.8226 - 242ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 29.5101 - mse: 9692.4102 - val_loss: 1.0752 - val_mse: 2.9668 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 26.8839 - mse: 8518.2080 - val_loss: 0.5052 - val_mse: 0.2720 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 23.9855 - mse: 5786.2700 - val_loss: 1.2477 - val_mse: 4.6997 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 22.8372 - mse: 5939.3496 - val_loss: 0.4201 - val_mse: 0.1908 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 20.1422 - mse: 4638.0962 - val_loss: 0.4969 - val_mse: 0.2975 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 19.6011 - mse: 5398.7905 - val_loss: 0.9319 - val_mse: 1.7087 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 18.3812 - mse: 4392.3906 - val_loss: 0.4090 - val_mse: 0.3740 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 17.0155 - mse: 3279.8311 - val_loss: 0.3497 - val_mse: 0.1389 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 16.0770 - mse: 3507.5928 - val_loss: 0.3605 - val_mse: 0.1449 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 14.9445 - mse: 2458.8677 - val_loss: 1.1592 - val_mse: 4.2730 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 14.2163 - mse: 2688.8457 - val_loss: 0.4569 - val_mse: 0.7668 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 13.8840 - mse: 2871.6785 - val_loss: 0.4525 - val_mse: 0.3534 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 12.2517 - mse: 1821.2225 - val_loss: 0.4453 - val_mse: 0.3714 - 243ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 11.4722 - mse: 1784.1868 - val_loss: 0.2034 - val_mse: 0.0577 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 10.6912 - mse: 1327.3344 - val_loss: 0.2005 - val_mse: 0.0602 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 10.8608 - mse: 1575.2159 - val_loss: 0.2626 - val_mse: 0.1009 - 244ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 9.5189 - mse: 1096.8044 - val_loss: 0.2558 - val_mse: 0.0772 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 9.9641 - mse: 1351.5260 - val_loss: 0.1831 - val_mse: 0.0504 - 238ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 9.0238 - mse: 1058.6433 - val_loss: 0.4051 - val_mse: 0.2586 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 8.4586 - mse: 838.6954 - val_loss: 0.2455 - val_mse: 0.0843 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 7.7272 - mse: 754.8069 - val_loss: 0.2560 - val_mse: 0.0912 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 6.8298 - mse: 572.8788 - val_loss: 0.2502 - val_mse: 0.0778 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 6.7173 - mse: 560.0445 - val_loss: 0.5772 - val_mse: 0.7385 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 6.7135 - mse: 642.3369 - val_loss: 0.4417 - val_mse: 0.3513 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 6.3364 - mse: 647.3763 - val_loss: 0.6318 - val_mse: 1.0322 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 5.6972 - mse: 435.4130 - val_loss: 0.3438 - val_mse: 0.1603 - 228ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 5.5035 - mse: 366.8345 - val_loss: 0.4822 - val_mse: 0.4419 - 241ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 5.2187 - mse: 406.7568 - val_loss: 0.5269 - val_mse: 0.5983 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 4.5039 - mse: 267.5978 - val_loss: 0.4726 - val_mse: 0.4243 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 4.8856 - mse: 300.8465 - val_loss: 0.3722 - val_mse: 0.2424 - 228ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 4.4654 - mse: 309.3242 - val_loss: 0.4271 - val_mse: 0.3742 - 246ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 4.4293 - mse: 253.4252 - val_loss: 0.3548 - val_mse: 0.2260 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 4.1757 - mse: 250.5151 - val_loss: 0.3456 - val_mse: 0.2400 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 3.9903 - mse: 212.3663 - val_loss: 0.2168 - val_mse: 0.0791 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 3.6311 - mse: 194.5160 - val_loss: 0.4108 - val_mse: 0.3856 - 228ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 3.3086 - mse: 130.5554 - val_loss: 0.2851 - val_mse: 0.1674 - 223ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 3.4277 - mse: 309.8026 - val_loss: 0.2319 - val_mse: 0.1154 - 231ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 18.8906\n",
            "Function value obtained: 0.1154\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [184, 190]\n",
            "Learning Rate: 0.0021692211670312975\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3683372324536306\n",
            "Batch Size: 78\n",
            "----------------------------------------\n",
            "108/108 - 4s - loss: 180.0605 - mse: 651555.1875 - val_loss: 0.4877 - val_mse: 0.3748 - 4s/epoch - 36ms/step\n",
            "108/108 - 1s - loss: 12.9970 - mse: 2158.7429 - val_loss: 0.2381 - val_mse: 0.0681 - 517ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 4.7384 - mse: 352.5511 - val_loss: 0.1296 - val_mse: 0.0239 - 527ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 2.0778 - mse: 75.5264 - val_loss: 0.1115 - val_mse: 0.0189 - 518ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 1.2373 - mse: 30.1561 - val_loss: 0.0910 - val_mse: 0.0132 - 522ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.7338 - mse: 10.0163 - val_loss: 0.0863 - val_mse: 0.0110 - 513ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.5095 - mse: 4.8380 - val_loss: 0.0910 - val_mse: 0.0125 - 529ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.3463 - mse: 2.0414 - val_loss: 0.0952 - val_mse: 0.0137 - 521ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.3079 - mse: 3.8214 - val_loss: 0.0900 - val_mse: 0.0123 - 530ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.2393 - mse: 1.4886 - val_loss: 0.0909 - val_mse: 0.0126 - 520ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.2080 - mse: 0.8400 - val_loss: 0.0914 - val_mse: 0.0129 - 522ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1791 - mse: 0.5194 - val_loss: 0.0904 - val_mse: 0.0127 - 521ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1572 - mse: 0.5845 - val_loss: 0.0886 - val_mse: 0.0123 - 518ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1604 - mse: 0.6164 - val_loss: 0.0885 - val_mse: 0.0120 - 513ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1433 - mse: 0.3939 - val_loss: 0.0864 - val_mse: 0.0115 - 519ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1354 - mse: 0.3442 - val_loss: 0.0863 - val_mse: 0.0115 - 519ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1211 - mse: 0.1428 - val_loss: 0.0857 - val_mse: 0.0112 - 513ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1208 - mse: 0.1155 - val_loss: 0.0844 - val_mse: 0.0106 - 524ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1234 - mse: 0.2614 - val_loss: 0.0851 - val_mse: 0.0111 - 518ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1117 - mse: 0.0921 - val_loss: 0.0866 - val_mse: 0.0115 - 515ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1156 - mse: 0.5359 - val_loss: 0.0872 - val_mse: 0.0116 - 515ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1088 - mse: 0.1462 - val_loss: 0.0863 - val_mse: 0.0114 - 511ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1042 - mse: 0.0462 - val_loss: 0.0832 - val_mse: 0.0104 - 516ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1008 - mse: 0.0554 - val_loss: 0.0836 - val_mse: 0.0106 - 516ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1040 - mse: 0.0750 - val_loss: 0.0824 - val_mse: 0.0103 - 513ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1028 - mse: 0.0774 - val_loss: 0.0830 - val_mse: 0.0104 - 509ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0974 - mse: 0.0407 - val_loss: 0.0854 - val_mse: 0.0113 - 525ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0957 - mse: 0.0350 - val_loss: 0.0826 - val_mse: 0.0103 - 532ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0946 - mse: 0.0414 - val_loss: 0.0796 - val_mse: 0.0093 - 525ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.1036 - mse: 0.1197 - val_loss: 0.0800 - val_mse: 0.0094 - 534ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0949 - mse: 0.0518 - val_loss: 0.0825 - val_mse: 0.0101 - 541ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0921 - mse: 0.0248 - val_loss: 0.0797 - val_mse: 0.0094 - 535ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0896 - mse: 0.0355 - val_loss: 0.0755 - val_mse: 0.0081 - 521ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0894 - mse: 0.0234 - val_loss: 0.0809 - val_mse: 0.0098 - 513ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0874 - mse: 0.0245 - val_loss: 0.0809 - val_mse: 0.0099 - 527ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0877 - mse: 0.0263 - val_loss: 0.0740 - val_mse: 0.0079 - 511ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0857 - mse: 0.0202 - val_loss: 0.0785 - val_mse: 0.0092 - 514ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0864 - mse: 0.0247 - val_loss: 0.0756 - val_mse: 0.0082 - 519ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0863 - mse: 0.0174 - val_loss: 0.0730 - val_mse: 0.0075 - 512ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0859 - mse: 0.0301 - val_loss: 0.0742 - val_mse: 0.0077 - 520ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0857 - mse: 0.0225 - val_loss: 0.0707 - val_mse: 0.0072 - 511ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0843 - mse: 0.0168 - val_loss: 0.0744 - val_mse: 0.0081 - 515ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0832 - mse: 0.0175 - val_loss: 0.0740 - val_mse: 0.0079 - 512ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0839 - mse: 0.0192 - val_loss: 0.0750 - val_mse: 0.0081 - 509ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0819 - mse: 0.0180 - val_loss: 0.0707 - val_mse: 0.0073 - 512ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0806 - mse: 0.0126 - val_loss: 0.0681 - val_mse: 0.0066 - 522ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0834 - mse: 0.0501 - val_loss: 0.0729 - val_mse: 0.0077 - 514ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0815 - mse: 0.0163 - val_loss: 0.0737 - val_mse: 0.0077 - 516ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0801 - mse: 0.0123 - val_loss: 0.0722 - val_mse: 0.0075 - 522ms/epoch - 5ms/step\n",
            "108/108 - 1s - loss: 0.0783 - mse: 0.0106 - val_loss: 0.0734 - val_mse: 0.0079 - 529ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.01489088]\n",
            "\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 34.0494\n",
            "Function value obtained: 0.0079\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [247]\n",
            "Learning Rate: 0.0220119179420171\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.33085489959074826\n",
            "Batch Size: 172\n",
            "----------------------------------------\n",
            "49/49 - 2s - loss: 608.5928 - mse: 20591290.0000 - val_loss: 1.4222 - val_mse: 12.3318 - 2s/epoch - 41ms/step\n",
            "49/49 - 0s - loss: 7.2232 - mse: 798.0048 - val_loss: 0.4995 - val_mse: 2.6982 - 252ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 1.6949 - mse: 181.7004 - val_loss: 0.2377 - val_mse: 1.0359 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.6926 - mse: 27.2396 - val_loss: 0.0275 - val_mse: 0.0573 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.2551 - mse: 1.5479 - val_loss: 0.3107 - val_mse: 1.5287 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.1728 - mse: 1.0085 - val_loss: 0.0079 - val_mse: 0.0159 - 251ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.1043 - mse: 21.3666 - val_loss: 0.0052 - val_mse: 0.0105 - 254ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0354 - mse: 0.0992 - val_loss: 0.0043 - val_mse: 0.0087 - 256ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0359 - mse: 0.3548 - val_loss: 0.1782 - val_mse: 0.6173 - 254ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0916 - mse: 0.3516 - val_loss: 0.0538 - val_mse: 0.1307 - 250ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0777 - mse: 4.2521 - val_loss: 0.0176 - val_mse: 0.0401 - 254ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0643 - mse: 3.2162 - val_loss: 0.0759 - val_mse: 0.2009 - 251ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.1887 - mse: 0.9336 - val_loss: 0.0956 - val_mse: 0.3059 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0423 - mse: 0.1464 - val_loss: 0.0237 - val_mse: 0.0559 - 262ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0140 - mse: 0.0334 - val_loss: 0.0123 - val_mse: 0.0267 - 261ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0253 - mse: 0.1509 - val_loss: 0.0162 - val_mse: 0.0337 - 253ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0164 - mse: 0.0387 - val_loss: 0.0044 - val_mse: 0.0089 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0080 - mse: 0.0172 - val_loss: 0.0080 - val_mse: 0.0169 - 258ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0054 - mse: 0.0110 - val_loss: 0.0035 - val_mse: 0.0069 - 251ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0126 - mse: 0.0322 - val_loss: 0.0047 - val_mse: 0.0095 - 252ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0113 - mse: 0.0250 - val_loss: 0.0077 - val_mse: 0.0161 - 256ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0485 - mse: 0.1809 - val_loss: 0.0033 - val_mse: 0.0066 - 252ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.1445 - mse: 1.1403 - val_loss: 0.5641 - val_mse: 3.5773 - 253ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.2573 - mse: 2.0173 - val_loss: 0.0207 - val_mse: 0.0484 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0726 - mse: 0.3246 - val_loss: 0.0045 - val_mse: 0.0090 - 254ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0059 - mse: 0.0126 - val_loss: 0.0035 - val_mse: 0.0071 - 263ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0052 - mse: 0.0106 - val_loss: 0.0034 - val_mse: 0.0068 - 267ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0043 - mse: 0.0087 - val_loss: 0.0038 - val_mse: 0.0076 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0034 - val_mse: 0.0069 - 265ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0034 - val_mse: 0.0068 - 269ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0033 - val_mse: 0.0066 - 270ms/epoch - 6ms/step\n",
            "49/49 - 0s - loss: 0.0070 - mse: 0.0586 - val_loss: 0.0031 - val_mse: 0.0062 - 261ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0047 - mse: 0.0096 - val_loss: 0.0035 - val_mse: 0.0069 - 265ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0035 - val_mse: 0.0070 - 259ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0043 - mse: 0.0087 - val_loss: 0.0052 - val_mse: 0.0107 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0032 - val_mse: 0.0064 - 266ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0030 - val_mse: 0.0061 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0030 - val_mse: 0.0060 - 257ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0033 - val_mse: 0.0067 - 264ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0030 - val_mse: 0.0060 - 256ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0036 - val_mse: 0.0072 - 258ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0032 - val_mse: 0.0063 - 266ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0033 - val_mse: 0.0065 - 258ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0030 - val_mse: 0.0061 - 251ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0030 - val_mse: 0.0061 - 259ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0044 - mse: 0.0089 - val_loss: 0.0032 - val_mse: 0.0065 - 256ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0032 - val_mse: 0.0065 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0038 - mse: 0.0075 - val_loss: 0.0029 - val_mse: 0.0059 - 254ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0040 - mse: 0.0082 - val_loss: 0.0036 - val_mse: 0.0072 - 255ms/epoch - 5ms/step\n",
            "49/49 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0034 - val_mse: 0.0068 - 254ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.68846679]\n",
            "\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 19.1166\n",
            "Function value obtained: 0.0068\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [166, 72]\n",
            "Learning Rate: 0.00010278800134488706\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3929083465244674\n",
            "Batch Size: 39\n",
            "----------------------------------------\n",
            "216/216 - 4s - loss: 414.6999 - mse: 2315435.2500 - val_loss: 35.5923 - val_mse: 7254.8799 - 4s/epoch - 17ms/step\n",
            "216/216 - 1s - loss: 245.0099 - mse: 692491.0625 - val_loss: 28.9454 - val_mse: 4817.2144 - 941ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 168.9026 - mse: 357269.9375 - val_loss: 19.4157 - val_mse: 2188.1111 - 970ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 111.6676 - mse: 142445.8281 - val_loss: 7.2101 - val_mse: 339.5662 - 918ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 79.1782 - mse: 76123.8203 - val_loss: 2.1525 - val_mse: 40.6909 - 922ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 58.7436 - mse: 41191.2930 - val_loss: 3.6790 - val_mse: 104.3040 - 922ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 45.9119 - mse: 31368.4336 - val_loss: 2.3507 - val_mse: 44.2629 - 926ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 34.4959 - mse: 15174.2627 - val_loss: 1.2543 - val_mse: 14.2804 - 926ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 26.4732 - mse: 9398.3467 - val_loss: 0.6379 - val_mse: 4.2540 - 913ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 21.0639 - mse: 5941.8701 - val_loss: 0.4807 - val_mse: 2.5275 - 906ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 16.1349 - mse: 3617.6702 - val_loss: 0.1637 - val_mse: 0.3615 - 911ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 12.9297 - mse: 2364.2334 - val_loss: 0.1513 - val_mse: 0.3306 - 913ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 10.7889 - mse: 2746.0156 - val_loss: 0.1401 - val_mse: 0.3042 - 943ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 8.1365 - mse: 1448.3816 - val_loss: 0.1193 - val_mse: 0.2503 - 935ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 7.1992 - mse: 1094.5651 - val_loss: 0.1074 - val_mse: 0.2244 - 950ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 5.1495 - mse: 507.7687 - val_loss: 0.0889 - val_mse: 0.1847 - 905ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 4.2163 - mse: 373.0345 - val_loss: 0.0769 - val_mse: 0.1592 - 912ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 3.4749 - mse: 372.2501 - val_loss: 0.0610 - val_mse: 0.1252 - 918ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 2.8208 - mse: 221.2107 - val_loss: 0.0319 - val_mse: 0.0648 - 915ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 2.3423 - mse: 209.4051 - val_loss: 0.0222 - val_mse: 0.0449 - 933ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 1.9550 - mse: 134.0184 - val_loss: 0.0135 - val_mse: 0.0271 - 909ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 1.4726 - mse: 112.5476 - val_loss: 0.0087 - val_mse: 0.0175 - 923ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 1.1212 - mse: 72.8260 - val_loss: 0.0089 - val_mse: 0.0179 - 906ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.9915 - mse: 75.4673 - val_loss: 0.0057 - val_mse: 0.0113 - 893ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.7709 - mse: 47.6308 - val_loss: 0.0035 - val_mse: 0.0070 - 921ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.6145 - mse: 27.1078 - val_loss: 0.0034 - val_mse: 0.0068 - 931ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.6050 - mse: 71.8119 - val_loss: 0.0037 - val_mse: 0.0073 - 942ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.4527 - mse: 13.5729 - val_loss: 0.0038 - val_mse: 0.0077 - 905ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.3922 - mse: 13.5061 - val_loss: 0.0042 - val_mse: 0.0084 - 905ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.3380 - mse: 14.9637 - val_loss: 0.0055 - val_mse: 0.0110 - 904ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.2428 - mse: 4.7828 - val_loss: 0.0041 - val_mse: 0.0082 - 905ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.4152 - mse: 62.8439 - val_loss: 0.0036 - val_mse: 0.0073 - 913ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.2425 - mse: 11.7286 - val_loss: 0.0036 - val_mse: 0.0072 - 916ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.2338 - mse: 29.1484 - val_loss: 0.0050 - val_mse: 0.0100 - 918ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.2170 - mse: 12.3630 - val_loss: 0.0066 - val_mse: 0.0134 - 908ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.1414 - mse: 6.5216 - val_loss: 0.0041 - val_mse: 0.0082 - 904ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.1358 - mse: 6.8347 - val_loss: 0.0048 - val_mse: 0.0096 - 918ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.1079 - mse: 2.1648 - val_loss: 0.0035 - val_mse: 0.0070 - 939ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0901 - mse: 2.4526 - val_loss: 0.0036 - val_mse: 0.0072 - 937ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0893 - mse: 2.8257 - val_loss: 0.0036 - val_mse: 0.0073 - 910ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.1095 - mse: 8.7410 - val_loss: 0.0034 - val_mse: 0.0068 - 907ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0891 - mse: 5.9149 - val_loss: 0.0053 - val_mse: 0.0107 - 913ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.1305 - mse: 10.0125 - val_loss: 0.0089 - val_mse: 0.0179 - 913ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0542 - mse: 1.4931 - val_loss: 0.0036 - val_mse: 0.0072 - 911ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0755 - mse: 2.9994 - val_loss: 0.0038 - val_mse: 0.0075 - 916ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0532 - mse: 3.4103 - val_loss: 0.0037 - val_mse: 0.0074 - 908ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0323 - mse: 0.5318 - val_loss: 0.0040 - val_mse: 0.0080 - 916ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0295 - mse: 0.3325 - val_loss: 0.0072 - val_mse: 0.0146 - 905ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0323 - mse: 0.5621 - val_loss: 0.0037 - val_mse: 0.0073 - 930ms/epoch - 4ms/step\n",
            "216/216 - 1s - loss: 0.0621 - mse: 5.7347 - val_loss: 0.0034 - val_mse: 0.0069 - 928ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 53.1407\n",
            "Function value obtained: 0.0069\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [114, 164]\n",
            "Learning Rate: 3.548359844377535e-06\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.43803755492150437\n",
            "Batch Size: 224\n",
            "----------------------------------------\n",
            "38/38 - 4s - loss: 846.7144 - mse: 9582281.0000 - val_loss: 99.7067 - val_mse: 48476.5508 - 4s/epoch - 96ms/step\n",
            "38/38 - 0s - loss: 814.3622 - mse: 7616217.0000 - val_loss: 78.1464 - val_mse: 29565.3477 - 264ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 797.7410 - mse: 6379100.5000 - val_loss: 59.2610 - val_mse: 16853.8711 - 258ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 771.8190 - mse: 7262726.5000 - val_loss: 46.2613 - val_mse: 10145.2412 - 255ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 746.1278 - mse: 5981409.0000 - val_loss: 35.4970 - val_mse: 5890.4946 - 264ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 734.1702 - mse: 6258339.0000 - val_loss: 25.1761 - val_mse: 2894.3604 - 257ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 714.4303 - mse: 5964605.0000 - val_loss: 15.9759 - val_mse: 1113.4774 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 701.7055 - mse: 5297878.0000 - val_loss: 9.0009 - val_mse: 323.7390 - 258ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 701.2919 - mse: 5430447.5000 - val_loss: 2.9027 - val_mse: 24.4077 - 250ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 716.9677 - mse: 6040014.5000 - val_loss: 4.5237 - val_mse: 181.1087 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 657.9196 - mse: 4721693.5000 - val_loss: 9.9064 - val_mse: 730.2297 - 249ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 695.3313 - mse: 5807179.0000 - val_loss: 15.6186 - val_mse: 1619.2559 - 246ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 677.3994 - mse: 5046773.5000 - val_loss: 19.6858 - val_mse: 2424.7107 - 254ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 663.6271 - mse: 5607451.0000 - val_loss: 22.9325 - val_mse: 3184.3135 - 246ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 666.1746 - mse: 5618328.5000 - val_loss: 25.1582 - val_mse: 3761.3271 - 246ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 621.7811 - mse: 4197279.0000 - val_loss: 25.1665 - val_mse: 3730.8330 - 245ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 625.8476 - mse: 4669921.5000 - val_loss: 26.1405 - val_mse: 3989.8035 - 248ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 614.6827 - mse: 4053471.7500 - val_loss: 26.3162 - val_mse: 4022.9905 - 241ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 613.4876 - mse: 4394285.0000 - val_loss: 28.1504 - val_mse: 4565.7930 - 252ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 610.0105 - mse: 4251696.0000 - val_loss: 29.8736 - val_mse: 5105.6807 - 249ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 622.7755 - mse: 4794605.5000 - val_loss: 30.9855 - val_mse: 5470.0171 - 265ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 620.6633 - mse: 4933030.5000 - val_loss: 32.7044 - val_mse: 6061.8042 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 594.6372 - mse: 4026915.0000 - val_loss: 33.1061 - val_mse: 6191.2559 - 254ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 584.3279 - mse: 3524513.7500 - val_loss: 31.8208 - val_mse: 5725.0957 - 273ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 589.7376 - mse: 4607811.0000 - val_loss: 32.7654 - val_mse: 6046.9976 - 262ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 611.8878 - mse: 4317389.5000 - val_loss: 29.4954 - val_mse: 4925.9053 - 258ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 585.6876 - mse: 4342670.0000 - val_loss: 25.8348 - val_mse: 3808.4216 - 248ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 580.7469 - mse: 4587760.0000 - val_loss: 24.2693 - val_mse: 3375.1409 - 267ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 559.8254 - mse: 3240101.0000 - val_loss: 22.0150 - val_mse: 2796.8315 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 588.0108 - mse: 4182180.2500 - val_loss: 22.1316 - val_mse: 2823.2341 - 265ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 602.4576 - mse: 4546024.5000 - val_loss: 20.1005 - val_mse: 2346.2341 - 252ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 594.9286 - mse: 4794063.5000 - val_loss: 19.8994 - val_mse: 2300.8076 - 246ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 544.6232 - mse: 3456857.5000 - val_loss: 18.9777 - val_mse: 2100.5808 - 255ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 596.4790 - mse: 4314060.5000 - val_loss: 20.7087 - val_mse: 2480.5410 - 259ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 573.2076 - mse: 3964042.2500 - val_loss: 18.1724 - val_mse: 1930.9285 - 242ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 589.8544 - mse: 4371971.5000 - val_loss: 14.9723 - val_mse: 1334.4142 - 239ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 531.7933 - mse: 2975443.7500 - val_loss: 12.1500 - val_mse: 898.2006 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 525.3221 - mse: 3105806.5000 - val_loss: 12.3291 - val_mse: 923.5402 - 247ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 538.9851 - mse: 3762064.7500 - val_loss: 9.8471 - val_mse: 604.8761 - 250ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 545.6018 - mse: 3661357.0000 - val_loss: 8.9678 - val_mse: 507.8266 - 251ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 507.2443 - mse: 3052181.2500 - val_loss: 7.7407 - val_mse: 385.9749 - 249ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 538.2930 - mse: 3141176.0000 - val_loss: 12.0606 - val_mse: 884.9433 - 248ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 569.6872 - mse: 4320821.5000 - val_loss: 13.9194 - val_mse: 1159.7460 - 252ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 556.8737 - mse: 3878405.5000 - val_loss: 11.3127 - val_mse: 783.5040 - 246ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 541.9698 - mse: 3573543.0000 - val_loss: 8.9209 - val_mse: 501.8327 - 245ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 542.3020 - mse: 3767494.2500 - val_loss: 12.7675 - val_mse: 984.0530 - 249ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 549.0889 - mse: 4010222.2500 - val_loss: 12.9135 - val_mse: 1005.6839 - 241ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 557.4882 - mse: 3527540.5000 - val_loss: 15.1552 - val_mse: 1362.4824 - 245ms/epoch - 6ms/step\n",
            "38/38 - 0s - loss: 542.6225 - mse: 3546429.0000 - val_loss: 14.4002 - val_mse: 1236.0482 - 249ms/epoch - 7ms/step\n",
            "38/38 - 0s - loss: 507.0473 - mse: 2918411.5000 - val_loss: 15.5855 - val_mse: 1436.7729 - 242ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 20.6291\n",
            "Function value obtained: 1436.7729\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [109]\n",
            "Learning Rate: 7.566532977270993e-06\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.32039053018857566\n",
            "Batch Size: 109\n",
            "----------------------------------------\n",
            "78/78 - 2s - loss: 795.4977 - mse: 8221844.5000 - val_loss: 104.6453 - val_mse: 54495.5938 - 2s/epoch - 28ms/step\n",
            "78/78 - 0s - loss: 762.9538 - mse: 7373376.5000 - val_loss: 101.2411 - val_mse: 50972.6680 - 351ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 732.2505 - mse: 6296091.5000 - val_loss: 94.7390 - val_mse: 44589.7656 - 350ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 702.5052 - mse: 5320972.0000 - val_loss: 89.2477 - val_mse: 39533.0039 - 360ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 679.3013 - mse: 5025146.5000 - val_loss: 82.1018 - val_mse: 33411.4531 - 356ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 691.3876 - mse: 5810862.5000 - val_loss: 75.0250 - val_mse: 27858.5742 - 348ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 665.2715 - mse: 4733050.5000 - val_loss: 65.3808 - val_mse: 21103.2773 - 340ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 668.1868 - mse: 4824710.5000 - val_loss: 58.9925 - val_mse: 17145.2051 - 346ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 632.6844 - mse: 4524674.0000 - val_loss: 51.0212 - val_mse: 12781.7959 - 341ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 636.1074 - mse: 4228791.0000 - val_loss: 45.6669 - val_mse: 10210.1729 - 338ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 640.3959 - mse: 4841117.0000 - val_loss: 38.0627 - val_mse: 7053.6021 - 344ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 640.5131 - mse: 5092177.5000 - val_loss: 30.8823 - val_mse: 4607.1704 - 341ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 619.7136 - mse: 4178373.5000 - val_loss: 31.4470 - val_mse: 4780.9087 - 343ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 609.0908 - mse: 3874845.7500 - val_loss: 27.0386 - val_mse: 3511.2100 - 343ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 585.0760 - mse: 3977118.2500 - val_loss: 22.6218 - val_mse: 2435.2812 - 342ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 598.5898 - mse: 3516283.7500 - val_loss: 18.2886 - val_mse: 1570.3510 - 341ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 587.8175 - mse: 3895072.2500 - val_loss: 15.1066 - val_mse: 1055.5950 - 337ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 607.9858 - mse: 4791736.0000 - val_loss: 11.9548 - val_mse: 646.2408 - 350ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 558.8934 - mse: 3446215.2500 - val_loss: 9.6708 - val_mse: 412.0948 - 343ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 579.9924 - mse: 3543677.0000 - val_loss: 10.7201 - val_mse: 513.2047 - 355ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 560.2177 - mse: 3369354.2500 - val_loss: 10.4925 - val_mse: 490.3848 - 338ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 536.7559 - mse: 3218290.2500 - val_loss: 7.8621 - val_mse: 263.9833 - 342ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 569.1905 - mse: 3332737.0000 - val_loss: 5.2843 - val_mse: 109.6571 - 342ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 524.1151 - mse: 3143984.0000 - val_loss: 6.8573 - val_mse: 195.8729 - 333ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 536.6407 - mse: 3158634.7500 - val_loss: 5.0209 - val_mse: 97.6726 - 354ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 540.1754 - mse: 3099000.0000 - val_loss: 4.7613 - val_mse: 86.5305 - 338ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 540.3622 - mse: 3011334.7500 - val_loss: 6.6126 - val_mse: 180.8773 - 353ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 525.6462 - mse: 3006507.0000 - val_loss: 9.5106 - val_mse: 397.9343 - 347ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 495.4208 - mse: 2422588.2500 - val_loss: 10.2802 - val_mse: 469.8409 - 343ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 517.7862 - mse: 3012928.5000 - val_loss: 12.4876 - val_mse: 709.1609 - 342ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 494.5384 - mse: 2485357.2500 - val_loss: 13.9248 - val_mse: 891.4653 - 351ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 488.4718 - mse: 2491270.0000 - val_loss: 11.4623 - val_mse: 592.1261 - 351ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 502.0481 - mse: 2859909.7500 - val_loss: 9.7036 - val_mse: 415.6974 - 347ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 483.3958 - mse: 2524196.0000 - val_loss: 9.1073 - val_mse: 362.9956 - 342ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 473.5663 - mse: 2389205.2500 - val_loss: 7.8776 - val_mse: 265.5303 - 343ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 447.7263 - mse: 2198663.0000 - val_loss: 4.9642 - val_mse: 95.3535 - 337ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 435.3759 - mse: 1951637.1250 - val_loss: 1.7373 - val_mse: 6.7204 - 337ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 436.9952 - mse: 2046348.5000 - val_loss: 2.6205 - val_mse: 20.5490 - 348ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 445.1409 - mse: 2312277.7500 - val_loss: 1.9956 - val_mse: 9.9497 - 344ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 450.0036 - mse: 2166900.5000 - val_loss: 2.3150 - val_mse: 14.8819 - 335ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 436.7681 - mse: 1947301.3750 - val_loss: 1.4524 - val_mse: 3.9408 - 336ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 410.7907 - mse: 1895723.6250 - val_loss: 0.6963 - val_mse: 0.6441 - 341ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 407.2859 - mse: 2148237.5000 - val_loss: 2.3762 - val_mse: 30.1310 - 346ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 413.5357 - mse: 1835019.1250 - val_loss: 0.6853 - val_mse: 0.5898 - 349ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 394.3839 - mse: 1675655.6250 - val_loss: 1.5468 - val_mse: 4.7782 - 350ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 376.4952 - mse: 1502577.0000 - val_loss: 2.1911 - val_mse: 12.8718 - 356ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 365.7450 - mse: 1294617.8750 - val_loss: 2.3290 - val_mse: 15.1531 - 344ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 357.4561 - mse: 1414410.0000 - val_loss: 1.1168 - val_mse: 4.5152 - 349ms/epoch - 4ms/step\n",
            "78/78 - 0s - loss: 360.2681 - mse: 1433413.7500 - val_loss: 1.6403 - val_mse: 12.9254 - 356ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 371.3357 - mse: 1896059.1250 - val_loss: 0.7663 - val_mse: 1.0496 - 348ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 24.6529\n",
            "Function value obtained: 1.0496\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [154, 85]\n",
            "Learning Rate: 0.00011150387661700066\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3216019449290624\n",
            "Batch Size: 95\n",
            "----------------------------------------\n",
            "89/89 - 3s - loss: 370.1103 - mse: 1989655.6250 - val_loss: 10.4523 - val_mse: 741.4144 - 3s/epoch - 35ms/step\n",
            "89/89 - 0s - loss: 292.3450 - mse: 1028863.1875 - val_loss: 11.7851 - val_mse: 932.2499 - 425ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 204.3098 - mse: 476454.2500 - val_loss: 2.8224 - val_mse: 45.7011 - 447ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 169.8021 - mse: 321035.1250 - val_loss: 0.0912 - val_mse: 0.1981 - 428ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 141.9924 - mse: 290936.8125 - val_loss: 2.8760 - val_mse: 49.7623 - 450ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 101.1841 - mse: 114107.7422 - val_loss: 5.9586 - val_mse: 203.0507 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 79.5971 - mse: 74230.2500 - val_loss: 1.5147 - val_mse: 17.4076 - 448ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 71.3205 - mse: 79222.3516 - val_loss: 3.1393 - val_mse: 71.7866 - 459ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 58.5179 - mse: 41042.8281 - val_loss: 2.0860 - val_mse: 34.6509 - 456ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 49.3819 - mse: 29170.9668 - val_loss: 1.1399 - val_mse: 12.6392 - 435ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 41.3845 - mse: 20908.3184 - val_loss: 0.1990 - val_mse: 0.5005 - 438ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 37.1120 - mse: 18449.0293 - val_loss: 0.4586 - val_mse: 2.5608 - 443ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 31.4766 - mse: 11511.0830 - val_loss: 0.1476 - val_mse: 0.3569 - 454ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 29.7947 - mse: 12438.6494 - val_loss: 0.4455 - val_mse: 1.5123 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 24.0300 - mse: 7008.3281 - val_loss: 0.2677 - val_mse: 0.7115 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 21.0765 - mse: 6939.3506 - val_loss: 0.0967 - val_mse: 0.2124 - 444ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 18.5127 - mse: 6419.2627 - val_loss: 0.3323 - val_mse: 1.4657 - 438ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 16.2181 - mse: 4020.6287 - val_loss: 0.1305 - val_mse: 0.3359 - 433ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 13.7349 - mse: 2505.8564 - val_loss: 0.1324 - val_mse: 0.3393 - 436ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 11.8830 - mse: 1958.8110 - val_loss: 0.0841 - val_mse: 0.1783 - 442ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 11.2130 - mse: 2260.5554 - val_loss: 0.0854 - val_mse: 0.1828 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 9.2670 - mse: 1397.9248 - val_loss: 0.0899 - val_mse: 0.1979 - 445ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 8.4011 - mse: 1171.4496 - val_loss: 0.0833 - val_mse: 0.1820 - 453ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 7.7424 - mse: 957.8979 - val_loss: 0.0606 - val_mse: 0.1252 - 455ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 6.6454 - mse: 794.1692 - val_loss: 0.0507 - val_mse: 0.1039 - 438ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 5.7215 - mse: 675.9751 - val_loss: 0.0381 - val_mse: 0.0775 - 447ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 4.8761 - mse: 405.7065 - val_loss: 0.0293 - val_mse: 0.0595 - 442ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 4.1875 - mse: 424.4765 - val_loss: 0.0171 - val_mse: 0.0346 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 3.9050 - mse: 382.6022 - val_loss: 0.0128 - val_mse: 0.0259 - 443ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 3.0633 - mse: 195.0365 - val_loss: 0.0087 - val_mse: 0.0174 - 443ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 2.6214 - mse: 181.9977 - val_loss: 0.0086 - val_mse: 0.0173 - 433ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 2.6809 - mse: 279.8515 - val_loss: 0.0057 - val_mse: 0.0115 - 439ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 2.1305 - mse: 114.0396 - val_loss: 0.0058 - val_mse: 0.0116 - 437ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.9015 - mse: 134.0001 - val_loss: 0.0066 - val_mse: 0.0132 - 435ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.5277 - mse: 86.7152 - val_loss: 0.0037 - val_mse: 0.0074 - 433ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.3226 - mse: 68.7619 - val_loss: 0.0041 - val_mse: 0.0082 - 431ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.2174 - mse: 59.7900 - val_loss: 0.0068 - val_mse: 0.0137 - 430ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.3024 - mse: 115.3350 - val_loss: 0.0079 - val_mse: 0.0160 - 431ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 1.1249 - mse: 105.2515 - val_loss: 0.0078 - val_mse: 0.0156 - 430ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.8970 - mse: 45.0364 - val_loss: 0.0046 - val_mse: 0.0092 - 444ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.9396 - mse: 118.4883 - val_loss: 0.0057 - val_mse: 0.0114 - 431ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.6931 - mse: 36.5174 - val_loss: 0.0046 - val_mse: 0.0092 - 441ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.6680 - mse: 81.7701 - val_loss: 0.0063 - val_mse: 0.0126 - 450ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.5347 - mse: 23.6495 - val_loss: 0.0046 - val_mse: 0.0092 - 454ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.5573 - mse: 38.6742 - val_loss: 0.0054 - val_mse: 0.0108 - 449ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.6567 - mse: 51.1141 - val_loss: 0.0048 - val_mse: 0.0096 - 474ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.4853 - mse: 22.9838 - val_loss: 0.0065 - val_mse: 0.0130 - 439ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.3479 - mse: 9.6235 - val_loss: 0.0058 - val_mse: 0.0117 - 439ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.4220 - mse: 25.3315 - val_loss: 0.0064 - val_mse: 0.0129 - 455ms/epoch - 5ms/step\n",
            "89/89 - 0s - loss: 0.3830 - mse: 13.5480 - val_loss: 0.0051 - val_mse: 0.0102 - 453ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 30.8360\n",
            "Function value obtained: 0.0102\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [147, 94]\n",
            "Learning Rate: 0.00011361467136740781\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.28014066492974155\n",
            "Batch Size: 131\n",
            "----------------------------------------\n",
            "65/65 - 3s - loss: 374.7008 - mse: 2203013.5000 - val_loss: 7.5408 - val_mse: 313.4453 - 3s/epoch - 52ms/step\n",
            "65/65 - 0s - loss: 207.4717 - mse: 526681.5625 - val_loss: 2.0861 - val_mse: 22.7439 - 381ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 167.3745 - mse: 332407.0000 - val_loss: 6.7387 - val_mse: 250.8671 - 369ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 150.6866 - mse: 314172.1562 - val_loss: 10.5721 - val_mse: 618.4800 - 381ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 117.1405 - mse: 177061.0469 - val_loss: 7.4307 - val_mse: 307.3958 - 365ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 98.3081 - mse: 120501.6406 - val_loss: 3.9510 - val_mse: 90.3649 - 366ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 85.5033 - mse: 77607.1016 - val_loss: 2.2112 - val_mse: 27.0353 - 371ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 73.8147 - mse: 63906.2305 - val_loss: 5.6309 - val_mse: 180.2634 - 380ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 69.3022 - mse: 69941.1797 - val_loss: 1.6981 - val_mse: 14.6865 - 386ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 50.3771 - mse: 27343.9863 - val_loss: 3.3538 - val_mse: 62.6873 - 380ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 45.0548 - mse: 25137.7539 - val_loss: 2.7646 - val_mse: 42.1952 - 373ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 39.3472 - mse: 19753.6855 - val_loss: 1.6082 - val_mse: 12.7904 - 361ms/epoch - 6ms/step\n",
            "65/65 - 0s - loss: 35.6372 - mse: 15720.0322 - val_loss: 2.3780 - val_mse: 31.1853 - 355ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 30.0250 - mse: 11147.1973 - val_loss: 1.3873 - val_mse: 9.1911 - 352ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 27.7075 - mse: 11736.8857 - val_loss: 0.9043 - val_mse: 2.7541 - 348ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 24.8065 - mse: 17907.2305 - val_loss: 0.8052 - val_mse: 1.8541 - 351ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 21.4652 - mse: 6712.1538 - val_loss: 0.6262 - val_mse: 0.6371 - 345ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 18.4124 - mse: 4104.7017 - val_loss: 0.5581 - val_mse: 0.3905 - 343ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 16.8284 - mse: 3468.1072 - val_loss: 0.5180 - val_mse: 0.2846 - 349ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 14.9596 - mse: 3011.7576 - val_loss: 0.6265 - val_mse: 0.4022 - 356ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 13.7695 - mse: 2532.3137 - val_loss: 0.5938 - val_mse: 0.3620 - 343ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 11.9399 - mse: 1853.1967 - val_loss: 0.7658 - val_mse: 0.6931 - 340ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 10.8133 - mse: 1451.1577 - val_loss: 0.7216 - val_mse: 0.5986 - 353ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 9.5852 - mse: 1014.1558 - val_loss: 0.6874 - val_mse: 0.5224 - 349ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 9.4901 - mse: 1394.6820 - val_loss: 0.7339 - val_mse: 0.6454 - 351ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 8.3079 - mse: 1014.3620 - val_loss: 0.8544 - val_mse: 1.0786 - 343ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 7.3731 - mse: 664.6741 - val_loss: 0.7658 - val_mse: 0.7649 - 355ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 6.9994 - mse: 666.0367 - val_loss: 0.7355 - val_mse: 0.6827 - 339ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 6.4524 - mse: 597.0068 - val_loss: 0.6003 - val_mse: 0.3854 - 343ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 5.5079 - mse: 420.4201 - val_loss: 0.5458 - val_mse: 0.3106 - 342ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 5.3891 - mse: 464.4461 - val_loss: 0.5509 - val_mse: 0.3199 - 348ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 4.7548 - mse: 356.4623 - val_loss: 0.4776 - val_mse: 0.2426 - 352ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 4.5586 - mse: 395.2387 - val_loss: 0.4702 - val_mse: 0.2365 - 340ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 4.1674 - mse: 327.4076 - val_loss: 0.4850 - val_mse: 0.2480 - 347ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 3.5913 - mse: 162.3864 - val_loss: 0.4480 - val_mse: 0.2178 - 354ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 3.7085 - mse: 333.6858 - val_loss: 0.4090 - val_mse: 0.1934 - 350ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 3.1393 - mse: 192.1425 - val_loss: 0.4021 - val_mse: 0.1876 - 355ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.9786 - mse: 179.4581 - val_loss: 0.4057 - val_mse: 0.1889 - 352ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.6348 - mse: 115.5790 - val_loss: 0.3951 - val_mse: 0.1798 - 353ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.5539 - mse: 145.4446 - val_loss: 0.3823 - val_mse: 0.1708 - 338ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.1792 - mse: 63.3129 - val_loss: 0.3729 - val_mse: 0.1635 - 342ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.2872 - mse: 97.2805 - val_loss: 0.3580 - val_mse: 0.1531 - 340ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 2.0346 - mse: 75.6899 - val_loss: 0.3508 - val_mse: 0.1471 - 346ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.9931 - mse: 75.3567 - val_loss: 0.3423 - val_mse: 0.1410 - 340ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.8682 - mse: 76.2018 - val_loss: 0.3342 - val_mse: 0.1349 - 343ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.6887 - mse: 48.0715 - val_loss: 0.3189 - val_mse: 0.1250 - 341ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.5076 - mse: 56.4719 - val_loss: 0.3101 - val_mse: 0.1190 - 341ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.2950 - mse: 32.3317 - val_loss: 0.3049 - val_mse: 0.1154 - 339ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.3482 - mse: 65.5828 - val_loss: 0.2953 - val_mse: 0.1092 - 341ms/epoch - 5ms/step\n",
            "65/65 - 0s - loss: 1.2003 - mse: 20.6383 - val_loss: 0.2854 - val_mse: 0.1030 - 340ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 26.4735\n",
            "Function value obtained: 0.1030\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [152, 88]\n",
            "Learning Rate: 0.00011147271220889003\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.30872333723292766\n",
            "Batch Size: 105\n",
            "----------------------------------------\n",
            "80/80 - 3s - loss: 290.4653 - mse: 895623.3750 - val_loss: 1.3776 - val_mse: 17.2110 - 3s/epoch - 37ms/step\n",
            "80/80 - 0s - loss: 215.0389 - mse: 513869.5625 - val_loss: 3.3792 - val_mse: 86.9304 - 385ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 168.5207 - mse: 344451.1562 - val_loss: 1.9640 - val_mse: 32.1158 - 391ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 128.4591 - mse: 192540.4219 - val_loss: 3.9276 - val_mse: 83.8899 - 400ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 110.7224 - mse: 136570.4375 - val_loss: 0.6507 - val_mse: 4.2562 - 393ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 86.5308 - mse: 96426.9844 - val_loss: 10.9385 - val_mse: 611.8163 - 409ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 72.1034 - mse: 66531.2734 - val_loss: 1.6744 - val_mse: 15.3169 - 407ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 56.9370 - mse: 40652.8516 - val_loss: 6.5570 - val_mse: 223.0870 - 396ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 48.5477 - mse: 28106.7754 - val_loss: 3.6151 - val_mse: 67.3233 - 384ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 40.3906 - mse: 22383.0137 - val_loss: 5.7723 - val_mse: 171.4392 - 389ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 35.3251 - mse: 15772.0811 - val_loss: 5.9232 - val_mse: 182.4553 - 386ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 29.8554 - mse: 10410.6426 - val_loss: 6.2058 - val_mse: 203.4394 - 394ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 27.7856 - mse: 11323.4414 - val_loss: 4.5937 - val_mse: 112.1114 - 386ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 24.7013 - mse: 9089.9629 - val_loss: 3.9365 - val_mse: 83.1084 - 394ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 21.0383 - mse: 7024.6948 - val_loss: 3.7365 - val_mse: 74.4514 - 384ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 19.0386 - mse: 6974.4214 - val_loss: 2.9417 - val_mse: 46.8156 - 385ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 16.4856 - mse: 3551.5928 - val_loss: 1.9844 - val_mse: 22.0955 - 388ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 13.6977 - mse: 2838.3921 - val_loss: 1.6783 - val_mse: 16.1613 - 387ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 13.3478 - mse: 2528.2205 - val_loss: 1.2723 - val_mse: 9.6943 - 389ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 11.3862 - mse: 1708.5695 - val_loss: 0.8328 - val_mse: 4.4168 - 385ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 9.9723 - mse: 1482.6613 - val_loss: 0.5541 - val_mse: 2.1260 - 388ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 8.7599 - mse: 1042.8444 - val_loss: 0.4475 - val_mse: 1.5170 - 398ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 8.2841 - mse: 1121.0385 - val_loss: 0.2375 - val_mse: 0.5749 - 396ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 7.0684 - mse: 781.5394 - val_loss: 0.2284 - val_mse: 0.5493 - 395ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 6.7217 - mse: 715.1341 - val_loss: 0.2301 - val_mse: 0.5591 - 396ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 6.1568 - mse: 675.5045 - val_loss: 0.1418 - val_mse: 0.3003 - 391ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 5.0115 - mse: 385.3853 - val_loss: 0.1186 - val_mse: 0.2479 - 387ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 4.7477 - mse: 461.1719 - val_loss: 0.1070 - val_mse: 0.2228 - 401ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 4.3080 - mse: 368.0009 - val_loss: 0.1006 - val_mse: 0.2093 - 399ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 3.6330 - mse: 234.8230 - val_loss: 0.0988 - val_mse: 0.2052 - 392ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 3.3280 - mse: 296.5900 - val_loss: 0.0818 - val_mse: 0.1691 - 399ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 2.9802 - mse: 175.5565 - val_loss: 0.0753 - val_mse: 0.1552 - 417ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 2.7970 - mse: 159.1887 - val_loss: 0.0727 - val_mse: 0.1498 - 393ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 2.3974 - mse: 166.8268 - val_loss: 0.0673 - val_mse: 0.1385 - 388ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.8818 - mse: 70.9057 - val_loss: 0.0539 - val_mse: 0.1104 - 390ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.6967 - mse: 63.7438 - val_loss: 0.0578 - val_mse: 0.1187 - 384ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.5924 - mse: 73.9715 - val_loss: 0.0407 - val_mse: 0.0831 - 387ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.4019 - mse: 63.4547 - val_loss: 0.0378 - val_mse: 0.0772 - 393ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.3871 - mse: 89.7160 - val_loss: 0.0256 - val_mse: 0.0520 - 385ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.1328 - mse: 40.8325 - val_loss: 0.0215 - val_mse: 0.0437 - 393ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 1.0617 - mse: 74.2118 - val_loss: 0.0099 - val_mse: 0.0199 - 390ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.9632 - mse: 42.3852 - val_loss: 0.0083 - val_mse: 0.0168 - 395ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.8234 - mse: 42.1494 - val_loss: 0.0068 - val_mse: 0.0137 - 393ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.7491 - mse: 24.3014 - val_loss: 0.0050 - val_mse: 0.0100 - 386ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.6952 - mse: 28.1737 - val_loss: 0.0080 - val_mse: 0.0162 - 387ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.4964 - mse: 13.1617 - val_loss: 0.0041 - val_mse: 0.0083 - 401ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.5963 - mse: 31.4216 - val_loss: 0.0059 - val_mse: 0.0118 - 385ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.4191 - mse: 12.3870 - val_loss: 0.0048 - val_mse: 0.0097 - 395ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.4548 - mse: 15.7199 - val_loss: 0.0039 - val_mse: 0.0079 - 390ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.4589 - mse: 21.1614 - val_loss: 0.0038 - val_mse: 0.0077 - 387ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 27.7157\n",
            "Function value obtained: 0.0077\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [155, 90]\n",
            "Learning Rate: 0.00011164072325307445\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3053530337372342\n",
            "Batch Size: 108\n",
            "----------------------------------------\n",
            "78/78 - 3s - loss: 484.7612 - mse: 3015730.0000 - val_loss: 22.8313 - val_mse: 2665.2214 - 3s/epoch - 40ms/step\n",
            "78/78 - 0s - loss: 283.4703 - mse: 1040682.2500 - val_loss: 10.4821 - val_mse: 564.2151 - 390ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 242.2224 - mse: 803935.1250 - val_loss: 9.4381 - val_mse: 453.8657 - 395ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 188.4227 - mse: 503568.6875 - val_loss: 10.7987 - val_mse: 595.5125 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 151.5536 - mse: 295565.1562 - val_loss: 17.4672 - val_mse: 1546.4398 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 124.3606 - mse: 205224.0469 - val_loss: 9.3776 - val_mse: 448.5212 - 403ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 98.3288 - mse: 129631.6406 - val_loss: 10.6703 - val_mse: 581.8326 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 89.2584 - mse: 135874.0312 - val_loss: 0.2390 - val_mse: 0.6235 - 394ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 71.4832 - mse: 60471.0977 - val_loss: 2.6605 - val_mse: 53.1675 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 62.1766 - mse: 75474.6172 - val_loss: 2.5101 - val_mse: 47.9973 - 391ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 49.6389 - mse: 29594.8359 - val_loss: 7.9848 - val_mse: 391.6535 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 41.8723 - mse: 24162.3711 - val_loss: 8.3015 - val_mse: 420.7039 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 36.4954 - mse: 21282.0859 - val_loss: 5.3989 - val_mse: 190.0278 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 30.1440 - mse: 11842.1826 - val_loss: 2.8240 - val_mse: 59.1635 - 391ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 27.5461 - mse: 12397.7812 - val_loss: 1.1861 - val_mse: 12.7643 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 23.5656 - mse: 9136.3398 - val_loss: 0.2492 - val_mse: 0.5459 - 394ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 21.2726 - mse: 15783.8643 - val_loss: 1.0115 - val_mse: 5.7538 - 388ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 18.3909 - mse: 7057.7329 - val_loss: 0.8298 - val_mse: 3.9872 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 13.9075 - mse: 3211.9890 - val_loss: 0.5852 - val_mse: 2.1072 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 11.6110 - mse: 3052.4421 - val_loss: 0.5238 - val_mse: 1.7460 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 9.8450 - mse: 1910.9102 - val_loss: 0.2735 - val_mse: 0.6285 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 8.7849 - mse: 1390.5225 - val_loss: 0.1772 - val_mse: 0.3785 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 7.7995 - mse: 1488.9579 - val_loss: 0.1672 - val_mse: 0.3563 - 409ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 6.6901 - mse: 1010.6544 - val_loss: 0.1548 - val_mse: 0.3293 - 408ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 5.7567 - mse: 1268.5638 - val_loss: 0.1552 - val_mse: 0.3296 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 4.7123 - mse: 624.4938 - val_loss: 0.1465 - val_mse: 0.3105 - 388ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 3.6137 - mse: 307.2506 - val_loss: 0.1421 - val_mse: 0.3005 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 3.8005 - mse: 736.5267 - val_loss: 0.1314 - val_mse: 0.2776 - 394ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 3.1160 - mse: 509.0780 - val_loss: 0.1321 - val_mse: 0.2784 - 413ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 2.8266 - mse: 506.0922 - val_loss: 0.1262 - val_mse: 0.2656 - 399ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 2.4289 - mse: 353.6070 - val_loss: 0.1196 - val_mse: 0.2513 - 417ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 2.0751 - mse: 316.5879 - val_loss: 0.1158 - val_mse: 0.2430 - 400ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.4398 - mse: 139.5671 - val_loss: 0.1130 - val_mse: 0.2367 - 403ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.6970 - mse: 437.2154 - val_loss: 0.1065 - val_mse: 0.2228 - 402ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.4003 - mse: 134.6186 - val_loss: 0.1022 - val_mse: 0.2135 - 417ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.3870 - mse: 173.4059 - val_loss: 0.0990 - val_mse: 0.2065 - 400ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.1699 - mse: 171.7249 - val_loss: 0.0963 - val_mse: 0.2005 - 404ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 1.1665 - mse: 131.1862 - val_loss: 0.0920 - val_mse: 0.1913 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.9791 - mse: 128.9660 - val_loss: 0.0887 - val_mse: 0.1844 - 407ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.6438 - mse: 39.0495 - val_loss: 0.0840 - val_mse: 0.1744 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.8606 - mse: 100.7713 - val_loss: 0.0816 - val_mse: 0.1692 - 418ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.8181 - mse: 97.4952 - val_loss: 0.0774 - val_mse: 0.1604 - 422ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.8087 - mse: 100.0569 - val_loss: 0.0762 - val_mse: 0.1576 - 421ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.7814 - mse: 87.5061 - val_loss: 0.0730 - val_mse: 0.1509 - 431ms/epoch - 6ms/step\n",
            "78/78 - 0s - loss: 0.5447 - mse: 36.8034 - val_loss: 0.0700 - val_mse: 0.1445 - 427ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.6344 - mse: 51.6562 - val_loss: 0.0668 - val_mse: 0.1377 - 431ms/epoch - 6ms/step\n",
            "78/78 - 0s - loss: 0.5965 - mse: 66.6883 - val_loss: 0.0642 - val_mse: 0.1323 - 425ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.6801 - mse: 80.2775 - val_loss: 0.0611 - val_mse: 0.1257 - 416ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.3968 - mse: 31.2900 - val_loss: 0.0592 - val_mse: 0.1217 - 414ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.3059 - mse: 12.1448 - val_loss: 0.0565 - val_mse: 0.1162 - 417ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 29.1048\n",
            "Function value obtained: 0.1162\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [148, 169]\n",
            "Learning Rate: 0.0025043092277708765\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.34990477678200677\n",
            "Batch Size: 149\n",
            "----------------------------------------\n",
            "57/57 - 3s - loss: 203.6138 - mse: 822141.1875 - val_loss: 1.4585 - val_mse: 10.6307 - 3s/epoch - 55ms/step\n",
            "57/57 - 0s - loss: 23.2021 - mse: 6794.0601 - val_loss: 0.4519 - val_mse: 0.2853 - 321ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 8.5513 - mse: 845.3387 - val_loss: 0.4549 - val_mse: 0.4749 - 319ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 4.5363 - mse: 264.5341 - val_loss: 0.2601 - val_mse: 0.0796 - 322ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 2.4870 - mse: 97.7859 - val_loss: 0.1628 - val_mse: 0.0359 - 327ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 1.4529 - mse: 37.4354 - val_loss: 0.1104 - val_mse: 0.0174 - 319ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.9061 - mse: 13.9472 - val_loss: 0.0898 - val_mse: 0.0115 - 322ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.6619 - mse: 10.9339 - val_loss: 0.0907 - val_mse: 0.0126 - 312ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.4500 - mse: 4.1784 - val_loss: 0.0966 - val_mse: 0.0140 - 322ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.3573 - mse: 4.3381 - val_loss: 0.0998 - val_mse: 0.0153 - 338ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.2729 - mse: 2.0802 - val_loss: 0.0984 - val_mse: 0.0143 - 326ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.2307 - mse: 1.2452 - val_loss: 0.0996 - val_mse: 0.0147 - 332ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1845 - mse: 0.5544 - val_loss: 0.0985 - val_mse: 0.0145 - 322ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1870 - mse: 2.3635 - val_loss: 0.0970 - val_mse: 0.0139 - 331ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1710 - mse: 1.5445 - val_loss: 0.0962 - val_mse: 0.0136 - 327ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1544 - mse: 0.5217 - val_loss: 0.1016 - val_mse: 0.0161 - 316ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1473 - mse: 0.4648 - val_loss: 0.0999 - val_mse: 0.0153 - 327ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1306 - mse: 0.3206 - val_loss: 0.0952 - val_mse: 0.0134 - 314ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1394 - mse: 1.2805 - val_loss: 0.0946 - val_mse: 0.0132 - 317ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1156 - mse: 0.1723 - val_loss: 0.0942 - val_mse: 0.0130 - 321ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1197 - mse: 0.2620 - val_loss: 0.0957 - val_mse: 0.0138 - 314ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1178 - mse: 0.2380 - val_loss: 0.0947 - val_mse: 0.0136 - 328ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1105 - mse: 0.1284 - val_loss: 0.0925 - val_mse: 0.0128 - 317ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1148 - mse: 0.2267 - val_loss: 0.0956 - val_mse: 0.0139 - 316ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1134 - mse: 0.4209 - val_loss: 0.0951 - val_mse: 0.0138 - 317ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1048 - mse: 0.1781 - val_loss: 0.0937 - val_mse: 0.0134 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.1076 - mse: 0.1306 - val_loss: 0.0960 - val_mse: 0.0143 - 321ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1103 - mse: 0.1211 - val_loss: 0.0949 - val_mse: 0.0139 - 321ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1024 - mse: 0.1104 - val_loss: 0.0907 - val_mse: 0.0122 - 325ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0954 - mse: 0.0445 - val_loss: 0.0910 - val_mse: 0.0124 - 320ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1028 - mse: 0.1066 - val_loss: 0.0898 - val_mse: 0.0120 - 314ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1060 - mse: 0.1401 - val_loss: 0.0884 - val_mse: 0.0115 - 318ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0957 - mse: 0.0560 - val_loss: 0.0907 - val_mse: 0.0124 - 310ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0976 - mse: 0.0722 - val_loss: 0.0902 - val_mse: 0.0124 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0986 - mse: 0.0557 - val_loss: 0.0844 - val_mse: 0.0102 - 316ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0979 - mse: 0.0687 - val_loss: 0.0876 - val_mse: 0.0113 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0935 - mse: 0.0341 - val_loss: 0.0890 - val_mse: 0.0118 - 312ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0999 - mse: 0.0825 - val_loss: 0.0880 - val_mse: 0.0115 - 310ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0900 - mse: 0.0284 - val_loss: 0.0885 - val_mse: 0.0119 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0927 - mse: 0.0329 - val_loss: 0.0861 - val_mse: 0.0109 - 327ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1007 - mse: 0.4189 - val_loss: 0.0924 - val_mse: 0.0134 - 325ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0994 - mse: 0.1590 - val_loss: 0.0885 - val_mse: 0.0118 - 322ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.1047 - mse: 0.8447 - val_loss: 0.0893 - val_mse: 0.0122 - 321ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0941 - mse: 0.0318 - val_loss: 0.0877 - val_mse: 0.0114 - 347ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0971 - mse: 0.1272 - val_loss: 0.0903 - val_mse: 0.0126 - 326ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0942 - mse: 0.0379 - val_loss: 0.0900 - val_mse: 0.0126 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0968 - mse: 0.3655 - val_loss: 0.0886 - val_mse: 0.0118 - 318ms/epoch - 6ms/step\n",
            "57/57 - 0s - loss: 0.0908 - mse: 0.0461 - val_loss: 0.0822 - val_mse: 0.0096 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0870 - mse: 0.0160 - val_loss: 0.0842 - val_mse: 0.0103 - 313ms/epoch - 5ms/step\n",
            "57/57 - 0s - loss: 0.0905 - mse: 0.0339 - val_loss: 0.0832 - val_mse: 0.0100 - 317ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.05961164]\n",
            "\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 24.4224\n",
            "Function value obtained: 0.0100\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 16 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [148, 88]\n",
            "Learning Rate: 0.00011201057800705661\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3144475264525675\n",
            "Batch Size: 115\n",
            "----------------------------------------\n",
            "74/74 - 3s - loss: 446.5880 - mse: 2380349.5000 - val_loss: 1.2177 - val_mse: 1.6155 - 3s/epoch - 39ms/step\n",
            "74/74 - 0s - loss: 304.5285 - mse: 1164472.7500 - val_loss: 2.2130 - val_mse: 15.4880 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 237.1283 - mse: 608664.3125 - val_loss: 5.8623 - val_mse: 149.4479 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 188.4298 - mse: 516253.1250 - val_loss: 2.3271 - val_mse: 20.3464 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 164.6379 - mse: 399361.2500 - val_loss: 3.9847 - val_mse: 63.3738 - 384ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 125.0238 - mse: 184238.2188 - val_loss: 0.7001 - val_mse: 0.5134 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 105.6146 - mse: 130298.0234 - val_loss: 1.0158 - val_mse: 1.3321 - 368ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 89.2477 - mse: 172563.4688 - val_loss: 1.5408 - val_mse: 4.8357 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 76.4351 - mse: 69337.9453 - val_loss: 2.1233 - val_mse: 12.3996 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 62.6130 - mse: 46694.1523 - val_loss: 2.1047 - val_mse: 13.0720 - 399ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 56.0905 - mse: 42302.7773 - val_loss: 1.2012 - val_mse: 2.5625 - 377ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 48.7211 - mse: 29953.2148 - val_loss: 1.4046 - val_mse: 4.2285 - 385ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 42.2401 - mse: 24338.1855 - val_loss: 0.6147 - val_mse: 0.4917 - 384ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 37.0279 - mse: 16431.4902 - val_loss: 0.7672 - val_mse: 0.6099 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 32.9392 - mse: 14188.0596 - val_loss: 0.6705 - val_mse: 0.4627 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 29.7598 - mse: 11534.4883 - val_loss: 0.5934 - val_mse: 0.3921 - 380ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 27.4984 - mse: 13728.0039 - val_loss: 0.6408 - val_mse: 0.6290 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 22.0749 - mse: 6012.4834 - val_loss: 0.6995 - val_mse: 0.9948 - 381ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 19.9118 - mse: 5537.8833 - val_loss: 0.7314 - val_mse: 1.2213 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 17.8016 - mse: 6083.1470 - val_loss: 0.8478 - val_mse: 2.2108 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 15.9616 - mse: 4438.7207 - val_loss: 0.7302 - val_mse: 1.2825 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 14.5314 - mse: 3426.2224 - val_loss: 0.5847 - val_mse: 0.4780 - 369ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 12.1531 - mse: 2337.2109 - val_loss: 0.5745 - val_mse: 0.4595 - 378ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 11.4975 - mse: 2709.9546 - val_loss: 0.5762 - val_mse: 0.4885 - 369ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 9.4273 - mse: 1274.5376 - val_loss: 0.5283 - val_mse: 0.3291 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 8.9713 - mse: 1795.8422 - val_loss: 0.5167 - val_mse: 0.2996 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 8.3445 - mse: 1227.3511 - val_loss: 0.5060 - val_mse: 0.2894 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 7.5852 - mse: 1452.1874 - val_loss: 0.5002 - val_mse: 0.2800 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 6.2538 - mse: 1098.4635 - val_loss: 0.4914 - val_mse: 0.2701 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 5.7793 - mse: 744.5015 - val_loss: 0.4886 - val_mse: 0.2641 - 378ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 4.9760 - mse: 552.7859 - val_loss: 0.4864 - val_mse: 0.2589 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 4.4680 - mse: 585.2779 - val_loss: 0.4761 - val_mse: 0.2483 - 369ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 4.5627 - mse: 688.8353 - val_loss: 0.4544 - val_mse: 0.2309 - 368ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 3.8580 - mse: 493.9576 - val_loss: 0.4546 - val_mse: 0.2274 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 3.7408 - mse: 686.8879 - val_loss: 0.4449 - val_mse: 0.2178 - 369ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.9799 - mse: 323.1155 - val_loss: 0.4381 - val_mse: 0.2100 - 381ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.7302 - mse: 212.2390 - val_loss: 0.4179 - val_mse: 0.1956 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.7872 - mse: 395.5904 - val_loss: 0.4120 - val_mse: 0.1891 - 378ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.5530 - mse: 228.1018 - val_loss: 0.3994 - val_mse: 0.1793 - 390ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.9902 - mse: 163.4831 - val_loss: 0.3938 - val_mse: 0.1731 - 367ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.8896 - mse: 135.6562 - val_loss: 0.3804 - val_mse: 0.1635 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.6761 - mse: 133.0547 - val_loss: 0.3713 - val_mse: 0.1562 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.5608 - mse: 128.6843 - val_loss: 0.3648 - val_mse: 0.1501 - 384ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.8116 - mse: 168.0379 - val_loss: 0.3504 - val_mse: 0.1409 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.4051 - mse: 73.5648 - val_loss: 0.3410 - val_mse: 0.1341 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.2070 - mse: 86.1993 - val_loss: 0.3324 - val_mse: 0.1279 - 367ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.3170 - mse: 124.9243 - val_loss: 0.3223 - val_mse: 0.1212 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.1278 - mse: 56.6409 - val_loss: 0.3143 - val_mse: 0.1155 - 372ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.2036 - mse: 132.6257 - val_loss: 0.3032 - val_mse: 0.1088 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.0089 - mse: 60.2924 - val_loss: 0.2944 - val_mse: 0.1033 - 379ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 16 ended. Search finished for the next optimal point.\n",
            "Time taken: 26.7771\n",
            "Function value obtained: 0.1033\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 17 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [150, 89]\n",
            "Learning Rate: 0.0001121976699056646\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2938177463527545\n",
            "Batch Size: 111\n",
            "----------------------------------------\n",
            "76/76 - 3s - loss: 421.5301 - mse: 2515421.5000 - val_loss: 17.7492 - val_mse: 1791.2317 - 3s/epoch - 38ms/step\n",
            "76/76 - 0s - loss: 294.7283 - mse: 1229351.8750 - val_loss: 20.8744 - val_mse: 2430.1677 - 385ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 235.2936 - mse: 720617.6875 - val_loss: 0.5905 - val_mse: 3.3249 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 193.7840 - mse: 497614.0625 - val_loss: 10.9012 - val_mse: 678.2893 - 404ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 155.9897 - mse: 288374.0625 - val_loss: 14.3200 - val_mse: 1167.8647 - 393ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 129.0670 - mse: 214289.5000 - val_loss: 11.8872 - val_mse: 848.5140 - 395ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 107.2260 - mse: 140841.5312 - val_loss: 7.0406 - val_mse: 317.9305 - 403ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 88.3136 - mse: 98781.9766 - val_loss: 6.6193 - val_mse: 283.7608 - 385ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 72.8407 - mse: 63973.5469 - val_loss: 4.6324 - val_mse: 145.8793 - 386ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 62.3322 - mse: 43860.2344 - val_loss: 1.5486 - val_mse: 20.5319 - 384ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 49.1836 - mse: 27919.8965 - val_loss: 0.5042 - val_mse: 1.6168 - 390ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 45.3861 - mse: 24033.5410 - val_loss: 0.3660 - val_mse: 0.9643 - 383ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 42.5887 - mse: 24837.2363 - val_loss: 0.1504 - val_mse: 0.3208 - 389ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 35.2260 - mse: 15697.3076 - val_loss: 0.5628 - val_mse: 3.4714 - 387ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 33.9013 - mse: 16116.3896 - val_loss: 1.0139 - val_mse: 9.8585 - 387ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 28.2230 - mse: 10331.9307 - val_loss: 0.2997 - val_mse: 1.0319 - 390ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 25.1315 - mse: 8265.2119 - val_loss: 0.2194 - val_mse: 0.6334 - 383ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 22.6913 - mse: 7869.1738 - val_loss: 0.4057 - val_mse: 1.8722 - 390ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 19.4063 - mse: 4650.1719 - val_loss: 0.3431 - val_mse: 1.4109 - 390ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 18.7200 - mse: 5328.6226 - val_loss: 0.4705 - val_mse: 2.5056 - 387ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 16.5782 - mse: 4452.1455 - val_loss: 0.6023 - val_mse: 3.9214 - 392ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 13.9688 - mse: 2753.2153 - val_loss: 0.1590 - val_mse: 0.3654 - 383ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 13.6570 - mse: 3238.5742 - val_loss: 0.4476 - val_mse: 2.3350 - 389ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 11.1721 - mse: 1624.1248 - val_loss: 0.1409 - val_mse: 0.3066 - 399ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 9.9786 - mse: 1465.1124 - val_loss: 0.1644 - val_mse: 0.4022 - 388ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 9.6652 - mse: 1426.6863 - val_loss: 0.1278 - val_mse: 0.2696 - 402ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 9.0407 - mse: 1312.1288 - val_loss: 0.1436 - val_mse: 0.3028 - 403ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 7.4859 - mse: 942.7089 - val_loss: 0.1215 - val_mse: 0.2554 - 409ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 7.1706 - mse: 878.0463 - val_loss: 0.1986 - val_mse: 0.4465 - 423ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 6.2064 - mse: 857.2305 - val_loss: 0.1806 - val_mse: 0.3980 - 411ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 6.0685 - mse: 682.6920 - val_loss: 0.1230 - val_mse: 0.2577 - 420ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 4.8370 - mse: 377.1852 - val_loss: 0.1318 - val_mse: 0.2769 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 4.4706 - mse: 377.3745 - val_loss: 0.1433 - val_mse: 0.3041 - 411ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 4.2796 - mse: 395.0934 - val_loss: 0.1407 - val_mse: 0.2990 - 403ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.7045 - mse: 224.8122 - val_loss: 0.1229 - val_mse: 0.2580 - 408ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.2812 - mse: 200.3351 - val_loss: 0.1181 - val_mse: 0.2479 - 401ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.1396 - mse: 193.7793 - val_loss: 0.1025 - val_mse: 0.2134 - 404ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.9618 - mse: 206.1662 - val_loss: 0.0908 - val_mse: 0.1882 - 397ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.6513 - mse: 266.6249 - val_loss: 0.0849 - val_mse: 0.1757 - 409ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.3622 - mse: 178.9234 - val_loss: 0.0708 - val_mse: 0.1459 - 403ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.0899 - mse: 89.8345 - val_loss: 0.0509 - val_mse: 0.1044 - 397ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.9179 - mse: 81.7681 - val_loss: 0.0388 - val_mse: 0.0792 - 435ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 1.6063 - mse: 48.5000 - val_loss: 0.0289 - val_mse: 0.0588 - 403ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.6883 - mse: 64.6037 - val_loss: 0.0240 - val_mse: 0.0487 - 391ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.5814 - mse: 66.0334 - val_loss: 0.0202 - val_mse: 0.0409 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.2979 - mse: 46.9971 - val_loss: 0.0175 - val_mse: 0.0355 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.1747 - mse: 45.3669 - val_loss: 0.0133 - val_mse: 0.0269 - 399ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.2067 - mse: 48.7391 - val_loss: 0.0084 - val_mse: 0.0169 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.0068 - mse: 39.7631 - val_loss: 0.0062 - val_mse: 0.0125 - 404ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.9913 - mse: 40.3864 - val_loss: 0.0054 - val_mse: 0.0109 - 416ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 17 ended. Search finished for the next optimal point.\n",
            "Time taken: 28.8505\n",
            "Function value obtained: 0.0109\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 18 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [142, 75]\n",
            "Learning Rate: 0.00011242579437649202\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2889456819613912\n",
            "Batch Size: 124\n",
            "----------------------------------------\n",
            "68/68 - 3s - loss: 494.8084 - mse: 3155480.2500 - val_loss: 20.4337 - val_mse: 2083.7134 - 3s/epoch - 44ms/step\n",
            "68/68 - 0s - loss: 337.6668 - mse: 1426753.5000 - val_loss: 1.8495 - val_mse: 17.2013 - 361ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 277.5026 - mse: 851476.1875 - val_loss: 2.5454 - val_mse: 48.8856 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 205.5442 - mse: 480663.6875 - val_loss: 2.8661 - val_mse: 41.4023 - 361ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 175.8258 - mse: 355499.8125 - val_loss: 8.0476 - val_mse: 399.9351 - 355ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 139.8809 - mse: 241114.7812 - val_loss: 10.5082 - val_mse: 661.7117 - 356ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 121.2625 - mse: 166195.5781 - val_loss: 9.2754 - val_mse: 525.4014 - 365ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 104.1522 - mse: 134271.4219 - val_loss: 4.4361 - val_mse: 133.4233 - 352ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 87.2044 - mse: 96618.3438 - val_loss: 3.9156 - val_mse: 107.6349 - 360ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 70.9011 - mse: 57968.8945 - val_loss: 6.1796 - val_mse: 250.2803 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 63.9564 - mse: 45445.8086 - val_loss: 3.6490 - val_mse: 95.4404 - 361ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 53.2947 - mse: 36244.4805 - val_loss: 2.2062 - val_mse: 38.8666 - 350ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 48.8936 - mse: 32513.1660 - val_loss: 0.3653 - val_mse: 1.4051 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 38.8297 - mse: 17602.9863 - val_loss: 1.0346 - val_mse: 10.0106 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 34.2058 - mse: 15692.8545 - val_loss: 0.1961 - val_mse: 0.4248 - 354ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 32.7116 - mse: 17595.8398 - val_loss: 0.2945 - val_mse: 0.6703 - 363ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 29.5731 - mse: 12372.3809 - val_loss: 0.4469 - val_mse: 1.2826 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 24.5425 - mse: 8862.6377 - val_loss: 0.1808 - val_mse: 0.3911 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 22.8912 - mse: 7616.8345 - val_loss: 0.3335 - val_mse: 0.8190 - 352ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 20.6753 - mse: 6785.9380 - val_loss: 0.1847 - val_mse: 0.3966 - 366ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 17.9925 - mse: 5793.7183 - val_loss: 0.3670 - val_mse: 0.9656 - 357ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 17.1828 - mse: 5453.0562 - val_loss: 0.2103 - val_mse: 0.5426 - 362ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 14.6447 - mse: 3784.8083 - val_loss: 0.2230 - val_mse: 0.6069 - 371ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 12.4251 - mse: 2478.3616 - val_loss: 0.3381 - val_mse: 1.3335 - 366ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 11.0242 - mse: 1802.9944 - val_loss: 0.2311 - val_mse: 0.6591 - 356ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 10.7647 - mse: 2404.2302 - val_loss: 0.1709 - val_mse: 0.3871 - 357ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 8.5343 - mse: 1079.7000 - val_loss: 0.1736 - val_mse: 0.4052 - 357ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 8.1180 - mse: 887.4666 - val_loss: 0.1610 - val_mse: 0.3620 - 356ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 7.7528 - mse: 1099.4078 - val_loss: 0.1455 - val_mse: 0.3124 - 357ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 7.2269 - mse: 1419.7971 - val_loss: 0.1391 - val_mse: 0.2952 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 6.4084 - mse: 934.3384 - val_loss: 0.1354 - val_mse: 0.2868 - 362ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 5.7478 - mse: 881.1455 - val_loss: 0.1316 - val_mse: 0.2783 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 4.9694 - mse: 507.5441 - val_loss: 0.1394 - val_mse: 0.2944 - 350ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 4.8681 - mse: 611.1740 - val_loss: 0.1352 - val_mse: 0.2851 - 359ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 4.4391 - mse: 1161.2599 - val_loss: 0.1310 - val_mse: 0.2759 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 3.8936 - mse: 570.9841 - val_loss: 0.1245 - val_mse: 0.2619 - 355ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 3.5401 - mse: 304.7309 - val_loss: 0.1200 - val_mse: 0.2522 - 349ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 3.4717 - mse: 399.2103 - val_loss: 0.1157 - val_mse: 0.2429 - 353ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 2.7820 - mse: 179.0342 - val_loss: 0.1135 - val_mse: 0.2379 - 351ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 2.9769 - mse: 302.1888 - val_loss: 0.1086 - val_mse: 0.2273 - 348ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 2.3293 - mse: 177.4409 - val_loss: 0.1058 - val_mse: 0.2211 - 350ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 2.4615 - mse: 293.5168 - val_loss: 0.1018 - val_mse: 0.2126 - 352ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 2.0482 - mse: 247.5556 - val_loss: 0.0994 - val_mse: 0.2072 - 356ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.8533 - mse: 99.5778 - val_loss: 0.0959 - val_mse: 0.1997 - 356ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.4983 - mse: 84.4057 - val_loss: 0.0920 - val_mse: 0.1913 - 361ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.8080 - mse: 318.4839 - val_loss: 0.0898 - val_mse: 0.1865 - 358ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.4824 - mse: 99.0635 - val_loss: 0.0862 - val_mse: 0.1789 - 363ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.3538 - mse: 96.3827 - val_loss: 0.0826 - val_mse: 0.1712 - 368ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.3007 - mse: 108.8922 - val_loss: 0.0805 - val_mse: 0.1667 - 358ms/epoch - 5ms/step\n",
            "68/68 - 0s - loss: 1.2205 - mse: 85.9453 - val_loss: 0.0771 - val_mse: 0.1594 - 362ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 18 ended. Search finished for the next optimal point.\n",
            "Time taken: 25.9541\n",
            "Function value obtained: 0.1594\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 19 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [195, 184]\n",
            "Learning Rate: 0.00011200783863073522\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2743781487636888\n",
            "Batch Size: 57\n",
            "----------------------------------------\n",
            "148/148 - 3s - loss: 189.8320 - mse: 440557.4688 - val_loss: 6.5252 - val_mse: 214.0466 - 3s/epoch - 22ms/step\n",
            "148/148 - 1s - loss: 117.7229 - mse: 153630.1250 - val_loss: 5.8503 - val_mse: 213.5515 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 88.7215 - mse: 98421.5703 - val_loss: 0.3299 - val_mse: 1.2627 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 62.6467 - mse: 48740.4531 - val_loss: 0.2209 - val_mse: 0.5232 - 652ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 49.1065 - mse: 30536.0273 - val_loss: 0.1677 - val_mse: 0.3889 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 38.0327 - mse: 16882.4746 - val_loss: 0.0706 - val_mse: 0.1466 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 30.8846 - mse: 11193.7354 - val_loss: 1.2158 - val_mse: 14.5006 - 652ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 25.4709 - mse: 7904.0562 - val_loss: 1.2704 - val_mse: 14.3787 - 648ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 22.1728 - mse: 6558.6401 - val_loss: 0.0888 - val_mse: 0.1856 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 18.3822 - mse: 4655.2808 - val_loss: 0.2226 - val_mse: 0.7552 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 14.2052 - mse: 2801.3411 - val_loss: 0.0788 - val_mse: 0.1889 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 12.4098 - mse: 2142.9133 - val_loss: 0.4422 - val_mse: 2.3752 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 10.1827 - mse: 1254.4867 - val_loss: 0.0734 - val_mse: 0.1531 - 651ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 8.8773 - mse: 1079.4586 - val_loss: 0.0589 - val_mse: 0.1207 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 7.6123 - mse: 844.4805 - val_loss: 0.0779 - val_mse: 0.1612 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 6.4889 - mse: 698.2043 - val_loss: 0.1432 - val_mse: 0.3210 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 5.5750 - mse: 495.2881 - val_loss: 0.0981 - val_mse: 0.2047 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 4.1385 - mse: 251.8122 - val_loss: 0.0768 - val_mse: 0.1587 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 3.6207 - mse: 211.9675 - val_loss: 0.0737 - val_mse: 0.1523 - 656ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 3.1002 - mse: 174.2475 - val_loss: 0.0624 - val_mse: 0.1286 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2.6452 - mse: 127.2573 - val_loss: 0.0592 - val_mse: 0.1218 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2.1491 - mse: 97.2744 - val_loss: 0.0671 - val_mse: 0.1432 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.7302 - mse: 54.7596 - val_loss: 0.0645 - val_mse: 0.1365 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.6245 - mse: 65.2432 - val_loss: 0.0502 - val_mse: 0.1035 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.2718 - mse: 35.5850 - val_loss: 0.0393 - val_mse: 0.0805 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1.1686 - mse: 35.5372 - val_loss: 0.0394 - val_mse: 0.0808 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.9250 - mse: 19.1511 - val_loss: 0.0333 - val_mse: 0.0678 - 682ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.9070 - mse: 27.7189 - val_loss: 0.0220 - val_mse: 0.0447 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.7247 - mse: 20.2330 - val_loss: 0.0152 - val_mse: 0.0307 - 652ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.5571 - mse: 10.2082 - val_loss: 0.0133 - val_mse: 0.0269 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.4946 - mse: 11.1372 - val_loss: 0.0117 - val_mse: 0.0236 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.4149 - mse: 6.8869 - val_loss: 0.0102 - val_mse: 0.0205 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.3434 - mse: 5.3760 - val_loss: 0.0065 - val_mse: 0.0130 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.3432 - mse: 8.0806 - val_loss: 0.0044 - val_mse: 0.0089 - 652ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.3071 - mse: 7.2841 - val_loss: 0.0041 - val_mse: 0.0083 - 654ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2426 - mse: 3.9293 - val_loss: 0.0041 - val_mse: 0.0081 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2431 - mse: 6.5810 - val_loss: 0.0054 - val_mse: 0.0108 - 653ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1921 - mse: 4.2131 - val_loss: 0.0035 - val_mse: 0.0070 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1590 - mse: 1.9637 - val_loss: 0.0075 - val_mse: 0.0151 - 656ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1274 - mse: 2.1541 - val_loss: 0.0067 - val_mse: 0.0135 - 656ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1430 - mse: 3.4974 - val_loss: 0.0035 - val_mse: 0.0070 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1141 - mse: 1.6944 - val_loss: 0.0037 - val_mse: 0.0075 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.0883 - mse: 1.3047 - val_loss: 0.0033 - val_mse: 0.0067 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.0749 - mse: 0.6564 - val_loss: 0.0035 - val_mse: 0.0071 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.1012 - mse: 2.0876 - val_loss: 0.0044 - val_mse: 0.0088 - 648ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0618 - mse: 0.8928 - val_loss: 0.0034 - val_mse: 0.0068 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0517 - mse: 0.4392 - val_loss: 0.0032 - val_mse: 0.0064 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0947 - mse: 7.3348 - val_loss: 0.0034 - val_mse: 0.0068 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0546 - mse: 0.8527 - val_loss: 0.0032 - val_mse: 0.0063 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0377 - mse: 0.2981 - val_loss: 0.0031 - val_mse: 0.0062 - 657ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 19 ended. Search finished for the next optimal point.\n",
            "Time taken: 41.1282\n",
            "Function value obtained: 0.0062\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 20 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [76]\n",
            "Learning Rate: 0.00016502938912937095\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.20526217606092337\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 308.4506 - mse: 1110298.0000 - val_loss: 0.2753 - val_mse: 0.6158 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 243.6907 - mse: 621454.8750 - val_loss: 8.0372 - val_mse: 270.4154 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 212.6443 - mse: 622705.9375 - val_loss: 4.4658 - val_mse: 91.6173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 171.5581 - mse: 431870.9688 - val_loss: 6.6821 - val_mse: 191.7175 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 148.4071 - mse: 316190.6562 - val_loss: 10.5037 - val_mse: 516.3228 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 116.9365 - mse: 166420.2969 - val_loss: 2.6008 - val_mse: 36.9778 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 95.7164 - mse: 110839.8516 - val_loss: 0.9125 - val_mse: 5.5994 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 75.3898 - mse: 67635.4141 - val_loss: 3.2196 - val_mse: 63.4005 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 62.6837 - mse: 50045.9180 - val_loss: 2.3540 - val_mse: 35.9589 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 51.2712 - mse: 27641.4629 - val_loss: 1.5055 - val_mse: 16.8805 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 40.3923 - mse: 21079.4355 - val_loss: 2.1088 - val_mse: 27.7121 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 31.1915 - mse: 12520.2559 - val_loss: 1.3390 - val_mse: 13.6252 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 25.0480 - mse: 8325.5254 - val_loss: 0.4725 - val_mse: 2.3094 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 19.1243 - mse: 5142.9385 - val_loss: 1.2377 - val_mse: 11.5729 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 13.4518 - mse: 2896.3503 - val_loss: 2.4945 - val_mse: 38.8928 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 10.4676 - mse: 2035.5387 - val_loss: 1.9355 - val_mse: 27.1349 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 7.2050 - mse: 737.6440 - val_loss: 0.0132 - val_mse: 0.0264 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 4.9461 - mse: 379.9207 - val_loss: 0.0791 - val_mse: 0.2049 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.2800 - mse: 187.4727 - val_loss: 0.3092 - val_mse: 1.1742 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 1.9328 - mse: 63.5539 - val_loss: 0.3925 - val_mse: 1.7110 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1054 - mse: 42.4681 - val_loss: 0.0498 - val_mse: 0.1089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5232 - mse: 19.0764 - val_loss: 0.1992 - val_mse: 0.6511 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2348 - mse: 8.9322 - val_loss: 0.0105 - val_mse: 0.0210 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0782 - mse: 0.2926 - val_loss: 0.0621 - val_mse: 0.1511 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0701 - mse: 0.5153 - val_loss: 0.0096 - val_mse: 0.0192 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0524 - mse: 0.2961 - val_loss: 0.0140 - val_mse: 0.0280 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0349 - mse: 0.1390 - val_loss: 0.0037 - val_mse: 0.0074 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0214 - mse: 0.0602 - val_loss: 0.0361 - val_mse: 0.0769 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0271 - mse: 0.1472 - val_loss: 0.0073 - val_mse: 0.0146 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0262 - mse: 0.1075 - val_loss: 0.0164 - val_mse: 0.0329 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0412 - mse: 1.2539 - val_loss: 0.0110 - val_mse: 0.0220 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0358 - mse: 0.1219 - val_loss: 0.0061 - val_mse: 0.0123 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0210 - mse: 0.0548 - val_loss: 0.0030 - val_mse: 0.0060 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0176 - mse: 0.0592 - val_loss: 0.0152 - val_mse: 0.0305 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0210 - mse: 0.0553 - val_loss: 0.0044 - val_mse: 0.0088 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0374 - mse: 0.1048 - val_loss: 0.0048 - val_mse: 0.0096 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0067 - mse: 0.0135 - val_loss: 0.0053 - val_mse: 0.0106 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0028 - val_mse: 0.0056 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0053 - mse: 0.0107 - val_loss: 0.0027 - val_mse: 0.0055 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0031 - val_mse: 0.0061 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0043 - val_mse: 0.0086 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0202 - mse: 0.0495 - val_loss: 0.0039 - val_mse: 0.0079 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0044 - val_mse: 0.0088 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0217 - val_loss: 0.0033 - val_mse: 0.0067 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0035 - val_mse: 0.0070 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0032 - val_mse: 0.0064 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0029 - val_mse: 0.0058 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0035 - mse: 0.0071 - val_loss: 0.0029 - val_mse: 0.0059 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0027 - val_mse: 0.0053 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 20 ended. Search finished for the next optimal point.\n",
            "Time taken: 99.3519\n",
            "Function value obtained: 0.0053\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 21 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [247]\n",
            "Learning Rate: 0.02085643641484385\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2611282331884616\n",
            "Batch Size: 111\n",
            "----------------------------------------\n",
            "76/76 - 2s - loss: 619.2935 - mse: 8829682.0000 - val_loss: 6.1980 - val_mse: 183.8090 - 2s/epoch - 28ms/step\n",
            "76/76 - 0s - loss: 11.6651 - mse: 2166.7400 - val_loss: 0.8673 - val_mse: 6.1635 - 351ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.6550 - mse: 202.2317 - val_loss: 0.1084 - val_mse: 0.3211 - 365ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.7131 - mse: 61.7069 - val_loss: 0.0069 - val_mse: 0.0138 - 352ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.8338 - mse: 15.9383 - val_loss: 0.0499 - val_mse: 0.1183 - 345ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.3933 - mse: 3.6647 - val_loss: 0.0192 - val_mse: 0.0383 - 342ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.2195 - mse: 1.5939 - val_loss: 0.0065 - val_mse: 0.0129 - 343ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.1186 - mse: 0.6624 - val_loss: 0.0030 - val_mse: 0.0060 - 345ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0512 - mse: 0.1763 - val_loss: 0.0038 - val_mse: 0.0076 - 342ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0260 - mse: 0.0837 - val_loss: 0.0030 - val_mse: 0.0060 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0532 - mse: 0.1799 - val_loss: 0.0032 - val_mse: 0.0064 - 347ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0384 - mse: 0.1252 - val_loss: 0.0036 - val_mse: 0.0071 - 345ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0251 - mse: 0.1044 - val_loss: 0.0031 - val_mse: 0.0062 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0477 - mse: 0.1809 - val_loss: 0.0065 - val_mse: 0.0130 - 350ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0279 - mse: 0.0860 - val_loss: 0.0073 - val_mse: 0.0145 - 352ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0696 - mse: 0.2426 - val_loss: 0.0038 - val_mse: 0.0076 - 346ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0266 - mse: 0.0784 - val_loss: 0.0032 - val_mse: 0.0064 - 351ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0254 - mse: 0.0764 - val_loss: 0.0034 - val_mse: 0.0067 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0210 - mse: 0.0605 - val_loss: 0.0043 - val_mse: 0.0086 - 349ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0272 - mse: 0.0747 - val_loss: 0.0032 - val_mse: 0.0063 - 348ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0088 - mse: 0.0190 - val_loss: 0.0027 - val_mse: 0.0053 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0026 - val_mse: 0.0053 - 353ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0027 - val_mse: 0.0054 - 359ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0034 - mse: 0.0069 - val_loss: 0.0026 - val_mse: 0.0051 - 352ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0026 - val_mse: 0.0053 - 350ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0033 - mse: 0.0067 - val_loss: 0.0027 - val_mse: 0.0054 - 342ms/epoch - 4ms/step\n",
            "76/76 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0025 - val_mse: 0.0049 - 350ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0026 - val_mse: 0.0052 - 353ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0026 - val_mse: 0.0052 - 358ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0032 - mse: 0.0064 - val_loss: 0.0027 - val_mse: 0.0055 - 355ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0031 - mse: 0.0063 - val_loss: 0.0024 - val_mse: 0.0049 - 357ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0024 - val_mse: 0.0048 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0229 - mse: 0.0763 - val_loss: 0.0157 - val_mse: 0.0314 - 348ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0468 - mse: 0.1661 - val_loss: 0.0038 - val_mse: 0.0076 - 346ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0125 - mse: 0.0312 - val_loss: 0.0051 - val_mse: 0.0102 - 346ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0038 - mse: 0.0075 - val_loss: 0.0026 - val_mse: 0.0051 - 352ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0025 - val_mse: 0.0050 - 347ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0030 - mse: 0.0061 - val_loss: 0.0024 - val_mse: 0.0049 - 355ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0050 - 351ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0027 - val_mse: 0.0053 - 346ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0024 - val_mse: 0.0049 - 346ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0025 - val_mse: 0.0050 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0024 - val_mse: 0.0049 - 343ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0024 - val_mse: 0.0048 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0023 - val_mse: 0.0047 - 345ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0028 - mse: 0.0055 - val_loss: 0.0023 - val_mse: 0.0047 - 344ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0024 - val_mse: 0.0047 - 341ms/epoch - 4ms/step\n",
            "76/76 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046 - 342ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0023 - val_mse: 0.0046 - 342ms/epoch - 4ms/step\n",
            "76/76 - 0s - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0024 - val_mse: 0.0047 - 343ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 21 ended. Search finished for the next optimal point.\n",
            "Time taken: 24.6102\n",
            "Function value obtained: 0.0047\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 22 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [167, 197]\n",
            "Learning Rate: 0.002477856691727444\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.29987144449028896\n",
            "Batch Size: 145\n",
            "----------------------------------------\n",
            "58/58 - 3s - loss: 166.9841 - mse: 618538.3750 - val_loss: 6.2336 - val_mse: 220.0898 - 3s/epoch - 51ms/step\n",
            "58/58 - 0s - loss: 19.1708 - mse: 3879.0112 - val_loss: 0.9637 - val_mse: 4.7053 - 311ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 7.1893 - mse: 687.1182 - val_loss: 0.1155 - val_mse: 0.0207 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 3.1461 - mse: 130.9232 - val_loss: 0.0745 - val_mse: 0.0091 - 309ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 1.6120 - mse: 47.3452 - val_loss: 0.1184 - val_mse: 0.0222 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.9890 - mse: 23.7262 - val_loss: 0.1135 - val_mse: 0.0202 - 310ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.6772 - mse: 14.8743 - val_loss: 0.1105 - val_mse: 0.0190 - 313ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.4203 - mse: 4.7801 - val_loss: 0.1109 - val_mse: 0.0191 - 307ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.3509 - mse: 3.2202 - val_loss: 0.1112 - val_mse: 0.0193 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.3221 - mse: 12.4392 - val_loss: 0.1075 - val_mse: 0.0178 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.2589 - mse: 1.7827 - val_loss: 0.1128 - val_mse: 0.0199 - 313ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.2037 - mse: 0.9264 - val_loss: 0.1120 - val_mse: 0.0196 - 316ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1996 - mse: 1.0001 - val_loss: 0.1116 - val_mse: 0.0194 - 316ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1684 - mse: 0.5989 - val_loss: 0.0999 - val_mse: 0.0136 - 326ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1685 - mse: 0.8249 - val_loss: 0.0792 - val_mse: 0.0083 - 322ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1561 - mse: 0.8936 - val_loss: 0.1016 - val_mse: 0.0144 - 327ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1515 - mse: 0.5395 - val_loss: 0.1043 - val_mse: 0.0151 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1556 - mse: 1.2291 - val_loss: 0.1004 - val_mse: 0.0141 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1376 - mse: 0.5098 - val_loss: 0.0748 - val_mse: 0.0077 - 319ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1381 - mse: 0.6189 - val_loss: 0.1115 - val_mse: 0.0182 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1441 - mse: 0.7903 - val_loss: 0.1101 - val_mse: 0.0179 - 335ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1357 - mse: 0.9233 - val_loss: 0.0914 - val_mse: 0.0111 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1200 - mse: 0.2790 - val_loss: 0.0820 - val_mse: 0.0089 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1345 - mse: 0.5748 - val_loss: 0.1046 - val_mse: 0.0154 - 318ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1196 - mse: 0.2728 - val_loss: 0.0980 - val_mse: 0.0132 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1108 - mse: 0.1670 - val_loss: 0.0980 - val_mse: 0.0133 - 328ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1172 - mse: 0.1792 - val_loss: 0.0661 - val_mse: 0.0064 - 316ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1115 - mse: 0.1236 - val_loss: 0.0774 - val_mse: 0.0079 - 322ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1100 - mse: 0.1969 - val_loss: 0.1095 - val_mse: 0.0170 - 328ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1065 - mse: 0.1651 - val_loss: 0.0855 - val_mse: 0.0096 - 324ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.0994 - mse: 0.0529 - val_loss: 0.0719 - val_mse: 0.0070 - 323ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1046 - mse: 0.0728 - val_loss: 0.0968 - val_mse: 0.0126 - 318ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0986 - mse: 0.0300 - val_loss: 0.0644 - val_mse: 0.0061 - 319ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1057 - mse: 0.0432 - val_loss: 0.1102 - val_mse: 0.0171 - 320ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1065 - mse: 0.0908 - val_loss: 0.1150 - val_mse: 0.0207 - 322ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1003 - mse: 0.0550 - val_loss: 0.0751 - val_mse: 0.0076 - 317ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1044 - mse: 0.1262 - val_loss: 0.1095 - val_mse: 0.0173 - 317ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1039 - mse: 0.0577 - val_loss: 0.1088 - val_mse: 0.0182 - 321ms/epoch - 6ms/step\n",
            "58/58 - 0s - loss: 0.1053 - mse: 0.1174 - val_loss: 0.1066 - val_mse: 0.0165 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0955 - mse: 0.0436 - val_loss: 0.1129 - val_mse: 0.0191 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1013 - mse: 0.0590 - val_loss: 0.0949 - val_mse: 0.0120 - 318ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0994 - mse: 0.0576 - val_loss: 0.0924 - val_mse: 0.0113 - 318ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0983 - mse: 0.0882 - val_loss: 0.1112 - val_mse: 0.0183 - 316ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0966 - mse: 0.0549 - val_loss: 0.1193 - val_mse: 0.0225 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1024 - mse: 0.1229 - val_loss: 0.0788 - val_mse: 0.0083 - 317ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0932 - mse: 0.1033 - val_loss: 0.1010 - val_mse: 0.0139 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1004 - mse: 0.1073 - val_loss: 0.1231 - val_mse: 0.0241 - 314ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0957 - mse: 0.0266 - val_loss: 0.0665 - val_mse: 0.0066 - 315ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.1028 - mse: 0.0330 - val_loss: 0.0773 - val_mse: 0.0079 - 312ms/epoch - 5ms/step\n",
            "58/58 - 0s - loss: 0.0959 - mse: 0.0728 - val_loss: 0.0798 - val_mse: 0.0085 - 312ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 22 ended. Search finished for the next optimal point.\n",
            "Time taken: 24.3442\n",
            "Function value obtained: 0.0085\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 23 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [187, 174]\n",
            "Learning Rate: 0.00011164636176727528\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.366320075280952\n",
            "Batch Size: 49\n",
            "----------------------------------------\n",
            "172/172 - 4s - loss: 306.6252 - mse: 1135893.3750 - val_loss: 1.5509 - val_mse: 21.0205 - 4s/epoch - 21ms/step\n",
            "172/172 - 1s - loss: 197.5674 - mse: 442666.4688 - val_loss: 1.0774 - val_mse: 7.1208 - 758ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 145.3078 - mse: 303001.3125 - val_loss: 8.7264 - val_mse: 432.5850 - 754ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 103.4271 - mse: 121694.6328 - val_loss: 5.7367 - val_mse: 189.8190 - 766ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 79.1299 - mse: 68200.8516 - val_loss: 9.6478 - val_mse: 513.5778 - 758ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 62.6607 - mse: 48042.6250 - val_loss: 1.1006 - val_mse: 7.8766 - 749ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 48.6734 - mse: 27444.5117 - val_loss: 0.4280 - val_mse: 1.3575 - 764ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 41.1517 - mse: 21114.5098 - val_loss: 0.1866 - val_mse: 0.3989 - 748ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 32.9747 - mse: 12906.6230 - val_loss: 0.1886 - val_mse: 0.4285 - 752ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 27.5743 - mse: 9966.6533 - val_loss: 0.2367 - val_mse: 0.7162 - 752ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 23.7124 - mse: 6984.7905 - val_loss: 0.1413 - val_mse: 0.3013 - 742ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 19.8267 - mse: 4374.5283 - val_loss: 0.1464 - val_mse: 0.3204 - 776ms/epoch - 5ms/step\n",
            "172/172 - 1s - loss: 17.2320 - mse: 4153.1953 - val_loss: 0.1829 - val_mse: 0.3907 - 777ms/epoch - 5ms/step\n",
            "172/172 - 1s - loss: 14.8710 - mse: 2948.6584 - val_loss: 0.4058 - val_mse: 1.1879 - 768ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 11.9604 - mse: 1981.2036 - val_loss: 0.2389 - val_mse: 0.5459 - 741ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 10.2066 - mse: 1317.1646 - val_loss: 0.2359 - val_mse: 0.5456 - 757ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 8.5757 - mse: 1105.4783 - val_loss: 0.1829 - val_mse: 0.3957 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 7.2599 - mse: 684.4550 - val_loss: 0.1382 - val_mse: 0.2908 - 745ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 6.4937 - mse: 697.2408 - val_loss: 0.1149 - val_mse: 0.2405 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 5.6207 - mse: 515.4980 - val_loss: 0.1107 - val_mse: 0.2312 - 760ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 4.4938 - mse: 274.4214 - val_loss: 0.0976 - val_mse: 0.2034 - 741ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 4.0298 - mse: 263.6292 - val_loss: 0.1057 - val_mse: 0.2202 - 748ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 3.3664 - mse: 188.8349 - val_loss: 0.0970 - val_mse: 0.2015 - 756ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 2.7056 - mse: 118.0029 - val_loss: 0.0757 - val_mse: 0.1564 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 2.4604 - mse: 111.8063 - val_loss: 0.0647 - val_mse: 0.1332 - 759ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 2.0401 - mse: 83.1608 - val_loss: 0.0541 - val_mse: 0.1111 - 781ms/epoch - 5ms/step\n",
            "172/172 - 1s - loss: 1.8659 - mse: 89.5061 - val_loss: 0.0511 - val_mse: 0.1048 - 766ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 1.4693 - mse: 64.9368 - val_loss: 0.0424 - val_mse: 0.0868 - 784ms/epoch - 5ms/step\n",
            "172/172 - 1s - loss: 1.3198 - mse: 39.9345 - val_loss: 0.0363 - val_mse: 0.0740 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 1.1824 - mse: 43.1588 - val_loss: 0.0348 - val_mse: 0.0710 - 744ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 1.0403 - mse: 31.2573 - val_loss: 0.0262 - val_mse: 0.0533 - 757ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.8440 - mse: 20.9154 - val_loss: 0.0242 - val_mse: 0.0491 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.7516 - mse: 18.7088 - val_loss: 0.0219 - val_mse: 0.0445 - 743ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.5895 - mse: 10.9622 - val_loss: 0.0154 - val_mse: 0.0312 - 750ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.5611 - mse: 13.7433 - val_loss: 0.0086 - val_mse: 0.0174 - 749ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.4536 - mse: 10.4925 - val_loss: 0.0101 - val_mse: 0.0204 - 744ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.3978 - mse: 7.5486 - val_loss: 0.0084 - val_mse: 0.0169 - 741ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.3490 - mse: 6.4738 - val_loss: 0.0063 - val_mse: 0.0127 - 744ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.2782 - mse: 3.7040 - val_loss: 0.0046 - val_mse: 0.0092 - 751ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.2509 - mse: 3.5890 - val_loss: 0.0043 - val_mse: 0.0087 - 760ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.2357 - mse: 3.5801 - val_loss: 0.0037 - val_mse: 0.0074 - 773ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.2242 - mse: 4.5227 - val_loss: 0.0045 - val_mse: 0.0090 - 778ms/epoch - 5ms/step\n",
            "172/172 - 1s - loss: 0.1927 - mse: 3.5009 - val_loss: 0.0052 - val_mse: 0.0104 - 759ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.1542 - mse: 2.4194 - val_loss: 0.0036 - val_mse: 0.0073 - 742ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.1369 - mse: 1.6423 - val_loss: 0.0038 - val_mse: 0.0076 - 753ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.1342 - mse: 2.7528 - val_loss: 0.0050 - val_mse: 0.0101 - 750ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.0923 - mse: 1.1874 - val_loss: 0.0034 - val_mse: 0.0069 - 747ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.0765 - mse: 0.6799 - val_loss: 0.0035 - val_mse: 0.0071 - 740ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.0859 - mse: 1.1275 - val_loss: 0.0035 - val_mse: 0.0069 - 754ms/epoch - 4ms/step\n",
            "172/172 - 1s - loss: 0.0767 - mse: 0.8597 - val_loss: 0.0038 - val_mse: 0.0075 - 746ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 23 ended. Search finished for the next optimal point.\n",
            "Time taken: 46.0725\n",
            "Function value obtained: 0.0075\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 24 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [140, 67]\n",
            "Learning Rate: 0.00011190440436292933\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.26580719652436896\n",
            "Batch Size: 133\n",
            "----------------------------------------\n",
            "64/64 - 3s - loss: 352.8905 - mse: 1591614.7500 - val_loss: 10.6223 - val_mse: 640.3831 - 3s/epoch - 45ms/step\n",
            "64/64 - 0s - loss: 258.8259 - mse: 853579.2500 - val_loss: 26.1879 - val_mse: 3713.2019 - 345ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 217.2642 - mse: 578243.2500 - val_loss: 1.0830 - val_mse: 4.1052 - 355ms/epoch - 6ms/step\n",
            "64/64 - 0s - loss: 163.2067 - mse: 340670.9375 - val_loss: 2.1519 - val_mse: 24.4901 - 361ms/epoch - 6ms/step\n",
            "64/64 - 0s - loss: 133.4155 - mse: 219621.2969 - val_loss: 0.6275 - val_mse: 0.4361 - 335ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 110.7744 - mse: 168413.6875 - val_loss: 1.2711 - val_mse: 3.0163 - 342ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 85.5320 - mse: 90760.5859 - val_loss: 2.3707 - val_mse: 17.5904 - 344ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 74.8622 - mse: 82865.9688 - val_loss: 1.9600 - val_mse: 10.8397 - 338ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 64.7361 - mse: 66801.4141 - val_loss: 3.4936 - val_mse: 45.8469 - 335ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 49.9786 - mse: 28346.4512 - val_loss: 2.2814 - val_mse: 16.8108 - 332ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 48.8299 - mse: 36974.4922 - val_loss: 0.7167 - val_mse: 1.2266 - 336ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 42.0307 - mse: 25535.4062 - val_loss: 0.6347 - val_mse: 0.7552 - 332ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 33.9269 - mse: 13338.4873 - val_loss: 0.5550 - val_mse: 0.3345 - 333ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 32.3225 - mse: 14530.4658 - val_loss: 0.7182 - val_mse: 0.5799 - 332ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 27.3176 - mse: 9583.9199 - val_loss: 0.6817 - val_mse: 0.5071 - 338ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 23.7669 - mse: 7359.3584 - val_loss: 0.5720 - val_mse: 0.5503 - 335ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 20.7566 - mse: 5281.6255 - val_loss: 1.0004 - val_mse: 4.1984 - 329ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 18.5353 - mse: 4849.0664 - val_loss: 0.7546 - val_mse: 1.8074 - 336ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 16.4812 - mse: 3703.6733 - val_loss: 0.6589 - val_mse: 1.0887 - 330ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 15.1314 - mse: 3295.0120 - val_loss: 0.6797 - val_mse: 1.1698 - 333ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 13.9762 - mse: 3241.1008 - val_loss: 0.6665 - val_mse: 1.0752 - 336ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 11.7625 - mse: 1925.1564 - val_loss: 0.5762 - val_mse: 0.5915 - 332ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 10.6783 - mse: 2592.5256 - val_loss: 0.6700 - val_mse: 1.1650 - 333ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 8.8885 - mse: 1173.4346 - val_loss: 0.5962 - val_mse: 0.7633 - 334ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 8.8193 - mse: 1422.7565 - val_loss: 0.5169 - val_mse: 0.4301 - 334ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 7.4242 - mse: 867.5659 - val_loss: 0.4135 - val_mse: 0.1900 - 341ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 6.8360 - mse: 722.8844 - val_loss: 0.3379 - val_mse: 0.1278 - 340ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 6.2688 - mse: 774.8014 - val_loss: 0.4042 - val_mse: 0.1807 - 352ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 5.6562 - mse: 591.5243 - val_loss: 0.3787 - val_mse: 0.1570 - 349ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 4.9395 - mse: 431.8885 - val_loss: 0.3363 - val_mse: 0.1240 - 342ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 4.4609 - mse: 490.7406 - val_loss: 0.3230 - val_mse: 0.1180 - 351ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 3.6974 - mse: 275.6372 - val_loss: 0.3027 - val_mse: 0.1062 - 360ms/epoch - 6ms/step\n",
            "64/64 - 0s - loss: 3.6178 - mse: 298.1904 - val_loss: 0.2414 - val_mse: 0.0690 - 345ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 3.1662 - mse: 200.4937 - val_loss: 0.2023 - val_mse: 0.0507 - 342ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 2.7633 - mse: 166.2733 - val_loss: 0.1385 - val_mse: 0.0253 - 348ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 2.6991 - mse: 180.5053 - val_loss: 0.0747 - val_mse: 0.0079 - 347ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 2.1098 - mse: 105.3449 - val_loss: 0.0787 - val_mse: 0.0087 - 344ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 2.0249 - mse: 150.6761 - val_loss: 0.0742 - val_mse: 0.0076 - 340ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.8135 - mse: 141.5950 - val_loss: 0.0796 - val_mse: 0.0088 - 339ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.6923 - mse: 98.8549 - val_loss: 0.0758 - val_mse: 0.0079 - 350ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.6086 - mse: 78.6083 - val_loss: 0.0719 - val_mse: 0.0071 - 335ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.1760 - mse: 45.0159 - val_loss: 0.0744 - val_mse: 0.0077 - 334ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.1122 - mse: 38.4446 - val_loss: 0.0736 - val_mse: 0.0076 - 337ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.1438 - mse: 43.4441 - val_loss: 0.0715 - val_mse: 0.0072 - 330ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 1.0883 - mse: 89.2380 - val_loss: 0.0769 - val_mse: 0.0082 - 343ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 0.9847 - mse: 41.5462 - val_loss: 0.0784 - val_mse: 0.0086 - 336ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 0.8016 - mse: 32.4239 - val_loss: 0.0742 - val_mse: 0.0078 - 334ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 0.8578 - mse: 31.1453 - val_loss: 0.0711 - val_mse: 0.0071 - 338ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 0.6969 - mse: 22.9730 - val_loss: 0.0721 - val_mse: 0.0073 - 339ms/epoch - 5ms/step\n",
            "64/64 - 0s - loss: 0.7548 - mse: 97.1779 - val_loss: 0.0701 - val_mse: 0.0071 - 329ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 24 ended. Search finished for the next optimal point.\n",
            "Time taken: 25.1328\n",
            "Function value obtained: 0.0071\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 25 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 189]\n",
            "Learning Rate: 0.002387186282902156\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2998280920708988\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 220.5858 - mse: 767406.8125 - val_loss: 37.7977 - val_mse: 7577.9233 - 3s/epoch - 84ms/step\n",
            "33/33 - 0s - loss: 38.7036 - mse: 24610.1895 - val_loss: 0.8845 - val_mse: 2.7783 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 16.3809 - mse: 3660.3245 - val_loss: 2.0920 - val_mse: 14.4755 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 8.3160 - mse: 815.6929 - val_loss: 0.8760 - val_mse: 1.8216 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 5.7373 - mse: 373.0871 - val_loss: 0.4178 - val_mse: 0.2622 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.9946 - mse: 209.5917 - val_loss: 0.3526 - val_mse: 0.1726 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.0792 - mse: 142.2167 - val_loss: 0.1283 - val_mse: 0.0234 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.1560 - mse: 86.8103 - val_loss: 0.0910 - val_mse: 0.0131 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.6071 - mse: 40.6646 - val_loss: 0.0908 - val_mse: 0.0156 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.2057 - mse: 20.0589 - val_loss: 0.0686 - val_mse: 0.0077 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.0299 - mse: 22.5490 - val_loss: 0.0644 - val_mse: 0.0060 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.7954 - mse: 10.2946 - val_loss: 0.0731 - val_mse: 0.0073 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6709 - mse: 12.1376 - val_loss: 0.0871 - val_mse: 0.0111 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.5591 - mse: 7.2518 - val_loss: 0.0720 - val_mse: 0.0070 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4472 - mse: 3.8487 - val_loss: 0.0864 - val_mse: 0.0103 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4027 - mse: 3.8457 - val_loss: 0.0972 - val_mse: 0.0133 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3369 - mse: 2.7764 - val_loss: 0.1198 - val_mse: 0.0225 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2994 - mse: 1.3735 - val_loss: 0.0930 - val_mse: 0.0123 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2761 - mse: 1.9451 - val_loss: 0.0906 - val_mse: 0.0114 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2748 - mse: 1.7670 - val_loss: 0.1103 - val_mse: 0.0178 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2403 - mse: 1.5037 - val_loss: 0.0877 - val_mse: 0.0107 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1986 - mse: 0.5687 - val_loss: 0.0929 - val_mse: 0.0124 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2230 - mse: 3.5655 - val_loss: 0.0831 - val_mse: 0.0100 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1847 - mse: 0.6643 - val_loss: 0.1013 - val_mse: 0.0141 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1776 - mse: 0.6021 - val_loss: 0.0879 - val_mse: 0.0106 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1519 - mse: 0.3621 - val_loss: 0.0831 - val_mse: 0.0098 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1591 - mse: 0.5287 - val_loss: 0.0816 - val_mse: 0.0095 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1559 - mse: 0.5594 - val_loss: 0.0816 - val_mse: 0.0097 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1436 - mse: 0.2763 - val_loss: 0.0796 - val_mse: 0.0092 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1541 - mse: 0.9357 - val_loss: 0.0803 - val_mse: 0.0092 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1418 - mse: 0.4464 - val_loss: 0.0782 - val_mse: 0.0087 - 221ms/epoch - 7ms/step\n",
            "33/33 - 1s - loss: 0.1342 - mse: 0.2789 - val_loss: 0.0762 - val_mse: 0.0085 - 723ms/epoch - 22ms/step\n",
            "33/33 - 0s - loss: 0.1211 - mse: 0.1681 - val_loss: 0.0812 - val_mse: 0.0092 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1262 - mse: 0.2027 - val_loss: 0.0794 - val_mse: 0.0090 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1199 - mse: 0.2351 - val_loss: 0.0789 - val_mse: 0.0089 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.1144 - mse: 0.1276 - val_loss: 0.0800 - val_mse: 0.0091 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1110 - mse: 0.1022 - val_loss: 0.0770 - val_mse: 0.0086 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.1218 - mse: 0.2555 - val_loss: 0.0733 - val_mse: 0.0079 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.1051 - mse: 0.0835 - val_loss: 0.0833 - val_mse: 0.0097 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1058 - mse: 0.0994 - val_loss: 0.0731 - val_mse: 0.0078 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1064 - mse: 0.1367 - val_loss: 0.0732 - val_mse: 0.0079 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1104 - mse: 0.6957 - val_loss: 0.0832 - val_mse: 0.0096 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0999 - mse: 0.1103 - val_loss: 0.0709 - val_mse: 0.0074 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1077 - mse: 0.2158 - val_loss: 0.0722 - val_mse: 0.0078 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0987 - mse: 0.1235 - val_loss: 0.0725 - val_mse: 0.0076 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0972 - mse: 0.1134 - val_loss: 0.0737 - val_mse: 0.0077 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1017 - mse: 0.1816 - val_loss: 0.0715 - val_mse: 0.0073 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0958 - mse: 0.0857 - val_loss: 0.0687 - val_mse: 0.0068 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0937 - mse: 0.0716 - val_loss: 0.0723 - val_mse: 0.0077 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0946 - mse: 0.1042 - val_loss: 0.0683 - val_mse: 0.0069 - 241ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 25 ended. Search finished for the next optimal point.\n",
            "Time taken: 20.5043\n",
            "Function value obtained: 0.0069\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 26 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [161, 134]\n",
            "Learning Rate: 0.00011181473734810293\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.27009527489234175\n",
            "Batch Size: 114\n",
            "----------------------------------------\n",
            "74/74 - 3s - loss: 206.0811 - mse: 549541.1250 - val_loss: 3.1207 - val_mse: 24.9780 - 3s/epoch - 41ms/step\n",
            "74/74 - 0s - loss: 153.2315 - mse: 268857.3125 - val_loss: 6.6517 - val_mse: 227.8794 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 120.3246 - mse: 181668.6719 - val_loss: 3.5567 - val_mse: 71.1069 - 379ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 95.6977 - mse: 124940.1328 - val_loss: 10.1695 - val_mse: 506.2187 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 77.0438 - mse: 79987.3594 - val_loss: 1.9576 - val_mse: 21.2407 - 388ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 65.3916 - mse: 52598.9023 - val_loss: 5.9067 - val_mse: 162.3941 - 384ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 53.1581 - mse: 33049.5234 - val_loss: 6.7338 - val_mse: 234.7020 - 389ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 44.1916 - mse: 22192.7676 - val_loss: 2.2677 - val_mse: 22.4097 - 389ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 37.3257 - mse: 15250.2139 - val_loss: 0.4980 - val_mse: 0.6781 - 386ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 33.7858 - mse: 13886.0312 - val_loss: 1.1783 - val_mse: 6.6340 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 26.9203 - mse: 8268.9912 - val_loss: 1.5338 - val_mse: 11.9539 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 25.4753 - mse: 9017.1064 - val_loss: 0.9639 - val_mse: 2.1582 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 21.7849 - mse: 6152.0122 - val_loss: 0.3837 - val_mse: 0.1830 - 367ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 18.6575 - mse: 3986.0696 - val_loss: 0.4297 - val_mse: 0.1958 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 16.9545 - mse: 3730.8879 - val_loss: 0.4059 - val_mse: 0.2409 - 374ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 14.2636 - mse: 2354.3831 - val_loss: 0.3062 - val_mse: 0.1063 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 13.2907 - mse: 2662.1321 - val_loss: 0.2342 - val_mse: 0.0729 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 11.1685 - mse: 1839.0443 - val_loss: 0.3199 - val_mse: 0.1272 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 10.3334 - mse: 1433.1118 - val_loss: 0.2573 - val_mse: 0.1230 - 378ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 9.0799 - mse: 1028.5143 - val_loss: 0.2235 - val_mse: 0.0797 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 8.0749 - mse: 835.3629 - val_loss: 0.1726 - val_mse: 0.0396 - 368ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 7.2464 - mse: 616.8674 - val_loss: 0.1719 - val_mse: 0.0414 - 377ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 6.5484 - mse: 622.3583 - val_loss: 0.1696 - val_mse: 0.0439 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 5.6339 - mse: 397.3680 - val_loss: 0.0843 - val_mse: 0.0111 - 380ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 4.9857 - mse: 498.6173 - val_loss: 0.1257 - val_mse: 0.0267 - 372ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 4.6280 - mse: 323.2781 - val_loss: 0.0921 - val_mse: 0.0145 - 372ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 3.7519 - mse: 225.7168 - val_loss: 0.1252 - val_mse: 0.0306 - 369ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 3.4947 - mse: 190.3477 - val_loss: 0.1457 - val_mse: 0.0452 - 379ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 3.1946 - mse: 164.9258 - val_loss: 0.1346 - val_mse: 0.0330 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.9308 - mse: 134.3226 - val_loss: 0.0937 - val_mse: 0.0161 - 383ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.6757 - mse: 134.9977 - val_loss: 0.0781 - val_mse: 0.0106 - 391ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.2397 - mse: 70.1006 - val_loss: 0.1077 - val_mse: 0.0170 - 386ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 2.2183 - mse: 93.3341 - val_loss: 0.0969 - val_mse: 0.0177 - 404ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.7922 - mse: 57.0480 - val_loss: 0.1359 - val_mse: 0.0279 - 403ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.5226 - mse: 43.9129 - val_loss: 0.0958 - val_mse: 0.0124 - 385ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.4847 - mse: 53.2083 - val_loss: 0.0999 - val_mse: 0.0134 - 371ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.3784 - mse: 41.2902 - val_loss: 0.0702 - val_mse: 0.0079 - 367ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.2326 - mse: 40.6247 - val_loss: 0.0745 - val_mse: 0.0087 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 1.0933 - mse: 32.6026 - val_loss: 0.0855 - val_mse: 0.0096 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.9615 - mse: 24.2844 - val_loss: 0.0690 - val_mse: 0.0069 - 377ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.7629 - mse: 12.9778 - val_loss: 0.0734 - val_mse: 0.0076 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.8269 - mse: 23.6969 - val_loss: 0.0692 - val_mse: 0.0070 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.7007 - mse: 16.0093 - val_loss: 0.0738 - val_mse: 0.0075 - 377ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.7204 - mse: 18.6101 - val_loss: 0.0660 - val_mse: 0.0064 - 375ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.5838 - mse: 12.6760 - val_loss: 0.0702 - val_mse: 0.0071 - 368ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.5719 - mse: 10.4097 - val_loss: 0.0914 - val_mse: 0.0112 - 372ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.5227 - mse: 11.9682 - val_loss: 0.0721 - val_mse: 0.0073 - 376ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.4798 - mse: 6.8835 - val_loss: 0.0801 - val_mse: 0.0085 - 370ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.4652 - mse: 11.1588 - val_loss: 0.0644 - val_mse: 0.0062 - 373ms/epoch - 5ms/step\n",
            "74/74 - 0s - loss: 0.4544 - mse: 38.1491 - val_loss: 0.0731 - val_mse: 0.0073 - 369ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 26 ended. Search finished for the next optimal point.\n",
            "Time taken: 26.9505\n",
            "Function value obtained: 0.0073\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 27 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [196, 135]\n",
            "Learning Rate: 0.00011181214759546315\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.2176594031467113\n",
            "Batch Size: 190\n",
            "----------------------------------------\n",
            "45/45 - 3s - loss: 217.7295 - mse: 671269.6250 - val_loss: 2.9593 - val_mse: 39.1209 - 3s/epoch - 63ms/step\n",
            "45/45 - 0s - loss: 157.9384 - mse: 320862.8750 - val_loss: 0.7714 - val_mse: 3.0651 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 117.9631 - mse: 154228.9375 - val_loss: 4.1446 - val_mse: 89.8872 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 106.7433 - mse: 135736.6562 - val_loss: 8.5620 - val_mse: 387.2395 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 92.2833 - mse: 107036.0391 - val_loss: 1.7286 - val_mse: 15.9611 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 77.3681 - mse: 71330.3750 - val_loss: 5.3810 - val_mse: 155.1138 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 68.5773 - mse: 57653.9883 - val_loss: 0.3228 - val_mse: 0.7944 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 61.1748 - mse: 48739.4688 - val_loss: 3.1882 - val_mse: 61.1719 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 51.6927 - mse: 34791.2617 - val_loss: 6.4783 - val_mse: 229.3382 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 43.2400 - mse: 20352.2461 - val_loss: 1.7902 - val_mse: 19.9767 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 38.2086 - mse: 20476.0625 - val_loss: 0.2664 - val_mse: 0.5930 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 34.4313 - mse: 16269.4395 - val_loss: 0.3444 - val_mse: 0.8368 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 28.9003 - mse: 10165.3711 - val_loss: 1.0766 - val_mse: 11.3017 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 28.1450 - mse: 10338.1006 - val_loss: 0.1970 - val_mse: 0.5319 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 23.9279 - mse: 6795.7930 - val_loss: 0.2071 - val_mse: 0.4686 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 21.3143 - mse: 5260.6118 - val_loss: 0.4161 - val_mse: 1.1369 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 20.5175 - mse: 6421.4248 - val_loss: 0.1910 - val_mse: 0.4115 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 17.3730 - mse: 3988.9587 - val_loss: 0.4013 - val_mse: 1.3680 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 15.6336 - mse: 3114.4409 - val_loss: 0.1115 - val_mse: 0.2347 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 13.5161 - mse: 2561.7612 - val_loss: 0.2427 - val_mse: 0.6423 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 12.6668 - mse: 1984.1737 - val_loss: 0.1081 - val_mse: 0.2258 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 11.7982 - mse: 1693.5326 - val_loss: 0.1853 - val_mse: 0.4388 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 11.3543 - mse: 1842.7367 - val_loss: 0.1282 - val_mse: 0.2737 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 9.8919 - mse: 1264.4241 - val_loss: 0.1046 - val_mse: 0.2182 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 9.6813 - mse: 1454.9716 - val_loss: 0.0984 - val_mse: 0.2046 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 7.8682 - mse: 953.6203 - val_loss: 0.3873 - val_mse: 1.4181 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 7.4492 - mse: 844.9552 - val_loss: 0.2346 - val_mse: 0.6556 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 7.4866 - mse: 842.8992 - val_loss: 0.1113 - val_mse: 0.2378 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 6.3556 - mse: 666.3033 - val_loss: 0.2834 - val_mse: 0.8921 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 5.8128 - mse: 572.8200 - val_loss: 0.2070 - val_mse: 0.5709 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 5.6016 - mse: 515.1075 - val_loss: 0.1428 - val_mse: 0.3433 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 4.7538 - mse: 324.6826 - val_loss: 0.0703 - val_mse: 0.1460 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 4.4124 - mse: 290.4264 - val_loss: 0.1228 - val_mse: 0.2900 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 4.0697 - mse: 282.5012 - val_loss: 0.1270 - val_mse: 0.3067 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 3.6815 - mse: 213.9220 - val_loss: 0.1256 - val_mse: 0.3083 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 3.3473 - mse: 164.5719 - val_loss: 0.0521 - val_mse: 0.1072 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 3.4383 - mse: 189.5926 - val_loss: 0.0401 - val_mse: 0.0818 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.9016 - mse: 120.7808 - val_loss: 0.0150 - val_mse: 0.0302 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.7605 - mse: 121.6253 - val_loss: 0.0185 - val_mse: 0.0375 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.4439 - mse: 97.0975 - val_loss: 0.0081 - val_mse: 0.0162 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.3672 - mse: 119.1221 - val_loss: 0.0159 - val_mse: 0.0322 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.1084 - mse: 85.6418 - val_loss: 0.0056 - val_mse: 0.0113 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.0947 - mse: 100.4336 - val_loss: 0.0085 - val_mse: 0.0170 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.7705 - mse: 71.7280 - val_loss: 0.0076 - val_mse: 0.0152 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.6130 - mse: 65.2171 - val_loss: 0.0062 - val_mse: 0.0125 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.6155 - mse: 63.8314 - val_loss: 0.0104 - val_mse: 0.0210 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.4965 - mse: 60.5941 - val_loss: 0.0130 - val_mse: 0.0262 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.3226 - mse: 56.5277 - val_loss: 0.0114 - val_mse: 0.0229 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.1628 - mse: 35.2873 - val_loss: 0.0090 - val_mse: 0.0182 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.0548 - mse: 27.1303 - val_loss: 0.0089 - val_mse: 0.0179 - 279ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 27 ended. Search finished for the next optimal point.\n",
            "Time taken: 21.6092\n",
            "Function value obtained: 0.0179\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 28 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [127, 91]\n",
            "Learning Rate: 0.0001113627938365896\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3499099199002183\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 434.2600 - mse: 2556577.7500 - val_loss: 14.2603 - val_mse: 903.8756 - 5s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 262.3301 - mse: 864089.8125 - val_loss: 1.2809 - val_mse: 2.5398 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 157.3496 - mse: 337814.3438 - val_loss: 2.3282 - val_mse: 18.3239 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 104.4640 - mse: 137576.3594 - val_loss: 2.6648 - val_mse: 23.9787 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 67.5977 - mse: 61419.3633 - val_loss: 2.9616 - val_mse: 34.6108 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 43.9082 - mse: 20667.4062 - val_loss: 0.6364 - val_mse: 1.2818 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 33.6581 - mse: 14636.1494 - val_loss: 1.3711 - val_mse: 5.1474 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 23.3214 - mse: 7524.6582 - val_loss: 0.4706 - val_mse: 0.3842 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 15.4081 - mse: 3029.7068 - val_loss: 0.3607 - val_mse: 0.1538 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 10.4034 - mse: 1540.8151 - val_loss: 0.3851 - val_mse: 0.2416 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 7.7529 - mse: 1580.2908 - val_loss: 0.2356 - val_mse: 0.0744 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 4.9706 - mse: 484.7499 - val_loss: 0.1569 - val_mse: 0.0339 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 3.1366 - mse: 173.7633 - val_loss: 0.0715 - val_mse: 0.0083 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.1589 - mse: 157.0475 - val_loss: 0.0738 - val_mse: 0.0080 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4295 - mse: 64.7015 - val_loss: 0.0783 - val_mse: 0.0085 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.9322 - mse: 52.0176 - val_loss: 0.0803 - val_mse: 0.0089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6610 - mse: 32.2121 - val_loss: 0.0699 - val_mse: 0.0071 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5823 - mse: 26.0806 - val_loss: 0.0676 - val_mse: 0.0067 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3528 - mse: 4.1406 - val_loss: 0.0914 - val_mse: 0.0110 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4193 - mse: 130.0041 - val_loss: 0.0738 - val_mse: 0.0078 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2886 - mse: 5.5123 - val_loss: 0.0670 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2590 - mse: 8.6867 - val_loss: 0.0692 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1667 - mse: 1.5403 - val_loss: 0.0690 - val_mse: 0.0069 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1737 - mse: 2.0736 - val_loss: 0.0810 - val_mse: 0.0086 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1316 - mse: 0.3323 - val_loss: 0.0919 - val_mse: 0.0112 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1353 - mse: 0.6704 - val_loss: 0.0698 - val_mse: 0.0069 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1252 - mse: 0.6325 - val_loss: 0.0667 - val_mse: 0.0067 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1157 - mse: 0.5086 - val_loss: 0.0695 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1029 - mse: 0.0455 - val_loss: 0.0770 - val_mse: 0.0079 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0999 - mse: 0.0769 - val_loss: 0.0710 - val_mse: 0.0070 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1011 - mse: 0.0382 - val_loss: 0.0675 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1195 - mse: 1.7611 - val_loss: 0.0660 - val_mse: 0.0064 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0971 - mse: 0.0683 - val_loss: 0.0704 - val_mse: 0.0069 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0995 - mse: 0.1089 - val_loss: 0.0665 - val_mse: 0.0064 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0937 - mse: 0.0368 - val_loss: 0.0671 - val_mse: 0.0065 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0909 - mse: 0.1176 - val_loss: 0.0666 - val_mse: 0.0065 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0873 - mse: 0.0137 - val_loss: 0.0789 - val_mse: 0.0088 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0887 - mse: 0.0155 - val_loss: 0.0755 - val_mse: 0.0077 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0889 - mse: 0.0137 - val_loss: 0.0816 - val_mse: 0.0089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0850 - mse: 0.0199 - val_loss: 0.0650 - val_mse: 0.0061 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0828 - mse: 0.0126 - val_loss: 0.0655 - val_mse: 0.0062 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0833 - mse: 0.0251 - val_loss: 0.0646 - val_mse: 0.0060 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0793 - mse: 0.0098 - val_loss: 0.0701 - val_mse: 0.0070 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0804 - mse: 0.0138 - val_loss: 0.0649 - val_mse: 0.0061 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0782 - mse: 0.0114 - val_loss: 0.0662 - val_mse: 0.0063 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0765 - mse: 0.0093 - val_loss: 0.0653 - val_mse: 0.0062 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0777 - mse: 0.0133 - val_loss: 0.0642 - val_mse: 0.0060 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0776 - mse: 0.0108 - val_loss: 0.0972 - val_mse: 0.0129 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0759 - mse: 0.0091 - val_loss: 0.0638 - val_mse: 0.0060 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0771 - mse: 0.0116 - val_loss: 0.0635 - val_mse: 0.0060 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 28 ended. Search finished for the next optimal point.\n",
            "Time taken: 111.4405\n",
            "Function value obtained: 0.0060\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 29 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [80, 166]\n",
            "Learning Rate: 0.00011135906332366963\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3350126083880538\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 261.5179 - mse: 819102.5000 - val_loss: 2.6345 - val_mse: 36.5425 - 5s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 150.3720 - mse: 298694.9062 - val_loss: 1.9987 - val_mse: 22.0526 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 95.5932 - mse: 109903.1016 - val_loss: 1.2932 - val_mse: 10.8610 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 68.6213 - mse: 56796.0391 - val_loss: 3.3927 - val_mse: 69.0790 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 49.9102 - mse: 29459.3574 - val_loss: 1.6915 - val_mse: 18.9900 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 37.3524 - mse: 16702.2285 - val_loss: 0.2358 - val_mse: 0.8457 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 28.0295 - mse: 8961.4980 - val_loss: 0.0703 - val_mse: 0.1464 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 20.0285 - mse: 4162.5063 - val_loss: 1.0071 - val_mse: 7.3158 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 15.0807 - mse: 3509.1748 - val_loss: 0.0656 - val_mse: 0.1355 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 11.9399 - mse: 1896.8269 - val_loss: 0.0683 - val_mse: 0.1461 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 8.5412 - mse: 1113.0823 - val_loss: 0.0556 - val_mse: 0.1141 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 6.2372 - mse: 530.7177 - val_loss: 0.0405 - val_mse: 0.0827 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.8428 - mse: 604.1621 - val_loss: 0.0342 - val_mse: 0.0696 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.5377 - mse: 267.1524 - val_loss: 0.0279 - val_mse: 0.0565 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.4897 - mse: 106.1423 - val_loss: 0.0229 - val_mse: 0.0465 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.8003 - mse: 64.6008 - val_loss: 0.0120 - val_mse: 0.0242 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2977 - mse: 34.9407 - val_loss: 0.0095 - val_mse: 0.0192 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1127 - mse: 41.4939 - val_loss: 0.0059 - val_mse: 0.0119 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7043 - mse: 18.3741 - val_loss: 0.0053 - val_mse: 0.0107 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5105 - mse: 12.9646 - val_loss: 0.0077 - val_mse: 0.0155 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3515 - mse: 5.4034 - val_loss: 0.0041 - val_mse: 0.0081 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2782 - mse: 4.5789 - val_loss: 0.0033 - val_mse: 0.0067 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1805 - mse: 2.3718 - val_loss: 0.0034 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1178 - mse: 1.2464 - val_loss: 0.0036 - val_mse: 0.0071 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 1.3100 - val_loss: 0.0034 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0887 - mse: 1.0002 - val_loss: 0.0097 - val_mse: 0.0197 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0714 - mse: 1.2219 - val_loss: 0.0097 - val_mse: 0.0197 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0486 - mse: 0.3980 - val_loss: 0.0034 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0352 - mse: 0.2557 - val_loss: 0.0069 - val_mse: 0.0139 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0276 - mse: 0.1670 - val_loss: 0.0073 - val_mse: 0.0148 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0321 - mse: 0.9416 - val_loss: 0.0082 - val_mse: 0.0164 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0221 - mse: 0.1461 - val_loss: 0.0089 - val_mse: 0.0179 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0184 - mse: 0.0753 - val_loss: 0.0070 - val_mse: 0.0141 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0175 - mse: 0.1220 - val_loss: 0.0094 - val_mse: 0.0190 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0155 - mse: 0.0670 - val_loss: 0.0097 - val_mse: 0.0196 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0102 - mse: 0.0286 - val_loss: 0.0096 - val_mse: 0.0194 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0108 - mse: 0.0361 - val_loss: 0.0099 - val_mse: 0.0199 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0118 - mse: 0.0549 - val_loss: 0.0087 - val_mse: 0.0176 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0084 - mse: 0.0187 - val_loss: 0.0093 - val_mse: 0.0188 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0095 - mse: 0.0352 - val_loss: 0.0050 - val_mse: 0.0101 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0089 - mse: 0.0217 - val_loss: 0.0074 - val_mse: 0.0148 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0070 - mse: 0.0153 - val_loss: 0.0072 - val_mse: 0.0144 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0072 - mse: 0.0164 - val_loss: 0.0041 - val_mse: 0.0083 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0060 - mse: 0.0123 - val_loss: 0.0085 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0064 - mse: 0.0136 - val_loss: 0.0040 - val_mse: 0.0081 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0066 - mse: 0.0140 - val_loss: 0.0041 - val_mse: 0.0083 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0065 - mse: 0.0139 - val_loss: 0.0046 - val_mse: 0.0092 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0065 - mse: 0.0135 - val_loss: 0.0033 - val_mse: 0.0066 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0063 - mse: 0.0134 - val_loss: 0.0071 - val_mse: 0.0143 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0059 - mse: 0.0123 - val_loss: 0.0039 - val_mse: 0.0078 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 29 ended. Search finished for the next optimal point.\n",
            "Time taken: 112.3667\n",
            "Function value obtained: 0.0078\n",
            "Current minimum: 0.0037\n",
            "Iteration No: 30 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 64]\n",
            "Learning Rate: 0.002698700662847881\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 29.4739 - mse: 36026.2383 - val_loss: 4.8410 - val_mse: 128.3596 - 4s/epoch - 8ms/step\n",
            "525/525 - 2s - loss: 0.6845 - mse: 12.9599 - val_loss: 0.0950 - val_mse: 0.0250 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 6.3046 - mse: 1423.7108 - val_loss: 1.0662 - val_mse: 5.5240 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0965 - mse: 0.1475 - val_loss: 0.0667 - val_mse: 0.0067 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3659 - mse: 3.3220 - val_loss: 0.4758 - val_mse: 1.0740 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1185 - mse: 0.1248 - val_loss: 0.1118 - val_mse: 0.0215 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4663 - mse: 6.4613 - val_loss: 0.5272 - val_mse: 1.2466 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1884 - mse: 0.7011 - val_loss: 0.0804 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5573 - mse: 9.1389 - val_loss: 0.0638 - val_mse: 0.0066 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0595 - mse: 0.0059 - val_loss: 0.0502 - val_mse: 0.0043 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0525 - mse: 0.0045 - val_loss: 0.0558 - val_mse: 0.0053 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0605 - mse: 0.0065 - val_loss: 0.0681 - val_mse: 0.0065 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0573 - mse: 0.0057 - val_loss: 0.0500 - val_mse: 0.0041 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0551 - mse: 0.0051 - val_loss: 0.0565 - val_mse: 0.0056 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0957 - mse: 0.2002 - val_loss: 0.0483 - val_mse: 0.0037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0495 - mse: 0.0040 - val_loss: 0.0476 - val_mse: 0.0037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0517 - mse: 0.0044 - val_loss: 0.0468 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0519 - mse: 0.0044 - val_loss: 0.0465 - val_mse: 0.0038 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0488 - mse: 0.0041 - val_loss: 0.0457 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0473 - mse: 0.0038 - val_loss: 0.0447 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0464 - mse: 0.0036 - val_loss: 0.0483 - val_mse: 0.0037 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0467 - mse: 0.0037 - val_loss: 0.0461 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0459 - mse: 0.0036 - val_loss: 0.0467 - val_mse: 0.0037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0479 - mse: 0.0037 - val_loss: 0.0452 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0490 - mse: 0.0039 - val_loss: 0.0457 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0471 - mse: 0.0036 - val_loss: 0.0476 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0472 - mse: 0.0036 - val_loss: 0.0460 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0470 - mse: 0.0036 - val_loss: 0.0456 - val_mse: 0.0033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0472 - mse: 0.0036 - val_loss: 0.0487 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0467 - mse: 0.0036 - val_loss: 0.0454 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0469 - mse: 0.0036 - val_loss: 0.0430 - val_mse: 0.0033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0469 - mse: 0.0037 - val_loss: 0.0474 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0454 - mse: 0.0034 - val_loss: 0.0499 - val_mse: 0.0039 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0454 - mse: 0.0034 - val_loss: 0.0469 - val_mse: 0.0034 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0452 - mse: 0.0034 - val_loss: 0.0448 - val_mse: 0.0033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0460 - mse: 0.0035 - val_loss: 0.0463 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0458 - mse: 0.0035 - val_loss: 0.0436 - val_mse: 0.0032 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0446 - mse: 0.0034 - val_loss: 0.0421 - val_mse: 0.0030 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0447 - mse: 0.0034 - val_loss: 0.0440 - val_mse: 0.0033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0468 - mse: 0.0042 - val_loss: 0.0539 - val_mse: 0.0047 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0476 - mse: 0.0038 - val_loss: 0.0450 - val_mse: 0.0034 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0446 - mse: 0.0033 - val_loss: 0.0442 - val_mse: 0.0032 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0445 - mse: 0.0033 - val_loss: 0.0465 - val_mse: 0.0034 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0444 - mse: 0.0033 - val_loss: 0.0426 - val_mse: 0.0030 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0447 - mse: 0.0033 - val_loss: 0.0431 - val_mse: 0.0030 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0440 - mse: 0.0032 - val_loss: 0.0495 - val_mse: 0.0039 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0442 - mse: 0.0033 - val_loss: 0.0416 - val_mse: 0.0029 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0446 - mse: 0.0033 - val_loss: 0.0414 - val_mse: 0.0030 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0445 - mse: 0.0033 - val_loss: 0.0433 - val_mse: 0.0033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0436 - mse: 0.0032 - val_loss: 0.0426 - val_mse: 0.0030 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 30 ended. Search finished for the next optimal point.\n",
            "Time taken: 106.4138\n",
            "Function value obtained: 0.0030\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 31 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [165]\n",
            "Learning Rate: 0.00016573837615111285\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 3s - loss: 0.9411 - mse: 196.4614 - val_loss: 0.0349 - val_mse: 0.0698 - 3s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 0.0133 - mse: 0.0266 - val_loss: 0.0048 - val_mse: 0.0097 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0041 - val_mse: 0.0082 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1405 - mse: 3.5417 - val_loss: 1.8376 - val_mse: 23.5667 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0270 - mse: 0.1151 - val_loss: 0.0037 - val_mse: 0.0075 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0037 - mse: 0.0073 - val_loss: 0.0037 - val_mse: 0.0074 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0033 - mse: 0.0065 - val_loss: 0.0027 - val_mse: 0.0054 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0033 - val_mse: 0.0065 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0026 - val_mse: 0.0052 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2793 - mse: 8.4041 - val_loss: 0.0056 - val_mse: 0.0113 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0023 - val_mse: 0.0047 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0022 - val_mse: 0.0043 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0022 - val_mse: 0.0044 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1321 - mse: 1.5418 - val_loss: 0.0124 - val_mse: 0.0248 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.3004 - mse: 4.4673 - val_loss: 0.0034 - val_mse: 0.0068 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0024 - val_mse: 0.0047 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.5873 - mse: 12.2539 - val_loss: 0.0136 - val_mse: 0.0271 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0044 - mse: 0.0090 - val_loss: 0.0030 - val_mse: 0.0059 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0028 - val_mse: 0.0056 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0025 - val_mse: 0.0050 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0022 - val_mse: 0.0044 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0020 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0021 - val_mse: 0.0043 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.6639 - mse: 44.2028 - val_loss: 0.0027 - val_mse: 0.0054 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0022 - val_mse: 0.0045 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0020 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0020 - val_mse: 0.0040 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0025 - val_mse: 0.0050 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0020 - val_mse: 0.0040 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0020 - val_mse: 0.0040 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0025 - val_mse: 0.0051 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0789 - mse: 0.7840 - val_loss: 0.0024 - val_mse: 0.0048 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0019 - val_mse: 0.0039 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0019 - val_mse: 0.0039 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2158 - mse: 3.3712 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0019 - val_mse: 0.0039 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0019 - val_mse: 0.0037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0018 - val_mse: 0.0037 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0019 - val_mse: 0.0039 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0102 - mse: 0.0265 - val_loss: 0.0097 - val_mse: 0.0193 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.4679 - mse: 8.9563 - val_loss: 0.0033 - val_mse: 0.0067 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0033 - mse: 0.0065 - val_loss: 0.0031 - val_mse: 0.0062 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 31 ended. Search finished for the next optimal point.\n",
            "Time taken: 95.8152\n",
            "Function value obtained: 0.0062\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 32 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [138]\n",
            "Learning Rate: 0.0216484501360473\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 117\n",
            "----------------------------------------\n",
            "72/72 - 2s - loss: 290.2995 - mse: 3403623.7500 - val_loss: 0.0655 - val_mse: 0.1318 - 2s/epoch - 31ms/step\n",
            "72/72 - 0s - loss: 0.6226 - mse: 9.0819 - val_loss: 0.0248 - val_mse: 0.0496 - 329ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.4654 - mse: 9.3594 - val_loss: 0.0063 - val_mse: 0.0127 - 336ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0665 - mse: 0.3155 - val_loss: 0.0034 - val_mse: 0.0069 - 337ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.2260 - mse: 2.0203 - val_loss: 0.0074 - val_mse: 0.0149 - 334ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0100 - mse: 0.0211 - val_loss: 0.0051 - val_mse: 0.0102 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0063 - mse: 0.0127 - val_loss: 0.0041 - val_mse: 0.0083 - 327ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0056 - mse: 0.0111 - val_loss: 0.0037 - val_mse: 0.0073 - 334ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0037 - val_mse: 0.0073 - 331ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0035 - val_mse: 0.0070 - 331ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0031 - val_mse: 0.0062 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0034 - val_mse: 0.0067 - 333ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0044 - mse: 0.0087 - val_loss: 0.0032 - val_mse: 0.0064 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0030 - val_mse: 0.0059 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0031 - val_mse: 0.0063 - 337ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0046 - mse: 0.0091 - val_loss: 0.0032 - val_mse: 0.0065 - 325ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0032 - val_mse: 0.0065 - 325ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0041 - mse: 0.0081 - val_loss: 0.0028 - val_mse: 0.0055 - 325ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0031 - val_mse: 0.0063 - 332ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0053 - mse: 0.0109 - val_loss: 0.0030 - val_mse: 0.0060 - 344ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0080 - mse: 0.0169 - val_loss: 0.0035 - val_mse: 0.0070 - 325ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0030 - val_mse: 0.0059 - 332ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0027 - val_mse: 0.0054 - 345ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0033 - val_mse: 0.0066 - 336ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0028 - val_mse: 0.0055 - 350ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0030 - val_mse: 0.0060 - 343ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0031 - val_mse: 0.0063 - 343ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0026 - val_mse: 0.0052 - 347ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0026 - val_mse: 0.0053 - 328ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0028 - val_mse: 0.0055 - 342ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0026 - val_mse: 0.0052 - 334ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0027 - val_mse: 0.0054 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0028 - val_mse: 0.0056 - 327ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0030 - val_mse: 0.0060 - 335ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0029 - val_mse: 0.0057 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0028 - val_mse: 0.0055 - 330ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0025 - val_mse: 0.0051 - 333ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0027 - val_mse: 0.0054 - 329ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0027 - val_mse: 0.0053 - 331ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0033 - val_mse: 0.0065 - 332ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0025 - val_mse: 0.0050 - 327ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0046 - mse: 0.0093 - val_loss: 0.0032 - val_mse: 0.0064 - 342ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0026 - val_mse: 0.0052 - 329ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0026 - val_mse: 0.0051 - 332ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0033 - val_mse: 0.0066 - 337ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0041 - mse: 0.0081 - val_loss: 0.0027 - val_mse: 0.0055 - 329ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0027 - val_mse: 0.0055 - 331ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0031 - val_mse: 0.0063 - 333ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0029 - val_mse: 0.0057 - 329ms/epoch - 5ms/step\n",
            "72/72 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0030 - val_mse: 0.0060 - 326ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.00701264]\n",
            "\n",
            "Iteration No: 32 ended. Search finished for the next optimal point.\n",
            "Time taken: 24.5914\n",
            "Function value obtained: 0.0060\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 33 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 256]\n",
            "Learning Rate: 0.002328149160533914\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 113\n",
            "----------------------------------------\n",
            "75/75 - 3s - loss: 124.1309 - mse: 239546.2188 - val_loss: 185.7204 - val_mse: 177728.1875 - 3s/epoch - 38ms/step\n",
            "75/75 - 0s - loss: 71.4935 - mse: 76573.1406 - val_loss: 6.8970 - val_mse: 148.8299 - 364ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 2.3842 - mse: 56.0762 - val_loss: 0.8913 - val_mse: 3.0138 - 363ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 3.3667 - mse: 139.0308 - val_loss: 5.6982 - val_mse: 150.0938 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.8366 - mse: 8.3278 - val_loss: 0.0718 - val_mse: 0.0081 - 367ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0625 - mse: 0.0069 - val_loss: 0.0570 - val_mse: 0.0062 - 362ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0572 - mse: 0.0055 - val_loss: 0.0878 - val_mse: 0.0195 - 367ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0561 - mse: 0.0055 - val_loss: 0.0579 - val_mse: 0.0056 - 375ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0551 - mse: 0.0051 - val_loss: 0.0529 - val_mse: 0.0044 - 363ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0540 - mse: 0.0049 - val_loss: 0.0556 - val_mse: 0.0056 - 365ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0567 - mse: 0.0058 - val_loss: 0.0679 - val_mse: 0.0076 - 364ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 1.5415 - mse: 171.7736 - val_loss: 83.3082 - val_mse: 35221.6602 - 368ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 54.4488 - mse: 32601.8203 - val_loss: 6.6415 - val_mse: 238.9178 - 379ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 6.8401 - mse: 1613.4304 - val_loss: 0.1592 - val_mse: 0.0719 - 363ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.1324 - mse: 0.0768 - val_loss: 0.0668 - val_mse: 0.0064 - 376ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0690 - mse: 0.0072 - val_loss: 0.0611 - val_mse: 0.0057 - 368ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0653 - mse: 0.0065 - val_loss: 0.0641 - val_mse: 0.0066 - 374ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0624 - mse: 0.0060 - val_loss: 0.0874 - val_mse: 0.0115 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0775 - mse: 0.0104 - val_loss: 0.0882 - val_mse: 0.0146 - 360ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.1708 - mse: 0.1411 - val_loss: 0.0764 - val_mse: 0.0087 - 373ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0950 - mse: 0.0260 - val_loss: 0.0658 - val_mse: 0.0067 - 367ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0694 - mse: 0.0078 - val_loss: 0.0716 - val_mse: 0.0074 - 370ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0662 - mse: 0.0070 - val_loss: 0.0625 - val_mse: 0.0059 - 377ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0609 - mse: 0.0059 - val_loss: 0.0635 - val_mse: 0.0063 - 368ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0606 - mse: 0.0058 - val_loss: 0.0631 - val_mse: 0.0063 - 357ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0622 - mse: 0.0063 - val_loss: 0.0652 - val_mse: 0.0064 - 368ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0650 - mse: 0.0070 - val_loss: 0.0655 - val_mse: 0.0066 - 357ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0862 - mse: 0.0156 - val_loss: 0.2045 - val_mse: 0.1490 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 1.3561 - mse: 65.8786 - val_loss: 8.5028 - val_mse: 366.8882 - 364ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 21.7723 - mse: 5320.1006 - val_loss: 7.4714 - val_mse: 289.1286 - 360ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 4.7947 - mse: 460.9613 - val_loss: 4.6692 - val_mse: 110.2934 - 363ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.4919 - mse: 3.7264 - val_loss: 0.1059 - val_mse: 0.0316 - 354ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0991 - mse: 0.0392 - val_loss: 0.0637 - val_mse: 0.0061 - 359ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0625 - mse: 0.0060 - val_loss: 0.0599 - val_mse: 0.0056 - 362ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0592 - mse: 0.0055 - val_loss: 0.0580 - val_mse: 0.0051 - 356ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0541 - mse: 0.0048 - val_loss: 0.0517 - val_mse: 0.0047 - 365ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0509 - mse: 0.0044 - val_loss: 0.0508 - val_mse: 0.0044 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0516 - mse: 0.0045 - val_loss: 0.0493 - val_mse: 0.0042 - 357ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0505 - mse: 0.0043 - val_loss: 0.0483 - val_mse: 0.0041 - 358ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0486 - mse: 0.0041 - val_loss: 0.0486 - val_mse: 0.0042 - 363ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0485 - mse: 0.0040 - val_loss: 0.0456 - val_mse: 0.0038 - 360ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0469 - mse: 0.0039 - val_loss: 0.0502 - val_mse: 0.0043 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0478 - mse: 0.0039 - val_loss: 0.0447 - val_mse: 0.0036 - 362ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0479 - mse: 0.0039 - val_loss: 0.0508 - val_mse: 0.0044 - 364ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0476 - mse: 0.0038 - val_loss: 0.0480 - val_mse: 0.0038 - 361ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0538 - mse: 0.0051 - val_loss: 0.0518 - val_mse: 0.0042 - 365ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0491 - mse: 0.0040 - val_loss: 0.0502 - val_mse: 0.0040 - 366ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0513 - mse: 0.0046 - val_loss: 0.0715 - val_mse: 0.0081 - 369ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0525 - mse: 0.0046 - val_loss: 0.0538 - val_mse: 0.0047 - 372ms/epoch - 5ms/step\n",
            "75/75 - 0s - loss: 0.0523 - mse: 0.0047 - val_loss: 0.0509 - val_mse: 0.0042 - 371ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 33 ended. Search finished for the next optimal point.\n",
            "Time taken: 26.4209\n",
            "Function value obtained: 0.0042\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 34 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [252, 209]\n",
            "Learning Rate: 0.00011125053731826374\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.00462069381817109\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 9.4256 - mse: 7913.8877 - val_loss: 0.3584 - val_mse: 0.5194 - 5s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 2.7679 - mse: 135.6686 - val_loss: 0.5965 - val_mse: 2.1580 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.5333 - mse: 177.0347 - val_loss: 0.5550 - val_mse: 1.5302 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.9728 - mse: 67.9970 - val_loss: 0.1344 - val_mse: 0.0727 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.9492 - mse: 211.8455 - val_loss: 1.2012 - val_mse: 7.4267 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.6120 - mse: 41.0129 - val_loss: 1.9230 - val_mse: 17.3586 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.1109 - mse: 81.8534 - val_loss: 0.1461 - val_mse: 0.0590 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.0704 - mse: 61.9887 - val_loss: 0.0752 - val_mse: 0.0081 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.9126 - mse: 62.0481 - val_loss: 0.0897 - val_mse: 0.0131 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3645 - mse: 31.8184 - val_loss: 0.1371 - val_mse: 0.0338 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2605 - mse: 31.0030 - val_loss: 0.1543 - val_mse: 0.0534 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3873 - mse: 31.5249 - val_loss: 6.4749 - val_mse: 210.8602 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1638 - mse: 32.4262 - val_loss: 0.1844 - val_mse: 0.0665 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.5437 - mse: 38.0404 - val_loss: 0.1446 - val_mse: 0.0338 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0024 - mse: 15.1496 - val_loss: 0.1153 - val_mse: 0.0245 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.6217 - mse: 44.4543 - val_loss: 0.0734 - val_mse: 0.0073 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5996 - mse: 5.6989 - val_loss: 0.0773 - val_mse: 0.0079 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7475 - mse: 10.0340 - val_loss: 0.1930 - val_mse: 0.1293 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1450 - mse: 23.2945 - val_loss: 3.5874 - val_mse: 66.5761 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0380 - mse: 17.9331 - val_loss: 2.3282 - val_mse: 27.7633 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7076 - mse: 9.2140 - val_loss: 0.5440 - val_mse: 1.3355 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8387 - mse: 8.6485 - val_loss: 0.1117 - val_mse: 0.0178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.9015 - mse: 18.5269 - val_loss: 0.2920 - val_mse: 0.3532 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4470 - mse: 3.4036 - val_loss: 0.2577 - val_mse: 0.2082 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3881 - mse: 2.4350 - val_loss: 0.1370 - val_mse: 0.0503 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4609 - mse: 3.6496 - val_loss: 0.2677 - val_mse: 0.3513 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6779 - mse: 12.4630 - val_loss: 0.8360 - val_mse: 3.3717 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4853 - mse: 3.7279 - val_loss: 0.0997 - val_mse: 0.0294 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2748 - mse: 0.7847 - val_loss: 0.1355 - val_mse: 0.0309 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8913 - mse: 18.2458 - val_loss: 0.0718 - val_mse: 0.0083 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2174 - mse: 0.5399 - val_loss: 0.0774 - val_mse: 0.0088 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2439 - mse: 0.5369 - val_loss: 0.1098 - val_mse: 0.0200 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2566 - mse: 0.6741 - val_loss: 0.0918 - val_mse: 0.0137 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4773 - mse: 5.0303 - val_loss: 0.0653 - val_mse: 0.0075 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2548 - mse: 0.6740 - val_loss: 0.4062 - val_mse: 0.7333 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2040 - mse: 0.3426 - val_loss: 0.0953 - val_mse: 0.0145 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2685 - mse: 0.8358 - val_loss: 0.2488 - val_mse: 0.2302 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1953 - mse: 0.4204 - val_loss: 0.0623 - val_mse: 0.0058 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2458 - mse: 0.8516 - val_loss: 0.0933 - val_mse: 0.0149 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1512 - mse: 0.1757 - val_loss: 0.1179 - val_mse: 0.0253 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2162 - mse: 0.4228 - val_loss: 0.3645 - val_mse: 0.4750 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1963 - mse: 0.3700 - val_loss: 0.1327 - val_mse: 0.0578 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1400 - mse: 0.1475 - val_loss: 0.0792 - val_mse: 0.0089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1267 - mse: 0.0936 - val_loss: 0.0980 - val_mse: 0.0180 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2170 - mse: 1.0624 - val_loss: 0.1749 - val_mse: 0.1110 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1178 - mse: 0.0807 - val_loss: 0.0624 - val_mse: 0.0072 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0904 - mse: 0.0643 - val_loss: 0.0801 - val_mse: 0.0096 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0804 - mse: 0.0195 - val_loss: 0.0586 - val_mse: 0.0054 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0827 - mse: 0.0174 - val_loss: 0.0591 - val_mse: 0.0059 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0777 - mse: 0.0162 - val_loss: 0.0476 - val_mse: 0.0040 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 34 ended. Search finished for the next optimal point.\n",
            "Time taken: 118.2015\n",
            "Function value obtained: 0.0040\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 35 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 0.021510666921248985\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 840.5762 - mse: 9368194.0000 - val_loss: 122.7474 - val_mse: 78214.1484 - 3s/epoch - 81ms/step\n",
            "33/33 - 0s - loss: 74.1089 - mse: 52033.6562 - val_loss: 3.1877 - val_mse: 72.6345 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 11.3601 - mse: 1222.6564 - val_loss: 0.0869 - val_mse: 0.1805 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0495 - mse: 0.1018 - val_loss: 0.0212 - val_mse: 0.0430 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0130 - mse: 0.0263 - val_loss: 0.0090 - val_mse: 0.0181 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 207ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 200ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 207ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 201ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 198ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 201ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 199ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 197ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 204ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 199ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 200ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 195ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 197ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 196ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 200ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 201ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 199ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 196ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 196ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0083 - val_mse: 0.0167 - 196ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 35 ended. Search finished for the next optimal point.\n",
            "Time taken: 24.0951\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 36 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [101]\n",
            "Learning Rate: 0.02115276218894519\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 94.3772 - mse: 1147530.6250 - val_loss: 0.0053 - val_mse: 0.0106 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0054 - val_mse: 0.0107 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0049 - val_mse: 0.0098 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0077 - mse: 0.0155 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0176 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0090 - val_mse: 0.0180 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0099 - val_mse: 0.0199 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.01719387]\n",
            "\n",
            "Iteration No: 36 ended. Search finished for the next optimal point.\n",
            "Time taken: 98.0729\n",
            "Function value obtained: 0.0172\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 37 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [210, 256]\n",
            "Learning Rate: 0.00011083708074750757\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.4316373016723008\n",
            "Batch Size: 111\n",
            "----------------------------------------\n",
            "76/76 - 3s - loss: 450.2718 - mse: 2747502.2500 - val_loss: 2.1069 - val_mse: 13.2263 - 3s/epoch - 38ms/step\n",
            "76/76 - 0s - loss: 328.8310 - mse: 1514740.1250 - val_loss: 7.4662 - val_mse: 217.8130 - 405ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 256.4666 - mse: 771774.4375 - val_loss: 16.7774 - val_mse: 1437.3654 - 402ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 207.5820 - mse: 539369.0000 - val_loss: 1.9738 - val_mse: 19.5603 - 404ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 153.8162 - mse: 264462.5625 - val_loss: 1.7102 - val_mse: 14.4785 - 397ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 145.6527 - mse: 276793.2188 - val_loss: 1.3775 - val_mse: 3.6562 - 405ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 122.7715 - mse: 160832.4531 - val_loss: 3.2132 - val_mse: 59.9333 - 402ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 109.2508 - mse: 160468.1094 - val_loss: 1.0750 - val_mse: 2.0948 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 93.9869 - mse: 108730.0469 - val_loss: 7.2061 - val_mse: 230.6082 - 404ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 76.9829 - mse: 72174.0938 - val_loss: 1.1101 - val_mse: 5.4018 - 401ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 70.6485 - mse: 75542.3750 - val_loss: 5.4547 - val_mse: 126.2584 - 418ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 62.7451 - mse: 48493.9297 - val_loss: 0.5513 - val_mse: 0.3128 - 409ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 54.9821 - mse: 36181.6211 - val_loss: 0.7140 - val_mse: 1.5450 - 412ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 47.8023 - mse: 30032.1973 - val_loss: 0.9151 - val_mse: 1.4205 - 408ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 42.7964 - mse: 20417.2617 - val_loss: 0.7395 - val_mse: 1.7489 - 419ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 38.7660 - mse: 16332.6504 - val_loss: 3.5527 - val_mse: 70.8244 - 408ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 33.1816 - mse: 10888.6084 - val_loss: 2.5342 - val_mse: 35.7833 - 416ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 31.1741 - mse: 11030.3887 - val_loss: 0.7379 - val_mse: 1.7611 - 412ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 29.6270 - mse: 9906.6250 - val_loss: 1.8575 - val_mse: 18.6272 - 419ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 24.7173 - mse: 6890.5181 - val_loss: 0.9824 - val_mse: 4.1735 - 399ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 22.7819 - mse: 6851.7759 - val_loss: 0.6730 - val_mse: 1.3162 - 419ms/epoch - 6ms/step\n",
            "76/76 - 0s - loss: 21.2855 - mse: 5559.0806 - val_loss: 0.8681 - val_mse: 2.9714 - 398ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 19.6167 - mse: 5066.7490 - val_loss: 0.7072 - val_mse: 1.6394 - 393ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 17.5456 - mse: 5559.9189 - val_loss: 0.7495 - val_mse: 1.9950 - 391ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 16.2164 - mse: 3568.8420 - val_loss: 0.6560 - val_mse: 1.3065 - 410ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 15.1533 - mse: 3286.8191 - val_loss: 0.4988 - val_mse: 0.4548 - 388ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 13.3004 - mse: 2512.0718 - val_loss: 0.5232 - val_mse: 0.5936 - 390ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 11.4889 - mse: 1375.5027 - val_loss: 0.6409 - val_mse: 1.2989 - 379ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 11.6028 - mse: 1778.6836 - val_loss: 0.5540 - val_mse: 0.7998 - 383ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 9.9538 - mse: 1392.5637 - val_loss: 0.4680 - val_mse: 0.4176 - 381ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 9.0056 - mse: 973.7949 - val_loss: 0.4763 - val_mse: 0.4677 - 381ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 7.9940 - mse: 840.3388 - val_loss: 0.3408 - val_mse: 0.1483 - 373ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 7.3044 - mse: 713.0237 - val_loss: 0.3390 - val_mse: 0.1522 - 376ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 7.5365 - mse: 826.4398 - val_loss: 0.3201 - val_mse: 0.1345 - 385ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 6.0843 - mse: 456.2814 - val_loss: 0.3012 - val_mse: 0.1191 - 376ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 6.1763 - mse: 492.6864 - val_loss: 0.2887 - val_mse: 0.1080 - 381ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 5.3600 - mse: 383.3616 - val_loss: 0.2668 - val_mse: 0.0939 - 383ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 5.2394 - mse: 545.8107 - val_loss: 0.2616 - val_mse: 0.0904 - 389ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 4.7986 - mse: 349.4760 - val_loss: 0.2200 - val_mse: 0.0678 - 406ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 4.4828 - mse: 304.7768 - val_loss: 0.2402 - val_mse: 0.0779 - 410ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.9538 - mse: 236.3355 - val_loss: 0.2372 - val_mse: 0.0757 - 406ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.7240 - mse: 213.7919 - val_loss: 0.2106 - val_mse: 0.0621 - 411ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 3.3710 - mse: 207.8040 - val_loss: 0.1931 - val_mse: 0.0536 - 410ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.9015 - mse: 117.5915 - val_loss: 0.1667 - val_mse: 0.0409 - 400ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.8206 - mse: 139.7401 - val_loss: 0.1421 - val_mse: 0.0303 - 389ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.5452 - mse: 94.8395 - val_loss: 0.1007 - val_mse: 0.0155 - 406ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.4697 - mse: 95.7262 - val_loss: 0.0854 - val_mse: 0.0109 - 406ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.0704 - mse: 59.8094 - val_loss: 0.0882 - val_mse: 0.0117 - 398ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 2.0194 - mse: 75.8606 - val_loss: 0.1384 - val_mse: 0.0291 - 406ms/epoch - 5ms/step\n",
            "76/76 - 0s - loss: 1.8401 - mse: 62.4488 - val_loss: 0.0858 - val_mse: 0.0107 - 399ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 37 ended. Search finished for the next optimal point.\n",
            "Time taken: 28.9061\n",
            "Function value obtained: 0.0107\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 38 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 0.02158678341227509\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 193.4737 - mse: 5710635.5000 - val_loss: 0.0059 - val_mse: 0.0119 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 0.0218 - mse: 0.0801 - val_loss: 0.0060 - val_mse: 0.0121 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0082 - mse: 0.0188 - val_loss: 0.0082 - val_mse: 0.0166 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0071 - mse: 0.0143 - val_loss: 0.0082 - val_mse: 0.0164 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0075 - mse: 0.0154 - val_loss: 0.0080 - val_mse: 0.0162 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0075 - mse: 0.0153 - val_loss: 0.0069 - val_mse: 0.0138 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0074 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0147 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0063 - val_mse: 0.0126 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0084 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0086 - mse: 0.0174 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0172 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0097 - val_mse: 0.0196 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0176 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0089 - val_mse: 0.0179 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0175 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0090 - val_mse: 0.0182 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0174 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0083 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0177 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0176 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.01622396]\n",
            "\n",
            "Iteration No: 38 ended. Search finished for the next optimal point.\n",
            "Time taken: 98.4308\n",
            "Function value obtained: 0.0176\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 39 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 0.021726963835480513\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 2s - loss: 1031.1638 - mse: 24612626.0000 - val_loss: 76.1500 - val_mse: 30698.6895 - 2s/epoch - 61ms/step\n",
            "33/33 - 0s - loss: 28.4435 - mse: 15133.7764 - val_loss: 0.1846 - val_mse: 0.3789 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 2.3538 - mse: 102.1077 - val_loss: 0.1089 - val_mse: 0.2584 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.7705 - mse: 642.7050 - val_loss: 0.1809 - val_mse: 0.5580 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.1750 - mse: 31.4690 - val_loss: 0.7456 - val_mse: 5.3627 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.5806 - mse: 7.5230 - val_loss: 0.1063 - val_mse: 0.2642 - 201ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.5517 - mse: 38.3202 - val_loss: 0.9570 - val_mse: 8.1343 - 208ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.6063 - mse: 18.6051 - val_loss: 0.4812 - val_mse: 2.4156 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.4304 - mse: 6.9702 - val_loss: 0.0200 - val_mse: 0.0419 - 208ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.2342 - mse: 22.4422 - val_loss: 0.0545 - val_mse: 0.1334 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.2006 - mse: 1.1185 - val_loss: 0.0253 - val_mse: 0.0507 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1760 - mse: 0.7904 - val_loss: 0.1820 - val_mse: 0.5523 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2860 - mse: 3.1881 - val_loss: 0.1725 - val_mse: 0.5848 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.2907 - mse: 1.8649 - val_loss: 0.2261 - val_mse: 0.8605 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1869 - mse: 1.7286 - val_loss: 0.0839 - val_mse: 0.1962 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1644 - mse: 18.2979 - val_loss: 0.0295 - val_mse: 0.0650 - 207ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0799 - mse: 0.2544 - val_loss: 0.0079 - val_mse: 0.0159 - 200ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1014 - mse: 0.3588 - val_loss: 0.1821 - val_mse: 0.5551 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0997 - mse: 1.1229 - val_loss: 0.0136 - val_mse: 0.0271 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0193 - mse: 0.1288 - val_loss: 0.0118 - val_mse: 0.0237 - 204ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0348 - mse: 0.8981 - val_loss: 0.0102 - val_mse: 0.0203 - 204ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0558 - mse: 0.8305 - val_loss: 0.0120 - val_mse: 0.0241 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0279 - mse: 0.0642 - val_loss: 0.0246 - val_mse: 0.0493 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0271 - mse: 0.0612 - val_loss: 0.0144 - val_mse: 0.0288 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0219 - mse: 0.0729 - val_loss: 0.0037 - val_mse: 0.0075 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0258 - mse: 1.0277 - val_loss: 0.0059 - val_mse: 0.0119 - 204ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0255 - mse: 0.0623 - val_loss: 0.0231 - val_mse: 0.0487 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0217 - mse: 0.0500 - val_loss: 0.0239 - val_mse: 0.0505 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0332 - mse: 0.0877 - val_loss: 0.0119 - val_mse: 0.0238 - 204ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0179 - mse: 0.3552 - val_loss: 0.0038 - val_mse: 0.0075 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0058 - mse: 0.0125 - val_loss: 0.0033 - val_mse: 0.0067 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0105 - mse: 0.0222 - val_loss: 0.0338 - val_mse: 0.0748 - 203ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0175 - mse: 0.0374 - val_loss: 0.0082 - val_mse: 0.0164 - 202ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0148 - mse: 0.0609 - val_loss: 0.0044 - val_mse: 0.0087 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0047 - val_mse: 0.0093 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0080 - mse: 0.0250 - val_loss: 0.0072 - val_mse: 0.0144 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0062 - mse: 0.0133 - val_loss: 0.0046 - val_mse: 0.0091 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0054 - val_mse: 0.0108 - 205ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0071 - mse: 0.0143 - val_loss: 0.0037 - val_mse: 0.0074 - 206ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0085 - mse: 0.0873 - val_loss: 0.0035 - val_mse: 0.0070 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0031 - val_mse: 0.0063 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0053 - mse: 0.0110 - val_loss: 0.0034 - val_mse: 0.0069 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0077 - val_mse: 0.0155 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0070 - mse: 0.0142 - val_loss: 0.0035 - val_mse: 0.0071 - 207ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0031 - val_mse: 0.0062 - 201ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0212 - val_loss: 0.0098 - val_mse: 0.0196 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0051 - mse: 0.0104 - val_loss: 0.0041 - val_mse: 0.0081 - 207ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0031 - val_mse: 0.0062 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0137 - mse: 0.0326 - val_loss: 0.0085 - val_mse: 0.0169 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0111 - mse: 0.0240 - val_loss: 0.0044 - val_mse: 0.0088 - 208ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 39 ended. Search finished for the next optimal point.\n",
            "Time taken: 18.0508\n",
            "Function value obtained: 0.0088\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 40 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 0.02188910917252035\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 3s - loss: 108.0633 - mse: 918484.5000 - val_loss: 0.0063 - val_mse: 0.0125 - 3s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 0.0033 - mse: 0.0065 - val_loss: 0.0029 - val_mse: 0.0058 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0024 - val_mse: 0.0048 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0028 - val_mse: 0.0055 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0043 - val_loss: 0.0023 - val_mse: 0.0045 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 2.9789 - mse: 3149.1960 - val_loss: 0.0026 - val_mse: 0.0052 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0021 - val_mse: 0.0043 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0019 - val_mse: 0.0038 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0023 - val_mse: 0.0046 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0019 - val_mse: 0.0038 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0019 - val_mse: 0.0038 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0021 - val_mse: 0.0041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0020 - val_mse: 0.0039 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0085 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0099 - mse: 0.0226 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0176 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0176 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0097 - val_mse: 0.0194 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.01052224]\n",
            "\n",
            "Iteration No: 40 ended. Search finished for the next optimal point.\n",
            "Time taken: 97.0613\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 41 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 256]\n",
            "Learning Rate: 0.0022402260553631872\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 209.0070 - mse: 1069540.2500 - val_loss: 175.8108 - val_mse: 157996.7812 - 3s/epoch - 76ms/step\n",
            "33/33 - 0s - loss: 96.9304 - mse: 74215.5000 - val_loss: 45.1897 - val_mse: 10243.2129 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 21.3233 - mse: 6435.5947 - val_loss: 13.1745 - val_mse: 924.2764 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 15.8763 - mse: 10204.3779 - val_loss: 0.6521 - val_mse: 1.5045 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.1686 - mse: 7.2642 - val_loss: 0.2373 - val_mse: 0.1847 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.7943 - mse: 5.2542 - val_loss: 0.3637 - val_mse: 0.3753 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4116 - mse: 1.6606 - val_loss: 0.1448 - val_mse: 0.0494 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1142 - mse: 0.0390 - val_loss: 0.0671 - val_mse: 0.0070 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0752 - mse: 0.0092 - val_loss: 0.0886 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0696 - mse: 0.0075 - val_loss: 0.0652 - val_mse: 0.0060 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0649 - mse: 0.0065 - val_loss: 0.0607 - val_mse: 0.0057 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0660 - mse: 0.0068 - val_loss: 0.0704 - val_mse: 0.0071 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0646 - mse: 0.0066 - val_loss: 0.0664 - val_mse: 0.0076 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0658 - mse: 0.0070 - val_loss: 0.1215 - val_mse: 0.0934 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.4567 - mse: 73.1215 - val_loss: 3.8111 - val_mse: 67.0907 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 52.2492 - mse: 44406.3984 - val_loss: 662.8912 - val_mse: 2232469.7500 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 150.4617 - mse: 287045.4375 - val_loss: 0.6594 - val_mse: 0.4757 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 13.7646 - mse: 1550.5447 - val_loss: 32.6117 - val_mse: 5554.8604 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 11.6266 - mse: 1322.0918 - val_loss: 1.6994 - val_mse: 13.6590 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.9690 - mse: 36.1558 - val_loss: 5.5000 - val_mse: 151.6209 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.1178 - mse: 41.5865 - val_loss: 2.0225 - val_mse: 20.9301 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.7739 - mse: 65.6529 - val_loss: 0.7428 - val_mse: 2.8086 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.3573 - mse: 122.4177 - val_loss: 6.1543 - val_mse: 192.9914 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.4964 - mse: 57.9198 - val_loss: 0.4710 - val_mse: 1.0905 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3768 - mse: 0.9290 - val_loss: 0.1579 - val_mse: 0.1006 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1882 - mse: 0.1667 - val_loss: 0.0923 - val_mse: 0.0272 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0952 - mse: 0.0269 - val_loss: 0.0674 - val_mse: 0.0077 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0626 - mse: 0.0060 - val_loss: 0.0598 - val_mse: 0.0054 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0570 - mse: 0.0051 - val_loss: 0.0557 - val_mse: 0.0050 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0520 - mse: 0.0045 - val_loss: 0.0498 - val_mse: 0.0041 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0496 - mse: 0.0042 - val_loss: 0.0511 - val_mse: 0.0045 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0498 - mse: 0.0042 - val_loss: 0.0475 - val_mse: 0.0039 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0497 - mse: 0.0041 - val_loss: 0.0505 - val_mse: 0.0042 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0478 - mse: 0.0039 - val_loss: 0.0463 - val_mse: 0.0037 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0475 - mse: 0.0038 - val_loss: 0.0501 - val_mse: 0.0041 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0479 - mse: 0.0039 - val_loss: 0.0553 - val_mse: 0.0049 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0482 - mse: 0.0039 - val_loss: 0.0484 - val_mse: 0.0040 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0486 - mse: 0.0040 - val_loss: 0.0469 - val_mse: 0.0038 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0482 - mse: 0.0039 - val_loss: 0.0457 - val_mse: 0.0035 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0471 - mse: 0.0038 - val_loss: 0.0452 - val_mse: 0.0036 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0455 - mse: 0.0036 - val_loss: 0.0459 - val_mse: 0.0036 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0463 - mse: 0.0036 - val_loss: 0.0478 - val_mse: 0.0039 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0458 - mse: 0.0036 - val_loss: 0.0499 - val_mse: 0.0041 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0468 - mse: 0.0038 - val_loss: 0.0475 - val_mse: 0.0038 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0455 - mse: 0.0035 - val_loss: 0.0435 - val_mse: 0.0034 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0440 - mse: 0.0034 - val_loss: 0.0433 - val_mse: 0.0034 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0447 - mse: 0.0035 - val_loss: 0.0439 - val_mse: 0.0035 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0444 - mse: 0.0034 - val_loss: 0.0449 - val_mse: 0.0035 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0442 - mse: 0.0034 - val_loss: 0.0443 - val_mse: 0.0035 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0476 - mse: 0.0038 - val_loss: 0.0483 - val_mse: 0.0040 - 216ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 41 ended. Search finished for the next optimal point.\n",
            "Time taken: 18.9878\n",
            "Function value obtained: 0.0040\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 42 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 64]\n",
            "Learning Rate: 0.0022323992738857244\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 174.8021 - mse: 703104.8125 - val_loss: 11.4572 - val_mse: 739.8101 - 3s/epoch - 77ms/step\n",
            "33/33 - 0s - loss: 16.1949 - mse: 1976.7269 - val_loss: 38.5918 - val_mse: 7622.5024 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 23.1681 - mse: 3488.3147 - val_loss: 17.1031 - val_mse: 1526.9017 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 95.0115 - mse: 77729.9453 - val_loss: 21.3316 - val_mse: 2523.4001 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 5.1616 - mse: 201.9415 - val_loss: 2.0531 - val_mse: 18.7818 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.9820 - mse: 5.3069 - val_loss: 0.4642 - val_mse: 0.6147 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4866 - mse: 1.2577 - val_loss: 0.2929 - val_mse: 0.2177 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2022 - mse: 0.1465 - val_loss: 0.1293 - val_mse: 0.0514 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1025 - mse: 0.0232 - val_loss: 0.0793 - val_mse: 0.0126 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0771 - mse: 0.0103 - val_loss: 0.0805 - val_mse: 0.0150 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0799 - mse: 0.0131 - val_loss: 0.0705 - val_mse: 0.0082 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0728 - mse: 0.0094 - val_loss: 0.0760 - val_mse: 0.0134 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0714 - mse: 0.0090 - val_loss: 0.0788 - val_mse: 0.0142 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0749 - mse: 0.0108 - val_loss: 0.0682 - val_mse: 0.0084 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0663 - mse: 0.0075 - val_loss: 0.0622 - val_mse: 0.0068 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0685 - mse: 0.0085 - val_loss: 0.0616 - val_mse: 0.0063 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0641 - mse: 0.0073 - val_loss: 0.0622 - val_mse: 0.0065 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0619 - mse: 0.0066 - val_loss: 0.0605 - val_mse: 0.0055 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0677 - mse: 0.0083 - val_loss: 0.1196 - val_mse: 0.0343 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0807 - mse: 0.0159 - val_loss: 0.0595 - val_mse: 0.0053 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1524 - mse: 0.1237 - val_loss: 0.1390 - val_mse: 0.0361 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1206 - mse: 0.0479 - val_loss: 0.1318 - val_mse: 0.0527 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1002 - mse: 0.0203 - val_loss: 5.4600 - val_mse: 162.0005 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 168.4040 - mse: 486914.1562 - val_loss: 24.8292 - val_mse: 3463.2192 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 15.1132 - mse: 2559.3979 - val_loss: 2.4060 - val_mse: 23.5231 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 2.5513 - mse: 59.6998 - val_loss: 1.7061 - val_mse: 13.9774 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 3.3136 - mse: 98.6053 - val_loss: 0.2250 - val_mse: 0.2343 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 4.2966 - mse: 177.6327 - val_loss: 0.5821 - val_mse: 0.8216 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 9.0253 - mse: 726.7697 - val_loss: 31.8687 - val_mse: 5346.8311 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 13.1638 - mse: 1836.4240 - val_loss: 46.6774 - val_mse: 11070.1914 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 12.2536 - mse: 1509.3939 - val_loss: 1.5227 - val_mse: 15.0702 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.5920 - mse: 23.1743 - val_loss: 0.9922 - val_mse: 3.8418 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.8574 - mse: 4.6206 - val_loss: 0.6401 - val_mse: 2.2574 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6929 - mse: 3.8559 - val_loss: 0.1812 - val_mse: 0.1668 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.3083 - mse: 1.0438 - val_loss: 0.1502 - val_mse: 0.1118 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.6857 - mse: 3.6252 - val_loss: 0.1238 - val_mse: 0.0617 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.1139 - mse: 16.2447 - val_loss: 5.6318 - val_mse: 164.5206 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.7255 - mse: 7.9223 - val_loss: 0.4430 - val_mse: 0.7927 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2657 - mse: 0.5066 - val_loss: 0.1009 - val_mse: 0.0152 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1165 - mse: 0.0399 - val_loss: 0.0824 - val_mse: 0.0095 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0811 - mse: 0.0101 - val_loss: 0.0754 - val_mse: 0.0089 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0749 - mse: 0.0086 - val_loss: 0.0710 - val_mse: 0.0077 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0700 - mse: 0.0074 - val_loss: 0.0657 - val_mse: 0.0070 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0651 - mse: 0.0068 - val_loss: 0.0618 - val_mse: 0.0065 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0595 - mse: 0.0058 - val_loss: 0.0572 - val_mse: 0.0055 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0553 - mse: 0.0052 - val_loss: 0.0524 - val_mse: 0.0047 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0534 - mse: 0.0049 - val_loss: 0.0494 - val_mse: 0.0044 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0504 - mse: 0.0044 - val_loss: 0.0485 - val_mse: 0.0042 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0503 - mse: 0.0044 - val_loss: 0.0514 - val_mse: 0.0046 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0530 - mse: 0.0048 - val_loss: 0.0487 - val_mse: 0.0041 - 213ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 42 ended. Search finished for the next optimal point.\n",
            "Time taken: 18.8042\n",
            "Function value obtained: 0.0041\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 43 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [146, 256]\n",
            "Learning Rate: 0.00011058641027916356\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 2.2246 - mse: 304.3341 - val_loss: 0.1147 - val_mse: 0.0196 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 3.6336 - mse: 351.3625 - val_loss: 0.0842 - val_mse: 0.0156 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1257 - mse: 0.0770 - val_loss: 0.1159 - val_mse: 0.0256 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5924 - mse: 8.4997 - val_loss: 6.5265 - val_mse: 210.1245 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.4587 - mse: 237.4105 - val_loss: 0.0723 - val_mse: 0.0088 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4457 - mse: 86.6476 - val_loss: 1.5539 - val_mse: 12.3221 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.5432 - mse: 42.0404 - val_loss: 0.1233 - val_mse: 0.0506 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0452 - mse: 34.7774 - val_loss: 0.0823 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7353 - mse: 24.9659 - val_loss: 0.0746 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.1501 - mse: 644.6246 - val_loss: 0.9717 - val_mse: 4.4922 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.0315 - mse: 107.6042 - val_loss: 0.0743 - val_mse: 0.0111 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0886 - mse: 0.0174 - val_loss: 0.1098 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1078 - mse: 0.0708 - val_loss: 0.0947 - val_mse: 0.0123 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.9477 - mse: 140.9067 - val_loss: 0.1695 - val_mse: 0.0910 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4588 - mse: 3.6283 - val_loss: 0.0627 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1324 - mse: 0.2191 - val_loss: 0.2337 - val_mse: 0.3369 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.0995 - mse: 150.9693 - val_loss: 0.0789 - val_mse: 0.0085 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3948 - mse: 4.4848 - val_loss: 0.1472 - val_mse: 0.1103 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1673 - mse: 0.2260 - val_loss: 0.3304 - val_mse: 0.4191 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.4556 - mse: 423.1571 - val_loss: 0.0543 - val_mse: 0.0047 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2143 - mse: 1.0716 - val_loss: 0.0598 - val_mse: 0.0070 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.0900 - mse: 125.5654 - val_loss: 0.0672 - val_mse: 0.0098 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1488 - mse: 0.1512 - val_loss: 0.4401 - val_mse: 0.8623 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1298 - mse: 21.4259 - val_loss: 0.0843 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2053 - mse: 0.3711 - val_loss: 0.6268 - val_mse: 1.7952 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.8502 - mse: 66.0567 - val_loss: 0.6685 - val_mse: 2.1632 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2474 - mse: 1.7629 - val_loss: 0.2224 - val_mse: 0.1776 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2482 - mse: 33.7116 - val_loss: 0.1440 - val_mse: 0.0516 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7537 - mse: 9.5277 - val_loss: 2.9396 - val_mse: 44.0367 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2053 - mse: 0.9853 - val_loss: 0.0734 - val_mse: 0.0094 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.5195 - mse: 127.9759 - val_loss: 1.7842 - val_mse: 15.3786 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.5574 - mse: 305.2148 - val_loss: 0.0589 - val_mse: 0.0054 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3781 - mse: 3.8104 - val_loss: 0.0746 - val_mse: 0.0103 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0958 - mse: 0.0306 - val_loss: 0.0698 - val_mse: 0.0072 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3399 - mse: 5.0420 - val_loss: 0.8619 - val_mse: 3.7191 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0872 - mse: 16.5306 - val_loss: 7.3352 - val_mse: 273.0090 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4359 - mse: 4.5786 - val_loss: 1.0456 - val_mse: 5.2637 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.5397 - mse: 77.3018 - val_loss: 0.5019 - val_mse: 1.0796 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1603 - mse: 0.1712 - val_loss: 0.0792 - val_mse: 0.0207 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3311 - mse: 1.3354 - val_loss: 0.2273 - val_mse: 0.2210 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3726 - mse: 44.3463 - val_loss: 1.6216 - val_mse: 13.8360 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3682 - mse: 4.2220 - val_loss: 2.5218 - val_mse: 32.7768 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3054 - mse: 1.4368 - val_loss: 0.0672 - val_mse: 0.0102 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2917 - mse: 89.2904 - val_loss: 0.0741 - val_mse: 0.0109 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0931 - mse: 0.0321 - val_loss: 0.0562 - val_mse: 0.0053 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.7954 - mse: 156.2229 - val_loss: 0.0835 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7088 - mse: 24.1078 - val_loss: 0.3187 - val_mse: 0.4299 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3635 - mse: 1.9194 - val_loss: 0.5694 - val_mse: 1.4456 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7706 - mse: 9.9664 - val_loss: 0.1398 - val_mse: 0.0932 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2237 - mse: 0.4538 - val_loss: 0.0973 - val_mse: 0.0165 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 43 ended. Search finished for the next optimal point.\n",
            "Time taken: 108.6919\n",
            "Function value obtained: 0.0165\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 44 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 256]\n",
            "Learning Rate: 0.002832455795566266\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 49.4402 - mse: 106914.3750 - val_loss: 0.0729 - val_mse: 0.0081 - 4s/epoch - 8ms/step\n",
            "525/525 - 2s - loss: 14.6886 - mse: 10544.6211 - val_loss: 0.0798 - val_mse: 0.0133 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0728 - mse: 0.0083 - val_loss: 0.0666 - val_mse: 0.0068 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0702 - mse: 0.0078 - val_loss: 0.1079 - val_mse: 0.0256 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0799 - mse: 0.0225 - val_loss: 0.0780 - val_mse: 0.0097 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0694 - mse: 0.0083 - val_loss: 0.1717 - val_mse: 0.0995 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 5.4597 - mse: 3547.6213 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1050 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0176 - val_loss: 0.1078 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1078 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1077 - mse: 0.0175 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1081 - mse: 0.0177 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 0.0176 - val_loss: 0.1075 - val_mse: 0.0174 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1081 - mse: 0.0177 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0176 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1061 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1081 - mse: 0.0177 - val_loss: 0.1071 - val_mse: 0.0173 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1084 - mse: 0.0178 - val_loss: 0.1057 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1081 - mse: 0.0177 - val_loss: 0.1053 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1079 - mse: 0.0176 - val_loss: 0.1057 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0176 - val_loss: 0.1056 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1086 - mse: 0.0179 - val_loss: 0.1075 - val_mse: 0.0178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1052 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0177 - val_loss: 0.1058 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0177 - val_loss: 0.1072 - val_mse: 0.0177 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0177 - val_loss: 0.1055 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1078 - mse: 0.0177 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1075 - mse: 0.0176 - val_loss: 0.1050 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1085 - mse: 0.0178 - val_loss: 0.1104 - val_mse: 0.0189 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1079 - mse: 0.0177 - val_loss: 0.1076 - val_mse: 0.0178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1078 - mse: 0.0176 - val_loss: 0.1053 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1078 - mse: 0.0176 - val_loss: 0.1107 - val_mse: 0.0183 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1079 - mse: 0.0177 - val_loss: 0.1097 - val_mse: 0.0180 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1057 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0177 - val_loss: 0.1056 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1077 - mse: 0.0176 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1077 - mse: 0.0175 - val_loss: 0.1063 - val_mse: 0.0174 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 0.0175 - val_loss: 0.1057 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1082 - mse: 0.0177 - val_loss: 0.1055 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1050 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1074 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1054 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1088 - val_mse: 0.0183 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1072 - mse: 0.0174 - val_loss: 0.1050 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1073 - mse: 0.0175 - val_loss: 0.1097 - val_mse: 0.0180 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1074 - mse: 0.0175 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.02459864]\n",
            "\n",
            "Iteration No: 44 ended. Search finished for the next optimal point.\n",
            "Time taken: 107.9054\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 45 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [64]\n",
            "Learning Rate: 4.9286090203660536e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 148.5809 - mse: 156351.5312 - val_loss: 0.3857 - val_mse: 1.1382 - 4s/epoch - 8ms/step\n",
            "525/525 - 2s - loss: 0.3058 - mse: 0.6693 - val_loss: 0.2700 - val_mse: 0.5413 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2938 - mse: 0.6307 - val_loss: 0.2779 - val_mse: 0.5557 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.3095 - mse: 0.7239 - val_loss: 0.2543 - val_mse: 0.5121 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.3146 - mse: 0.7860 - val_loss: 0.2961 - val_mse: 0.7150 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2947 - mse: 0.6885 - val_loss: 0.2518 - val_mse: 0.5035 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2727 - mse: 0.6075 - val_loss: 0.2345 - val_mse: 0.4799 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.3092 - mse: 0.7977 - val_loss: 0.2235 - val_mse: 0.4470 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2909 - mse: 0.7438 - val_loss: 0.2315 - val_mse: 0.4949 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2928 - mse: 0.7863 - val_loss: 0.5177 - val_mse: 2.4905 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2559 - mse: 0.6171 - val_loss: 0.1983 - val_mse: 0.3983 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2517 - mse: 0.6067 - val_loss: 0.2846 - val_mse: 0.5776 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2856 - mse: 0.8226 - val_loss: 0.2294 - val_mse: 0.4589 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2212 - mse: 0.5002 - val_loss: 0.2569 - val_mse: 0.5189 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2322 - mse: 0.5726 - val_loss: 0.1706 - val_mse: 0.3412 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2025 - mse: 0.4589 - val_loss: 0.1613 - val_mse: 0.3229 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2197 - mse: 0.5385 - val_loss: 0.1552 - val_mse: 0.3105 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1891 - mse: 0.4290 - val_loss: 0.1508 - val_mse: 0.3016 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2218 - mse: 0.5600 - val_loss: 0.2019 - val_mse: 0.4960 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1954 - mse: 0.4798 - val_loss: 0.1749 - val_mse: 0.3973 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.2172 - mse: 0.5649 - val_loss: 0.1596 - val_mse: 0.3193 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1902 - mse: 0.4718 - val_loss: 0.1295 - val_mse: 0.2590 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1888 - mse: 0.5207 - val_loss: 0.1208 - val_mse: 0.2423 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1763 - mse: 0.4523 - val_loss: 0.1170 - val_mse: 0.2354 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1428 - mse: 0.3222 - val_loss: 0.1190 - val_mse: 0.2440 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1473 - mse: 0.3580 - val_loss: 0.1301 - val_mse: 0.2821 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1372 - mse: 0.3058 - val_loss: 0.1322 - val_mse: 0.2941 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1369 - mse: 0.3161 - val_loss: 0.0918 - val_mse: 0.1836 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1235 - mse: 0.2760 - val_loss: 0.1021 - val_mse: 0.2041 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1066 - mse: 0.2371 - val_loss: 0.0955 - val_mse: 0.1956 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0962 - mse: 0.2018 - val_loss: 0.0853 - val_mse: 0.1721 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0926 - mse: 0.1942 - val_loss: 0.0918 - val_mse: 0.1909 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1045 - mse: 0.2405 - val_loss: 0.0678 - val_mse: 0.1356 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0730 - mse: 0.1474 - val_loss: 0.0636 - val_mse: 0.1273 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0741 - mse: 0.1515 - val_loss: 0.0605 - val_mse: 0.1210 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0706 - mse: 0.1442 - val_loss: 0.0560 - val_mse: 0.1120 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0578 - mse: 0.1158 - val_loss: 0.0521 - val_mse: 0.1042 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0559 - mse: 0.1122 - val_loss: 0.0526 - val_mse: 0.1051 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0551 - mse: 0.1139 - val_loss: 0.0457 - val_mse: 0.0913 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0509 - mse: 0.1029 - val_loss: 0.0415 - val_mse: 0.0830 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0430 - mse: 0.0865 - val_loss: 0.0380 - val_mse: 0.0761 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0382 - mse: 0.0765 - val_loss: 0.0407 - val_mse: 0.0814 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0383 - mse: 0.0776 - val_loss: 0.0352 - val_mse: 0.0705 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0309 - mse: 0.0617 - val_loss: 0.0295 - val_mse: 0.0589 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0302 - mse: 0.0604 - val_loss: 0.0269 - val_mse: 0.0537 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0263 - mse: 0.0525 - val_loss: 0.0246 - val_mse: 0.0493 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0243 - mse: 0.0486 - val_loss: 0.0223 - val_mse: 0.0446 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0212 - mse: 0.0425 - val_loss: 0.0201 - val_mse: 0.0402 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0231 - mse: 0.0469 - val_loss: 0.0188 - val_mse: 0.0378 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0190 - mse: 0.0383 - val_loss: 0.0209 - val_mse: 0.0417 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.51805443]\n",
            "\n",
            "Iteration No: 45 ended. Search finished for the next optimal point.\n",
            "Time taken: 96.7385\n",
            "Function value obtained: 0.0417\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 46 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 64]\n",
            "Learning Rate: 0.002934506433735167\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 39.2712 - mse: 142987.2812 - val_loss: 0.1001 - val_mse: 0.0150 - 4s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 0.4277 - mse: 54.5842 - val_loss: 0.1036 - val_mse: 0.0159 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1764 - mse: 1.8365 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1407 - mse: 0.7218 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1226 - mse: 0.3844 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1167 - mse: 0.1366 - val_loss: 0.1050 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1159 - mse: 0.1780 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1122 - mse: 0.0425 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1310 - mse: 1.8860 - val_loss: 0.1054 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1176 - mse: 0.1734 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1187 - mse: 0.6777 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1109 - mse: 0.0602 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1082 - mse: 0.0231 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1050 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1171 - mse: 0.2479 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1087 - mse: 0.0242 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1082 - mse: 0.0287 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0174 - val_loss: 0.1051 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1169 - mse: 0.4360 - val_loss: 0.1050 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1190 - mse: 1.1759 - val_loss: 0.1049 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1091 - mse: 0.0286 - val_loss: 0.1052 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0175 - val_loss: 0.1052 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1076 - mse: 0.0195 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1080 - mse: 0.0236 - val_loss: 0.1049 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1085 - mse: 0.0224 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1084 - mse: 0.0382 - val_loss: 0.1057 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0174 - val_loss: 0.1048 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1049 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1052 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1053 - val_mse: 0.0169 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1051 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1064 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1048 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1050 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1069 - mse: 0.0173 - val_loss: 0.1055 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1070 - mse: 0.0173 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1052 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1071 - mse: 0.0174 - val_loss: 0.1047 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.01607856]\n",
            "\n",
            "Iteration No: 46 ended. Search finished for the next optimal point.\n",
            "Time taken: 113.5669\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 47 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [64]\n",
            "Learning Rate: 0.00016725740519533413\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 53.2803 - mse: 200607.6875 - val_loss: 0.1601 - val_mse: 0.3208 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 0.0895 - mse: 0.1808 - val_loss: 0.0478 - val_mse: 0.0959 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0304 - mse: 0.0609 - val_loss: 0.0164 - val_mse: 0.0328 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0106 - mse: 0.0213 - val_loss: 0.0062 - val_mse: 0.0125 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0059 - val_mse: 0.0117 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0055 - val_mse: 0.0109 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0607 - mse: 0.4006 - val_loss: 0.1320 - val_mse: 0.3389 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0247 - mse: 0.0680 - val_loss: 0.0056 - val_mse: 0.0113 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0068 - val_mse: 0.0136 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0049 - mse: 0.0099 - val_loss: 0.0044 - val_mse: 0.0087 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0049 - mse: 0.0097 - val_loss: 0.0045 - val_mse: 0.0091 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0043 - val_mse: 0.0086 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0050 - mse: 0.0101 - val_loss: 0.0083 - val_mse: 0.0165 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1426 - mse: 2.2903 - val_loss: 0.5365 - val_mse: 3.0499 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1008 - mse: 1.1259 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0040 - val_mse: 0.0081 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0040 - val_mse: 0.0081 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0047 - val_mse: 0.0095 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0038 - val_mse: 0.0077 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0043 - val_mse: 0.0085 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0036 - val_mse: 0.0073 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.8060 - mse: 20.2826 - val_loss: 0.0618 - val_mse: 0.1529 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0105 - mse: 0.0216 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0041 - val_mse: 0.0082 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0038 - mse: 0.0075 - val_loss: 0.0037 - val_mse: 0.0075 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0037 - mse: 0.0073 - val_loss: 0.0035 - val_mse: 0.0071 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0036 - val_mse: 0.0072 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0035 - val_mse: 0.0070 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0033 - val_mse: 0.0065 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0033 - val_mse: 0.0065 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0035 - val_mse: 0.0070 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.6046 - mse: 19.9455 - val_loss: 0.0047 - val_mse: 0.0094 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0047 - val_mse: 0.0095 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0048 - val_mse: 0.0097 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0046 - val_mse: 0.0091 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0047 - val_mse: 0.0093 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0052 - val_mse: 0.0104 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0051 - mse: 0.0101 - val_loss: 0.0070 - val_mse: 0.0140 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0052 - mse: 0.0105 - val_loss: 0.0049 - val_mse: 0.0097 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0043 - val_mse: 0.0087 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0891 - mse: 0.7345 - val_loss: 1.4024 - val_mse: 14.1328 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1525 - mse: 2.6796 - val_loss: 0.0046 - val_mse: 0.0092 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0044 - mse: 0.0089 - val_loss: 0.0041 - val_mse: 0.0083 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0039 - val_mse: 0.0078 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0279 - mse: 0.1795 - val_loss: 0.0038 - val_mse: 0.0076 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0034 - val_mse: 0.0069 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0157 - mse: 0.0463 - val_loss: 0.0067 - val_mse: 0.0134 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0067 - mse: 0.0143 - val_loss: 0.0039 - val_mse: 0.0078 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 47 ended. Search finished for the next optimal point.\n",
            "Time taken: 97.5003\n",
            "Function value obtained: 0.0078\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 48 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 4.918744345118625e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 383.7891 - mse: 1860393.3750 - val_loss: 14.6674 - val_mse: 1139.2589 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 358.5353 - mse: 1520586.6250 - val_loss: 6.6444 - val_mse: 239.7596 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 344.0245 - mse: 1212000.8750 - val_loss: 5.7982 - val_mse: 178.0052 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 330.9955 - mse: 1174428.5000 - val_loss: 4.6544 - val_mse: 112.4773 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 324.6410 - mse: 1186561.8750 - val_loss: 2.9259 - val_mse: 44.0187 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 337.1516 - mse: 1433050.8750 - val_loss: 2.4401 - val_mse: 29.9576 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 339.2021 - mse: 1377501.3750 - val_loss: 2.3005 - val_mse: 26.3474 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 325.6139 - mse: 1453333.2500 - val_loss: 1.5351 - val_mse: 11.3539 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 319.4705 - mse: 1142205.2500 - val_loss: 1.3100 - val_mse: 8.2253 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 322.4642 - mse: 1260657.8750 - val_loss: 0.5953 - val_mse: 1.7412 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 339.4061 - mse: 1845132.7500 - val_loss: 0.2344 - val_mse: 0.4689 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 300.0382 - mse: 877501.8125 - val_loss: 0.3013 - val_mse: 0.6109 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 296.7397 - mse: 1119472.3750 - val_loss: 0.3420 - val_mse: 0.7173 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 312.6365 - mse: 1129311.7500 - val_loss: 0.8706 - val_mse: 3.6819 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 295.3320 - mse: 1029946.5625 - val_loss: 0.7095 - val_mse: 2.4915 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 303.3648 - mse: 1001501.4375 - val_loss: 0.2546 - val_mse: 0.6213 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 299.5201 - mse: 1112295.6250 - val_loss: 0.6668 - val_mse: 2.2076 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 292.2388 - mse: 1167048.8750 - val_loss: 1.1771 - val_mse: 6.7952 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 287.4875 - mse: 1007600.7500 - val_loss: 0.4155 - val_mse: 0.9695 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 306.4393 - mse: 1351077.6250 - val_loss: 0.2571 - val_mse: 0.5154 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 278.2835 - mse: 1208918.1250 - val_loss: 0.7230 - val_mse: 2.6271 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 286.0988 - mse: 926520.3750 - val_loss: 0.4052 - val_mse: 0.9468 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 277.2520 - mse: 932559.3125 - val_loss: 0.2416 - val_mse: 0.5884 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 280.1187 - mse: 1063164.6250 - val_loss: 0.1896 - val_mse: 0.3851 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 283.2077 - mse: 979663.3125 - val_loss: 0.6799 - val_mse: 4.3695 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 264.9608 - mse: 902297.0000 - val_loss: 0.5575 - val_mse: 3.0131 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 274.3658 - mse: 895445.4375 - val_loss: 0.8915 - val_mse: 7.2169 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 268.4268 - mse: 924184.8750 - val_loss: 0.4119 - val_mse: 0.9855 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 259.6745 - mse: 740925.1250 - val_loss: 0.5331 - val_mse: 1.5407 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 252.5403 - mse: 746285.0625 - val_loss: 0.2709 - val_mse: 0.5517 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 260.4741 - mse: 793089.8125 - val_loss: 0.7608 - val_mse: 3.0122 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 257.0890 - mse: 788390.3125 - val_loss: 2.3211 - val_mse: 27.5125 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 235.0705 - mse: 584009.8750 - val_loss: 1.1271 - val_mse: 6.5721 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 258.6662 - mse: 824972.2500 - val_loss: 0.7784 - val_mse: 3.1914 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 252.4233 - mse: 794599.1875 - val_loss: 0.4885 - val_mse: 1.3746 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 240.9619 - mse: 700161.5000 - val_loss: 0.1649 - val_mse: 0.3306 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 256.2534 - mse: 861237.0000 - val_loss: 0.2140 - val_mse: 0.5112 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 240.6104 - mse: 731815.3125 - val_loss: 0.1946 - val_mse: 0.4342 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 237.4578 - mse: 675703.5625 - val_loss: 0.1640 - val_mse: 0.3279 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 234.8839 - mse: 714657.3125 - val_loss: 0.1634 - val_mse: 0.3269 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 231.9000 - mse: 739512.5000 - val_loss: 0.1571 - val_mse: 0.3142 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 234.2603 - mse: 694532.6250 - val_loss: 0.8439 - val_mse: 3.8351 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 219.6022 - mse: 544096.1875 - val_loss: 0.7669 - val_mse: 3.2078 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 224.1066 - mse: 598027.7500 - val_loss: 1.2795 - val_mse: 8.6475 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 220.8219 - mse: 529378.4375 - val_loss: 0.6193 - val_mse: 2.1678 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 217.2146 - mse: 493815.3125 - val_loss: 0.5820 - val_mse: 1.9415 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 226.6147 - mse: 683861.1250 - val_loss: 0.6388 - val_mse: 2.3082 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 228.0181 - mse: 615478.9375 - val_loss: 0.5609 - val_mse: 1.8309 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 212.0868 - mse: 602010.0000 - val_loss: 0.4179 - val_mse: 1.1075 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 214.6384 - mse: 540510.0000 - val_loss: 0.1585 - val_mse: 0.3170 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 48 ended. Search finished for the next optimal point.\n",
            "Time taken: 102.0004\n",
            "Function value obtained: 0.3170\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 49 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [209, 64]\n",
            "Learning Rate: 0.0027370145086572785\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 76.7420 - mse: 226890.4688 - val_loss: 8.5583 - val_mse: 446.2447 - 3s/epoch - 81ms/step\n",
            "33/33 - 0s - loss: 3.2025 - mse: 102.9958 - val_loss: 0.5791 - val_mse: 3.0488 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 296.2549 - mse: 773031.1875 - val_loss: 64.3547 - val_mse: 21687.3496 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 40.1444 - mse: 20875.6641 - val_loss: 61.9909 - val_mse: 20105.5918 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 37.3248 - mse: 8998.7852 - val_loss: 14.7782 - val_mse: 1227.4521 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 23.0276 - mse: 4452.0547 - val_loss: 6.6843 - val_mse: 233.9646 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 30.8099 - mse: 11933.7119 - val_loss: 33.9075 - val_mse: 5903.4600 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 45.9900 - mse: 15323.1904 - val_loss: 11.6321 - val_mse: 773.8146 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 19.0897 - mse: 4371.0317 - val_loss: 30.2941 - val_mse: 4722.6802 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 18.3926 - mse: 2263.3987 - val_loss: 4.4438 - val_mse: 108.5232 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 8.4665 - mse: 591.6163 - val_loss: 4.2395 - val_mse: 115.3733 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.3263 - mse: 94.8567 - val_loss: 4.2105 - val_mse: 101.3816 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.5157 - mse: 98.9643 - val_loss: 0.3668 - val_mse: 1.6480 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1786 - mse: 0.6060 - val_loss: 0.0635 - val_mse: 0.1327 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0271 - mse: 0.0546 - val_loss: 0.0091 - val_mse: 0.0183 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0041 - val_mse: 0.0082 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0038 - val_mse: 0.0077 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0037 - val_mse: 0.0075 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0037 - val_mse: 0.0074 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0036 - val_mse: 0.0073 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0073 - val_loss: 0.0036 - val_mse: 0.0072 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0072 - val_loss: 0.0036 - val_mse: 0.0072 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0036 - val_mse: 0.0071 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0036 - val_mse: 0.0071 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0035 - val_mse: 0.0071 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0071 - val_loss: 0.0035 - val_mse: 0.0071 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0071 - val_loss: 0.0035 - val_mse: 0.0071 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0071 - val_loss: 0.0035 - val_mse: 0.0070 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0069 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0069 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0070 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0069 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0069 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0069 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0069 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0068 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0069 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0068 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0068 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0068 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0068 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0069 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0069 - 246ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 49 ended. Search finished for the next optimal point.\n",
            "Time taken: 19.9859\n",
            "Function value obtained: 0.0069\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 50 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 64]\n",
            "Learning Rate: 0.0027079254050972512\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 207.7320 - mse: 442350.7188 - val_loss: 14.5247 - val_mse: 1000.2149 - 3s/epoch - 80ms/step\n",
            "33/33 - 0s - loss: 3.7876 - mse: 198.6754 - val_loss: 0.5585 - val_mse: 0.9966 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.8841 - mse: 14.4940 - val_loss: 1.0392 - val_mse: 5.7142 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 6.2808 - mse: 294.9091 - val_loss: 3.3134 - val_mse: 52.1479 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 8.0599 - mse: 539.3286 - val_loss: 2.9751 - val_mse: 47.9670 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 6.9009 - mse: 373.0513 - val_loss: 2.9257 - val_mse: 40.5594 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 12.5549 - mse: 1353.6127 - val_loss: 12.7767 - val_mse: 819.4268 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 9.0855 - mse: 730.0787 - val_loss: 0.9051 - val_mse: 4.2544 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 35.4916 - mse: 12957.8008 - val_loss: 34.6776 - val_mse: 6150.9141 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 22.7423 - mse: 4710.8320 - val_loss: 10.5629 - val_mse: 581.8619 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 4.9399 - mse: 762.7185 - val_loss: 0.6697 - val_mse: 2.3589 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2752 - mse: 0.5038 - val_loss: 0.1702 - val_mse: 0.0715 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.1170 - mse: 0.0383 - val_loss: 0.0865 - val_mse: 0.0133 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0807 - mse: 0.0138 - val_loss: 0.1980 - val_mse: 0.1264 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1469 - mse: 0.0943 - val_loss: 0.0647 - val_mse: 0.0069 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0571 - mse: 0.0051 - val_loss: 0.0533 - val_mse: 0.0048 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0537 - mse: 0.0048 - val_loss: 0.0536 - val_mse: 0.0048 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0520 - mse: 0.0046 - val_loss: 0.0510 - val_mse: 0.0044 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0510 - mse: 0.0045 - val_loss: 0.0527 - val_mse: 0.0046 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0504 - mse: 0.0044 - val_loss: 0.0518 - val_mse: 0.0046 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0502 - mse: 0.0044 - val_loss: 0.0496 - val_mse: 0.0042 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0504 - mse: 0.0044 - val_loss: 0.0496 - val_mse: 0.0043 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0495 - mse: 0.0042 - val_loss: 0.0500 - val_mse: 0.0043 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0492 - mse: 0.0042 - val_loss: 0.0486 - val_mse: 0.0041 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0491 - mse: 0.0042 - val_loss: 0.0501 - val_mse: 0.0043 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0488 - mse: 0.0041 - val_loss: 0.0486 - val_mse: 0.0042 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0498 - mse: 0.0043 - val_loss: 0.0494 - val_mse: 0.0042 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0493 - mse: 0.0042 - val_loss: 0.0482 - val_mse: 0.0040 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0484 - mse: 0.0041 - val_loss: 0.0483 - val_mse: 0.0041 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0482 - mse: 0.0040 - val_loss: 0.0489 - val_mse: 0.0041 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0492 - mse: 0.0042 - val_loss: 0.0476 - val_mse: 0.0040 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0481 - mse: 0.0040 - val_loss: 0.0470 - val_mse: 0.0039 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0490 - mse: 0.0041 - val_loss: 0.0488 - val_mse: 0.0042 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0479 - mse: 0.0039 - val_loss: 0.0464 - val_mse: 0.0038 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0481 - mse: 0.0040 - val_loss: 0.0478 - val_mse: 0.0040 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0477 - mse: 0.0039 - val_loss: 0.0465 - val_mse: 0.0038 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0475 - mse: 0.0038 - val_loss: 0.0479 - val_mse: 0.0039 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0478 - mse: 0.0039 - val_loss: 0.0459 - val_mse: 0.0038 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0472 - mse: 0.0038 - val_loss: 0.0476 - val_mse: 0.0039 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0473 - mse: 0.0038 - val_loss: 0.0485 - val_mse: 0.0040 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0481 - mse: 0.0039 - val_loss: 0.0474 - val_mse: 0.0038 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0489 - mse: 0.0040 - val_loss: 0.0585 - val_mse: 0.0056 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0513 - mse: 0.0043 - val_loss: 0.0502 - val_mse: 0.0040 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0487 - mse: 0.0040 - val_loss: 0.0465 - val_mse: 0.0037 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0498 - mse: 0.0041 - val_loss: 0.0680 - val_mse: 0.0074 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0679 - mse: 0.0093 - val_loss: 0.0548 - val_mse: 0.0050 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0491 - mse: 0.0040 - val_loss: 0.0474 - val_mse: 0.0037 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0462 - mse: 0.0036 - val_loss: 0.0505 - val_mse: 0.0041 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0486 - mse: 0.0039 - val_loss: 0.0600 - val_mse: 0.0056 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0487 - mse: 0.0039 - val_loss: 0.0447 - val_mse: 0.0034 - 213ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 50 ended. Search finished for the next optimal point.\n",
            "Time taken: 19.0699\n",
            "Function value obtained: 0.0034\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 51 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 143]\n",
            "Learning Rate: 0.0001101947785468405\n",
            "Activation Function: relu\n",
            "Loss Function: logcosh\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.5\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 372.5327 - mse: 1622047.6250 - val_loss: 2.2884 - val_mse: 27.3539 - 5s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 179.4244 - mse: 442617.3750 - val_loss: 0.8171 - val_mse: 3.2303 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 101.2797 - mse: 130909.9531 - val_loss: 0.3783 - val_mse: 0.9492 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 63.2446 - mse: 55721.0820 - val_loss: 0.1903 - val_mse: 0.4241 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 37.0480 - mse: 20487.1543 - val_loss: 0.1843 - val_mse: 0.3970 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 25.8782 - mse: 11805.3232 - val_loss: 0.1639 - val_mse: 0.3506 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 16.8715 - mse: 4490.6636 - val_loss: 0.1519 - val_mse: 0.3221 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 10.9044 - mse: 1760.7478 - val_loss: 0.1291 - val_mse: 0.2720 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 7.5388 - mse: 903.5620 - val_loss: 0.1066 - val_mse: 0.2223 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.7212 - mse: 363.4758 - val_loss: 0.0689 - val_mse: 0.1419 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.2372 - mse: 244.3049 - val_loss: 0.0404 - val_mse: 0.0824 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.2348 - mse: 221.4875 - val_loss: 0.0214 - val_mse: 0.0432 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3911 - mse: 59.0432 - val_loss: 0.0067 - val_mse: 0.0136 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8572 - mse: 29.8619 - val_loss: 0.0048 - val_mse: 0.0096 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6680 - mse: 23.5524 - val_loss: 0.0037 - val_mse: 0.0074 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4982 - mse: 30.1329 - val_loss: 0.0083 - val_mse: 0.0166 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2707 - mse: 7.2669 - val_loss: 0.0081 - val_mse: 0.0164 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2341 - mse: 6.0423 - val_loss: 0.0078 - val_mse: 0.0157 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1385 - mse: 2.2022 - val_loss: 0.0068 - val_mse: 0.0138 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1337 - mse: 6.1696 - val_loss: 0.0074 - val_mse: 0.0149 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1167 - mse: 2.5328 - val_loss: 0.0078 - val_mse: 0.0156 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0612 - mse: 0.5167 - val_loss: 0.0080 - val_mse: 0.0161 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0359 - mse: 0.3223 - val_loss: 0.0079 - val_mse: 0.0160 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0478 - mse: 0.9669 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0399 - mse: 0.6102 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0399 - mse: 0.8565 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0243 - mse: 0.1757 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0223 - mse: 0.1986 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0182 - mse: 0.1540 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0167 - mse: 0.0849 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0476 - mse: 9.9723 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0293 - mse: 0.8932 - val_loss: 0.0083 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0179 - mse: 0.2450 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0123 - mse: 0.0520 - val_loss: 0.0069 - val_mse: 0.0138 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0108 - mse: 0.0285 - val_loss: 0.0085 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0138 - mse: 0.1046 - val_loss: 0.0050 - val_mse: 0.0100 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0222 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0111 - mse: 0.1179 - val_loss: 0.0052 - val_mse: 0.0105 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0151 - mse: 0.1075 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0076 - mse: 0.0159 - val_loss: 0.0049 - val_mse: 0.0097 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0072 - mse: 0.0149 - val_loss: 0.0062 - val_mse: 0.0125 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0097 - mse: 0.0308 - val_loss: 0.0042 - val_mse: 0.0084 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0071 - mse: 0.0145 - val_loss: 0.0058 - val_mse: 0.0117 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0080 - mse: 0.0170 - val_loss: 0.0055 - val_mse: 0.0111 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0066 - mse: 0.0133 - val_loss: 0.0055 - val_mse: 0.0110 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0075 - mse: 0.0168 - val_loss: 0.0073 - val_mse: 0.0146 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0073 - mse: 0.0152 - val_loss: 0.0073 - val_mse: 0.0146 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0067 - mse: 0.0137 - val_loss: 0.0059 - val_mse: 0.0118 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0065 - mse: 0.0137 - val_loss: 0.0038 - val_mse: 0.0077 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0081 - mse: 0.0210 - val_loss: 0.0082 - val_mse: 0.0166 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.5354742]\n",
            "\n",
            "Iteration No: 51 ended. Search finished for the next optimal point.\n",
            "Time taken: 111.8983\n",
            "Function value obtained: 0.0166\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 52 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 64]\n",
            "Learning Rate: 0.002684173337097027\n",
            "Activation Function: relu\n",
            "Loss Function: mae\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 73.1012 - mse: 84365.1797 - val_loss: 11.3036 - val_mse: 577.4708 - 3s/epoch - 76ms/step\n",
            "33/33 - 0s - loss: 17.2701 - mse: 2366.7791 - val_loss: 6.7609 - val_mse: 200.4147 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 14.0020 - mse: 1622.9337 - val_loss: 31.2950 - val_mse: 4868.4087 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 27.8982 - mse: 6015.3242 - val_loss: 8.6360 - val_mse: 399.7769 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 5.9974 - mse: 246.3271 - val_loss: 0.6146 - val_mse: 0.6424 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1.5284 - mse: 14.0073 - val_loss: 1.5648 - val_mse: 9.4292 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.3215 - mse: 18.8399 - val_loss: 0.2306 - val_mse: 0.0939 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1344 - mse: 0.0470 - val_loss: 0.1371 - val_mse: 0.0386 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1059 - mse: 0.0288 - val_loss: 0.1147 - val_mse: 0.0199 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0917 - mse: 0.0144 - val_loss: 0.0840 - val_mse: 0.0093 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0858 - mse: 0.0111 - val_loss: 0.0801 - val_mse: 0.0099 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0861 - mse: 0.0120 - val_loss: 0.0839 - val_mse: 0.0103 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0848 - mse: 0.0116 - val_loss: 0.0821 - val_mse: 0.0091 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0867 - mse: 0.0118 - val_loss: 0.0803 - val_mse: 0.0090 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0813 - mse: 0.0098 - val_loss: 0.0814 - val_mse: 0.0122 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0965 - mse: 0.0167 - val_loss: 0.0977 - val_mse: 0.0212 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0994 - mse: 0.0226 - val_loss: 0.0979 - val_mse: 0.0199 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0747 - mse: 0.0107 - val_loss: 0.0597 - val_mse: 0.0071 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0598 - mse: 0.0066 - val_loss: 0.0587 - val_mse: 0.0057 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0632 - mse: 0.0078 - val_loss: 0.0541 - val_mse: 0.0047 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1039 - mse: 0.0400 - val_loss: 0.2790 - val_mse: 0.3474 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1629 - mse: 0.1087 - val_loss: 0.1652 - val_mse: 0.0724 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0941 - mse: 0.0185 - val_loss: 0.0775 - val_mse: 0.0087 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0866 - mse: 0.0122 - val_loss: 0.1194 - val_mse: 0.0300 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1394 - mse: 0.1222 - val_loss: 0.1295 - val_mse: 0.0654 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0917 - mse: 0.0171 - val_loss: 0.0757 - val_mse: 0.0093 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0813 - mse: 0.0101 - val_loss: 0.0725 - val_mse: 0.0074 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0795 - mse: 0.0095 - val_loss: 0.0791 - val_mse: 0.0083 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0812 - mse: 0.0102 - val_loss: 0.0745 - val_mse: 0.0082 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1103 - mse: 0.0503 - val_loss: 0.3853 - val_mse: 0.6240 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.6904 - mse: 42.3470 - val_loss: 1.3448 - val_mse: 9.6458 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 84.2961 - mse: 133887.5312 - val_loss: 65.0413 - val_mse: 21170.1875 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 29.2474 - mse: 7308.0474 - val_loss: 1.2199 - val_mse: 4.0605 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.3082 - mse: 76.8535 - val_loss: 10.7403 - val_mse: 616.3507 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.0363 - mse: 70.8566 - val_loss: 1.1741 - val_mse: 7.1390 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6436 - mse: 2.6237 - val_loss: 0.3448 - val_mse: 0.4184 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6293 - mse: 2.5693 - val_loss: 0.6579 - val_mse: 2.4624 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2114 - mse: 0.2818 - val_loss: 0.1360 - val_mse: 0.0343 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0994 - mse: 0.0213 - val_loss: 0.0780 - val_mse: 0.0110 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1025 - mse: 0.0247 - val_loss: 0.0792 - val_mse: 0.0091 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0998 - mse: 0.0221 - val_loss: 0.0950 - val_mse: 0.0166 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0853 - mse: 0.0125 - val_loss: 0.0819 - val_mse: 0.0136 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0790 - mse: 0.0098 - val_loss: 0.0747 - val_mse: 0.0079 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0746 - mse: 0.0084 - val_loss: 0.0711 - val_mse: 0.0073 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0722 - mse: 0.0080 - val_loss: 0.0698 - val_mse: 0.0073 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0744 - mse: 0.0086 - val_loss: 0.0714 - val_mse: 0.0080 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0725 - mse: 0.0080 - val_loss: 0.0726 - val_mse: 0.0092 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0699 - mse: 0.0074 - val_loss: 0.0688 - val_mse: 0.0070 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0728 - mse: 0.0082 - val_loss: 0.0677 - val_mse: 0.0070 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0706 - mse: 0.0079 - val_loss: 0.0682 - val_mse: 0.0076 - 210ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 52 ended. Search finished for the next optimal point.\n",
            "Time taken: 20.1092\n",
            "Function value obtained: 0.0076\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 53 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [256, 64]\n",
            "Learning Rate: 0.003264986803249905\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 210.4111 - mse: 454605.2188 - val_loss: 21.6761 - val_mse: 2594.8193 - 3s/epoch - 79ms/step\n",
            "33/33 - 0s - loss: 38.3688 - mse: 15821.5635 - val_loss: 63.3913 - val_mse: 21015.9727 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 12.0886 - mse: 2587.5205 - val_loss: 0.6661 - val_mse: 2.4404 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6896 - mse: 5.5941 - val_loss: 0.2704 - val_mse: 0.6313 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0922 - mse: 0.2240 - val_loss: 0.0266 - val_mse: 0.0531 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0133 - mse: 0.0266 - val_loss: 0.0068 - val_mse: 0.0136 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0052 - mse: 0.0103 - val_loss: 0.0045 - val_mse: 0.0089 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0042 - val_mse: 0.0084 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0041 - val_mse: 0.0083 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0043 - mse: 0.0087 - val_loss: 0.0039 - val_mse: 0.0078 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0037 - val_mse: 0.0075 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0037 - val_mse: 0.0074 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0038 - val_mse: 0.0077 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0036 - val_mse: 0.0073 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0038 - val_mse: 0.0077 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0035 - val_mse: 0.0070 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0069 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0038 - val_mse: 0.0075 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0038 - val_mse: 0.0076 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0072 - val_loss: 0.0037 - val_mse: 0.0073 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0034 - val_mse: 0.0068 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0072 - val_loss: 0.0034 - val_mse: 0.0067 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0038 - val_mse: 0.0075 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0047 - val_mse: 0.0094 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0039 - val_mse: 0.0079 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0068 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0034 - val_mse: 0.0069 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0035 - val_mse: 0.0070 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0034 - val_mse: 0.0068 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0033 - val_mse: 0.0066 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0033 - val_mse: 0.0065 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0035 - val_mse: 0.0070 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0033 - val_mse: 0.0065 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0032 - val_mse: 0.0064 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0065 - val_loss: 0.0032 - val_mse: 0.0064 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0034 - val_mse: 0.0069 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0069 - val_loss: 0.0038 - val_mse: 0.0075 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0034 - mse: 0.0069 - val_loss: 0.0033 - val_mse: 0.0066 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0034 - val_mse: 0.0067 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0036 - mse: 0.0071 - val_loss: 0.0035 - val_mse: 0.0069 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0035 - val_mse: 0.0069 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0067 - val_loss: 0.0033 - val_mse: 0.0066 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0037 - val_mse: 0.0074 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0032 - val_mse: 0.0064 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0033 - val_mse: 0.0065 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0067 - val_loss: 0.0032 - val_mse: 0.0063 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0067 - val_loss: 0.0036 - val_mse: 0.0073 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0033 - mse: 0.0066 - val_loss: 0.0033 - val_mse: 0.0067 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0032 - mse: 0.0065 - val_loss: 0.0033 - val_mse: 0.0066 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0046 - val_mse: 0.0091 - 229ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 53 ended. Search finished for the next optimal point.\n",
            "Time taken: 19.3791\n",
            "Function value obtained: 0.0091\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 54 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [256]\n",
            "Learning Rate: 0.00016644083313022576\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.3159856065589853\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 4s - loss: 144.8419 - mse: 297177.7500 - val_loss: 0.4688 - val_mse: 1.0517 - 4s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 105.3143 - mse: 158987.2188 - val_loss: 0.5547 - val_mse: 3.2891 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 76.1635 - mse: 65664.5625 - val_loss: 1.8261 - val_mse: 24.9269 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 58.5443 - mse: 42112.3867 - val_loss: 1.1138 - val_mse: 15.4849 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 45.5807 - mse: 25414.8008 - val_loss: 0.6592 - val_mse: 5.6570 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 36.1367 - mse: 16865.2070 - val_loss: 0.0318 - val_mse: 0.0667 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 28.4726 - mse: 9605.3359 - val_loss: 0.0614 - val_mse: 0.1280 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 21.1639 - mse: 6385.7271 - val_loss: 0.0874 - val_mse: 0.2526 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 15.6834 - mse: 3165.7415 - val_loss: 0.2857 - val_mse: 1.0748 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 11.6265 - mse: 1856.2015 - val_loss: 0.2223 - val_mse: 0.7831 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 8.3130 - mse: 1013.7223 - val_loss: 0.3264 - val_mse: 1.5130 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 5.3082 - mse: 392.8472 - val_loss: 0.1415 - val_mse: 0.3733 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.4696 - mse: 167.3621 - val_loss: 0.0266 - val_mse: 0.0532 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 2.0056 - mse: 70.2815 - val_loss: 0.0108 - val_mse: 0.0215 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 1.0793 - mse: 21.4924 - val_loss: 0.0204 - val_mse: 0.0408 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.5442 - mse: 7.6308 - val_loss: 0.0095 - val_mse: 0.0189 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.3283 - mse: 3.4950 - val_loss: 0.0102 - val_mse: 0.0204 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1629 - mse: 0.8844 - val_loss: 0.0090 - val_mse: 0.0179 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1218 - mse: 0.5517 - val_loss: 0.0063 - val_mse: 0.0126 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1942 - mse: 1.3338 - val_loss: 0.0045 - val_mse: 0.0089 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1004 - mse: 0.4682 - val_loss: 0.0077 - val_mse: 0.0155 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0927 - mse: 0.3788 - val_loss: 0.0061 - val_mse: 0.0122 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0775 - mse: 0.3178 - val_loss: 0.0150 - val_mse: 0.0299 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0662 - mse: 0.2259 - val_loss: 0.0057 - val_mse: 0.0114 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0694 - mse: 0.2641 - val_loss: 0.0041 - val_mse: 0.0083 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0573 - mse: 0.2006 - val_loss: 0.0069 - val_mse: 0.0138 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0379 - mse: 0.1035 - val_loss: 0.0038 - val_mse: 0.0077 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0387 - mse: 0.1245 - val_loss: 0.0049 - val_mse: 0.0098 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0268 - mse: 0.0810 - val_loss: 0.0047 - val_mse: 0.0095 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0194 - mse: 0.0506 - val_loss: 0.0036 - val_mse: 0.0072 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0145 - mse: 0.0375 - val_loss: 0.0038 - val_mse: 0.0076 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0155 - mse: 0.0374 - val_loss: 0.0071 - val_mse: 0.0142 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0078 - mse: 0.0158 - val_loss: 0.0021 - val_mse: 0.0042 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0022 - val_mse: 0.0044 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0037 - val_mse: 0.0075 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0024 - val_mse: 0.0047 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0020 - val_mse: 0.0039 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0019 - val_mse: 0.0037 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0029 - mse: 0.0059 - val_loss: 0.0019 - val_mse: 0.0038 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0029 - mse: 0.0059 - val_loss: 0.0018 - val_mse: 0.0037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0019 - val_mse: 0.0038 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0028 - mse: 0.0055 - val_loss: 0.0018 - val_mse: 0.0036 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0018 - val_mse: 0.0036 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0018 - val_mse: 0.0035 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0018 - val_mse: 0.0035 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0017 - val_mse: 0.0035 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0017 - val_mse: 0.0034 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0018 - val_mse: 0.0035 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0017 - val_mse: 0.0034 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0017 - val_mse: 0.0034 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.75018622]\n",
            "\n",
            "Iteration No: 54 ended. Search finished for the next optimal point.\n",
            "Time taken: 99.7105\n",
            "Function value obtained: 0.0034\n",
            "Current minimum: 0.0030\n",
            "Iteration No: 55 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 64]\n",
            "Learning Rate: 0.0031395730004489955\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 200\n",
            "Dropout Rate: 0.006043928660265851\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 23.1972 - mse: 17510.5820 - val_loss: 0.0072 - val_mse: 0.0144 - 5s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Export the best one\n",
        "\n",
        "---\n",
        "\n",
        "And then, ***the best one***'s Inductive Biases would be a friendly guide for your Symbolic Regression later."
      ],
      "metadata": {
        "id": "yFOAH6IdSFqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export best '.h5' file\n",
        "#-----------------------------------------------------------\n",
        "best_number_of_layers = best_params[0]\n",
        "best_layer_nodes = best_params[1:1+best_number_of_layers]\n",
        "best_batch_size = best_params[1+max_layers]\n",
        "best_epochs = best_params[2+max_layers]\n",
        "best_learning_rate = best_params[3+max_layers]\n",
        "best_activation = best_params[4+max_layers]\n",
        "best_loss_function = best_params[5+max_layers]\n",
        "best_optimizer = best_params[6+max_layers]\n",
        "best_dropout_rate = best_params[7+max_layers]\n",
        "\n",
        "best_model = SumNet(\n",
        "    layer_nodes=best_layer_nodes,\n",
        "    learning_rate=best_learning_rate,\n",
        "    activation=best_activation,\n",
        "    dropout_rate=best_dropout_rate,\n",
        "    optimizer=best_optimizer,\n",
        "    loss_function=best_loss_function,\n",
        ")\n",
        "\n",
        "best_model.model.fit(X_train, y_train, epochs=best_epochs, batch_size=best_batch_size)\n",
        "best_model.model.save(\"Best_Model_{}.h5\".format(\n",
        "    time.strftime('%Y_%m_%d_%H_%M', time.localtime(time.time()))\n",
        "    ))\n",
        "\n",
        "best_val_loss = min(best_model.history.history['val_loss'])\n",
        "print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "#-----------------------------------------------------------"
      ],
      "metadata": {
        "id": "lCsHcVMfSFyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Chapter.3 Symbolic Regression\n",
        "---"
      ],
      "metadata": {
        "id": "QMwDjkqzSHZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Generate Train Data for PySR\n",
        "---\n",
        "In this section(chapter), 2 equations would be developed.\n",
        "\n",
        "Each equations would be fitted to model_g, and model_f.\n",
        "\n",
        "According to the inductive biases of well-optimized MLP SumNet,\n",
        "\n",
        "your Symbolic Regression would be well-fitted:\n",
        "\n",
        "> * Lower Complexity\n",
        "> * Faster fitting speed\n",
        "> * Greatly Practical"
      ],
      "metadata": {
        "id": "82tTKTIr5IeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "idx = np.random.randint(0, len(X_selected), size=int(len(X_selected)*0.8))\n",
        "\n",
        "X_for_pysr = X_selected[idx]\n",
        "y_for_pysr = best_model.model_g.predict(X_for_pysr)  # `y` 값만 추출\n",
        "z_for_pysr = y[idx]  # 진짜 결과 값\n",
        "\n",
        "print(X_for_pysr.shape, y_for_pysr.shape, z_for_pysr.shape)"
      ],
      "metadata": {
        "id": "GTmqeaAzSHip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Generate Dataframe\n",
        "---\n",
        "Symbolic Regression with Julia is quite fragile.\n",
        "\n",
        "don't forget to export your tasks as *pickle*."
      ],
      "metadata": {
        "id": "cmVUX-gO5OTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors to NumPy arrays\n",
        "X_for_pysr_np = X_for_pysr.detach().numpy()\n",
        "y_for_pysr_np = y_for_pysr.detach().numpy()\n",
        "z_for_pysr_np = z_for_pysr.detach().numpy()\n",
        "\n",
        "# Convert arrays to pandas DataFrame\n",
        "df = pd.DataFrame(X_for_pysr_np, columns=[f'X_{i}' for i in range(N)])\n",
        "\n",
        "df['y_for_pysr'] = y_for_pysr_np\n",
        "df['z_for_pysr'] = z_for_pysr_np\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv(\"data.csv\", index=False)\n",
        "\n",
        "nnet_recordings = {\n",
        "    \"g_input\": X_for_pysr.detach().cpu().numpy().reshape(-1, N),\n",
        "    \"g_output\": y_for_pysr.detach().cpu().numpy().reshape(-1),\n",
        "    \"f_input\": y_for_pysr.detach().cpu().numpy().reshape(-1, 1),\n",
        "    \"f_output\": z_for_pysr.detach().cpu().numpy().reshape(-1),\n",
        "}\n",
        "\n",
        "# Save the data for later use:\n",
        "import pickle as pkl\n",
        "\n",
        "with open(\"nnet_recordings.pkl\", \"wb\") as f:\n",
        "    pkl.dump(nnet_recordings, f)"
      ],
      "metadata": {
        "id": "533p8WFU5ObE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pick out the sample, for PySR\n",
        "---\n",
        "Symbolic Regression is very sensive to its input data, and hyperparameters.\n",
        "\n",
        "Don't be afraid to adjust you size of sample.\n",
        "\n",
        "Get ready for ***trial & error***"
      ],
      "metadata": {
        "id": "rukGXtWr5Oiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnet_recordings = pkl.load(open(\"nnet_recordings.pkl\", \"rb\"))\n",
        "f_input = nnet_recordings[\"f_input\"]\n",
        "f_output = nnet_recordings[\"f_output\"]\n",
        "g_input = nnet_recordings[\"g_input\"]\n",
        "g_output = nnet_recordings[\"g_output\"]\n",
        "\n",
        "rstate = np.random.RandomState(0)\n",
        "sample_idx = rstate.choice(X_for_pysr.shape[0], size=3000, replace=False)\n",
        "\n",
        "print(sample_idx.shape)\n",
        "print(f_input[sample_idx])"
      ],
      "metadata": {
        "id": "offsK8Ul5Oqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Fit model_G for your SumNet.model_g\n",
        "---"
      ],
      "metadata": {
        "id": "fKj76oq65Oxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pysr import PySRRegressor\n",
        "\n",
        "model_G = PySRRegressor(\n",
        "    procs=4,\n",
        "    populations=8,\n",
        "    # ^ 2 populations per core, so one is always running.\n",
        "    population_size=50,\n",
        "    # ^ Slightly larger populations, for greater diversity.\n",
        "    ncyclesperiteration=500,\n",
        "    # ^ Generations between migrations.\n",
        "    niterations=10000000,  # Run forever: 10000000\n",
        "    early_stop_condition=(\n",
        "        \"stop_if(loss, complexity) = loss < 3e-5 && complexity < 280\"\n",
        "        # Stop early if we find a good and simple equation\n",
        "    ),\n",
        "    timeout_in_seconds=60*60*1,\n",
        "    # ^ Alternatively, stop after 'timeout_in_seconds'sec have passed.\n",
        "    maxsize=300,\n",
        "    # ^ Allow greater complexity.\n",
        "    maxdepth=12,\n",
        "    # ^ But, avoid deep nesting.\n",
        "    binary_operators=[\"*\", \"+\", \"-\", \"/\"],\n",
        "    unary_operators=[\"square\", \"cube\", \"exp\",\"sqrt\"],\n",
        "    constraints={\n",
        "        \"/\": (-1, 9),\n",
        "        \"square\": 9,\n",
        "        \"cube\": 9,\n",
        "        \"exp\": 9,\n",
        "        \"sqrt\": 9,\n",
        "    },\n",
        "    # ^ Limit the complexity within each argument.\n",
        "    # \"inv\": (-1, 9) states that the numerator has no constraint,\n",
        "    # but the denominator has a max complexity of 9.\n",
        "    # \"exp\": 9 simply states that `exp` can only have\n",
        "    # an expression of complexity 9 as input.\n",
        "    nested_constraints={\n",
        "        \"square\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"cube\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"exp\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"sqrt\": {\"square\": 0, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "    },\n",
        "    # ^ Nesting constraints on operators. For example,\n",
        "    # \"square(exp(x))\" is not allowed, since \"square\": {\"exp\": 0}.\n",
        "    complexity_of_operators={\"/\": 2, \"exp\": 3},\n",
        "    # ^ Custom complexity of particular operators.\n",
        "    complexity_of_constants=2,\n",
        "    # ^ Punish constants more than variables\n",
        "    select_k_features=N,\n",
        "    # ^ Train on only the 'k' most important features\n",
        "    progress=True,\n",
        "    # ^ Can set to false if printing to a file.\n",
        "    weight_randomize=0.1,\n",
        "    # ^ Randomize the tree much more frequently\n",
        "    cluster_manager=None,\n",
        "    # ^ Can be set to, e.g., \"slurm\", to run a slurm\n",
        "    # cluster. Just launch one script from the head node.\n",
        "    precision=64,\n",
        "    # ^ Higher precision calculations.\n",
        "    warm_start=True,\n",
        "    # ^ Start from where left off.\n",
        "    turbo=True,\n",
        "    # ^ Faster evaluation (experimental)\n",
        "    julia_project=None,\n",
        "    # ^ Can set to the path of a folder containing the\n",
        "    # \"SymbolicRegression.jl\" repo, for custom modifications.\n",
        "    update=False,\n",
        "    # ^ Don't update Julia packages\n",
        "    model_selection='accuracy',\n",
        "    parsimony=0.001, # Recommended Value: Target Loss / 10\n",
        ")\n",
        "\n",
        "model_G.fit(g_input[sample_idx], g_output[sample_idx])\n",
        "\n",
        "model_G.equations_[[\"complexity\", \"loss\", \"equation\"]]\n",
        "\n",
        "print(model_G.sympy())"
      ],
      "metadata": {
        "id": "IFWQ0mcl5O6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Fit model_G for your SumNet.model_f\n",
        "---\n",
        "Simply do the same for model_F, yet be careful that model_F don't need much times than that of model_G.\n",
        "\n",
        "It's just (1 input)-(1 output) model."
      ],
      "metadata": {
        "id": "Z-GDmDVg5PD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_F = PySRRegressor(\n",
        "    procs=4,\n",
        "    populations=8,\n",
        "    # ^ 2 populations per core, so one is always running.\n",
        "    population_size=50,\n",
        "    # ^ Slightly larger populations, for greater diversity.\n",
        "    ncyclesperiteration=500,\n",
        "    # ^ Generations between migrations.\n",
        "    niterations=10000000,  # Run forever: 10000000\n",
        "    early_stop_condition=(\n",
        "        \"stop_if(loss, complexity) = loss < 3e-5 && complexity < 90\"\n",
        "        # Stop early if we find a good and simple equation\n",
        "    ),\n",
        "    timeout_in_seconds=60*60*0.5,\n",
        "    # ^ Alternatively, stop after 'timeout_in_seconds'sec have passed.\n",
        "    maxsize=100,\n",
        "    # ^ Allow greater complexity.\n",
        "    maxdepth=15,\n",
        "    # ^ But, avoid deep nesting.\n",
        "    binary_operators=[\"*\", \"+\", \"-\", \"/\"],\n",
        "    unary_operators=[\"square\", \"cube\", \"exp\",\"sqrt\"],\n",
        "    constraints={\n",
        "        \"/\": (-1, 9),\n",
        "        \"square\": 9,\n",
        "        \"cube\": 9,\n",
        "        \"exp\": 9,\n",
        "        \"sqrt\": 9,\n",
        "    },\n",
        "    # ^ Limit the complexity within each argument.\n",
        "    # \"inv\": (-1, 9) states that the numerator has no constraint,\n",
        "    # but the denominator has a max complexity of 9.\n",
        "    # \"exp\": 9 simply states that `exp` can only have\n",
        "    # an expression of complexity 9 as input.\n",
        "    nested_constraints={\n",
        "        \"square\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"cube\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"exp\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"sqrt\": {\"square\": 0, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "    },\n",
        "    # ^ Nesting constraints on operators. For example,\n",
        "    # \"square(exp(x))\" is not allowed, since \"square\": {\"exp\": 0}.\n",
        "    complexity_of_operators={\"/\": 2, \"exp\": 3},\n",
        "    # ^ Custom complexity of particular operators.\n",
        "    complexity_of_constants=2,\n",
        "    # ^ Punish constants more than variables\n",
        "    select_k_features=None,\n",
        "    # ^ Train on only the 'k' most important features\n",
        "    progress=True,\n",
        "    # ^ Can set to false if printing to a file.\n",
        "    weight_randomize=0.1,\n",
        "    # ^ Randomize the tree much more frequently\n",
        "    cluster_manager=None,\n",
        "    # ^ Can be set to, e.g., \"slurm\", to run a slurm\n",
        "    # cluster. Just launch one script from the head node.\n",
        "    precision=64,\n",
        "    # ^ Higher precision calculations.\n",
        "    warm_start=True,\n",
        "    # ^ Start from where left off.\n",
        "    turbo=True,\n",
        "    # ^ Faster evaluation (experimental)\n",
        "    julia_project=None,\n",
        "    # ^ Can set to the path of a folder containing the\n",
        "    # \"SymbolicRegression.jl\" repo, for custom modifications.\n",
        "    update=False,\n",
        "    # ^ Don't update Julia packages\n",
        "    model_selection='accuracy',\n",
        "    parsimony=0.005 # Recommended Value: Target Loss / 10\n",
        ")\n",
        "\n",
        "model_F.fit(f_input[sample_idx], f_output[sample_idx])\n",
        "\n",
        "model_F.equations_[[\"complexity\", \"loss\", \"equation\"]]\n",
        "\n",
        "print(model_F.sympy())"
      ],
      "metadata": {
        "id": "agkKKA6x5PJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Print out the result\n",
        "---"
      ],
      "metadata": {
        "id": "aAAWWSeI8oDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_G.sympy())\n",
        "print(model_F.sympy())\n",
        "\n",
        "G_output = model_G.predict(X_train.reshape(-1,N))\n",
        "y_pred = model_F.predict(G_output.reshape(-1, 1))\n",
        "\n",
        "y_test = y_train.numpy()\n",
        "\n",
        "\n",
        "# for plot\n",
        "min_axis = min(np.amin(y_pred), np.amin(y_test))\n",
        "max_axis = max(np.amax(y_pred), np.amax(y_test))\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# R squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# COV\n",
        "cov = (np.std(y_pred - y_test) / np.mean(y_test))\n",
        "\n",
        "# Show Plot: Data vs Predicted Value\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(y_test, y_pred, alpha=0.2)\n",
        "plt.plot([min_axis, max_axis], [min_axis, max_axis], color='red', linestyle='--')  # y=x line\n",
        "plt.title(f\"Data vs Predicted (R^2: {r2:.5f}, COV: {cov:.5f})\")\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "#plt.xlim([0.4, 1])\n",
        "#plt.ylim([0.4, 1])\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(np.mean(y_pred/y_test))"
      ],
      "metadata": {
        "id": "8ZV9I6k38oLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ~Fin."
      ],
      "metadata": {
        "id": "-PvzemEN8oWQ"
      }
    }
  ]
}