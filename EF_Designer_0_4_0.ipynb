{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinkyoHan/NAS-SR/blob/main/EF_Designer_0_4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwdqhaK_E0Mf"
      },
      "source": [
        "# **E.F Designer**\n",
        "> Empirical Formula Designer\n",
        ">\n",
        "> **ver 0.4.0**\n",
        "---\n",
        "> Written by **Jinkyo Han**, OST, SNU NAOE\n",
        ">\n",
        "> * 38jinkyo@snu.ac.kr\n",
        ">\n",
        "> Supervised by **Do Kyun Kim**, OST, SNU NAOE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DNGxgVqBTLh"
      },
      "source": [
        "> ![Untitled.jpg](data:image/jpeg;base64,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)\n",
        ">\n",
        ">* # contact OST [here](https://ost.snu.ac.kr/home)\n",
        "\n",
        "---\n",
        "\n",
        "¬ Copyright (c) 2023 Jinkyo Han\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdsHs3iVBWGv"
      },
      "source": [
        "---\n",
        "\n",
        "# Chapter.0 Introduction\n",
        "\n",
        "---\n",
        "\n",
        "# Here are 4 main tasks herein\n",
        "\n",
        "1.   Generate nondimensionalized parameters from you dataset.\n",
        "> * during (1), task (2) could be applied\n",
        "\n",
        "2.   By random forest regression: select a few nondimensionalized parameters, which can most greatly represent the dataset.\n",
        "3.   Using NAS algorithm, generate the most-fitted & simple MLP model, **\"SumNET\"** (=MLP+MLP)\n",
        "> * During searching by NAS, NuSVR would estimate the model's performance, which described by Baker et al., 2017.\n",
        "> * visit [here](https://colab.research.google.com/github/JinkyoHan/JinkyoHan/blob/main/ann_designer_basic_1_0_0.ipynb) for NAS tutorials\n",
        "4.   By Symbolic Regression, based on GP method: automatically generate empirical formula, using PySR package by Cranmer et al., 2023.(which achieved the best score within *EmpiricalBench*)\n",
        "\n",
        "Tasks above could be figurized as:\n",
        "\n",
        "![intro_01.png](data:image/png;base64,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)\n",
        "\n",
        "# **[Reference]**\n",
        "\n",
        "># [NAS]\n",
        ">\n",
        "> Elsken, T., Metzen, J. H., & Hutter, F. (2019). Neural architecture search: A survey. The Journal of Machine Learning Research, 20(1), 1997-2017.\n",
        "* https://arxiv.org/abs/1808.05377\n",
        ">\n",
        "> Baker, B., Gupta, O., Raskar, R., & Naik, N. (2017). Accelerating neural architecture search using performance prediction. arXiv preprint arXiv:1705.10823.\n",
        "* https://arxiv.org/abs/1705.10823\n",
        "\n",
        "># [PySR]\n",
        ">\n",
        "> Cranmer, M. (2023). Interpretable machine learning for science with PySR and SymbolicRegression. jl. arXiv preprint arXiv:2305.01582.\n",
        "* https://arxiv.org/abs/2305.01582\n",
        ">\n",
        "> Cranmer, M., Sanchez Gonzalez, A., Battaglia, P., Xu, R., Cranmer, K., Spergel, D., & Ho, S. (2020). Discovering symbolic models from deep learning with inductive biases. Advances in Neural Information Processing Systems, 33, 17429-17442.\n",
        "* https://arxiv.org/abs/2006.11287\n",
        ">\n",
        "> Miles Cranmer Github\n",
        "* https://github.com/MilesCranmer/PySR\n",
        ">\n",
        "> Useful PySR tutorial by Miles Cranmer\n",
        "* https://colab.research.google.com/github/MilesCranmer/PySR/blob/master/examples/pysr_demo.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAzwsc1ZOHRS"
      },
      "source": [
        "---\n",
        "\n",
        "# Chapter.1 Nondim' Parameters\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Z-uPv6Bi__"
      },
      "source": [
        "# 1. Install Julia\n",
        "\n",
        "---\n",
        "\n",
        "![logo.svg](data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="320pt" height="200pt" version="1.1" viewBox="0 0 320 200"><g id="surface61"><path fill="#000" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 67.871094 164.3125 C 67.871094 171.847656 67.023438 177.933594 65.328125 182.566406 C 63.632812 187.203125 61.222656 190.800781 58.09375 193.363281 C 54.96875 195.925781 51.21875 197.640625 46.847656 198.507812 C 42.476562 199.371094 37.613281 199.804688 32.265625 199.804688 C 25.027344 199.804688 19.488281 198.675781 15.648438 196.414062 C 11.804688 194.152344 9.882812 191.441406 9.882812 188.273438 C 9.882812 185.636719 10.953125 183.414062 13.101562 181.605469 C 15.25 179.796875 18.132812 178.894531 21.75 178.894531 C 24.464844 178.894531 26.632812 179.628906 28.25 181.097656 C 29.871094 182.566406 31.210938 184.019531 32.265625 185.449219 C 33.46875 187.03125 34.488281 188.085938 35.316406 188.613281 C 36.144531 189.140625 36.898438 189.40625 37.578125 189.40625 C 39.007812 189.40625 40.101562 188.558594 40.855469 186.863281 C 41.609375 185.167969 41.984375 181.871094 41.984375 176.972656 L 41.984375 84.050781 L 67.871094 76.929688 L 67.871094 164.3125 M 104.738281 79.414062 L 104.738281 139.214844 C 104.738281 140.875 105.058594 142.4375 105.699219 143.90625 C 106.339844 145.375 107.226562 146.640625 108.355469 147.695312 C 109.488281 148.75 110.804688 149.597656 112.3125 150.238281 C 113.820312 150.878906 115.441406 151.199219 117.175781 151.199219 C 119.132812 151.199219 121.359375 150.101562 124.070312 148.203125 C 128.363281 145.195312 130.964844 143.128906 130.964844 140.683594 C 130.964844 140.097656 130.964844 79.414062 130.964844 79.414062 L 156.738281 79.414062 L 156.738281 164.3125 L 130.964844 164.3125 L 130.964844 156.398438 C 127.574219 159.261719 123.957031 161.558594 120.113281 163.292969 C 116.269531 165.027344 112.539062 165.894531 108.921875 165.894531 C 104.703125 165.894531 100.78125 165.195312 97.164062 163.800781 C 93.546875 162.40625 90.382812 160.503906 87.671875 158.09375 C 84.957031 155.683594 82.828125 152.855469 81.28125 149.613281 C 79.738281 146.375 78.964844 142.90625 78.964844 139.214844 L 78.964844 79.414062 L 104.738281 79.414062 M 192.882812 164.3125 L 167.222656 164.3125 L 167.222656 45.277344 L 192.882812 38.15625 L 192.882812 164.3125 M 203.601562 84.050781 L 229.375 76.929688 L 229.375 164.3125 L 203.601562 164.3125 L 203.601562 84.050781 M 283.226562 120.449219 C 280.738281 121.507812 278.230469 122.730469 275.707031 124.125 C 273.183594 125.519531 270.882812 127.046875 268.8125 128.703125 C 266.738281 130.359375 265.0625 132.132812 263.78125 134.015625 C 262.5 135.898438 261.859375 137.859375 261.859375 139.894531 C 261.859375 141.476562 262.066406 143.003906 262.480469 144.472656 C 262.894531 145.941406 263.480469 147.203125 264.234375 148.257812 C 264.988281 149.3125 265.816406 150.160156 266.722656 150.800781 C 267.625 151.441406 268.605469 151.761719 269.660156 151.761719 C 271.769531 151.761719 273.898438 151.121094 276.046875 149.839844 C 278.195312 148.558594 280.585938 146.941406 283.226562 144.980469 L 283.226562 120.449219 M 309.109375 164.3125 L 283.226562 164.3125 L 283.226562 157.527344 C 281.792969 158.734375 280.398438 159.847656 279.042969 160.863281 C 277.6875 161.878906 276.160156 162.765625 274.464844 163.519531 C 272.769531 164.273438 270.867188 164.855469 268.753906 165.273438 C 266.644531 165.6875 264.15625 165.894531 261.296875 165.894531 C 257.375 165.894531 253.851562 165.328125 250.726562 164.199219 C 247.597656 163.066406 244.941406 161.523438 242.757812 159.5625 C 240.570312 157.605469 238.894531 155.285156 237.726562 152.609375 C 236.558594 149.9375 235.972656 147.015625 235.972656 143.851562 C 235.972656 140.609375 236.59375 137.671875 237.839844 135.03125 C 239.082031 132.394531 240.777344 130.023438 242.925781 127.910156 C 245.074219 125.800781 247.578125 123.917969 250.441406 122.257812 C 253.304688 120.601562 256.378906 119.074219 259.65625 117.679688 C 262.933594 116.285156 266.34375 115.007812 269.886719 113.839844 C 273.425781 112.671875 276.933594 111.558594 280.398438 110.503906 L 283.226562 109.824219 L 283.226562 101.460938 C 283.226562 96.035156 282.1875 92.191406 280.117188 89.929688 C 278.042969 87.667969 275.273438 86.539062 271.808594 86.539062 C 267.738281 86.539062 264.910156 87.519531 263.328125 89.476562 C 261.746094 91.4375 260.953125 93.808594 260.953125 96.597656 C 260.953125 98.179688 260.785156 99.726562 260.445312 101.234375 C 260.109375 102.742188 259.523438 104.058594 258.695312 105.191406 C 257.867188 106.320312 256.679688 107.226562 255.132812 107.902344 C 253.589844 108.582031 251.648438 108.921875 249.3125 108.921875 C 245.695312 108.921875 242.757812 107.882812 240.496094 105.8125 C 238.234375 103.738281 237.105469 101.121094 237.105469 97.953125 C 237.105469 95.015625 238.101562 92.285156 240.097656 89.761719 C 242.097656 87.234375 244.789062 85.066406 248.183594 83.261719 C 251.574219 81.449219 255.492188 80.019531 259.9375 78.964844 C 264.382812 77.910156 269.09375 77.382812 274.066406 77.382812 C 280.171875 77.382812 285.429688 77.929688 289.839844 79.019531 C 294.246094 80.113281 297.882812 81.675781 300.746094 83.710938 C 303.609375 85.746094 305.71875 88.195312 307.074219 91.058594 C 308.433594 93.921875 309.109375 97.128906 309.109375 100.667969 L 309.109375 164.3125"/><path fill="#CB3C33" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 235.273438 55.089844 C 235.273438 64.757812 227.4375 72.589844 217.773438 72.589844 C 208.105469 72.589844 200.273438 64.757812 200.273438 55.089844 C 200.273438 45.425781 208.105469 37.589844 217.773438 37.589844 C 227.4375 37.589844 235.273438 45.425781 235.273438 55.089844"/><path fill="#4063D8" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 72.953125 55.089844 C 72.953125 64.757812 65.117188 72.589844 55.453125 72.589844 C 45.789062 72.589844 37.953125 64.757812 37.953125 55.089844 C 37.953125 45.425781 45.789062 37.589844 55.453125 37.589844 C 65.117188 37.589844 72.953125 45.425781 72.953125 55.089844"/><path fill="#9558B2" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 277.320312 55.089844 C 277.320312 64.757812 269.484375 72.589844 259.820312 72.589844 C 250.15625 72.589844 242.320312 64.757812 242.320312 55.089844 C 242.320312 45.425781 250.15625 37.589844 259.820312 37.589844 C 269.484375 37.589844 277.320312 45.425781 277.320312 55.089844"/><path fill="#389826" fill-opacity="1" fill-rule="nonzero" stroke="#eee" stroke-width="2" d="M 256.300781 18.671875 C 256.300781 28.335938 248.464844 36.171875 238.800781 36.171875 C 229.132812 36.171875 221.300781 28.335938 221.300781 18.671875 C 221.300781 9.007812 229.132812 1.171875 238.800781 1.171875 C 248.464844 1.171875 256.300781 9.007812 256.300781 18.671875"/></g></svg>)\n",
        "\n",
        "Julia is a new-born computational data science language, developed at 2012.\n",
        "\n",
        "PySR will fluently help you out with executing Julia at back-end, so no worries.\n",
        "\n",
        "Within Colab, order below would automatically install Julia.\n",
        "\n",
        "If you want to execute PySR at *VS Code* environment, please visit [here](https://julialang.org/downloads/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bctYJkhBNRF",
        "outputId": "cb00d0e9-b2b7-490a-80da-afce89d8e65c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 8,380 B/110 kB 8%] [Connecte\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [498 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [966 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,064 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [993 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,254 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,234 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 6,353 kB in 2s (3,459 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "33 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2 libpam-systemd libsystemd0\n",
            "  libudev1 systemd systemd-sysv\n",
            "The following packages will be upgraded:\n",
            "  base-files binutils binutils-common binutils-x86-64-linux-gnu cuda-keyring\n",
            "  cuda-toolkit-config-common file libbinutils libc-bin libc-dev-bin libc6\n",
            "  libc6-dev libc6-i386 libcap2 libctf-nobfd0 libctf0 libcups2 libflac-dev\n",
            "  libflac8 libldap-2.5-0 libmagic-mgc libmagic1 linux-libc-dev locales\n",
            "24 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "Need to get 19.1 MB of archives.\n",
            "After this operation, 50.2 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dev amd64 2.35-0ubuntu3.3 [2,100 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-keyring 1.1-1 [4,332 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-config-common 12.2.140-1 [16.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-dev-bin amd64 2.35-0ubuntu3.3 [20.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-libc-dev amd64 5.15.0-83.92 [1,330 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-i386 amd64 2.35-0ubuntu3.3 [2,837 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6 amd64 2.35-0ubuntu3.3 [3,235 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 base-files amd64 12ubuntu4.4 [62.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-bin amd64 2.35-0ubuntu3.3 [706 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcap2 amd64 1:2.44-1ubuntu0.22.04.1 [18.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 locales all 2.35-0ubuntu3.3 [4,245 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 file amd64 1:5.41-3ubuntu0.1 [21.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmagic1 amd64 1:5.41-3ubuntu0.1 [87.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmagic-mgc amd64 1:5.41-3ubuntu0.1 [257 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.3 [103 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf-nobfd0 amd64 2.38-4ubuntu2.3 [107 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.3 [2,327 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.3 [662 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.3 [3,190 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.3 [222 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcups2 amd64 2.4.1op1-1ubuntu4.6 [263 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libflac-dev amd64 1.3.3-2ubuntu0.2 [162 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libflac8 amd64 1.3.3-2ubuntu0.2 [111 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libldap-2.5-0 amd64 2.5.16+dfsg-0ubuntu0.22.04.1 [183 kB]\n",
            "Fetched 19.1 MB in 0s (39.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libc6-dev_2.35-0ubuntu3.3_amd64.deb ...\n",
            "Unpacking libc6-dev:amd64 (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Preparing to unpack .../libc-dev-bin_2.35-0ubuntu3.3_amd64.deb ...\n",
            "Unpacking libc-dev-bin (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Preparing to unpack .../linux-libc-dev_5.15.0-83.92_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (5.15.0-83.92) over (5.15.0-75.82) ...\n",
            "Preparing to unpack .../libc6-i386_2.35-0ubuntu3.3_amd64.deb ...\n",
            "Unpacking libc6-i386 (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Preparing to unpack .../libc6_2.35-0ubuntu3.3_amd64.deb ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Unpacking libc6:amd64 (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Setting up libc6:amd64 (2.35-0ubuntu3.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_12ubuntu4.4_amd64.deb ...\n",
            "Unpacking base-files (12ubuntu4.4) over (12ubuntu4.3) ...\n",
            "Setting up base-files (12ubuntu4.4) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-bin_2.35-0ubuntu3.3_amd64.deb ...\n",
            "Unpacking libc-bin (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Setting up libc-bin (2.35-0ubuntu3.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libcap2_1%3a2.44-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libcap2:amd64 (1:2.44-1ubuntu0.22.04.1) over (1:2.44-1build3) ...\n",
            "Setting up libcap2:amd64 (1:2.44-1ubuntu0.22.04.1) ...\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../00-locales_2.35-0ubuntu3.3_all.deb ...\n",
            "Unpacking locales (2.35-0ubuntu3.3) over (2.35-0ubuntu3.1) ...\n",
            "Preparing to unpack .../01-file_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
            "Unpacking file (1:5.41-3ubuntu0.1) over (1:5.41-3) ...\n",
            "Preparing to unpack .../02-libmagic1_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.41-3ubuntu0.1) over (1:5.41-3) ...\n",
            "Preparing to unpack .../03-libmagic-mgc_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.41-3ubuntu0.1) over (1:5.41-3) ...\n",
            "Preparing to unpack .../04-libctf0_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libctf0:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../05-libctf-nobfd0_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libctf-nobfd0:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../06-binutils-x86-64-linux-gnu_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../07-libbinutils_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../08-binutils_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../09-binutils-common_2.38-4ubuntu2.3_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.38-4ubuntu2.3) over (2.38-4ubuntu2.2) ...\n",
            "Preparing to unpack .../10-cuda-keyring_1.1-1_all.deb ...\n",
            "Unpacking cuda-keyring (1.1-1) over (1.0-1) ...\n",
            "Preparing to unpack .../11-cuda-toolkit-config-common_12.2.140-1_all.deb ...\n",
            "Unpacking cuda-toolkit-config-common (12.2.140-1) over (12.1.105-1) ...\n",
            "Preparing to unpack .../12-libcups2_2.4.1op1-1ubuntu4.6_amd64.deb ...\n",
            "Unpacking libcups2:amd64 (2.4.1op1-1ubuntu4.6) over (2.4.1op1-1ubuntu4.4) ...\n",
            "Preparing to unpack .../13-libflac-dev_1.3.3-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libflac-dev:amd64 (1.3.3-2ubuntu0.2) over (1.3.3-2ubuntu0.1) ...\n",
            "Preparing to unpack .../14-libflac8_1.3.3-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libflac8:amd64 (1.3.3-2ubuntu0.2) over (1.3.3-2ubuntu0.1) ...\n",
            "Preparing to unpack .../15-libldap-2.5-0_2.5.16+dfsg-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libldap-2.5-0:amd64 (2.5.16+dfsg-0ubuntu0.22.04.1) over (2.5.14+dfsg-0ubuntu0.22.04.2) ...\n",
            "Setting up cuda-toolkit-config-common (12.2.140-1) ...\n",
            "Setting up libmagic-mgc (1:5.41-3ubuntu0.1) ...\n",
            "Setting up binutils-common:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.41-3ubuntu0.1) ...\n",
            "Setting up linux-libc-dev:amd64 (5.15.0-83.92) ...\n",
            "Setting up libctf-nobfd0:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up file (1:5.41-3ubuntu0.1) ...\n",
            "Setting up locales (2.35-0ubuntu3.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n",
            "Setting up libldap-2.5-0:amd64 (2.5.16+dfsg-0ubuntu0.22.04.1) ...\n",
            "Setting up libflac8:amd64 (1.3.3-2ubuntu0.2) ...\n",
            "Setting up cuda-keyring (1.1-1) ...\n",
            "Setting up libcups2:amd64 (2.4.1op1-1ubuntu4.6) ...\n",
            "Setting up libc6-i386 (2.35-0ubuntu3.3) ...\n",
            "Setting up libbinutils:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up libc-dev-bin (2.35-0ubuntu3.3) ...\n",
            "Setting up libctf0:amd64 (2.38-4ubuntu2.3) ...\n",
            "Setting up libflac-dev:amd64 (1.3.3-2ubuntu0.2) ...\n",
            "Setting up libc6-dev:amd64 (2.35-0ubuntu3.3) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.3) ...\n",
            "Setting up binutils (2.38-4ubuntu2.3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "--2023-09-13 03:11:12--  https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz\n",
            "Resolving julialang-s3.julialang.org (julialang-s3.julialang.org)... 151.101.2.49, 151.101.66.49, 151.101.130.49, ...\n",
            "Connecting to julialang-s3.julialang.org (julialang-s3.julialang.org)|151.101.2.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146268149 (139M) [application/x-tar]\n",
            "Saving to: ‘julia-1.9.3-linux-x86_64.tar.gz’\n",
            "\n",
            "julia-1.9.3-linux-x 100%[===================>] 139.49M   204MB/s    in 0.7s    \n",
            "\n",
            "2023-09-13 03:11:13 (204 MB/s) - ‘julia-1.9.3-linux-x86_64.tar.gz’ saved [146268149/146268149]\n",
            "\n",
            "julia-1.9.3/\n",
            "julia-1.9.3/lib/\n",
            "julia-1.9.3/lib/libjulia.so.1.9\n",
            "julia-1.9.3/lib/libjulia.so\n",
            "julia-1.9.3/lib/libjulia.so.1\n",
            "julia-1.9.3/lib/julia/\n",
            "julia-1.9.3/lib/julia/libcholmod.so.3.0.14\n",
            "julia-1.9.3/lib/julia/libuv.so.2\n",
            "julia-1.9.3/lib/julia/libuv.so.2.0.0\n",
            "julia-1.9.3/lib/julia/libopenlibm.so.4.0\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so.0\n",
            "julia-1.9.3/lib/julia/libstdc++.so.6\n",
            "julia-1.9.3/lib/julia/libunwind.so\n",
            "julia-1.9.3/lib/julia/libccalltest.so.debug\n",
            "julia-1.9.3/lib/julia/libnghttp2.so.14\n",
            "julia-1.9.3/lib/julia/libatomic.so.1.2.0\n",
            "julia-1.9.3/lib/julia/libopenlibm.so.4\n",
            "julia-1.9.3/lib/julia/libquadmath.so\n",
            "julia-1.9.3/lib/julia/libklu.so.1\n",
            "julia-1.9.3/lib/julia/libgfortran.so.5.0.0\n",
            "julia-1.9.3/lib/julia/librbio.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so\n",
            "julia-1.9.3/lib/julia/libccolamd.so.2.9.6\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so.5.10.1\n",
            "julia-1.9.3/lib/julia/libssp.so.0\n",
            "julia-1.9.3/lib/julia/libopenblas64_.so.0\n",
            "julia-1.9.3/lib/julia/sys.so\n",
            "julia-1.9.3/lib/julia/libopenlibm.so\n",
            "julia-1.9.3/lib/julia/libgmpxx.so.4.6.1\n",
            "julia-1.9.3/lib/julia/libz.so.1.2.13\n",
            "julia-1.9.3/lib/julia/libbtf.so.1\n",
            "julia-1.9.3/lib/julia/libgit2.so.1.5\n",
            "julia-1.9.3/lib/julia/libstdc++.so.6.0.30\n",
            "julia-1.9.3/lib/julia/libldl.so.2\n",
            "julia-1.9.3/lib/julia/libssh2.so.1.0.1\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so.1\n",
            "julia-1.9.3/lib/julia/libunwind.so.8\n",
            "julia-1.9.3/lib/julia/libgmpxx.so.4\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so.5.4.0\n",
            "julia-1.9.3/lib/julia/libz.so.1\n",
            "julia-1.9.3/lib/julia/libLLVM-14jl.so\n",
            "julia-1.9.3/lib/julia/libgmp.so.10\n",
            "julia-1.9.3/lib/julia/libgomp.so.1\n",
            "julia-1.9.3/lib/julia/libcolamd.so\n",
            "julia-1.9.3/lib/julia/libgmp.so.10.4.1\n",
            "julia-1.9.3/lib/julia/libklu.so.1.3.8\n",
            "julia-1.9.3/lib/julia/libgcc_s.so.1\n",
            "julia-1.9.3/lib/julia/libccolamd.so\n",
            "julia-1.9.3/lib/julia/libLLVM.so\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so.0.11.2\n",
            "julia-1.9.3/lib/julia/libspqr.so.2\n",
            "julia-1.9.3/lib/julia/libunwind.so.8.0.1\n",
            "julia-1.9.3/lib/julia/libcamd.so\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so.1.9\n",
            "julia-1.9.3/lib/julia/libllvmcalltest.so\n",
            "julia-1.9.3/lib/julia/libatomic.so\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so.1\n",
            "julia-1.9.3/lib/julia/libquadmath.so.0.0.0\n",
            "julia-1.9.3/lib/julia/libssh2.so\n",
            "julia-1.9.3/lib/julia/libbtf.so.1.2.6\n",
            "julia-1.9.3/lib/julia/libldl.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so.7\n",
            "julia-1.9.3/lib/julia/libssh2.so.1\n",
            "julia-1.9.3/lib/julia/libgit2.so.1.5.0\n",
            "julia-1.9.3/lib/julia/libstdc++.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so.14\n",
            "julia-1.9.3/lib/julia/libgfortran.so\n",
            "julia-1.9.3/lib/julia/libcamd.so.2\n",
            "julia-1.9.3/lib/julia/libgit2.so\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so\n",
            "julia-1.9.3/lib/julia/libcholmod.so.3\n",
            "julia-1.9.3/lib/julia/libccolamd.so.2\n",
            "julia-1.9.3/lib/julia/libmbedx509.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libklu.so\n",
            "julia-1.9.3/lib/julia/libumfpack.so\n",
            "julia-1.9.3/lib/julia/libgfortran.so.5\n",
            "julia-1.9.3/lib/julia/libpcre2-8.so\n",
            "julia-1.9.3/lib/julia/libbtf.so\n",
            "julia-1.9.3/lib/julia/libjulia-internal.so\n",
            "julia-1.9.3/lib/julia/libz.so\n",
            "julia-1.9.3/lib/julia/libcolamd.so.2.9.6\n",
            "julia-1.9.3/lib/julia/libccalltest.so\n",
            "julia-1.9.3/lib/julia/libsuitesparseconfig.so.5\n",
            "julia-1.9.3/lib/julia/libcurl.so\n",
            "julia-1.9.3/lib/julia/libopenblas64_.so\n",
            "julia-1.9.3/lib/julia/libgomp.so.1.0.0\n",
            "julia-1.9.3/lib/julia/libmpfr.so.6\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so.1.9\n",
            "julia-1.9.3/lib/julia/libnghttp2.so\n",
            "julia-1.9.3/lib/julia/libamd.so.2.4.6\n",
            "julia-1.9.3/lib/julia/libmpfr.so\n",
            "julia-1.9.3/lib/julia/libcholmod.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so\n",
            "julia-1.9.3/lib/julia/libmbedtls.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libssp.so.0.0.0\n",
            "julia-1.9.3/lib/julia/libgmp.so\n",
            "julia-1.9.3/lib/julia/libmbedcrypto.so.2.28.2\n",
            "julia-1.9.3/lib/julia/libmbedx509.so.1\n",
            "julia-1.9.3/lib/julia/libumfpack.so.5\n",
            "julia-1.9.3/lib/julia/libcurl.so.4.8.0\n",
            "julia-1.9.3/lib/julia/libcamd.so.2.4.6\n",
            "julia-1.9.3/lib/julia/librbio.so.2\n",
            "julia-1.9.3/lib/julia/libgmpxx.so\n",
            "julia-1.9.3/lib/julia/libspqr.so\n",
            "julia-1.9.3/lib/julia/libblastrampoline.so.5\n",
            "julia-1.9.3/lib/julia/libmbedx509.so\n",
            "julia-1.9.3/lib/julia/libamd.so.2\n",
            "julia-1.9.3/lib/julia/libssp.so\n",
            "julia-1.9.3/lib/julia/libcurl.so.4\n",
            "julia-1.9.3/lib/julia/libmpfr.so.6.1.1\n",
            "julia-1.9.3/lib/julia/libatomic.so.1\n",
            "julia-1.9.3/lib/julia/libldl.so.2.2.6\n",
            "julia-1.9.3/lib/julia/librbio.so.2.2.6\n",
            "julia-1.9.3/lib/julia/libdSFMT.so\n",
            "julia-1.9.3/lib/julia/libquadmath.so.0\n",
            "julia-1.9.3/lib/julia/libumfpack.so.5.7.9\n",
            "julia-1.9.3/lib/julia/libnghttp2.so.14.22.0\n",
            "julia-1.9.3/lib/julia/libamd.so\n",
            "julia-1.9.3/lib/julia/libopenblas64_.0.3.21.so\n",
            "julia-1.9.3/lib/julia/libgomp.so\n",
            "julia-1.9.3/lib/julia/libuv.so\n",
            "julia-1.9.3/lib/julia/libjulia-codegen.so\n",
            "julia-1.9.3/lib/julia/libspqr.so.2.0.9\n",
            "julia-1.9.3/lib/julia/libcolamd.so.2\n",
            "julia-1.9.3/share/\n",
            "julia-1.9.3/share/doc/\n",
            "julia-1.9.3/share/doc/julia/\n",
            "julia-1.9.3/share/doc/julia/html/\n",
            "julia-1.9.3/share/doc/julia/html/en/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/cover-splash.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themeswap.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/warner.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/documenter.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/cover.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/julia.ico\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/search.js\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/custom.sty\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo.svg\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/preamble.tex\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/documenter-light.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/themes/documenter-dark.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/julia-manual.css\n",
            "julia-1.9.3/share/doc/julia/html/en/assets/logo-dark.svg\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/missing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/environment-variables.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/style-guide.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/documentation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/handling-operating-system-variation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/metaprogramming.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/multi-threading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/unicode-input.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/complex-and-rational-numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/embedding.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/distributed-computing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/strings.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/variables.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/faq.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/types.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/asynchronous-programming.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/methods.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/running-external-programs.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/getting-started.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/noteworthy-differences.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/mathematical-operations.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/integers-and-floating-point-numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/variables-and-scoping.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/functions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/calling-c-and-fortran-code.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/command-line-interface.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/stacktraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/control-flow.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/parallel-computing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/modules.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/code-loading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/networking-and-streams.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/interfaces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/workflow-tips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/conversion-and-promotion.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/profile.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/constructors.html\n",
            "julia-1.9.3/share/doc/julia/html/en/manual/performance-tips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LibGit2.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LazyArtifacts.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/REPL.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Profile.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Statistics.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Mmap.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Random.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Downloads.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Logging.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Future.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Test.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/DelimitedFiles.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Sockets.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Artifacts.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SHA.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LinearAlgebra.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/UUIDs.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/CRC32c.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Tar.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/TOML.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Unicode.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/NetworkOptions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Serialization.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Libdl.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/FileWatching.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/InteractiveUtils.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Markdown.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/ArgTools.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Dates.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Printf.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SharedArrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Base64.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/LibCURL.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Pkg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/SparseArrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/stdlib/Distributed.html\n",
            "julia-1.9.3/share/doc/julia/html/en/index.html\n",
            "julia-1.9.3/share/doc/julia/html/en/search_index.js\n",
            "julia-1.9.3/share/doc/julia/html/en/NEWS.html\n",
            "julia-1.9.3/share/doc/julia/html/en/search.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/cartesian.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/object.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/subarrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/locks.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/linux.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/arm.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/freebsd.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/build.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/windows.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/macos.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/build/distributing.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/gc.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/reflection.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/init.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/compiler.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/offset-arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/types.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/isbitsunionarrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/probes.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/valgrind.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/stdio.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/callconv.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/inference.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/debuggingtips.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/functions.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/ssair.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/llvm.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/gc-sa.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/require.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/EscapeAnalysis.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/eval.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/meta.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/sysimg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/pkgimg.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/backtraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/ast.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/boundscheck.html\n",
            "julia-1.9.3/share/doc/julia/html/en/devdocs/sanitizers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/\n",
            "julia-1.9.3/share/doc/julia/html/en/base/multi-threading.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/collections.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/arrays.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/strings.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/base.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/parallel.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/iterators.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/sort.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/punctuation.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/libc.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/stacktraces.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/io-network.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/constants.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/c.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/math.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/numbers.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/file.html\n",
            "julia-1.9.3/share/doc/julia/html/en/base/simd-types.html\n",
            "julia-1.9.3/share/man/\n",
            "julia-1.9.3/share/man/man1/\n",
            "julia-1.9.3/share/man/man1/julia.1\n",
            "julia-1.9.3/share/appdata/\n",
            "julia-1.9.3/share/appdata/julia.appdata.xml\n",
            "julia-1.9.3/share/applications/\n",
            "julia-1.9.3/share/applications/julia.desktop\n",
            "julia-1.9.3/share/julia/\n",
            "julia-1.9.3/share/julia/julia-config.jl\n",
            "julia-1.9.3/share/julia/base.cache\n",
            "julia-1.9.3/share/julia/cert.pem\n",
            "julia-1.9.3/share/julia/compiled/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Statistics/ERcPL_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/libLLVM_jll/BYxGh_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/dSFMT_jll/48Kea_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLD_jll/ZHBMJ_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse_jll/ME9At_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUV_jll/MMpyl_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MbedTLS_jll/u5NEn_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/Zlib_jll/xjq3Q_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/MPFR_jll/NBMLS_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/GMP_jll/1Lisu_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LLVMLibUnwind_jll/6CF5v_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibSSH2_jll/K6mup_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/DelimitedFiles/dlKZm_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibUnwind_jll/CxrEE_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/SuiteSparse/X9Gex_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/OpenLibm_jll/ToVO1_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KtHpY.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/PCRE2_jll/8i0KO_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KtHpY.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KhnTo.so\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KhnTo.ji\n",
            "julia-1.9.3/share/julia/compiled/v1.9/LibGit2_jll/nfCpg_KtHpY.so\n",
            "julia-1.9.3/share/julia/stdlib/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/src/SharedArrays.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SharedArrays/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/src/Statistics.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Statistics/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/src/libLLVM_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libLLVM_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/src/LibCURL_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/src/Mmap.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Mmap/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/Logging.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/src/ConsoleLogger.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Logging/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/src/dSFMT_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/dSFMT_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/src/LLD_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLD_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/IPAddr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/PipeServer.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/Sockets.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/src/addrinfo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/nettest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Sockets/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/TOML.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/src/print.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/values.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/toml_test.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/readme.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/error_printing.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/utils/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/utils/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/print.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/invalids.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/docs/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/tune.json\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/files/Registry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/TOML/benchmark/benchmarks.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/src/Artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/refresh_artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Artifacts/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/hessenberg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/symmetriceigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lapack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/schur.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lq.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/uniformscaling.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/ldlt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/diagonal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/matmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/exceptions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/givens.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/structuredbroadcast.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/symmetric.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/lbt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/generic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/triangular.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/tridiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/blas.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bidiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bunchkaufman.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/dense.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/factorization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/LinearAlgebra.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/qr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/special.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/cholesky.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/transpose.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/bitarray.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/src/svd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/hessenberg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/ambiguous_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/trickyarithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lapack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/schur.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lq.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/eigen.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/uniformscaling.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/ldlt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/diagonal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/matmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/givens.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/structuredbroadcast.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/symmetric.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/lu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/pinv.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/testutils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/generic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/triangular.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/tridiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/blas.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/bidiag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/bunchkaufman.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/dense.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/factorization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/qr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/special.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/cholesky.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/adjtrans.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/addmul.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/test/svd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LinearAlgebra/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/InteractiveUtils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/editless.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/macros.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/codeview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/src/clipboard.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/test/highlighting.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/InteractiveUtils/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Versions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/API.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/argument_parsers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/REPLMode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/command_declarations.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/REPLMode/completions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/GitTools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/project.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/Registry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Registry/registry_instance.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/HistoricalStdlibs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Operations.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/BinaryPlatforms_compat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/maxsum.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/fieldvalues.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/graphtype.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/versionweights.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Resolve/Resolve.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/PlatformEngines.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/MiniProgressBars.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/manifest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/src/Artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/CHANGELOG.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/LazilyInitializedFields/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/LazilyInitializedFields/LazilyInitializedFields.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/ext/update.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v3.0_unknown/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v1.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/formats/v2.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/noproject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/noproject/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_path.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/ambiguous_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_tree_sha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/missing_entry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_repo_url.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/inconsistent_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_field.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/missing_dep.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/inconsistent_dep2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_tree_sha2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/duplicate_deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/parse_error.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/string_pinned.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_pinned.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/malformed_repo_rev.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/bad/bad_dep_name.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/unpruned/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/not_unique_names.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifest/good/simple.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/misc.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolve.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/force_latest_compatible_version.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/unlisted_targets.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/targets_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/target_entry_twice.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_unlisted.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/repeated_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_version2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/deps_is_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_deps_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_uuid2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/parse_error.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/compat_entry_not_a_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/bad_version.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/repeated_extras_uuid.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/bad/target_entry_not_a_list.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/simple.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/pkg.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project/good/withcompat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/subdir.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/manifests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/api.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/platformengines.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/NastyGenerator.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/extensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/repl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/coverage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/coverage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/new.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/sandbox.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/FakeTerminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/incorrect_sha256.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/doesnotexist.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/incorrect_gitsha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/not_a_table.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/artifacts/bad/no_gitsha.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolve_utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/project_manifest.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/resolvedata.tar.gz\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/registry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredUUID/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/src/TestTargetCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTargetCompat/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/src/BigProject.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/src/SubModule2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule2/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/src/SubModule.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/SubModule/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/src/RecursiveDep.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/src/RecursiveDep2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BigProject/RecursiveDep2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SandboxFallback2/dev/Unregistered/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveSemver/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/src/Sandbox_PreserveTestDeps.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreserveTestDeps/dev/Foo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/src/TOML.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TOML/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/NotUpdated/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/src/ArtifactOverrideLoading.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactOverrideLoading/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/src/ExtraDirectDep.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtraDirectDep/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/src/DependsOnExample.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/DependsOnExample/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveAll/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveNone/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/src/TestDepTrackingPath.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingPath/test/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/src/SameNameDifferentUUID.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/src/Example.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SameNameDifferentUUID/dev/Example/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/src/UnregisteredWithProject.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/UnregisteredWithProject/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatExtras/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatExtras/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/src/Unpruned.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Unpruned/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/src/OldOnly2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/src/OldOnly1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/OldOnly1/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/src/BothOldAndNew.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/BothOldAndNew/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/src/DirectDepWithoutCompatEntry.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/DirectDepWithoutCompatEntry/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/src/NewOnly.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/force_latest_compatible_version/NewOnly/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/src/PackageWithDependency.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/PackageWithDependency/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTarget/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestTarget/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/src/BuildProjectFixedDeps.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BuildProjectFixedDeps/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/src/TestSubgraphTrackingRepo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestSubgraphTrackingRepo/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/src/TestDepTrackingRepo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepTrackingRepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/src/BasicTestTarget.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicTestTarget/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Status/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/src/SimplePackage.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/Project2.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/SimplePackage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_module/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_module/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/JuliaArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/julia_artifacts_test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/pkg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactTOMLSearch/sub_package/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/src/FailBuild.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/FailBuild/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/src/SubDir.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/MainRepo/SubDir/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/src/AugmentedPlatform.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/platform_augmentation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/AugmentedPlatform/.pkg/select_artifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/src/BasicSandbox.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicSandbox/deps/build.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/src/x2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/src/A.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/A/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/src/C.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/C/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/src/D.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/D/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/A/dev/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/src/Sandbox_PreservePreferences.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/LocalPreferences.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Sandbox_PreservePreferences/dev/Foo/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/src/x3.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x3/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/src/TestFailure.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestFailure/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/src/TestArguments.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestArguments/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/src/ArtifactInstallation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ArtifactInstallation/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/src/Example.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/Example/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/src/BasicCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/BasicCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/src/A.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/src/C.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/C/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/src/D.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/D/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/monorepo/packages/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/src/EmptyPackage.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/EmptyPackage/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Package.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/WeakCompat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Versions.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/Deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasExtensions/WeakDeps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Package.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Compat.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Versions.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/H/HasDepWithExtensions/Deps.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/ExtensionRegistry/Registry.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/ext/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/ext/OffsetArraysExt.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/src/HasDepWithExtensions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ExtensionExamples/HasDepWithExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/src/TestDepCompat.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TestDepCompat/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/src/Foo.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/src/Unregistered.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/TransferSubgraph/dev/Unregistered/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/CompatOutOfSync/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/src/x1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/x1/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ShouldPreserveDirect/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/src/ActiveProjectInTestSubgraph.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/src/B.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/test/test_packages/ActiveProjectInTestSubgraph/dev/B/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/logo.png\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/assets/custom.css\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/managing-packages.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/compatibility.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/environments.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/basedocs.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/glossary.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/getting-started.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/creating-packages.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/registries.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/artifacts.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/api.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/src/toml-files.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/NEWS-update.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/CODEOWNERS\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.github/workflows/test.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Pkg/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/Profile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/src/Allocs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/allocs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Profile/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/src/CRC32c.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CRC32c/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/src/MozillaCACerts_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MozillaCACerts_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/extract.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/Tar.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/header.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/src/create.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/data/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/data/LF10-fragment.tar\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/git_tools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/perf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/test/perf/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Tar/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/src/SuiteSparse_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/src/LazyArtifacts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/Artifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LazyArtifacts/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/src/LibUV_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUV_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/src/UUIDs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/UUIDs/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/src/Printf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Printf/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/src/OpenBLAS_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenBLAS_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Downloads.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Easy.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Curl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/src/Curl/Multi.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/json.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Downloads/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/src/Future.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Future/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/src/libblastrampoline_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/libblastrampoline_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/src/MbedTLS_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MbedTLS_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/src/Zlib_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Zlib_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/constants.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha3.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/SHA.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/base_functions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha1.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/sha2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/common.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/src/hmac.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/constants.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/perf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/PULL_REQUEST_TEMPLATE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/workflows/CI.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SHA/.github/ISSUE_TEMPLATE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/src/MPFR_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/MPFR_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/src/nghttp2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/nghttp2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/decode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/encode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/Base64.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/src/buffer.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Base64/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/LineEdit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/REPLCompletions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/latex_symbols.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/options.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/emoji_symbols.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/Terminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/MultiSelectMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/TerminalMenus.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/AbstractMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/Pager.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/util.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/TerminalMenus/RadioMenu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/REPL.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/src/docview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/lineedit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/replcompletions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/repl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/pager.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/old_multiselect_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/legacytests/old_radio_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/radio_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/multiselect_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/dynamic_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/TerminalMenus/multiselect_with_skip_menu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/FakeTerminals.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/test/docview.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/REPL/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/src/GMP_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/GMP_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/NetworkOptions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/ssh_options.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/ca_roots.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/src/verify_host.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/setup.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/NetworkOptions/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/src/ArgTools.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/CompatHelper.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/ArgTools/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/process_messages.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/clusterserialize.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/managers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/messages.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/macros.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/cluster.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/pmap.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/remotecall.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/Distributed.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/src/workerpool.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/distributed_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/topology.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/splitrange.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/managers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/includefile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Distributed/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/ranges.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/query.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/periods.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/adjusters.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/Dates.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/rounding.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/arithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/conversions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/io.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/src/accessors.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/ranges.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/query.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/periods.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/adjusters.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/rounding.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/arithmetic.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/conversions.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/io.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/test/accessors.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Dates/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/src/Unicode.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Unicode/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/misc.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/Random.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/XoshiroSimd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/Xoshiro.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/RNGs.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/generation.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/DSFMT.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/src/normal.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Random/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/src/Libdl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Libdl/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/src/LLVMLibUnwind_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LLVMLibUnwind_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/src/Serialization.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Serialization/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/src/LibSSH2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibSSH2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/src/DelimitedFiles.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/LICENSE\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/DelimitedFiles/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/IPython/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/IPython/IPython.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/util.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/parse/parse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/Common.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/inline.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Common/block.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Markdown.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/interp.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/Julia/Julia.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/latex.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/render.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/terminal/formatting.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/html.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/plain.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/rst.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/render/rich.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/table.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/src/GitHub/GitHub.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Markdown/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/gen/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/gen/generate.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_common_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_exports_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_curl_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/Mime_ext.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/lC_defines_h.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/src/LibCURL.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.gitignore\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/ssl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/TagBot.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibCURL/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/src/LibUnwind_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibUnwind_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/src/SuiteSparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/devcontainer.json\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.devcontainer/Dockerfile\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SuiteSparse/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/src/p7zip_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/p7zip_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/src/OpenLibm_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/OpenLibm_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/src/CompilerSupportLibraries_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/CompilerSupportLibraries_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/pidfile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/src/FileWatching.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/pidfile.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/FileWatching/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/generator.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/generator.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/gen/Manifest.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparsevector.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/higherorderfns.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/deprecated.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-apple-darwin14.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-w64-mingw32.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/armv7l-linux-musleabihf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/x86_64-unknown-freebsd.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/armv7l-linux-gnueabihf.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-w64-mingw32.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-linux-musl.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/aarch64-apple-darwin20.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/powerpc64le-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/lib/i686-linux-gnu.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/LibSuiteSparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/cholmod.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/spqr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/umfpack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/solvers/solvers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/linalg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/abstractsparse.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/SparseArrays.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparsematrix.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/sparseconvert.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/src/readonly.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.ci/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.ci/test_and_change_uuid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/simplesmatrix.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsematrix_constructors_indexing.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsevector.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/fixed.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/ambiguous.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/forbidproperties.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/threads.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/higherorderfns.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/allowscalar.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/cholmod.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/linalg.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/spqr.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/umfpack.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/matrices/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/matrices/stiffness_sym_indef\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/issues.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/sparsematrix_ops.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/test/linalg_solvers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/README.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/src/solvers.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/docs/make.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/LICENSE.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/ci.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.github/workflows/backport.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/SparseArrays/.codecov.yml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/src/PCRE2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/PCRE2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/StdlibArtifacts.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/src/LibGit2_jll.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2_jll/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/logging.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/src/Test.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/test_pop_testset_exec.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/nothrow_testset.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/Test/docs/src/index.md\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/gitcredential.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/config.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/utils.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/rebase.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/tag.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/status.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/LibGit2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/merge.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/index.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/commit.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/error.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/reference.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/repository.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/diff.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/blame.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/types.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/oid.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/consts.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/strarray.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/blob.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/callbacks.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/tree.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/remote.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/walker.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/src/signature.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/Project.toml\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2-helpers.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/testgroups\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/bad_ca_roots.pem\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/online-tests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid-passphrase.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/invalid.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid-passphrase\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/invalid\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid.pub\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/keys/valid\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/known_hosts\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/bad_ca_roots.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/online.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/libgit2-tests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/test/runtests.jl\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/src/\n",
            "julia-1.9.3/share/julia/stdlib/v1.9/LibGit2/docs/src/index.md\n",
            "julia-1.9.3/share/julia/test/\n",
            "julia-1.9.3/share/julia/test/depot/\n",
            "julia-1.9.3/share/julia/test/depot/packages/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/src/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Baz/81oLe/src/Baz.jl\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/src/\n",
            "julia-1.9.3/share/julia/test/depot/packages/Foo/I05Qq/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/vecelement.jl\n",
            "julia-1.9.3/share/julia/test/specificity.jl\n",
            "julia-1.9.3/share/julia/test/env.jl\n",
            "julia-1.9.3/share/julia/test/loading.jl\n",
            "julia-1.9.3/share/julia/test/manifest/\n",
            "julia-1.9.3/share/julia/test/manifest/v1.0/\n",
            "julia-1.9.3/share/julia/test/manifest/v1.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/manifest/v2.0/\n",
            "julia-1.9.3/share/julia/test/manifest/v2.0/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/sysinfo.jl\n",
            "julia-1.9.3/share/julia/test/version.jl\n",
            "julia-1.9.3/share/julia/test/meta.jl\n",
            "julia-1.9.3/share/julia/test/ranges.jl\n",
            "julia-1.9.3/share/julia/test/subtype.jl\n",
            "julia-1.9.3/share/julia/test/opaque_closure.jl\n",
            "julia-1.9.3/share/julia/test/reinterpretarray.jl\n",
            "julia-1.9.3/share/julia/test/osutils.jl\n",
            "julia-1.9.3/share/julia/test/deprecation_exec.jl\n",
            "julia-1.9.3/share/julia/test/triplequote.jl\n",
            "julia-1.9.3/share/julia/test/clangsa/\n",
            "julia-1.9.3/share/julia/test/clangsa/ImplicitAtomicsTest.c\n",
            "julia-1.9.3/share/julia/test/clangsa/.gitignore\n",
            "julia-1.9.3/share/julia/test/clangsa/GCPushPop.cpp\n",
            "julia-1.9.3/share/julia/test/clangsa/MissingRoots.c\n",
            "julia-1.9.3/share/julia/test/clangsa/lit.cfg.py\n",
            "julia-1.9.3/share/julia/test/clangsa/Makefile\n",
            "julia-1.9.3/share/julia/test/misc.jl\n",
            "julia-1.9.3/share/julia/test/ccall.jl\n",
            "julia-1.9.3/share/julia/test/.gitignore\n",
            "julia-1.9.3/share/julia/test/stack_overflow.jl\n",
            "julia-1.9.3/share/julia/test/backtrace.jl\n",
            "julia-1.9.3/share/julia/test/profile_spawnmany_exec.jl\n",
            "julia-1.9.3/share/julia/test/smallarrayshrink.jl\n",
            "julia-1.9.3/share/julia/test/project/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithDeps/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/src/SomePackage.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/SomePackage/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensionsv2/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/ext/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/ext/Extension2.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions_v2.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/EnvWithHasExtensions/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/src/HasExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/Extension.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/ExtensionFolder/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/ext/ExtensionFolder/ExtensionFolder.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/src/HasDepWithExtensions.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/HasDepWithExtensions.jl/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/src/ExtDep2.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep2/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/src/ExtDep.jl\n",
            "julia-1.9.3/share/julia/test/project/Extensions/ExtDep.jl/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/project/deps/\n",
            "julia-1.9.3/share/julia/test/project/deps/Qux.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Bar/src/Bar.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/SubFoo1.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/subdir/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/src/subdir/SubFoo2.jl\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo1/Project.toml\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/src/\n",
            "julia-1.9.3/share/julia/test/project/deps/Foo2.jl/src/Foo.jl\n",
            "julia-1.9.3/share/julia/test/threads_exec.jl\n",
            "julia-1.9.3/share/julia/test/iobuffer.jl\n",
            "julia-1.9.3/share/julia/test/strings/\n",
            "julia-1.9.3/share/julia/test/strings/search.jl\n",
            "julia-1.9.3/share/julia/test/strings/util.jl\n",
            "julia-1.9.3/share/julia/test/strings/types.jl\n",
            "julia-1.9.3/share/julia/test/strings/io.jl\n",
            "julia-1.9.3/share/julia/test/strings/basic.jl\n",
            "julia-1.9.3/share/julia/test/reduce.jl\n",
            "julia-1.9.3/share/julia/test/gcext/\n",
            "julia-1.9.3/share/julia/test/gcext/.gitignore\n",
            "julia-1.9.3/share/julia/test/gcext/gcext.c\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/src/\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/src/ForeignObjSerialization.jl\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/ForeignObjSerialization/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/gcext-test.jl\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/src/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/src/Foreign.jl\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/deps/\n",
            "julia-1.9.3/share/julia/test/gcext/Foreign/deps/foreignlib.c\n",
            "julia-1.9.3/share/julia/test/gcext/Makefile\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/src/\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/src/DependsOnForeign.jl\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/Project.toml\n",
            "julia-1.9.3/share/julia/test/gcext/DependsOnForeign/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/gcext/LocalTest.jl\n",
            "julia-1.9.3/share/julia/test/hashing.jl\n",
            "julia-1.9.3/share/julia/test/sorting.jl\n",
            "julia-1.9.3/share/julia/test/missing.jl\n",
            "julia-1.9.3/share/julia/test/interpreter.jl\n",
            "julia-1.9.3/share/julia/test/filesystem.jl\n",
            "julia-1.9.3/share/julia/test/functional.jl\n",
            "julia-1.9.3/share/julia/test/complex.jl\n",
            "julia-1.9.3/share/julia/test/bitset.jl\n",
            "julia-1.9.3/share/julia/test/docs.jl\n",
            "julia-1.9.3/share/julia/test/download_exec.jl\n",
            "julia-1.9.3/share/julia/test/ryu.jl\n",
            "julia-1.9.3/share/julia/test/sets.jl\n",
            "julia-1.9.3/share/julia/test/reducedim.jl\n",
            "julia-1.9.3/share/julia/test/math.jl\n",
            "julia-1.9.3/share/julia/test/mpfr.jl\n",
            "julia-1.9.3/share/julia/test/ordering.jl\n",
            "julia-1.9.3/share/julia/test/spawn.jl\n",
            "julia-1.9.3/share/julia/test/syntax.jl\n",
            "julia-1.9.3/share/julia/test/keywordargs.jl\n",
            "julia-1.9.3/share/julia/test/offsetarray.jl\n",
            "julia-1.9.3/share/julia/test/reflection.jl\n",
            "julia-1.9.3/share/julia/test/corelogging.jl\n",
            "julia-1.9.3/share/julia/test/asyncmap.jl\n",
            "julia-1.9.3/share/julia/test/dict.jl\n",
            "julia-1.9.3/share/julia/test/operators.jl\n",
            "julia-1.9.3/share/julia/test/namedtuple.jl\n",
            "julia-1.9.3/share/julia/test/choosetests.jl\n",
            "julia-1.9.3/share/julia/test/read.jl\n",
            "julia-1.9.3/share/julia/test/threadpool_latency.jl\n",
            "julia-1.9.3/share/julia/test/ambiguous.jl\n",
            "julia-1.9.3/share/julia/test/channels.jl\n",
            "julia-1.9.3/share/julia/test/exceptions.jl\n",
            "julia-1.9.3/share/julia/test/enums.jl\n",
            "julia-1.9.3/share/julia/test/threads.jl\n",
            "julia-1.9.3/share/julia/test/error.jl\n",
            "julia-1.9.3/share/julia/test/precompile.jl\n",
            "julia-1.9.3/share/julia/test/generic_map_tests.jl\n",
            "julia-1.9.3/share/julia/test/iostream.jl\n",
            "julia-1.9.3/share/julia/test/download.jl\n",
            "julia-1.9.3/share/julia/test/int.jl\n",
            "julia-1.9.3/share/julia/test/boundscheck_exec.jl\n",
            "julia-1.9.3/share/julia/test/goto.jl\n",
            "julia-1.9.3/share/julia/test/threadpool_use.jl\n",
            "julia-1.9.3/share/julia/test/boundscheck.jl\n",
            "julia-1.9.3/share/julia/test/stress.jl\n",
            "julia-1.9.3/share/julia/test/intrinsics.jl\n",
            "julia-1.9.3/share/julia/test/stress_fd_exec.jl\n",
            "julia-1.9.3/share/julia/test/mod2pi.jl\n",
            "julia-1.9.3/share/julia/test/worlds.jl\n",
            "julia-1.9.3/share/julia/test/arrayops.jl\n",
            "julia-1.9.3/share/julia/test/gmp.jl\n",
            "julia-1.9.3/share/julia/test/llvmcall2.jl\n",
            "julia-1.9.3/share/julia/test/unicode/\n",
            "julia-1.9.3/share/julia/test/unicode/utf8.jl\n",
            "julia-1.9.3/share/julia/test/subarray.jl\n",
            "julia-1.9.3/share/julia/test/broadcast.jl\n",
            "julia-1.9.3/share/julia/test/fastmath.jl\n",
            "julia-1.9.3/share/julia/test/rational.jl\n",
            "julia-1.9.3/share/julia/test/core.jl\n",
            "julia-1.9.3/share/julia/test/floatapprox.jl\n",
            "julia-1.9.3/share/julia/test/compiler/\n",
            "julia-1.9.3/share/julia/test/compiler/AbstractInterpreter.jl\n",
            "julia-1.9.3/share/julia/test/compiler/ssair.jl\n",
            "julia-1.9.3/share/julia/test/compiler/validation.jl\n",
            "julia-1.9.3/share/julia/test/compiler/datastructures.jl\n",
            "julia-1.9.3/share/julia/test/compiler/irutils.jl\n",
            "julia-1.9.3/share/julia/test/compiler/codegen.jl\n",
            "julia-1.9.3/share/julia/test/compiler/inline.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/EAUtils.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/local.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/interprocedural.jl\n",
            "julia-1.9.3/share/julia/test/compiler/EscapeAnalysis/setup.jl\n",
            "julia-1.9.3/share/julia/test/compiler/inference.jl\n",
            "julia-1.9.3/share/julia/test/compiler/effects.jl\n",
            "julia-1.9.3/share/julia/test/compiler/irpasses.jl\n",
            "julia-1.9.3/share/julia/test/compiler/interpreter_exec.jl\n",
            "julia-1.9.3/share/julia/test/compiler/contextual.jl\n",
            "julia-1.9.3/share/julia/test/client.jl\n",
            "julia-1.9.3/share/julia/test/regex.jl\n",
            "julia-1.9.3/share/julia/test/netload/\n",
            "julia-1.9.3/share/julia/test/netload/memtest.jl\n",
            "julia-1.9.3/share/julia/test/tuple.jl\n",
            "julia-1.9.3/share/julia/test/TestPkg/\n",
            "julia-1.9.3/share/julia/test/TestPkg/src/\n",
            "julia-1.9.3/share/julia/test/TestPkg/src/TestPkg.jl\n",
            "julia-1.9.3/share/julia/test/TestPkg/Project.toml\n",
            "julia-1.9.3/share/julia/test/TestPkg/Manifest.toml\n",
            "julia-1.9.3/share/julia/test/intfuncs.jl\n",
            "julia-1.9.3/share/julia/test/file.jl\n",
            "julia-1.9.3/share/julia/test/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/test/simdloop.jl\n",
            "julia-1.9.3/share/julia/test/atexit.jl\n",
            "julia-1.9.3/share/julia/test/parse.jl\n",
            "julia-1.9.3/share/julia/test/test_sourcepath.jl\n",
            "julia-1.9.3/share/julia/test/floatfuncs.jl\n",
            "julia-1.9.3/share/julia/test/testdefs.jl\n",
            "julia-1.9.3/share/julia/test/rounding.jl\n",
            "julia-1.9.3/share/julia/test/char.jl\n",
            "julia-1.9.3/share/julia/test/cmdlineargs.jl\n",
            "julia-1.9.3/share/julia/test/numbers.jl\n",
            "julia-1.9.3/share/julia/test/some.jl\n",
            "julia-1.9.3/share/julia/test/copy.jl\n",
            "julia-1.9.3/share/julia/test/errorshow.jl\n",
            "julia-1.9.3/share/julia/test/secretbuffer.jl\n",
            "julia-1.9.3/share/julia/test/iterators.jl\n",
            "julia-1.9.3/share/julia/test/float16.jl\n",
            "julia-1.9.3/share/julia/test/runtests.jl\n",
            "julia-1.9.3/share/julia/test/checked.jl\n",
            "julia-1.9.3/share/julia/test/embedding/\n",
            "julia-1.9.3/share/julia/test/embedding/embedding.c\n",
            "julia-1.9.3/share/julia/test/embedding/.gitignore\n",
            "julia-1.9.3/share/julia/test/embedding/LocalModule.jl\n",
            "julia-1.9.3/share/julia/test/embedding/include_and_eval.jl\n",
            "julia-1.9.3/share/julia/test/embedding/embedding-test.jl\n",
            "julia-1.9.3/share/julia/test/embedding/Makefile\n",
            "julia-1.9.3/share/julia/test/staged.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/\n",
            "julia-1.9.3/share/julia/test/llvmpasses/late-lower-gc-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/final-lower-gc-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/.gitignore\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o0.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-pipeline.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/late-lower-gc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/float16.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/propagate-addrspace-non-zero.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-unsized.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/safepoint_stress.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/loopinfo.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/returnstwicegc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lit.cfg.py\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lower-handlers.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/gcroots.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/lower-handlers-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o2-allocs.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-gcframe-addrspaces.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/fastmath.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/propagate-addrspace.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/muladd.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-pass.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/noinline.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/refinements.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/Makefile\n",
            "julia-1.9.3/share/julia/test/llvmpasses/fmf.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/simdloop.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/julia-licm.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/remove-addrspaces.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/aliasscopes.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/final-lower-gc.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/cpu-features.ll\n",
            "julia-1.9.3/share/julia/test/llvmpasses/pipeline-o2.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/llvmcall.jl\n",
            "julia-1.9.3/share/julia/test/llvmpasses/alloc-opt-gcframe.jl\n",
            "julia-1.9.3/share/julia/test/cartesian.jl\n",
            "julia-1.9.3/share/julia/test/print_process_affinity.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/\n",
            "julia-1.9.3/share/julia/test/testhelpers/Furlongs.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info.bad2\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/include_error.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/FakePTYs.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/withlocales.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/allocation_file.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/SizedArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info.bad\n",
            "julia-1.9.3/share/julia/test/testhelpers/InfiniteArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/ImmutableArrays.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/Quaternions.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/coverage_file.info\n",
            "julia-1.9.3/share/julia/test/testhelpers/llvmpasses.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/MacroCalls.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/PhysQuantities.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/arrayindexingtypes.jl\n",
            "julia-1.9.3/share/julia/test/testhelpers/OffsetArrays.jl\n",
            "julia-1.9.3/share/julia/test/stacktraces.jl\n",
            "julia-1.9.3/share/julia/test/testenv.jl\n",
            "julia-1.9.3/share/julia/test/abstractarray.jl\n",
            "julia-1.9.3/share/julia/test/euler.jl\n",
            "julia-1.9.3/share/julia/test/path.jl\n",
            "julia-1.9.3/share/julia/test/llvmcall.jl\n",
            "julia-1.9.3/share/julia/test/bitarray.jl\n",
            "julia-1.9.3/share/julia/test/atomics.jl\n",
            "julia-1.9.3/share/julia/test/combinatorics.jl\n",
            "julia-1.9.3/share/julia/test/show.jl\n",
            "julia-1.9.3/share/julia/test/test_exec.jl\n",
            "julia-1.9.3/share/julia/base/\n",
            "julia-1.9.3/share/julia/base/env.jl\n",
            "julia-1.9.3/share/julia/base/loading.jl\n",
            "julia-1.9.3/share/julia/base/Enums.jl\n",
            "julia-1.9.3/share/julia/base/sysinfo.jl\n",
            "julia-1.9.3/share/julia/base/version.jl\n",
            "julia-1.9.3/share/julia/base/meta.jl\n",
            "julia-1.9.3/share/julia/base/uuid.jl\n",
            "julia-1.9.3/share/julia/base/permuteddimsarray.jl\n",
            "julia-1.9.3/share/julia/base/uv_constants.jl\n",
            "julia-1.9.3/share/julia/base/timing.jl\n",
            "julia-1.9.3/share/julia/base/opaque_closure.jl\n",
            "julia-1.9.3/share/julia/base/iddict.jl\n",
            "julia-1.9.3/share/julia/base/reinterpretarray.jl\n",
            "julia-1.9.3/share/julia/base/views.jl\n",
            "julia-1.9.3/share/julia/base/sysimg.jl\n",
            "julia-1.9.3/share/julia/base/osutils.jl\n",
            "julia-1.9.3/share/julia/base/stat.jl\n",
            "julia-1.9.3/share/julia/base/float.jl\n",
            "julia-1.9.3/share/julia/base/.gitignore\n",
            "julia-1.9.3/share/julia/base/Base.jl\n",
            "julia-1.9.3/share/julia/base/threadcall.jl\n",
            "julia-1.9.3/share/julia/base/indices.jl\n",
            "julia-1.9.3/share/julia/base/errno_h.jl\n",
            "julia-1.9.3/share/julia/base/iobuffer.jl\n",
            "julia-1.9.3/share/julia/base/strings/\n",
            "julia-1.9.3/share/julia/base/strings/unicode.jl\n",
            "julia-1.9.3/share/julia/base/strings/substring.jl\n",
            "julia-1.9.3/share/julia/base/strings/strings.jl\n",
            "julia-1.9.3/share/julia/base/strings/search.jl\n",
            "julia-1.9.3/share/julia/base/strings/lazy.jl\n",
            "julia-1.9.3/share/julia/base/strings/string.jl\n",
            "julia-1.9.3/share/julia/base/strings/util.jl\n",
            "julia-1.9.3/share/julia/base/strings/io.jl\n",
            "julia-1.9.3/share/julia/base/strings/basic.jl\n",
            "julia-1.9.3/share/julia/base/reduce.jl\n",
            "julia-1.9.3/share/julia/base/boot.jl\n",
            "julia-1.9.3/share/julia/base/div.jl\n",
            "julia-1.9.3/share/julia/base/ntuple.jl\n",
            "julia-1.9.3/share/julia/base/hashing.jl\n",
            "julia-1.9.3/share/julia/base/missing.jl\n",
            "julia-1.9.3/share/julia/base/gcutils.jl\n",
            "julia-1.9.3/share/julia/base/filesystem.jl\n",
            "julia-1.9.3/share/julia/base/threads_overloads.jl\n",
            "julia-1.9.3/share/julia/base/pointer.jl\n",
            "julia-1.9.3/share/julia/base/file_constants.jl\n",
            "julia-1.9.3/share/julia/base/sort.jl\n",
            "julia-1.9.3/share/julia/base/arrayshow.jl\n",
            "julia-1.9.3/share/julia/base/cmd.jl\n",
            "julia-1.9.3/share/julia/base/complex.jl\n",
            "julia-1.9.3/share/julia/base/bitset.jl\n",
            "julia-1.9.3/share/julia/base/twiceprecision.jl\n",
            "julia-1.9.3/share/julia/base/features_h.jl\n",
            "julia-1.9.3/share/julia/base/task.jl\n",
            "julia-1.9.3/share/julia/base/reducedim.jl\n",
            "julia-1.9.3/share/julia/base/math.jl\n",
            "julia-1.9.3/share/julia/base/mpfr.jl\n",
            "julia-1.9.3/share/julia/base/generator.jl\n",
            "julia-1.9.3/share/julia/base/ordering.jl\n",
            "julia-1.9.3/share/julia/base/reflection.jl\n",
            "julia-1.9.3/share/julia/base/cpuid.jl\n",
            "julia-1.9.3/share/julia/base/shell.jl\n",
            "julia-1.9.3/share/julia/base/asyncmap.jl\n",
            "julia-1.9.3/share/julia/base/dict.jl\n",
            "julia-1.9.3/share/julia/base/operators.jl\n",
            "julia-1.9.3/share/julia/base/namedtuple.jl\n",
            "julia-1.9.3/share/julia/base/threadingconstructs.jl\n",
            "julia-1.9.3/share/julia/base/slicearray.jl\n",
            "julia-1.9.3/share/julia/base/abstractset.jl\n",
            "julia-1.9.3/share/julia/base/abstractarraymath.jl\n",
            "julia-1.9.3/share/julia/base/c.jl\n",
            "julia-1.9.3/share/julia/base/pair.jl\n",
            "julia-1.9.3/share/julia/base/channels.jl\n",
            "julia-1.9.3/share/julia/base/libdl.jl\n",
            "julia-1.9.3/share/julia/base/partr.jl\n",
            "julia-1.9.3/share/julia/base/condition.jl\n",
            "julia-1.9.3/share/julia/base/weakkeydict.jl\n",
            "julia-1.9.3/share/julia/base/threads.jl\n",
            "julia-1.9.3/share/julia/base/error.jl\n",
            "julia-1.9.3/share/julia/base/refvalue.jl\n",
            "julia-1.9.3/share/julia/base/asyncevent.jl\n",
            "julia-1.9.3/share/julia/base/deprecated.jl\n",
            "julia-1.9.3/share/julia/base/iostream.jl\n",
            "julia-1.9.3/share/julia/base/logging.jl\n",
            "julia-1.9.3/share/julia/base/deepcopy.jl\n",
            "julia-1.9.3/share/julia/base/range.jl\n",
            "julia-1.9.3/share/julia/base/baseext.jl\n",
            "julia-1.9.3/share/julia/base/initdefs.jl\n",
            "julia-1.9.3/share/julia/base/download.jl\n",
            "julia-1.9.3/share/julia/base/int.jl\n",
            "julia-1.9.3/share/julia/base/bool.jl\n",
            "julia-1.9.3/share/julia/base/arraymath.jl\n",
            "julia-1.9.3/share/julia/base/methodshow.jl\n",
            "julia-1.9.3/share/julia/base/libuv.jl\n",
            "julia-1.9.3/share/julia/base/multinverses.jl\n",
            "julia-1.9.3/share/julia/base/gmp.jl\n",
            "julia-1.9.3/share/julia/base/ctypes.jl\n",
            "julia-1.9.3/share/julia/base/subarray.jl\n",
            "julia-1.9.3/share/julia/base/ryu/\n",
            "julia-1.9.3/share/julia/base/ryu/utils.jl\n",
            "julia-1.9.3/share/julia/base/ryu/exp.jl\n",
            "julia-1.9.3/share/julia/base/ryu/fixed.jl\n",
            "julia-1.9.3/share/julia/base/ryu/LICENSE.md\n",
            "julia-1.9.3/share/julia/base/ryu/Ryu.jl\n",
            "julia-1.9.3/share/julia/base/ryu/shortest.jl\n",
            "julia-1.9.3/share/julia/base/broadcast.jl\n",
            "julia-1.9.3/share/julia/base/summarysize.jl\n",
            "julia-1.9.3/share/julia/base/fastmath.jl\n",
            "julia-1.9.3/share/julia/base/rational.jl\n",
            "julia-1.9.3/share/julia/base/promotion.jl\n",
            "julia-1.9.3/share/julia/base/pkgid.jl\n",
            "julia-1.9.3/share/julia/base/reshapedarray.jl\n",
            "julia-1.9.3/share/julia/base/abstractdict.jl\n",
            "julia-1.9.3/share/julia/base/process.jl\n",
            "julia-1.9.3/share/julia/base/compiler/\n",
            "julia-1.9.3/share/julia/base/compiler/typeinfer.jl\n",
            "julia-1.9.3/share/julia/base/compiler/bootstrap.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typelattice.jl\n",
            "julia-1.9.3/share/julia/base/compiler/stmtinfo.jl\n",
            "julia-1.9.3/share/julia/base/compiler/sort.jl\n",
            "julia-1.9.3/share/julia/base/compiler/validation.jl\n",
            "julia-1.9.3/share/julia/base/compiler/inferencestate.jl\n",
            "julia-1.9.3/share/julia/base/compiler/utilities.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/basicblock.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/irinterp.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/legacy.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/passes.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/ir.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/inlining.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/driver.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/EscapeAnalysis.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/disjoint_set.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/EscapeAnalysis/interprocedural.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/verify.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/domtree.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/heap.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/slot2ssa.jl\n",
            "julia-1.9.3/share/julia/base/compiler/ssair/show.jl\n",
            "julia-1.9.3/share/julia/base/compiler/tfuncs.jl\n",
            "julia-1.9.3/share/julia/base/compiler/cicache.jl\n",
            "julia-1.9.3/share/julia/base/compiler/abstractlattice.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typeutils.jl\n",
            "julia-1.9.3/share/julia/base/compiler/inferenceresult.jl\n",
            "julia-1.9.3/share/julia/base/compiler/parsing.jl\n",
            "julia-1.9.3/share/julia/base/compiler/types.jl\n",
            "julia-1.9.3/share/julia/base/compiler/typelimits.jl\n",
            "julia-1.9.3/share/julia/base/compiler/abstractinterpretation.jl\n",
            "julia-1.9.3/share/julia/base/compiler/optimize.jl\n",
            "julia-1.9.3/share/julia/base/compiler/effects.jl\n",
            "julia-1.9.3/share/julia/base/compiler/compiler.jl\n",
            "julia-1.9.3/share/julia/base/compiler/methodtable.jl\n",
            "julia-1.9.3/share/julia/base/client.jl\n",
            "julia-1.9.3/share/julia/base/regex.jl\n",
            "julia-1.9.3/share/julia/base/pcre_h.jl\n",
            "julia-1.9.3/share/julia/base/options.jl\n",
            "julia-1.9.3/share/julia/base/version_git.jl\n",
            "julia-1.9.3/share/julia/base/multimedia.jl\n",
            "julia-1.9.3/share/julia/base/ttyhascolor.jl\n",
            "julia-1.9.3/share/julia/base/tuple.jl\n",
            "julia-1.9.3/share/julia/base/intfuncs.jl\n",
            "julia-1.9.3/share/julia/base/file.jl\n",
            "julia-1.9.3/share/julia/base/util.jl\n",
            "julia-1.9.3/share/julia/base/binaryplatforms.jl\n",
            "julia-1.9.3/share/julia/base/simdloop.jl\n",
            "julia-1.9.3/share/julia/base/stream.jl\n",
            "julia-1.9.3/share/julia/base/pcre.jl\n",
            "julia-1.9.3/share/julia/base/array.jl\n",
            "julia-1.9.3/share/julia/base/toml_parser.jl\n",
            "julia-1.9.3/share/julia/base/parse.jl\n",
            "julia-1.9.3/share/julia/base/mathconstants.jl\n",
            "julia-1.9.3/share/julia/base/floatfuncs.jl\n",
            "julia-1.9.3/share/julia/base/essentials.jl\n",
            "julia-1.9.3/share/julia/base/set.jl\n",
            "julia-1.9.3/share/julia/base/rounding.jl\n",
            "julia-1.9.3/share/julia/base/char.jl\n",
            "julia-1.9.3/share/julia/base/refpointer.jl\n",
            "julia-1.9.3/share/julia/base/Makefile\n",
            "julia-1.9.3/share/julia/base/some.jl\n",
            "julia-1.9.3/share/julia/base/errorshow.jl\n",
            "julia-1.9.3/share/julia/base/secretbuffer.jl\n",
            "julia-1.9.3/share/julia/base/iterators.jl\n",
            "julia-1.9.3/share/julia/base/linked_list.jl\n",
            "julia-1.9.3/share/julia/base/number.jl\n",
            "julia-1.9.3/share/julia/base/expr.jl\n",
            "julia-1.9.3/share/julia/base/lock.jl\n",
            "julia-1.9.3/share/julia/base/docs/\n",
            "julia-1.9.3/share/julia/base/docs/utils.jl\n",
            "julia-1.9.3/share/julia/base/docs/Docs.jl\n",
            "julia-1.9.3/share/julia/base/docs/core.jl\n",
            "julia-1.9.3/share/julia/base/docs/basedocs.jl\n",
            "julia-1.9.3/share/julia/base/docs/bindings.jl\n",
            "julia-1.9.3/share/julia/base/idset.jl\n",
            "julia-1.9.3/share/julia/base/multidimensional.jl\n",
            "julia-1.9.3/share/julia/base/checked.jl\n",
            "julia-1.9.3/share/julia/base/exports.jl\n",
            "julia-1.9.3/share/julia/base/linking.jl\n",
            "julia-1.9.3/share/julia/base/cartesian.jl\n",
            "julia-1.9.3/share/julia/base/traits.jl\n",
            "julia-1.9.3/share/julia/base/coreio.jl\n",
            "julia-1.9.3/share/julia/base/stacktraces.jl\n",
            "julia-1.9.3/share/julia/base/build_h.jl\n",
            "julia-1.9.3/share/julia/base/irrationals.jl\n",
            "julia-1.9.3/share/julia/base/abstractarray.jl\n",
            "julia-1.9.3/share/julia/base/accumulate.jl\n",
            "julia-1.9.3/share/julia/base/libc.jl\n",
            "julia-1.9.3/share/julia/base/special/\n",
            "julia-1.9.3/share/julia/base/special/log.jl\n",
            "julia-1.9.3/share/julia/base/special/exp.jl\n",
            "julia-1.9.3/share/julia/base/special/rem_pio2.jl\n",
            "julia-1.9.3/share/julia/base/special/hyperbolic.jl\n",
            "julia-1.9.3/share/julia/base/special/cbrt.jl\n",
            "julia-1.9.3/share/julia/base/special/trig.jl\n",
            "julia-1.9.3/share/julia/base/path.jl\n",
            "julia-1.9.3/share/julia/base/io.jl\n",
            "julia-1.9.3/share/julia/base/experimental.jl\n",
            "julia-1.9.3/share/julia/base/locks-mt.jl\n",
            "julia-1.9.3/share/julia/base/bitarray.jl\n",
            "julia-1.9.3/share/julia/base/atomics.jl\n",
            "julia-1.9.3/share/julia/base/combinatorics.jl\n",
            "julia-1.9.3/share/julia/base/show.jl\n",
            "julia-1.9.3/libexec/\n",
            "julia-1.9.3/libexec/julia/\n",
            "julia-1.9.3/libexec/julia/dsymutil\n",
            "julia-1.9.3/libexec/julia/7z\n",
            "julia-1.9.3/libexec/julia/lld\n",
            "julia-1.9.3/include/\n",
            "julia-1.9.3/include/julia/\n",
            "julia-1.9.3/include/julia/utf8.h\n",
            "julia-1.9.3/include/julia/htable.h\n",
            "julia-1.9.3/include/julia/strtod.h\n",
            "julia-1.9.3/include/julia/rle.h\n",
            "julia-1.9.3/include/julia/libsupport.h\n",
            "julia-1.9.3/include/julia/julia_gcext.h\n",
            "julia-1.9.3/include/julia/hashing.h\n",
            "julia-1.9.3/include/julia/utils.h\n",
            "julia-1.9.3/include/julia/arraylist.h\n",
            "julia-1.9.3/include/julia/bitvector.h\n",
            "julia-1.9.3/include/julia/julia_version.h\n",
            "julia-1.9.3/include/julia/MurmurHash3.h\n",
            "julia-1.9.3/include/julia/julia.h\n",
            "julia-1.9.3/include/julia/timefuncs.h\n",
            "julia-1.9.3/include/julia/ptrhash.h\n",
            "julia-1.9.3/include/julia/END.h\n",
            "julia-1.9.3/include/julia/uv/\n",
            "julia-1.9.3/include/julia/uv/linux.h\n",
            "julia-1.9.3/include/julia/uv/unix.h\n",
            "julia-1.9.3/include/julia/uv/errno.h\n",
            "julia-1.9.3/include/julia/uv/version.h\n",
            "julia-1.9.3/include/julia/uv/threadpool.h\n",
            "julia-1.9.3/include/julia/julia_threads.h\n",
            "julia-1.9.3/include/julia/julia_fasttls.h\n",
            "julia-1.9.3/include/julia/uv.h\n",
            "julia-1.9.3/include/julia/jloptions.h\n",
            "julia-1.9.3/include/julia/ENTRY.i387.h\n",
            "julia-1.9.3/include/julia/tzfile.h\n",
            "julia-1.9.3/include/julia/dtypes.h\n",
            "julia-1.9.3/include/julia/dirpath.h\n",
            "julia-1.9.3/include/julia/julia_locks.h\n",
            "julia-1.9.3/include/julia/analyzer_annotations.h\n",
            "julia-1.9.3/include/julia/julia_atomics.h\n",
            "julia-1.9.3/include/julia/platform.h\n",
            "julia-1.9.3/include/julia/ios.h\n",
            "julia-1.9.3/include/julia/julia_assert.h\n",
            "julia-1.9.3/include/julia/ENTRY.amd64.h\n",
            "julia-1.9.3/bin/\n",
            "julia-1.9.3/bin/julia\n",
            "julia-1.9.3/etc/\n",
            "julia-1.9.3/etc/julia/\n",
            "julia-1.9.3/etc/julia/startup.jl\n",
            "julia-1.9.3/LICENSE.md\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update -y\n",
        "!sudo apt upgrade -y\n",
        "!sudo apt install wget -y\n",
        "!wget https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.3-linux-x86_64.tar.gz\n",
        "!tar -xvzf julia-1.9.3-linux-x86_64.tar.gz\n",
        "!sudo cp -r julia-1.9.3 /opt/\n",
        "!sudo ln -s /opt/julia-1.9.3/bin/julia /usr/local/bin/julia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWIsh2NxBdPy"
      },
      "source": [
        "# 2. Install PySR\n",
        "\n",
        "---\n",
        "\n",
        "PySR is an useful tool, providing the most extensive authority\n",
        "\n",
        "for symbolic regression users, between pip-installable packages..\n",
        "\n",
        "\n",
        "공개된 기호적 회귀 패키지 중 가장 높은 자유도를 지닙니다.\n",
        "\n",
        "PySR need to be installed only once, **the very first time** you try this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyC1i5oJFM-n",
        "outputId": "4a1f2800-c71f-46cb-f70e-477cb79433b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: julia in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: pysr in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from pysr) (1.12)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pysr) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.2.2)\n",
            "Requirement already satisfied: julia>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (0.6.1)\n",
            "Requirement already satisfied: click>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (8.1.7)\n",
            "Requirement already satisfied: setuptools>=50.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.21.0->pysr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.21.0->pysr) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pysr) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->pysr) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.21.0->pysr) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install julia\n",
        "!pip install pysr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3LNvr1PFOhO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] += \":/usr/local/bin/julia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPeRsaORFlpW",
        "outputId": "efc22d6a-22a5-40c0-d5d3-b833f5b6c649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Precompiling PyCall...\n",
            "Precompiling PyCall... DONE\n",
            "PyCall is installed and built successfully.\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:208: UserWarning: Your system's Python library is static (e.g., conda), so precompilation will be turned off. For a dynamic library, try using `pyenv` and installing with `--enable-shared`: https://github.com/pyenv/pyenv/blob/master/plugins/python-build/README.md#building-with---enable-shared.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:118: UserWarning: It is recommended to restart Python after installing PySR's dependencies, so that the Julia environment is properly initialized.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pysr\n",
        "\n",
        "# We don't precompile in colab because compiled modules\n",
        "# are incompatible static Python libraries:\n",
        "pysr.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KFM0G8SF1o-"
      },
      "source": [
        "# 3. Import basics\n",
        "\n",
        "---\n",
        "\n",
        "Some packages need to be imported,,,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pM6uKN13F8QY"
      },
      "outputs": [],
      "source": [
        "import sympy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pysr import PySRRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXpaUovYF9UO"
      },
      "source": [
        "# 4. Mount Google Drive & Read Dataset\n",
        "\n",
        "---\n",
        "\n",
        "By mounting google drive, you can easily back-up your each processes.\n",
        "\n",
        "Caution: This code is very fragile. Please be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p7XOFwrxGRS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd75031-85e7-4055-b7d2-306414640bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "upcrYPSrGVYY"
      },
      "outputs": [],
      "source": [
        "# where is your dataset\n",
        "# file_path = '/content/drive/MyDrive/MyInput.xlsx'  # should be modified into your path\n",
        "\n",
        "file_path = 'MyInput.xlsx'  # should be modified into your path\n",
        "\n",
        "\n",
        "# read dataset\n",
        "data = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn39PBOtGZXO"
      },
      "source": [
        "# 5. Split dataset into Input&Output\n",
        "\n",
        "---\n",
        "\n",
        "This code assumes that your dataset has the same unit for the input data,\n",
        "\n",
        "and un-nondimensionalized output data.\n",
        "\n",
        "You can easily modify the code, from now on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhXw66qaGeFc",
        "outputId": "cf6e5ae9-daf6-4dae-801d-d6c409253ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         TP   BF    TW  TF    HW\n",
            "0      44.5  100  10.0  14   200\n",
            "1      44.5  100  10.0  14   284\n",
            "2      44.5  100  10.0  14   300\n",
            "3      44.5  100  10.0  14   360\n",
            "4      44.5  100  10.0  14   425\n",
            "...     ...  ...   ...  ..   ...\n",
            "10493   9.5  200  28.0  30   500\n",
            "10494   9.5  200  28.0  30   460\n",
            "10495   9.5  200  28.0  30   700\n",
            "10496   9.5  200  28.0  30   800\n",
            "10497   9.5  200  28.0  30  1000\n",
            "\n",
            "[10498 rows x 5 columns]\n",
            "0        0.553074\n",
            "1        0.705244\n",
            "2        0.719511\n",
            "3        0.751525\n",
            "4        0.816629\n",
            "           ...   \n",
            "10493    0.793881\n",
            "10494    0.813152\n",
            "10495    0.705881\n",
            "10496    0.655486\n",
            "10497    0.585506\n",
            "Name: ULS, Length: 10498, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Read Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import combinations\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "# Assuming the last column in your dataset is the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]/315 # y value nondim'ed herein.\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvF1W5QeGfkG"
      },
      "source": [
        "# 6. generate nondimensionalized parameters\n",
        "\n",
        "---\n",
        "\n",
        "Implemented methods: ***Buckingham's Pi Theorem***\n",
        "\n",
        "i) define \"powers\"\n",
        "\n",
        "ii) generate combinations for \"powers\"\n",
        "\n",
        "iii) for sum(power)==0: generate nondimensionalized\n",
        "\n",
        "\n",
        "During each generation of nondim' parameters, its feature importance would be evaluated by RandomForestRegressor;\n",
        "\n",
        "thus only ***top_n*** of parameters would be remained.\n",
        "\n",
        "\n",
        "# **CAUTION: Don't Execute this cell more than once.**\n",
        "\n",
        "cell above must be executed previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QT5hs3rGiLS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def create_dimensionless_parameters(df, y, drop_origin=True, top_n=10):\n",
        "    powers = [-3, -2, -1, -1/2, 0, 1/2, 1, 2, 3] # you can modify here as your needs\n",
        "    columns = df.columns\n",
        "    result = pd.DataFrame()\n",
        "\n",
        "    # generate combinations of 'power', for you nondim' parameters.\n",
        "    combinations = itertools.product(powers, repeat=len(columns))\n",
        "    iters = 0\n",
        "\n",
        "    for idx, combo in enumerate(combinations):\n",
        "        if sum(combo) == 0:  # for 'sum to zeros' only\n",
        "            # Update naming convention\n",
        "            iters = iters + 1\n",
        "\n",
        "            new_col_name = '_'.join([f\"{col}_p{str(p).replace('-', 'n').replace('.', 'd')}\" for col, p in zip(columns, combo)])\n",
        "            temp_result = df.apply(lambda row: prod_with_power(row, combo), axis=1)\n",
        "            result = result.copy()\n",
        "            result.loc[:, new_col_name] = temp_result\n",
        "\n",
        "            # between each iterations,\n",
        "            combined_df = pd.concat([df, result], axis=1)\n",
        "            if drop_origin:\n",
        "                training_df = combined_df.drop(columns=columns)\n",
        "            else:\n",
        "                training_df = combined_df\n",
        "\n",
        "            model = RandomForestRegressor(n_estimators=30)\n",
        "            model.fit(training_df, y)\n",
        "            feature_importances = model.feature_importances_\n",
        "\n",
        "            # maintain only (top_n) features\n",
        "            important_indices = feature_importances.argsort()[-top_n:][::-1]\n",
        "            important_features = training_df.columns[important_indices]\n",
        "\n",
        "            # print procedures\n",
        "            print(f\"Iteration {iters}\")\n",
        "            print(f\"Important features: {important_features.tolist()}\")\n",
        "\n",
        "            result = combined_df[important_features]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def prod_with_power(row, powers):\n",
        "    result = 1\n",
        "    for value, power in zip(row, powers):\n",
        "        result *= value**power\n",
        "    return result\n",
        "\n",
        "# Figure out the most important nondim' features\n",
        "X = create_dimensionless_parameters(X, y, drop_origin=True, top_n=10)\n",
        "X.to_csv('top_n_features.csv', index=False)\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSzgwcZeGqDi"
      },
      "source": [
        "# 7. RandomForestRegressor would pick out some number of best nondim' parameters for your dataset.\n",
        "\n",
        "---\n",
        "\n",
        "**Caution:** Random Forest Regression is alreay defined inside the *PySR*.\n",
        "\n",
        "Yet to print out, exclusive package of sklearn would be applied herein.\n",
        "\n",
        "Moreover, selected features by Random Forest Regression may *not represent the optimal* features for your training.\n",
        "\n",
        "However, such sets would be suboptimal, at least.\n",
        "\n",
        "Thus herein, you could define 'N', which will figure out the most important *N* features, among *top_n* features.\n",
        "\n",
        "Good Luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d53NVduL-eM",
        "outputId": "cf74fe3c-1c2c-4873-fe1a-05c9059f4583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2, Importance: 0.36912851238814387\n",
            "Feature: TPp3_BFpn1_TWp0_TFpn1_HWpn1, Importance: 0.12064485320510256\n",
            "Feature: TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2, Importance: 0.1505048779038222\n",
            "Feature: TPpn2_BFp0_TWpn1_TFp0_HWp3, Importance: 0.09483178764841392\n",
            "Feature: TPpn1_BFp0_TWp0_TFp0d5_HWp0d5, Importance: 0.024535590101506948\n",
            "Feature: TPp3_BFp0_TWp0_TFpn2_HWpn1, Importance: 0.028325841115249027\n",
            "Feature: TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2, Importance: 0.0276508753043265\n",
            "Feature: TPpn1_BFp0_TWp0_TFp0_HWp1, Importance: 0.023814345185042402\n",
            "Feature: TPp0_BFpn1_TWp3_TFpn1_HWpn1, Importance: 0.020036394596694686\n",
            "Feature: TPp0d5_BFpn1_TWpn0d5_TFpn1_HWp2, Importance: 0.017425387465979648\n",
            "Feature: TPp0d5_BFp0_TWp0_TFp0_HWpn0d5, Importance: 0.015523521158666263\n",
            "Feature: TPp3_BFp0_TWpn2_TFp0_HWpn1, Importance: 0.01617332391642722\n",
            "Feature: TPp2_BFpn2_TWp0_TFp0_HWp0, Importance: 0.01689229969599252\n",
            "Feature: TPp1_BFp0_TWp0_TFp0_HWpn1, Importance: 0.015266930217747207\n",
            "Feature: TPpn2_BFp0d5_TWp0_TFp0d5_HWp1, Importance: 0.013624810180254873\n",
            "Feature: TPpn2_BFp0_TWp2_TFp0_HWp0, Importance: 0.01127059246153245\n",
            "Feature: TPp3_BFpn1_TWpn0d5_TFpn0d5_HWpn1, Importance: 0.010896692184509338\n",
            "Feature: TPp0d5_BFp0_TWpn0d5_TFp0_HWp0, Importance: 0.009957584020405459\n",
            "Feature: TPp1_BFp0_TWpn1_TFp0_HWp0, Importance: 0.009816483239903657\n",
            "Feature: TPp3_BFp1_TWpn2_TFp0_HWpn2, Importance: 0.0036792980102791275\n",
            "Top 6 important features:\n",
            "Feature: TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2, Importance: 0.36912851238814387\n",
            "Feature: TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2, Importance: 0.1505048779038222\n",
            "Feature: TPp3_BFpn1_TWp0_TFpn1_HWpn1, Importance: 0.12064485320510256\n",
            "Feature: TPpn2_BFp0_TWpn1_TFp0_HWp3, Importance: 0.09483178764841392\n",
            "Feature: TPp3_BFp0_TWp0_TFpn2_HWpn1, Importance: 0.028325841115249027\n",
            "Feature: TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2, Importance: 0.0276508753043265\n"
          ]
        }
      ],
      "source": [
        "X = pd.read_csv('top_n_features.csv')\n",
        "\n",
        "# Initialize and fit the Random Forest Regressor\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# get feature importances\n",
        "feature_importances = regressor.feature_importances_\n",
        "\n",
        "# print it out\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(f'Feature: {feature}, Importance: {importance}')\n",
        "\n",
        "# pick out the best 'N' parameters, with score.\n",
        "N = 6\n",
        "top_features = sorted(zip(X.columns, feature_importances), key=lambda x: x[1], reverse=True)[:N]\n",
        "print(f'Top {N} important features:')\n",
        "for feature, importance in top_features:\n",
        "    print(f'Feature: {feature}, Importance: {importance}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaXVOixrMDHY"
      },
      "source": [
        "# 8. Show the best parameter set\n",
        "\n",
        "---\n",
        "\n",
        "Meanwhile, there could be NaN values, somehow.\n",
        "\n",
        "Drop NaN values here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQprtuwMfRl",
        "outputId": "bf10b63e-599a-4940-8709-2d4285ff22b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       TPp2_BFp0_TWp0d5_TFpn0d5_HWpn2  TPpn2_BFp0_TWpn0d5_TFp0d5_HWp2  \\\n",
            "0                            0.041840                       23.900335   \n",
            "1                            0.020750                       48.192635   \n",
            "2                            0.018596                       53.775754   \n",
            "3                            0.012914                       77.437085   \n",
            "4                            0.009266                      107.924950   \n",
            "...                               ...                             ...   \n",
            "10493                        0.000349                     2867.308418   \n",
            "10494                        0.000412                     2426.889845   \n",
            "10495                        0.000178                     5619.924500   \n",
            "10496                        0.000136                     7340.309551   \n",
            "10497                        0.000087                    11469.233673   \n",
            "\n",
            "       TPp3_BFpn1_TWp0_TFpn1_HWpn1  TPpn2_BFp0_TWpn1_TFp0_HWp3  \\\n",
            "0                         0.314718                  403.989395   \n",
            "1                         0.221633                 1156.737988   \n",
            "2                         0.209812                 1363.464209   \n",
            "3                         0.174844                 2356.066153   \n",
            "4                         0.148103                 3876.562303   \n",
            "...                            ...                         ...   \n",
            "10493                     0.000286                49465.769687   \n",
            "10494                     0.000311                38518.401266   \n",
            "10495                     0.000204               135734.072022   \n",
            "10496                     0.000179               202611.792639   \n",
            "10497                     0.000143               395726.157499   \n",
            "\n",
            "       TPp3_BFp0_TWp0_TFpn2_HWpn1  TPpn0d5_BFpn0d5_TWpn1_TFp0_HWp2  \n",
            "0                        2.247988                        59.962535  \n",
            "1                        1.583090                       120.908456  \n",
            "2                        1.498659                       134.915704  \n",
            "3                        1.248882                       194.278614  \n",
            "4                        1.057877                       270.768323  \n",
            "...                           ...                              ...  \n",
            "10493                    0.001905                       204.835477  \n",
            "10494                    0.002071                       173.372747  \n",
            "10495                    0.001361                       401.477534  \n",
            "10496                    0.001191                       524.378820  \n",
            "10497                    0.000953                       819.341907  \n",
            "\n",
            "[10498 rows x 6 columns]\n",
            "0        0.553074\n",
            "1        0.705244\n",
            "2        0.719511\n",
            "3        0.751525\n",
            "4        0.816629\n",
            "           ...   \n",
            "10493    0.793881\n",
            "10494    0.813152\n",
            "10495    0.705881\n",
            "10496    0.655486\n",
            "10497    0.585506\n",
            "Name: ULS, Length: 10498, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Best Parameter Set for YOU\n",
        "\n",
        "selected_features = [feature for feature, _ in top_features]\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# find out rows with NaN values\n",
        "drop_indices = X_selected.dropna().index\n",
        "\n",
        "# drop NaN\n",
        "X_selected = X_selected.loc[drop_indices]\n",
        "y = y.loc[drop_indices]\n",
        "\n",
        "print(X_selected)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn1qZpQ3RBLg"
      },
      "source": [
        "---\n",
        "\n",
        "# Chapter.2 Generate model by NAS\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT2VOpnMMwOV"
      },
      "source": [
        "# 1. Import Tensorflow\n",
        "\n",
        "---\n",
        "\n",
        "Basic Requirments would be fulfilled herein."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOnCGrUeRLgJ",
        "outputId": "8fe1d152-b3da-4104-9433-d34037c23e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.9.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.9.5 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install scikit-optimize\n",
        "\n",
        "# Import Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import json\n",
        "#-----------------------------------------------------------\n",
        "# Add the required libraries for Bayesian optimization\n",
        "import skopt\n",
        "    # Caution : please open your scikit-optimize package,\n",
        "    # and then replace every 'np.int' into 'int', in 'transformer.py'\n",
        "    # Anaconda\\Lib\\site-packages\\skopt\\space\\transformers.py\n",
        "from skopt import gp_minimize\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaBDv2hRRUA7"
      },
      "source": [
        "# 2. Engage your GPU\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g66TEU4zRR3U",
        "outputId": "789f370d-38cc-43cb-8da3-2cfbf5f4430e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6175063170604068536\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14357954560\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11968585342080438415\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Does GPU Works?\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "#-----------------------------------------------------------\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "print(device_lib.list_local_devices())\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C07r1Om1Rk_p"
      },
      "source": [
        "# 3. Split Data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpZKYnL2RlG1",
        "outputId": "01c2f338-5b83-41fa-e67f-cdb9c1815251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.51773715e-02 3.97182049e+01 3.90092330e-02 3.78698225e+02\n",
            "  3.54629390e-01 2.48069469e+01]\n",
            " [3.86392688e-03 2.58804069e+02 1.59064901e-02 4.95539297e+03\n",
            "  7.23022276e-02 1.73947203e+02]\n",
            " [5.04413749e-03 1.98249949e+02 1.12679989e-02 3.60472842e+03\n",
            "  1.40849986e-01 7.54585952e+01]\n",
            " ...\n",
            " [2.68249714e-03 3.72786977e+02 5.15090543e-03 8.94777500e+03\n",
            "  7.35843633e-02 1.42581011e+02]\n",
            " [2.95014733e-03 3.38966122e+02 4.00550568e-02 1.29276606e+04\n",
            "  2.27585550e-01 4.29056975e+02]\n",
            " [4.28449753e-04 2.33399598e+03 9.49342561e-04 6.80470914e+04\n",
            "  6.98046000e-03 4.19325273e+02]] [0.86033048 0.81743365 0.92112127 ... 0.76684381 0.88360667 0.67025587]\n",
            "[[5.34785694e-04 1.86990791e+03 1.32560386e-03 4.96612245e+04\n",
            "  6.62801932e-03 4.61749056e+02]\n",
            " [6.05415405e-05 1.65175843e+04 1.42895833e-04 8.20765364e+05\n",
            "  9.52638889e-04 1.69937581e+03]\n",
            " [1.92093675e-03 5.20579347e+02 2.88471639e-02 2.40543502e+04\n",
            "  1.69689199e-01 6.36679155e+02]\n",
            " ...\n",
            " [1.10895826e-02 9.01747192e+01 6.53869048e-02 2.04497041e+03\n",
            "  5.83811650e-01 1.12962894e+02]\n",
            " [2.98922383e-03 3.34535002e+02 1.83585677e-02 9.23404332e+03\n",
            "  1.22390451e-01 2.42285230e+02]\n",
            " [3.60135858e-03 2.77672989e+02 4.23150660e-02 1.28304039e+04\n",
            "  4.35596268e-01 4.11304330e+02]] [0.69768508 0.49199587 0.85335365 ... 0.86095365 0.96188571 0.9130381 ]\n"
          ]
        }
      ],
      "source": [
        "# Read Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#-----------------------------------------------------------\n",
        "X_clean = X_selected.values\n",
        "y_clean = y.values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.2, random_state=7)\n",
        "\n",
        "# Reshaping data\n",
        "input_data_train = [X_train[:, i].reshape(-1, 1) for i in range(X_train.shape[1])]\n",
        "input_data_val = [X_val[:, i].reshape(-1, 1) for i in range(X_val.shape[1])]\n",
        "\n",
        "print(X_train, y_train)\n",
        "print(X_val, y_val)\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC20megQRlQ9"
      },
      "source": [
        "# 4. Definitions by TensorFlow\n",
        "\n",
        "---\n",
        "\n",
        "# You will define almost everything here:\n",
        "\n",
        "> 1) N: number of input features for SumNET\n",
        ">\n",
        "> 2) num_of_med_vals: number of intermediate features, to be extruded as an ***inductive bias***\n",
        ">\n",
        "> 3) Search Space for NAS\n",
        "\n",
        "![15658638.png](data:image/png;base64,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)\n",
        "\n",
        "a) Early Stopping\n",
        "\n",
        "b) Create Model = (N, num_of_med_vals) + (num_of_med_vals, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6GQ_Q-JDRlYA"
      },
      "outputs": [],
      "source": [
        "# Generate earlyStopping callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#-----------------------------------------------------------\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function : Create SumNET\n",
        "num_of_med_vals = 2\n",
        "#-----------------------------------------------------------\n",
        "class SumNet:\n",
        "    def __init__(self,\n",
        "                 layer_nodes, learning_rate, activation,\n",
        "                 dropout_rate, optimizer, loss_function):\n",
        "        self.model_g = self.create_sumnet_g(layer_nodes, activation, dropout_rate)\n",
        "        self.model_f = self.create_sumnet_f(layer_nodes, activation, dropout_rate)\n",
        "        self.model = self.build_model(layer_nodes, learning_rate, activation, dropout_rate, optimizer, loss_function)\n",
        "\n",
        "    def create_sumnet_g(self, layer_nodes, activation, dropout_rate):\n",
        "        model_g_inputs = [tf.keras.layers.Input(shape=(1,)) for _ in range(N)]\n",
        "        x = tf.keras.layers.Concatenate()(model_g_inputs)\n",
        "\n",
        "        for nodes in layer_nodes:\n",
        "            x = tf.keras.layers.Dense(nodes, activation=activation)(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "        model_g_output = tf.keras.layers.Dense(num_of_med_vals)(x)\n",
        "        return tf.keras.Model(inputs=model_g_inputs, outputs=model_g_output)\n",
        "\n",
        "    def create_sumnet_f(self, layer_nodes, activation, dropout_rate):\n",
        "        model_f_input = tf.keras.layers.Input(shape=(num_of_med_vals,))\n",
        "        x = model_f_input\n",
        "\n",
        "        for nodes in layer_nodes:\n",
        "            x = tf.keras.layers.Dense(nodes, activation=activation)(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "        model_f_output = tf.keras.layers.Dense(1)(x)\n",
        "        return tf.keras.Model(inputs=model_f_input, outputs=model_f_output)\n",
        "\n",
        "    def build_model(self, layer_nodes, learning_rate, activation, dropout_rate, optimizer, loss_function):\n",
        "        inputs = [tf.keras.layers.Input(shape=(1,)) for _ in range(N)]\n",
        "        g_out = self.model_g(inputs)\n",
        "        f_out = self.model_f(g_out)\n",
        "        outputs = f_out\n",
        "\n",
        "        sumnet_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        opt = None\n",
        "        if optimizer == 'adam':\n",
        "            opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        elif optimizer == 'sgd':\n",
        "            opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "        sumnet_model.compile(optimizer=opt, loss=loss_function, metrics=['mse'])\n",
        "        return sumnet_model\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# Function: show plot\n",
        "#-----------------------------------------------------------\n",
        "def show_plot(params, val_mse, epoch_rate, predicted_performance, toshow=False):\n",
        "    if toshow==True:\n",
        "        plt.plot(np.arange(int(params['epochs']*epoch_rate)), val_mse, label='Actual')\n",
        "        plt.axhline(y=predicted_performance, color='r', linestyle='dashed', label='Predicted')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Validation MSE')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDUzVPDVRlgb"
      },
      "source": [
        "Search space could be defined by your own here.\n",
        "\n",
        "Recommended Options:\n",
        "\n",
        "*   Activation Function - ReLu\n",
        "\n",
        "*   Optimizer - Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zl5xGmSaRlmz"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "#-----------------------------------------------------------\n",
        "    # Define the hyperparameter search space\n",
        "    # Caution: this\n",
        "max_layers = 3\n",
        "layer_nodes_space = [Integer(32, 128, name=f'layer_{i+1}_nodes') for i in range(max_layers)]\n",
        "space = [\n",
        "    Integer(1, max_layers, name='number_of_layers'),\n",
        "    *layer_nodes_space,\n",
        "    Integer(16, 256, name='batch_size'),\n",
        "    Categorical([400], name='epochs'),\n",
        "    Real(1e-6, 1e-1, \"log-uniform\", name='learning_rate'),\n",
        "    Categorical(['relu'], name='activation'),\n",
        "    Categorical(['huber'], name='loss_function'),\n",
        "    Categorical(['adam'], name='optimizer'),\n",
        "    Real(0, 0.5, name='dropout_rate')\n",
        "]\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function: Print Hyperparameters\n",
        "#-----------------------------------------------------------\n",
        "def print_model(params, layer_nodes):\n",
        "    print(\"----------------------------------------\")\n",
        "    print(\"Model Specifications:\")\n",
        "    print(f\"Number of Layers: {params['number_of_layers']}\")\n",
        "    print(f\"Layer Nodes: {layer_nodes}\")\n",
        "    print(f\"Learning Rate: {params['learning_rate']}\")\n",
        "    print(f\"Activation Function: {params['activation']}\")\n",
        "    print(f\"Loss Function: {params['loss_function']}\")\n",
        "    print(f\"Optimizer: {params['optimizer']}\")\n",
        "    print(f\"Epochs: {params['epochs']}\")\n",
        "    print(f\"Dropout Rate: {params['dropout_rate']}\")\n",
        "    print(f\"Batch Size: {params['batch_size']}\")\n",
        "    print(\"----------------------------------------\")\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Function: SVR Trainer\n",
        "from sklearn.svm import NuSVR\n",
        "from sklearn.svm import SVR\n",
        "from skopt.sampler import Lhs\n",
        "from joblib import dump\n",
        "#-----------------------------------------------------------\n",
        "# Function: Model Performance Estimation Strategy\n",
        "    # by nu-SVR, would predict model performance\n",
        "def predict_final_performance(val_loss, model=None, total_epochs=None):\n",
        "    x_pred = np.array(val_loss).reshape(1,-1)\n",
        "    prediction = model.predict(x_pred)\n",
        "    return prediction\n",
        "\n",
        "def pretrain_Estimator(X, y, model=None):\n",
        "    if model is None:\n",
        "        model = NuSVR(kernel='rbf', nu=0.5, gamma=0.1, C=100)\n",
        "    model.fit(X, y)\n",
        "    dump(model, 'estimator.joblib')\n",
        "    return model\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4sDGWzdSBq2"
      },
      "source": [
        "# 5. Train NuSVR\n",
        "\n",
        "---\n",
        "\n",
        "*n_samples* of models would be randomly generated, and trained herein.\n",
        "\n",
        "From its 25% learning curve and final val_loss,\n",
        "\n",
        "NuSVR would get trained thus it'll be a useful estimator for your Bayesian Optimization with Gaussian Process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBx_FmuzSBx_",
        "outputId": "fc1dfaee-2fa9-4374-ed7f-ebbb59d3e02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 80/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0096 - mse: 0.0224 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 81/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 82/100\n",
            "467/467 [==============================] - 2s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 83/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 84/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 85/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 86/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 87/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0110 - mse: 0.0588 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 88/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 89/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 90/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 91/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 92/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 93/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 94/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 95/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 96/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 97/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 98/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 99/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 100/100\n",
            "467/467 [==============================] - 2s 5ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 101/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "467/467 - 2s - loss: 0.0142 - mse: 0.2068 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "467/467 - 2s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 86 started****\n",
            "\n",
            "Epoch 1/100\n",
            "41/41 [==============================] - 2s 9ms/step - loss: 1797.0518 - mse: 30850988.0000 - val_loss: 85.9547 - val_mse: 37597.0117\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1894.2345 - mse: 35993964.0000 - val_loss: 81.8329 - val_mse: 34109.6250\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1854.6813 - mse: 33573188.0000 - val_loss: 76.8606 - val_mse: 30127.3379\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1865.9379 - mse: 34059544.0000 - val_loss: 73.6643 - val_mse: 27700.6934\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1840.8745 - mse: 33674648.0000 - val_loss: 70.6976 - val_mse: 25539.5000\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1811.2393 - mse: 33150104.0000 - val_loss: 66.0522 - val_mse: 22329.7793\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1859.8521 - mse: 35356796.0000 - val_loss: 62.3081 - val_mse: 19901.8438\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1787.4640 - mse: 32391736.0000 - val_loss: 58.0958 - val_mse: 17337.8848\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1831.6682 - mse: 35047888.0000 - val_loss: 53.5117 - val_mse: 14745.0518\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1803.3287 - mse: 32134954.0000 - val_loss: 50.1616 - val_mse: 12984.6992\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1821.8683 - mse: 35894348.0000 - val_loss: 46.6049 - val_mse: 11239.2158\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1734.1395 - mse: 29375798.0000 - val_loss: 42.8818 - val_mse: 9546.2471\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1823.8973 - mse: 31812806.0000 - val_loss: 40.0706 - val_mse: 8359.6836\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1766.2969 - mse: 30871216.0000 - val_loss: 36.4367 - val_mse: 6940.3105\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1841.9010 - mse: 33406176.0000 - val_loss: 32.4380 - val_mse: 5527.1313\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1818.0304 - mse: 31846834.0000 - val_loss: 28.9511 - val_mse: 4422.2222\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1795.3164 - mse: 35095432.0000 - val_loss: 25.1483 - val_mse: 3350.3354\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1822.2649 - mse: 33160392.0000 - val_loss: 21.1920 - val_mse: 2380.1829\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1805.5050 - mse: 30809440.0000 - val_loss: 18.0780 - val_mse: 1721.1267\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1760.8242 - mse: 30616360.0000 - val_loss: 15.0481 - val_mse: 1171.0367\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1709.3928 - mse: 26512502.0000 - val_loss: 12.2612 - val_mse: 741.7245\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1742.9935 - mse: 28564792.0000 - val_loss: 10.4610 - val_mse: 505.5519\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1769.6322 - mse: 28784232.0000 - val_loss: 9.2721 - val_mse: 367.9221\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1822.5505 - mse: 34348620.0000 - val_loss: 7.8293 - val_mse: 221.4714\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1748.8506 - mse: 31253930.0000 - val_loss: 7.0855 - val_mse: 146.7017\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1754.0515 - mse: 27740184.0000 - val_loss: 7.7525 - val_mse: 186.1299\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1713.1277 - mse: 30158240.0000 - val_loss: 9.3375 - val_mse: 312.0150\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1733.9418 - mse: 30253732.0000 - val_loss: 10.6183 - val_mse: 436.7589\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1703.6599 - mse: 26558326.0000 - val_loss: 12.4463 - val_mse: 648.6228\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1730.4646 - mse: 28524392.0000 - val_loss: 14.8456 - val_mse: 986.1874\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1811.9609 - mse: 33097096.0000 - val_loss: 17.3121 - val_mse: 1397.2404\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1748.2325 - mse: 33490594.0000 - val_loss: 19.3222 - val_mse: 1781.6711\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1796.5513 - mse: 33745344.0000 - val_loss: 20.8200 - val_mse: 2098.5923\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1692.8441 - mse: 27648670.0000 - val_loss: 22.1910 - val_mse: 2411.0776\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1709.6843 - mse: 27897424.0000 - val_loss: 24.3131 - val_mse: 2931.7861\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1741.7546 - mse: 26257810.0000 - val_loss: 26.4727 - val_mse: 3509.6831\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1717.2018 - mse: 29602404.0000 - val_loss: 28.6476 - val_mse: 4140.5425\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1776.5479 - mse: 32351526.0000 - val_loss: 30.1657 - val_mse: 4610.1870\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1834.4017 - mse: 38701624.0000 - val_loss: 31.8866 - val_mse: 5171.6274\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1693.8374 - mse: 27550368.0000 - val_loss: 34.1307 - val_mse: 5949.4741\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1691.1422 - mse: 25557730.0000 - val_loss: 36.5132 - val_mse: 6832.8213\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1646.6300 - mse: 24130010.0000 - val_loss: 39.0326 - val_mse: 7833.2944\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1701.2854 - mse: 26928588.0000 - val_loss: 41.6952 - val_mse: 8965.3242\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1699.4768 - mse: 28764054.0000 - val_loss: 42.6695 - val_mse: 9402.0361\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1656.8656 - mse: 28492432.0000 - val_loss: 45.0931 - val_mse: 10530.8545\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1667.9786 - mse: 26971438.0000 - val_loss: 46.8925 - val_mse: 11413.6846\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1749.0824 - mse: 28986574.0000 - val_loss: 49.6693 - val_mse: 12848.0635\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1753.7628 - mse: 31731808.0000 - val_loss: 52.0456 - val_mse: 14143.5293\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1684.6107 - mse: 25143654.0000 - val_loss: 54.7883 - val_mse: 15723.1807\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1645.3392 - mse: 25841178.0000 - val_loss: 56.4510 - val_mse: 16758.0156\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1611.8364 - mse: 26239610.0000 - val_loss: 57.7846 - val_mse: 17648.0410\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1624.4218 - mse: 27018520.0000 - val_loss: 59.0105 - val_mse: 18507.7324\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1713.0312 - mse: 29154012.0000 - val_loss: 60.5690 - val_mse: 19577.1699\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1751.1429 - mse: 30947542.0000 - val_loss: 61.4029 - val_mse: 20083.5234\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1673.1115 - mse: 25766062.0000 - val_loss: 61.9944 - val_mse: 20432.0703\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1620.6710 - mse: 24761000.0000 - val_loss: 63.0808 - val_mse: 21123.4238\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1665.6630 - mse: 26251094.0000 - val_loss: 63.9088 - val_mse: 21690.1934\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1639.3351 - mse: 26097406.0000 - val_loss: 64.4514 - val_mse: 22097.9121\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1694.6982 - mse: 28051718.0000 - val_loss: 64.5723 - val_mse: 22245.1992\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1586.4764 - mse: 24728660.0000 - val_loss: 64.2526 - val_mse: 22103.9531\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1690.1150 - mse: 29105472.0000 - val_loss: 64.1575 - val_mse: 22149.4219\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1639.1138 - mse: 23047646.0000 - val_loss: 64.2534 - val_mse: 22351.0762\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1603.9766 - mse: 23312362.0000 - val_loss: 63.9642 - val_mse: 22192.1191\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1655.1478 - mse: 27027782.0000 - val_loss: 63.3042 - val_mse: 21716.7949\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1683.9064 - mse: 28989262.0000 - val_loss: 62.5027 - val_mse: 21175.4258\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1645.7467 - mse: 26503360.0000 - val_loss: 61.5716 - val_mse: 20573.8652\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1645.2482 - mse: 26626090.0000 - val_loss: 60.7368 - val_mse: 20056.8652\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1663.1144 - mse: 25588918.0000 - val_loss: 59.7637 - val_mse: 19455.7266\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1634.3251 - mse: 25644742.0000 - val_loss: 58.5568 - val_mse: 18702.1816\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1604.2422 - mse: 23645534.0000 - val_loss: 57.5654 - val_mse: 18088.4375\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1645.4120 - mse: 25106784.0000 - val_loss: 56.5201 - val_mse: 17455.1914\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1581.7869 - mse: 23850142.0000 - val_loss: 55.3768 - val_mse: 16775.5977\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1685.4008 - mse: 28021668.0000 - val_loss: 54.1495 - val_mse: 16061.1201\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1642.3926 - mse: 24353570.0000 - val_loss: 53.0680 - val_mse: 15438.7461\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1680.4135 - mse: 27839228.0000 - val_loss: 51.7972 - val_mse: 14717.1084\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1581.3036 - mse: 23359006.0000 - val_loss: 51.0139 - val_mse: 14270.0742\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1682.7603 - mse: 26226940.0000 - val_loss: 49.9977 - val_mse: 13692.4570\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1557.8275 - mse: 22326168.0000 - val_loss: 48.9983 - val_mse: 13131.7197\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1696.6484 - mse: 28884490.0000 - val_loss: 48.1627 - val_mse: 12641.9316\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1618.8210 - mse: 24599996.0000 - val_loss: 47.3981 - val_mse: 12193.9209\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1568.8682 - mse: 23873308.0000 - val_loss: 46.6730 - val_mse: 11810.4219\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1716.3470 - mse: 32439008.0000 - val_loss: 45.9400 - val_mse: 11459.9346\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1592.9611 - mse: 25325054.0000 - val_loss: 45.3211 - val_mse: 11165.0557\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1633.9598 - mse: 26553532.0000 - val_loss: 44.9836 - val_mse: 11006.3789\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1702.5034 - mse: 27441054.0000 - val_loss: 44.3760 - val_mse: 10720.4424\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1603.7311 - mse: 25077078.0000 - val_loss: 43.6429 - val_mse: 10379.1084\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1587.3242 - mse: 25169456.0000 - val_loss: 43.0228 - val_mse: 10094.1953\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1617.4543 - mse: 23948336.0000 - val_loss: 42.4806 - val_mse: 9845.5430\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1528.8888 - mse: 21269366.0000 - val_loss: 41.9537 - val_mse: 9602.3291\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1545.3744 - mse: 20079098.0000 - val_loss: 41.6579 - val_mse: 9459.2734\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1667.0696 - mse: 28273244.0000 - val_loss: 41.2360 - val_mse: 9240.7637\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1576.4543 - mse: 24204698.0000 - val_loss: 40.8363 - val_mse: 9030.8896\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1577.6978 - mse: 27487272.0000 - val_loss: 40.5133 - val_mse: 8831.0391\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1534.8351 - mse: 21392314.0000 - val_loss: 40.2681 - val_mse: 8644.3584\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1570.4813 - mse: 22341916.0000 - val_loss: 40.2722 - val_mse: 8540.8984\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1580.2993 - mse: 23806836.0000 - val_loss: 40.4430 - val_mse: 8449.0762\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1580.0801 - mse: 25054240.0000 - val_loss: 41.2072 - val_mse: 8621.4199\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1665.1256 - mse: 28910858.0000 - val_loss: 42.0927 - val_mse: 9028.3652\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1553.3933 - mse: 22259474.0000 - val_loss: 43.3238 - val_mse: 9614.0049\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 1599.1166 - mse: 24271724.0000 - val_loss: 44.3510 - val_mse: 10081.1348\n",
            "Epoch 101/400\n",
            "41/41 - 0s - loss: 1580.6897 - mse: 23629206.0000 - val_loss: 45.2007 - val_mse: 10477.9883 - 241ms/epoch - 6ms/step\n",
            "Epoch 102/400\n",
            "41/41 - 0s - loss: 1604.1582 - mse: 27346680.0000 - val_loss: 45.9068 - val_mse: 10818.2842 - 176ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "41/41 - 0s - loss: 1647.7637 - mse: 26351610.0000 - val_loss: 46.3670 - val_mse: 11049.5273 - 179ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "41/41 - 0s - loss: 1515.2574 - mse: 22452886.0000 - val_loss: 47.4564 - val_mse: 11609.7832 - 176ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "41/41 - 0s - loss: 1651.9033 - mse: 26785780.0000 - val_loss: 48.0081 - val_mse: 11911.6729 - 172ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "41/41 - 0s - loss: 1603.1125 - mse: 23786470.0000 - val_loss: 48.3649 - val_mse: 12139.1104 - 181ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "41/41 - 0s - loss: 1572.6274 - mse: 24045158.0000 - val_loss: 48.7124 - val_mse: 12391.6289 - 183ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "41/41 - 0s - loss: 1555.5295 - mse: 23025130.0000 - val_loss: 49.2201 - val_mse: 12721.4229 - 181ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "41/41 - 0s - loss: 1558.3621 - mse: 25181908.0000 - val_loss: 49.4838 - val_mse: 12855.5957 - 178ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "41/41 - 0s - loss: 1552.6200 - mse: 22939164.0000 - val_loss: 49.4777 - val_mse: 12848.3467 - 172ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "41/41 - 0s - loss: 1505.6270 - mse: 20124372.0000 - val_loss: 49.3368 - val_mse: 12771.7178 - 179ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "41/41 - 0s - loss: 1639.9287 - mse: 27589298.0000 - val_loss: 49.2981 - val_mse: 12745.8203 - 183ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "41/41 - 0s - loss: 1597.5933 - mse: 24337992.0000 - val_loss: 49.3455 - val_mse: 12761.0547 - 183ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "41/41 - 0s - loss: 1489.0068 - mse: 21997292.0000 - val_loss: 49.5440 - val_mse: 12846.7402 - 175ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "41/41 - 0s - loss: 1582.2524 - mse: 27068976.0000 - val_loss: 49.3346 - val_mse: 12724.8711 - 181ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "41/41 - 0s - loss: 1573.4532 - mse: 26415196.0000 - val_loss: 49.3276 - val_mse: 12696.9092 - 176ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "41/41 - 0s - loss: 1568.8982 - mse: 22661514.0000 - val_loss: 49.5137 - val_mse: 12749.2041 - 179ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "41/41 - 0s - loss: 1545.4799 - mse: 23728962.0000 - val_loss: 49.7177 - val_mse: 12796.9297 - 181ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "41/41 - 0s - loss: 1596.3008 - mse: 26953344.0000 - val_loss: 49.8996 - val_mse: 12823.4092 - 185ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "41/41 - 0s - loss: 1487.6799 - mse: 20450308.0000 - val_loss: 49.8755 - val_mse: 12741.6123 - 193ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "41/41 - 0s - loss: 1587.9152 - mse: 24405784.0000 - val_loss: 50.1407 - val_mse: 12750.6689 - 185ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "41/41 - 0s - loss: 1512.4031 - mse: 22254626.0000 - val_loss: 50.4719 - val_mse: 12803.5664 - 186ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "41/41 - 0s - loss: 1582.9537 - mse: 22478000.0000 - val_loss: 51.2487 - val_mse: 13192.3955 - 184ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "41/41 - 0s - loss: 1503.3319 - mse: 23977738.0000 - val_loss: 52.1157 - val_mse: 13676.1328 - 185ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "41/41 - 0s - loss: 1505.5638 - mse: 21997102.0000 - val_loss: 52.7345 - val_mse: 14044.0322 - 187ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "41/41 - 0s - loss: 1507.9337 - mse: 20100208.0000 - val_loss: 53.3893 - val_mse: 14450.8877 - 180ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "41/41 - 0s - loss: 1602.1317 - mse: 25322994.0000 - val_loss: 54.1544 - val_mse: 14936.3486 - 184ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "41/41 - 0s - loss: 1542.7418 - mse: 24597754.0000 - val_loss: 54.6891 - val_mse: 15320.4883 - 189ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "41/41 - 0s - loss: 1526.4142 - mse: 22545622.0000 - val_loss: 55.1790 - val_mse: 15668.1650 - 193ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "41/41 - 0s - loss: 1513.7489 - mse: 22743722.0000 - val_loss: 55.4927 - val_mse: 15880.0469 - 189ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "41/41 - 0s - loss: 1502.2300 - mse: 19703206.0000 - val_loss: 55.4535 - val_mse: 15860.6045 - 189ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 87 started****\n",
            "\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - 2s 8ms/step - loss: 248.6761 - mse: 870475.8125 - val_loss: 20.2174 - val_mse: 1914.4381\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 47.1365 - mse: 26593.7012 - val_loss: 2.1439 - val_mse: 25.5174\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 21.4365 - mse: 5274.2598 - val_loss: 3.7361 - val_mse: 105.5622\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 15.1547 - mse: 2458.5291 - val_loss: 7.2331 - val_mse: 282.4446\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 13.5646 - mse: 2416.4807 - val_loss: 0.5747 - val_mse: 2.9169\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.4182 - mse: 1005.4395 - val_loss: 6.4452 - val_mse: 237.0132\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.2729 - mse: 849.1524 - val_loss: 7.8135 - val_mse: 338.8922\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.8150 - mse: 265.8347 - val_loss: 2.1556 - val_mse: 28.1185\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8800 - mse: 130.9769 - val_loss: 0.3300 - val_mse: 1.2118\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.1857 - mse: 86.3349 - val_loss: 0.0799 - val_mse: 0.1957\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.4128 - mse: 37.6348 - val_loss: 0.2042 - val_mse: 0.7066\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.3590 - mse: 5.9479 - val_loss: 0.0294 - val_mse: 0.0592\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0646 - mse: 0.5885 - val_loss: 0.0107 - val_mse: 0.0214\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0478 - mse: 0.1747 - val_loss: 0.0153 - val_mse: 0.0306\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0296 - mse: 0.1628 - val_loss: 0.0175 - val_mse: 0.0351\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0269 - mse: 0.1635 - val_loss: 0.0189 - val_mse: 0.0391\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0354 - mse: 0.4320 - val_loss: 0.0066 - val_mse: 0.0131\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0119 - mse: 0.0587 - val_loss: 0.0041 - val_mse: 0.0083\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.1342 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0085 - mse: 0.0246 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0206 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0088 - mse: 0.0330 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0078 - mse: 0.0265 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0110 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0659 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0100 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0111 - val_loss: 0.0052 - val_mse: 0.0105\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 0.0115 - val_loss: 0.0046 - val_mse: 0.0091\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 0.0158 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0046 - val_mse: 0.0091\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0091 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0091 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0104 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0094 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 0.0212 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 0.0121 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0090 - mse: 0.0671 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0076 - mse: 0.0506 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0062 - mse: 0.0139 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 0.0121 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0096 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0089 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0100 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0094 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0121 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0049 - val_mse: 0.0097\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0101 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0095 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0099 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 64/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0048 - val_mse: 0.0097\n",
            "Epoch 65/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0112 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 66/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0051 - val_mse: 0.0102\n",
            "Epoch 67/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 68/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0099 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 69/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 70/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0093 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 71/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 72/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 73/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0046 - val_mse: 0.0091\n",
            "Epoch 74/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 75/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 76/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 0.0152 - val_loss: 0.0056 - val_mse: 0.0111\n",
            "Epoch 77/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 78/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0064 - mse: 0.0288 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 79/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0099 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 80/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0101 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 81/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 0.0124 - val_loss: 0.0054 - val_mse: 0.0109\n",
            "Epoch 82/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 0.0116 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 83/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0099 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 84/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0051 - mse: 0.0102 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 85/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0050 - val_mse: 0.0101\n",
            "Epoch 86/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0100 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 87/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0105 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 88/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0103 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 89/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 90/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0109 - val_loss: 0.0058 - val_mse: 0.0117\n",
            "Epoch 91/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0130 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 92/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0059 - mse: 0.0117 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 93/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0054 - mse: 0.0109 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 94/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0105 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 95/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0060 - mse: 0.0121 - val_loss: 0.0050 - val_mse: 0.0101\n",
            "Epoch 96/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 97/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0110 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 98/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 99/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0101 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 100/100\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0168 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 101/400\n",
            "45/45 - 0s - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0076 - val_mse: 0.0152 - 252ms/epoch - 6ms/step\n",
            "Epoch 102/400\n",
            "45/45 - 0s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0042 - val_mse: 0.0084 - 207ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "45/45 - 0s - loss: 0.0061 - mse: 0.0253 - val_loss: 0.0045 - val_mse: 0.0091 - 203ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "45/45 - 0s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0043 - val_mse: 0.0087 - 198ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "45/45 - 0s - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0050 - val_mse: 0.0100 - 200ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "45/45 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0047 - val_mse: 0.0093 - 187ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "45/45 - 0s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0052 - val_mse: 0.0104 - 193ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "45/45 - 0s - loss: 0.0051 - mse: 0.0103 - val_loss: 0.0045 - val_mse: 0.0090 - 194ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "45/45 - 0s - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0043 - val_mse: 0.0085 - 181ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "45/45 - 0s - loss: 0.0054 - mse: 0.0109 - val_loss: 0.0042 - val_mse: 0.0084 - 194ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "45/45 - 0s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0043 - val_mse: 0.0086 - 185ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "45/45 - 0s - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0044 - val_mse: 0.0089 - 195ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "45/45 - 0s - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0043 - val_mse: 0.0087 - 199ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "45/45 - 0s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0042 - val_mse: 0.0083 - 198ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "45/45 - 0s - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0042 - val_mse: 0.0085 - 201ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "45/45 - 0s - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0044 - val_mse: 0.0088 - 192ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "45/45 - 0s - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0044 - val_mse: 0.0088 - 196ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "45/45 - 0s - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0048 - val_mse: 0.0097 - 196ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "45/45 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0054 - val_mse: 0.0108 - 192ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "45/45 - 0s - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0066 - val_mse: 0.0133 - 191ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "45/45 - 0s - loss: 0.0076 - mse: 0.0151 - val_loss: 0.0084 - val_mse: 0.0167 - 195ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 199ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 194ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 194ms/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 192ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 193ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 196ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 190ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "45/45 - 0s - loss: 21.2015 - mse: 33843.7539 - val_loss: 0.0084 - val_mse: 0.0167 - 192ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 189ms/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0083 - val_mse: 0.0167 - 196ms/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0083 - val_mse: 0.0166 - 193ms/epoch - 4ms/step\n",
            "Epoch 136/400\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0083 - val_mse: 0.0165 - 192ms/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0082 - val_mse: 0.0163 - 191ms/epoch - 4ms/step\n",
            "Epoch 138/400\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0167 - val_loss: 0.0080 - val_mse: 0.0161 - 192ms/epoch - 4ms/step\n",
            "Epoch 139/400\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0078 - val_mse: 0.0157 - 190ms/epoch - 4ms/step\n",
            "Epoch 140/400\n",
            "45/45 - 0s - loss: 0.0080 - mse: 0.0161 - val_loss: 0.0076 - val_mse: 0.0153 - 191ms/epoch - 4ms/step\n",
            "Epoch 141/400\n",
            "45/45 - 0s - loss: 0.0078 - mse: 0.0156 - val_loss: 0.0074 - val_mse: 0.0147 - 197ms/epoch - 4ms/step\n",
            "Epoch 142/400\n",
            "45/45 - 0s - loss: 0.0074 - mse: 0.0147 - val_loss: 0.0067 - val_mse: 0.0133 - 193ms/epoch - 4ms/step\n",
            "Epoch 143/400\n",
            "45/45 - 0s - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0058 - val_mse: 0.0116 - 192ms/epoch - 4ms/step\n",
            "Epoch 144/400\n",
            "45/45 - 0s - loss: 0.0060 - mse: 0.0119 - val_loss: 0.0049 - val_mse: 0.0098 - 196ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 88 started****\n",
            "\n",
            "Epoch 1/100\n",
            "47/47 [==============================] - 4s 11ms/step - loss: 600.7885 - mse: 33947896.0000 - val_loss: 0.1089 - val_mse: 0.2177\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.3782 - mse: 11.2913 - val_loss: 0.0093 - val_mse: 0.0186\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.1584 - mse: 3.6690 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.1015 - mse: 1.0058 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0716 - mse: 0.6261 - val_loss: 0.0056 - val_mse: 0.0112\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0461 - mse: 0.2688 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0362 - mse: 0.1817 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0457 - mse: 0.3269 - val_loss: 0.0078 - val_mse: 0.0156\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0337 - mse: 0.1560 - val_loss: 0.0080 - val_mse: 0.0159\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0253 - mse: 0.1086 - val_loss: 0.0073 - val_mse: 0.0146\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0268 - mse: 0.1199 - val_loss: 0.0074 - val_mse: 0.0148\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0180 - mse: 0.0622 - val_loss: 0.0074 - val_mse: 0.0148\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0241 - mse: 0.1112 - val_loss: 0.0071 - val_mse: 0.0141\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0203 - mse: 0.1124 - val_loss: 0.0067 - val_mse: 0.0133\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0187 - mse: 0.1168 - val_loss: 0.0066 - val_mse: 0.0132\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0171 - mse: 0.0677 - val_loss: 0.0064 - val_mse: 0.0129\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0146 - mse: 0.0389 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0158 - mse: 0.0509 - val_loss: 0.0062 - val_mse: 0.0125\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0199 - mse: 0.2584 - val_loss: 0.0066 - val_mse: 0.0131\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0165 - mse: 0.0707 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0195 - mse: 0.1484 - val_loss: 0.0060 - val_mse: 0.0121\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0117 - mse: 0.0387 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0119 - mse: 0.0426 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0125 - mse: 0.0359 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0188 - mse: 0.5955 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0129 - mse: 0.0427 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0215 - val_loss: 0.0065 - val_mse: 0.0131\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0207 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0335 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0228 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0214 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0993 - val_loss: 0.0062 - val_mse: 0.0123\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0113 - mse: 0.0475 - val_loss: 0.0067 - val_mse: 0.0134\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0304 - val_loss: 0.0067 - val_mse: 0.0134\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0213 - val_loss: 0.0068 - val_mse: 0.0135\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0111 - mse: 0.0556 - val_loss: 0.0068 - val_mse: 0.0136\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0327 - val_loss: 0.0068 - val_mse: 0.0135\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0195 - val_loss: 0.0065 - val_mse: 0.0130\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0208 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0288 - val_loss: 0.0066 - val_mse: 0.0131\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0172 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0184 - val_loss: 0.0067 - val_mse: 0.0133\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0203 - val_loss: 0.0065 - val_mse: 0.0130\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0204 - val_loss: 0.0064 - val_mse: 0.0127\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0130 - mse: 0.1067 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0197 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0191 - val_loss: 0.0064 - val_mse: 0.0129\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0081 - mse: 0.0161 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0177 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0168 - val_loss: 0.0063 - val_mse: 0.0125\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0062 - val_mse: 0.0123\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0081 - mse: 0.0163 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0192 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0168 - val_loss: 0.0059 - val_mse: 0.0119\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0184 - val_loss: 0.0062 - val_mse: 0.0125\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0080 - mse: 0.0163 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0085 - mse: 0.0177 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0400 - val_loss: 0.0064 - val_mse: 0.0127\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0218 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0181 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0173 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0193 - val_loss: 0.0064 - val_mse: 0.0128\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0079 - mse: 0.0158 - val_loss: 0.0061 - val_mse: 0.0122\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0080 - mse: 0.0161 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0200 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0229 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0153 - val_loss: 0.0063 - val_mse: 0.0127\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0079 - mse: 0.0159 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0172 - val_loss: 0.0061 - val_mse: 0.0123\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0079 - mse: 0.0157 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0185 - val_loss: 0.0065 - val_mse: 0.0129\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0082 - mse: 0.0167 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0168 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0233 - val_loss: 0.0060 - val_mse: 0.0121\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0155 - val_loss: 0.0061 - val_mse: 0.0122\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0234 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0078 - mse: 0.0157 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0060 - val_mse: 0.0119\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0153 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0082 - mse: 0.0182 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0186 - val_loss: 0.0059 - val_mse: 0.0117\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0058 - val_mse: 0.0115\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0059 - val_mse: 0.0117\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0058 - val_mse: 0.0117\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0074 - mse: 0.0148 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0145 - val_loss: 0.0060 - val_mse: 0.0120\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0074 - mse: 0.0149 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0059 - val_mse: 0.0117\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0056 - val_mse: 0.0113\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0055 - val_mse: 0.0111\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0152 - val_loss: 0.0056 - val_mse: 0.0111\n",
            "Epoch 101/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0147 - val_loss: 0.0056 - val_mse: 0.0111 - 315ms/epoch - 7ms/step\n",
            "Epoch 102/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0055 - val_mse: 0.0111 - 258ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0057 - val_mse: 0.0113 - 246ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0057 - val_mse: 0.0114 - 243ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0143 - val_loss: 0.0057 - val_mse: 0.0113 - 248ms/epoch - 5ms/step\n",
            "Epoch 106/400\n",
            "47/47 - 0s - loss: 0.0077 - mse: 0.0162 - val_loss: 0.0058 - val_mse: 0.0115 - 253ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "47/47 - 0s - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0057 - val_mse: 0.0114 - 247ms/epoch - 5ms/step\n",
            "Epoch 108/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0055 - val_mse: 0.0110 - 254ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0149 - val_loss: 0.0055 - val_mse: 0.0111 - 244ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "47/47 - 0s - loss: 0.0101 - mse: 0.0240 - val_loss: 0.0059 - val_mse: 0.0118 - 244ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "47/47 - 0s - loss: 0.0077 - mse: 0.0156 - val_loss: 0.0059 - val_mse: 0.0117 - 239ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "47/47 - 0s - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0058 - val_mse: 0.0116 - 246ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0148 - val_loss: 0.0060 - val_mse: 0.0120 - 242ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "47/47 - 0s - loss: 0.0077 - mse: 0.0157 - val_loss: 0.0060 - val_mse: 0.0119 - 239ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0148 - val_loss: 0.0058 - val_mse: 0.0116 - 238ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "47/47 - 0s - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0058 - val_mse: 0.0115 - 244ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0057 - val_mse: 0.0113 - 238ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0057 - val_mse: 0.0114 - 244ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0057 - val_mse: 0.0114 - 239ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0056 - val_mse: 0.0113 - 244ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0056 - val_mse: 0.0111 - 242ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "47/47 - 0s - loss: 0.0093 - mse: 0.0420 - val_loss: 0.0056 - val_mse: 0.0112 - 240ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0056 - val_mse: 0.0113 - 237ms/epoch - 5ms/step\n",
            "Epoch 124/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0058 - val_mse: 0.0117 - 245ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0143 - val_loss: 0.0055 - val_mse: 0.0110 - 245ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "47/47 - 0s - loss: 0.0088 - mse: 0.0303 - val_loss: 0.0056 - val_mse: 0.0112 - 240ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0055 - val_mse: 0.0110 - 239ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0055 - val_mse: 0.0111 - 243ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "47/47 - 0s - loss: 0.0076 - mse: 0.0159 - val_loss: 0.0056 - val_mse: 0.0112 - 239ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0146 - val_loss: 0.0054 - val_mse: 0.0108 - 250ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0055 - val_mse: 0.0109 - 248ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0148 - val_loss: 0.0056 - val_mse: 0.0112 - 246ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0055 - val_mse: 0.0109 - 263ms/epoch - 6ms/step\n",
            "Epoch 134/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0055 - val_mse: 0.0109 - 248ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "47/47 - 0s - loss: 0.0073 - mse: 0.0152 - val_loss: 0.0054 - val_mse: 0.0108 - 268ms/epoch - 6ms/step\n",
            "Epoch 136/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0057 - val_mse: 0.0113 - 251ms/epoch - 5ms/step\n",
            "Epoch 137/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0055 - val_mse: 0.0110 - 251ms/epoch - 5ms/step\n",
            "Epoch 138/400\n",
            "47/47 - 0s - loss: 0.0075 - mse: 0.0187 - val_loss: 0.0055 - val_mse: 0.0111 - 245ms/epoch - 5ms/step\n",
            "Epoch 139/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0139 - val_loss: 0.0055 - val_mse: 0.0111 - 246ms/epoch - 5ms/step\n",
            "Epoch 140/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0055 - val_mse: 0.0109 - 251ms/epoch - 5ms/step\n",
            "Epoch 141/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0055 - val_mse: 0.0111 - 253ms/epoch - 5ms/step\n",
            "Epoch 142/400\n",
            "47/47 - 0s - loss: 0.0075 - mse: 0.0156 - val_loss: 0.0056 - val_mse: 0.0112 - 262ms/epoch - 6ms/step\n",
            "Epoch 143/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0052 - val_mse: 0.0103 - 245ms/epoch - 5ms/step\n",
            "Epoch 144/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0139 - val_loss: 0.0053 - val_mse: 0.0106 - 240ms/epoch - 5ms/step\n",
            "Epoch 145/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0054 - val_mse: 0.0108 - 246ms/epoch - 5ms/step\n",
            "Epoch 146/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0053 - val_mse: 0.0106 - 244ms/epoch - 5ms/step\n",
            "Epoch 147/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0139 - val_loss: 0.0056 - val_mse: 0.0113 - 241ms/epoch - 5ms/step\n",
            "Epoch 148/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0054 - val_mse: 0.0108 - 245ms/epoch - 5ms/step\n",
            "Epoch 149/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0053 - val_mse: 0.0107 - 242ms/epoch - 5ms/step\n",
            "Epoch 150/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0053 - val_mse: 0.0106 - 243ms/epoch - 5ms/step\n",
            "Epoch 151/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0054 - val_mse: 0.0109 - 244ms/epoch - 5ms/step\n",
            "Epoch 152/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0141 - val_loss: 0.0054 - val_mse: 0.0109 - 243ms/epoch - 5ms/step\n",
            "Epoch 153/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0053 - val_mse: 0.0107 - 242ms/epoch - 5ms/step\n",
            "Epoch 154/400\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0149 - val_loss: 0.0053 - val_mse: 0.0105 - 234ms/epoch - 5ms/step\n",
            "Epoch 155/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0053 - val_mse: 0.0106 - 235ms/epoch - 5ms/step\n",
            "Epoch 156/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0141 - val_loss: 0.0054 - val_mse: 0.0108 - 242ms/epoch - 5ms/step\n",
            "Epoch 157/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0052 - val_mse: 0.0105 - 248ms/epoch - 5ms/step\n",
            "Epoch 158/400\n",
            "47/47 - 0s - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0053 - val_mse: 0.0105 - 246ms/epoch - 5ms/step\n",
            "Epoch 159/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0053 - val_mse: 0.0106 - 244ms/epoch - 5ms/step\n",
            "Epoch 160/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0053 - val_mse: 0.0105 - 245ms/epoch - 5ms/step\n",
            "Epoch 161/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0053 - val_mse: 0.0106 - 244ms/epoch - 5ms/step\n",
            "Epoch 162/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0054 - val_mse: 0.0108 - 241ms/epoch - 5ms/step\n",
            "Epoch 163/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0137 - val_loss: 0.0052 - val_mse: 0.0105 - 239ms/epoch - 5ms/step\n",
            "Epoch 164/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0053 - val_mse: 0.0107 - 243ms/epoch - 5ms/step\n",
            "Epoch 165/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0137 - val_loss: 0.0053 - val_mse: 0.0106 - 241ms/epoch - 5ms/step\n",
            "Epoch 166/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0052 - val_mse: 0.0104 - 238ms/epoch - 5ms/step\n",
            "Epoch 167/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0052 - val_mse: 0.0103 - 249ms/epoch - 5ms/step\n",
            "Epoch 168/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0051 - val_mse: 0.0102 - 248ms/epoch - 5ms/step\n",
            "Epoch 169/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0054 - val_mse: 0.0108 - 246ms/epoch - 5ms/step\n",
            "Epoch 170/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0055 - val_mse: 0.0111 - 248ms/epoch - 5ms/step\n",
            "Epoch 171/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0137 - val_loss: 0.0051 - val_mse: 0.0102 - 245ms/epoch - 5ms/step\n",
            "Epoch 172/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0052 - val_mse: 0.0103 - 245ms/epoch - 5ms/step\n",
            "Epoch 173/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0137 - val_loss: 0.0052 - val_mse: 0.0103 - 242ms/epoch - 5ms/step\n",
            "Epoch 174/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0052 - val_mse: 0.0104 - 243ms/epoch - 5ms/step\n",
            "Epoch 175/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0137 - val_loss: 0.0052 - val_mse: 0.0105 - 242ms/epoch - 5ms/step\n",
            "Epoch 176/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0050 - val_mse: 0.0101 - 248ms/epoch - 5ms/step\n",
            "Epoch 177/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0133 - val_loss: 0.0050 - val_mse: 0.0100 - 246ms/epoch - 5ms/step\n",
            "Epoch 178/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0053 - val_mse: 0.0105 - 241ms/epoch - 5ms/step\n",
            "Epoch 179/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0135 - val_loss: 0.0053 - val_mse: 0.0105 - 241ms/epoch - 5ms/step\n",
            "Epoch 180/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0135 - val_loss: 0.0051 - val_mse: 0.0102 - 242ms/epoch - 5ms/step\n",
            "Epoch 181/400\n",
            "47/47 - 0s - loss: 0.0077 - mse: 0.0176 - val_loss: 0.0069 - val_mse: 0.0138 - 242ms/epoch - 5ms/step\n",
            "Epoch 182/400\n",
            "47/47 - 0s - loss: 0.0079 - mse: 0.0159 - val_loss: 0.0060 - val_mse: 0.0120 - 235ms/epoch - 5ms/step\n",
            "Epoch 183/400\n",
            "47/47 - 0s - loss: 0.0088 - mse: 0.0199 - val_loss: 0.0054 - val_mse: 0.0109 - 252ms/epoch - 5ms/step\n",
            "Epoch 184/400\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0153 - val_loss: 0.0052 - val_mse: 0.0105 - 251ms/epoch - 5ms/step\n",
            "Epoch 185/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0139 - val_loss: 0.0054 - val_mse: 0.0107 - 254ms/epoch - 5ms/step\n",
            "Epoch 186/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0051 - val_mse: 0.0103 - 257ms/epoch - 5ms/step\n",
            "Epoch 187/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0055 - val_mse: 0.0109 - 264ms/epoch - 6ms/step\n",
            "Epoch 188/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0052 - val_mse: 0.0103 - 256ms/epoch - 5ms/step\n",
            "Epoch 189/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0051 - val_mse: 0.0102 - 269ms/epoch - 6ms/step\n",
            "Epoch 190/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0129 - val_loss: 0.0052 - val_mse: 0.0104 - 245ms/epoch - 5ms/step\n",
            "Epoch 191/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0049 - val_mse: 0.0098 - 255ms/epoch - 5ms/step\n",
            "Epoch 192/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0051 - val_mse: 0.0101 - 257ms/epoch - 5ms/step\n",
            "Epoch 193/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0052 - val_mse: 0.0104 - 261ms/epoch - 6ms/step\n",
            "Epoch 194/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0053 - val_mse: 0.0106 - 244ms/epoch - 5ms/step\n",
            "Epoch 195/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0138 - val_loss: 0.0052 - val_mse: 0.0104 - 242ms/epoch - 5ms/step\n",
            "Epoch 196/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0053 - val_mse: 0.0106 - 247ms/epoch - 5ms/step\n",
            "Epoch 197/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0051 - val_mse: 0.0103 - 246ms/epoch - 5ms/step\n",
            "Epoch 198/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0129 - val_loss: 0.0054 - val_mse: 0.0108 - 245ms/epoch - 5ms/step\n",
            "Epoch 199/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0053 - val_mse: 0.0106 - 238ms/epoch - 5ms/step\n",
            "Epoch 200/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0134 - val_loss: 0.0049 - val_mse: 0.0099 - 240ms/epoch - 5ms/step\n",
            "Epoch 201/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0051 - val_mse: 0.0102 - 245ms/epoch - 5ms/step\n",
            "Epoch 202/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0129 - val_loss: 0.0049 - val_mse: 0.0098 - 250ms/epoch - 5ms/step\n",
            "Epoch 203/400\n",
            "47/47 - 0s - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0050 - val_mse: 0.0101 - 244ms/epoch - 5ms/step\n",
            "Epoch 204/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0129 - val_loss: 0.0048 - val_mse: 0.0097 - 251ms/epoch - 5ms/step\n",
            "Epoch 205/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0049 - val_mse: 0.0099 - 244ms/epoch - 5ms/step\n",
            "Epoch 206/400\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0048 - val_mse: 0.0096 - 252ms/epoch - 5ms/step\n",
            "Epoch 207/400\n",
            "47/47 - 0s - loss: 0.0063 - mse: 0.0127 - val_loss: 0.0048 - val_mse: 0.0097 - 242ms/epoch - 5ms/step\n",
            "Epoch 208/400\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0050 - val_mse: 0.0100 - 242ms/epoch - 5ms/step\n",
            "Epoch 209/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0052 - val_mse: 0.0104 - 240ms/epoch - 5ms/step\n",
            "Epoch 210/400\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0049 - val_mse: 0.0099 - 241ms/epoch - 5ms/step\n",
            "Epoch 211/400\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0127 - val_loss: 0.0051 - val_mse: 0.0102 - 237ms/epoch - 5ms/step\n",
            "Epoch 212/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0142 - val_loss: 0.0047 - val_mse: 0.0095 - 244ms/epoch - 5ms/step\n",
            "Epoch 213/400\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0140 - val_loss: 0.0056 - val_mse: 0.0112 - 237ms/epoch - 5ms/step\n",
            "Epoch 214/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0135 - val_loss: 0.0051 - val_mse: 0.0102 - 246ms/epoch - 5ms/step\n",
            "Epoch 215/400\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0050 - val_mse: 0.0099 - 249ms/epoch - 5ms/step\n",
            "Epoch 216/400\n",
            "47/47 - 0s - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0054 - val_mse: 0.0107 - 254ms/epoch - 5ms/step\n",
            "Epoch 217/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0051 - val_mse: 0.0102 - 251ms/epoch - 5ms/step\n",
            "Epoch 218/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0050 - val_mse: 0.0100 - 244ms/epoch - 5ms/step\n",
            "Epoch 219/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0050 - val_mse: 0.0100 - 247ms/epoch - 5ms/step\n",
            "Epoch 220/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0129 - val_loss: 0.0050 - val_mse: 0.0100 - 251ms/epoch - 5ms/step\n",
            "Epoch 221/400\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0050 - val_mse: 0.0101 - 243ms/epoch - 5ms/step\n",
            "Epoch 222/400\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0131 - val_loss: 0.0050 - val_mse: 0.0101 - 240ms/epoch - 5ms/step\n",
            "Epoch 223/400\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0049 - val_mse: 0.0098 - 245ms/epoch - 5ms/step\n",
            "Epoch 224/400\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0047 - val_mse: 0.0094 - 252ms/epoch - 5ms/step\n",
            "Epoch 225/400\n",
            "47/47 - 0s - loss: 0.1903 - mse: 114.4025 - val_loss: 0.0089 - val_mse: 0.0177 - 242ms/epoch - 5ms/step\n",
            "Epoch 226/400\n",
            "47/47 - 0s - loss: 5.6788 - mse: 28763.7559 - val_loss: 0.0084 - val_mse: 0.0168 - 246ms/epoch - 5ms/step\n",
            "Epoch 227/400\n",
            "47/47 - 0s - loss: 0.2627 - mse: 242.4093 - val_loss: 0.0084 - val_mse: 0.0168 - 261ms/epoch - 6ms/step\n",
            "Epoch 228/400\n",
            "47/47 - 0s - loss: 0.0115 - mse: 0.0366 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 5ms/step\n",
            "Epoch 229/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 247ms/epoch - 5ms/step\n",
            "Epoch 230/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 5ms/step\n",
            "Epoch 231/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 5ms/step\n",
            "Epoch 232/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 240ms/epoch - 5ms/step\n",
            "Epoch 233/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 241ms/epoch - 5ms/step\n",
            "Epoch 234/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 250ms/epoch - 5ms/step\n",
            "Epoch 235/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 5ms/step\n",
            "Epoch 236/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 250ms/epoch - 5ms/step\n",
            "Epoch 237/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 6ms/step\n",
            "Epoch 238/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 253ms/epoch - 5ms/step\n",
            "Epoch 239/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 246ms/epoch - 5ms/step\n",
            "Epoch 240/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 248ms/epoch - 5ms/step\n",
            "Epoch 241/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 250ms/epoch - 5ms/step\n",
            "Epoch 242/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 5ms/step\n",
            "Epoch 243/400\n",
            "47/47 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 251ms/epoch - 5ms/step\n",
            "Epoch 244/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 5ms/step\n",
            "Epoch 245/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 5ms/step\n",
            "Epoch 246/400\n",
            "47/47 - 0s - loss: 0.0089 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0167 - 240ms/epoch - 5ms/step\n",
            "Epoch 247/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 240ms/epoch - 5ms/step\n",
            "Epoch 248/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 241ms/epoch - 5ms/step\n",
            "Epoch 249/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 5ms/step\n",
            "Epoch 250/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 240ms/epoch - 5ms/step\n",
            "Epoch 251/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 238ms/epoch - 5ms/step\n",
            "Epoch 252/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 243ms/epoch - 5ms/step\n",
            "Epoch 253/400\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 5ms/step\n",
            "Epoch 254/400\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 249ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 89 started****\n",
            "\n",
            "Epoch 1/100\n",
            "159/159 [==============================] - 3s 6ms/step - loss: 1861.2190 - mse: 34898160.0000 - val_loss: 280.5630 - val_mse: 427507.4062\n",
            "Epoch 2/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1714.5801 - mse: 28381814.0000 - val_loss: 91.5039 - val_mse: 50783.3242\n",
            "Epoch 3/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1604.5815 - mse: 25170802.0000 - val_loss: 38.0015 - val_mse: 5315.8320\n",
            "Epoch 4/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1537.1849 - mse: 24011664.0000 - val_loss: 127.5037 - val_mse: 76776.1484\n",
            "Epoch 5/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1429.7820 - mse: 19752682.0000 - val_loss: 164.4441 - val_mse: 136190.9219\n",
            "Epoch 6/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1332.3561 - mse: 17279366.0000 - val_loss: 150.7190 - val_mse: 115420.0469\n",
            "Epoch 7/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1329.8154 - mse: 19262168.0000 - val_loss: 154.5786 - val_mse: 122387.1484\n",
            "Epoch 8/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1209.2845 - mse: 14836657.0000 - val_loss: 148.4823 - val_mse: 114038.1484\n",
            "Epoch 9/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1187.5110 - mse: 14609904.0000 - val_loss: 143.9701 - val_mse: 103238.9844\n",
            "Epoch 10/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1127.9850 - mse: 11965125.0000 - val_loss: 152.7409 - val_mse: 114671.9375\n",
            "Epoch 11/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1106.7885 - mse: 12684110.0000 - val_loss: 142.1590 - val_mse: 100535.7031\n",
            "Epoch 12/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1032.9005 - mse: 11016407.0000 - val_loss: 148.5162 - val_mse: 116682.4141\n",
            "Epoch 13/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 1006.1813 - mse: 11244589.0000 - val_loss: 121.9943 - val_mse: 81673.5547\n",
            "Epoch 14/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 980.8569 - mse: 9734121.0000 - val_loss: 103.1025 - val_mse: 61796.1562\n",
            "Epoch 15/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 916.1490 - mse: 8249626.0000 - val_loss: 63.6618 - val_mse: 25060.2422\n",
            "Epoch 16/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 905.4766 - mse: 7745685.0000 - val_loss: 58.6068 - val_mse: 21176.1816\n",
            "Epoch 17/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 871.5111 - mse: 7692450.0000 - val_loss: 40.6777 - val_mse: 9476.8340\n",
            "Epoch 18/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 827.1537 - mse: 6173213.5000 - val_loss: 40.9063 - val_mse: 8576.1289\n",
            "Epoch 19/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 841.4134 - mse: 7506589.0000 - val_loss: 42.4767 - val_mse: 9258.3740\n",
            "Epoch 20/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 818.5334 - mse: 7166143.0000 - val_loss: 45.3109 - val_mse: 10485.0713\n",
            "Epoch 21/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 823.4839 - mse: 7631784.0000 - val_loss: 44.1694 - val_mse: 9825.5020\n",
            "Epoch 22/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 787.2343 - mse: 6846698.5000 - val_loss: 43.2172 - val_mse: 9448.5088\n",
            "Epoch 23/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 721.7194 - mse: 5172482.5000 - val_loss: 40.7921 - val_mse: 8441.0576\n",
            "Epoch 24/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 732.7344 - mse: 5405619.0000 - val_loss: 39.8912 - val_mse: 8178.6694\n",
            "Epoch 25/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 712.6138 - mse: 6080059.0000 - val_loss: 40.6614 - val_mse: 8108.5840\n",
            "Epoch 26/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 686.1851 - mse: 4520680.0000 - val_loss: 38.1099 - val_mse: 7198.0010\n",
            "Epoch 27/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 669.8439 - mse: 4464174.5000 - val_loss: 40.5483 - val_mse: 7422.4043\n",
            "Epoch 28/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 650.1475 - mse: 4127257.5000 - val_loss: 36.5571 - val_mse: 6256.3022\n",
            "Epoch 29/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 616.6885 - mse: 3655134.5000 - val_loss: 40.2407 - val_mse: 7408.3066\n",
            "Epoch 30/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 589.2420 - mse: 3102219.5000 - val_loss: 42.4070 - val_mse: 8520.9375\n",
            "Epoch 31/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 600.2588 - mse: 4316120.0000 - val_loss: 45.8873 - val_mse: 10071.8848\n",
            "Epoch 32/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 569.0961 - mse: 3511537.2500 - val_loss: 49.5069 - val_mse: 11773.2139\n",
            "Epoch 33/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 540.6966 - mse: 2884780.7500 - val_loss: 48.7843 - val_mse: 11533.1787\n",
            "Epoch 34/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 504.6728 - mse: 2379770.5000 - val_loss: 45.8301 - val_mse: 10685.9150\n",
            "Epoch 35/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 527.2260 - mse: 2804894.5000 - val_loss: 42.1493 - val_mse: 9349.7246\n",
            "Epoch 36/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 505.9367 - mse: 2531511.5000 - val_loss: 42.1556 - val_mse: 9221.2725\n",
            "Epoch 37/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 496.4864 - mse: 2632334.0000 - val_loss: 39.4520 - val_mse: 7990.4570\n",
            "Epoch 38/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 477.8605 - mse: 2415427.2500 - val_loss: 36.3547 - val_mse: 6831.7002\n",
            "Epoch 39/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 459.6708 - mse: 1822835.7500 - val_loss: 34.8306 - val_mse: 6366.3203\n",
            "Epoch 40/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 438.8994 - mse: 1749986.1250 - val_loss: 32.0185 - val_mse: 5341.0625\n",
            "Epoch 41/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 449.4436 - mse: 2253484.5000 - val_loss: 30.1136 - val_mse: 4741.7324\n",
            "Epoch 42/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 419.5423 - mse: 1798006.2500 - val_loss: 28.6615 - val_mse: 4313.6406\n",
            "Epoch 43/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 400.9435 - mse: 1600381.2500 - val_loss: 29.4253 - val_mse: 4496.7769\n",
            "Epoch 44/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 398.0386 - mse: 1737314.0000 - val_loss: 29.1448 - val_mse: 4496.2520\n",
            "Epoch 45/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 394.6427 - mse: 1756878.7500 - val_loss: 24.2671 - val_mse: 3051.2588\n",
            "Epoch 46/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 390.3221 - mse: 1758191.0000 - val_loss: 21.9884 - val_mse: 2523.0063\n",
            "Epoch 47/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 377.1891 - mse: 1621933.7500 - val_loss: 22.0013 - val_mse: 2686.8689\n",
            "Epoch 48/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 343.1401 - mse: 1053668.3750 - val_loss: 20.2024 - val_mse: 2253.1567\n",
            "Epoch 49/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 347.0060 - mse: 1271361.0000 - val_loss: 17.2948 - val_mse: 1623.2261\n",
            "Epoch 50/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 333.8597 - mse: 1105478.0000 - val_loss: 15.2819 - val_mse: 1312.1573\n",
            "Epoch 51/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 321.5732 - mse: 1141308.6250 - val_loss: 12.5927 - val_mse: 886.5011\n",
            "Epoch 52/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 319.5073 - mse: 1069901.7500 - val_loss: 10.9871 - val_mse: 678.3639\n",
            "Epoch 53/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 295.7070 - mse: 894429.8750 - val_loss: 7.8418 - val_mse: 369.6119\n",
            "Epoch 54/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 295.1572 - mse: 925311.5000 - val_loss: 6.8702 - val_mse: 287.1608\n",
            "Epoch 55/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 280.6601 - mse: 919604.3125 - val_loss: 6.0666 - val_mse: 228.0326\n",
            "Epoch 56/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 268.4911 - mse: 749759.0625 - val_loss: 6.4788 - val_mse: 260.4902\n",
            "Epoch 57/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 265.9779 - mse: 716572.0625 - val_loss: 6.7256 - val_mse: 280.5518\n",
            "Epoch 58/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 252.2401 - mse: 612918.3750 - val_loss: 8.9424 - val_mse: 476.1141\n",
            "Epoch 59/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 245.4059 - mse: 691848.0000 - val_loss: 8.0445 - val_mse: 393.3419\n",
            "Epoch 60/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 241.1659 - mse: 607706.6875 - val_loss: 8.5712 - val_mse: 445.0473\n",
            "Epoch 61/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 233.5051 - mse: 556812.7500 - val_loss: 7.5164 - val_mse: 346.4346\n",
            "Epoch 62/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 223.9909 - mse: 550648.1250 - val_loss: 7.4248 - val_mse: 327.3176\n",
            "Epoch 63/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 227.6105 - mse: 533293.2500 - val_loss: 7.8180 - val_mse: 370.6383\n",
            "Epoch 64/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 218.2980 - mse: 540684.1875 - val_loss: 7.5406 - val_mse: 346.6321\n",
            "Epoch 65/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 206.8513 - mse: 440624.8750 - val_loss: 6.9632 - val_mse: 299.2530\n",
            "Epoch 66/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 202.5050 - mse: 526883.8125 - val_loss: 6.6705 - val_mse: 276.7466\n",
            "Epoch 67/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 192.7086 - mse: 374473.3438 - val_loss: 6.8533 - val_mse: 296.6875\n",
            "Epoch 68/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 188.8219 - mse: 443319.0312 - val_loss: 6.3760 - val_mse: 258.1821\n",
            "Epoch 69/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 178.4397 - mse: 321499.9688 - val_loss: 6.0765 - val_mse: 235.9426\n",
            "Epoch 70/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 172.3770 - mse: 329916.9062 - val_loss: 5.5092 - val_mse: 196.8490\n",
            "Epoch 71/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 168.6560 - mse: 299348.9062 - val_loss: 5.4599 - val_mse: 193.6721\n",
            "Epoch 72/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 162.5953 - mse: 282892.2812 - val_loss: 5.0835 - val_mse: 169.0042\n",
            "Epoch 73/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 160.9769 - mse: 296130.9688 - val_loss: 4.3151 - val_mse: 124.7354\n",
            "Epoch 74/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 160.3630 - mse: 300552.0000 - val_loss: 3.5143 - val_mse: 85.9437\n",
            "Epoch 75/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 148.9968 - mse: 246926.1719 - val_loss: 2.9523 - val_mse: 62.5320\n",
            "Epoch 76/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 150.1477 - mse: 238071.7344 - val_loss: 2.8625 - val_mse: 59.2301\n",
            "Epoch 77/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 136.0143 - mse: 188843.9688 - val_loss: 2.5012 - val_mse: 46.3751\n",
            "Epoch 78/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 136.7308 - mse: 229155.0312 - val_loss: 2.2951 - val_mse: 39.6550\n",
            "Epoch 79/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 133.0983 - mse: 201581.4062 - val_loss: 1.9501 - val_mse: 29.4565\n",
            "Epoch 80/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 125.9429 - mse: 157915.3281 - val_loss: 1.8005 - val_mse: 25.3994\n",
            "Epoch 81/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 126.2793 - mse: 172345.4375 - val_loss: 1.6648 - val_mse: 22.1868\n",
            "Epoch 82/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 112.2160 - mse: 131531.5625 - val_loss: 1.7427 - val_mse: 24.1476\n",
            "Epoch 83/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 115.1678 - mse: 164913.1875 - val_loss: 1.7393 - val_mse: 23.7422\n",
            "Epoch 84/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 117.7414 - mse: 157493.3438 - val_loss: 1.5077 - val_mse: 18.3401\n",
            "Epoch 85/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 103.3245 - mse: 108048.1719 - val_loss: 1.4268 - val_mse: 16.5405\n",
            "Epoch 86/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 101.5027 - mse: 112375.4766 - val_loss: 1.3322 - val_mse: 14.5617\n",
            "Epoch 87/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 100.7106 - mse: 119801.4297 - val_loss: 1.2131 - val_mse: 12.2301\n",
            "Epoch 88/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 101.4501 - mse: 118775.7344 - val_loss: 1.1737 - val_mse: 11.5027\n",
            "Epoch 89/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 95.3155 - mse: 107602.6641 - val_loss: 1.0178 - val_mse: 8.7959\n",
            "Epoch 90/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 94.1722 - mse: 103897.0469 - val_loss: 0.9349 - val_mse: 7.4875\n",
            "Epoch 91/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 86.0419 - mse: 85872.8203 - val_loss: 0.7985 - val_mse: 5.5310\n",
            "Epoch 92/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 88.3244 - mse: 105116.0625 - val_loss: 0.7186 - val_mse: 4.5067\n",
            "Epoch 93/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 79.1637 - mse: 76022.5000 - val_loss: 0.6117 - val_mse: 3.2856\n",
            "Epoch 94/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 81.8791 - mse: 80691.8750 - val_loss: 0.5835 - val_mse: 3.0000\n",
            "Epoch 95/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 74.9216 - mse: 63823.7188 - val_loss: 0.5161 - val_mse: 2.3523\n",
            "Epoch 96/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 73.2407 - mse: 62351.8867 - val_loss: 0.4747 - val_mse: 2.0126\n",
            "Epoch 97/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 69.8770 - mse: 65321.9297 - val_loss: 0.4368 - val_mse: 1.7368\n",
            "Epoch 98/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 67.7711 - mse: 57624.6875 - val_loss: 0.3984 - val_mse: 1.4087\n",
            "Epoch 99/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 66.2122 - mse: 54786.8359 - val_loss: 0.4710 - val_mse: 1.9678\n",
            "Epoch 100/100\n",
            "159/159 [==============================] - 1s 5ms/step - loss: 64.1146 - mse: 47866.2891 - val_loss: 0.4797 - val_mse: 2.0484\n",
            "Epoch 101/400\n",
            "159/159 - 1s - loss: 60.1076 - mse: 37217.2812 - val_loss: 0.5011 - val_mse: 2.2453 - 705ms/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "159/159 - 1s - loss: 58.1941 - mse: 41653.2422 - val_loss: 0.5265 - val_mse: 2.4676 - 656ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "159/159 - 1s - loss: 56.6678 - mse: 39145.2852 - val_loss: 0.6398 - val_mse: 3.5786 - 663ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "159/159 - 1s - loss: 55.5764 - mse: 39593.1602 - val_loss: 0.8144 - val_mse: 5.6629 - 660ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "159/159 - 1s - loss: 51.8928 - mse: 37364.3359 - val_loss: 0.9610 - val_mse: 7.7632 - 641ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "159/159 - 1s - loss: 54.8847 - mse: 39156.1328 - val_loss: 1.1120 - val_mse: 10.1948 - 722ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "159/159 - 1s - loss: 50.0930 - mse: 35894.2422 - val_loss: 1.1622 - val_mse: 11.0625 - 691ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "159/159 - 1s - loss: 47.3652 - mse: 32937.2773 - val_loss: 1.2684 - val_mse: 12.9859 - 680ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "159/159 - 1s - loss: 44.8708 - mse: 26256.3242 - val_loss: 1.3641 - val_mse: 14.8731 - 692ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "159/159 - 1s - loss: 44.6814 - mse: 30851.9395 - val_loss: 1.5155 - val_mse: 18.0728 - 666ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "159/159 - 1s - loss: 43.4124 - mse: 28082.4297 - val_loss: 1.5865 - val_mse: 19.6501 - 653ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "159/159 - 1s - loss: 43.7070 - mse: 38395.0117 - val_loss: 1.6374 - val_mse: 20.8058 - 669ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "159/159 - 1s - loss: 41.4607 - mse: 26528.7344 - val_loss: 1.7005 - val_mse: 22.2550 - 670ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "159/159 - 1s - loss: 39.0557 - mse: 18923.6074 - val_loss: 1.6804 - val_mse: 21.7763 - 669ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "159/159 - 1s - loss: 34.5782 - mse: 15784.6406 - val_loss: 1.6490 - val_mse: 21.1876 - 672ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "159/159 - 1s - loss: 34.9556 - mse: 19285.7617 - val_loss: 1.6228 - val_mse: 21.0633 - 676ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "159/159 - 1s - loss: 34.7761 - mse: 21356.6738 - val_loss: 1.5056 - val_mse: 18.5483 - 680ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "159/159 - 1s - loss: 32.1458 - mse: 16882.1719 - val_loss: 1.4030 - val_mse: 16.2837 - 667ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "159/159 - 1s - loss: 30.8174 - mse: 15283.2080 - val_loss: 1.3220 - val_mse: 14.5904 - 664ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "159/159 - 1s - loss: 29.9556 - mse: 11364.9795 - val_loss: 1.2312 - val_mse: 12.7910 - 664ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "159/159 - 1s - loss: 27.9619 - mse: 12087.6934 - val_loss: 1.1409 - val_mse: 11.1026 - 683ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "159/159 - 1s - loss: 28.1876 - mse: 12313.0225 - val_loss: 1.0331 - val_mse: 9.2180 - 668ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "159/159 - 1s - loss: 26.5003 - mse: 11361.6016 - val_loss: 0.9742 - val_mse: 8.2584 - 669ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "159/159 - 1s - loss: 26.7995 - mse: 12996.9111 - val_loss: 0.9059 - val_mse: 7.2065 - 686ms/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "159/159 - 1s - loss: 25.7249 - mse: 11242.0781 - val_loss: 0.8153 - val_mse: 5.8987 - 694ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "159/159 - 1s - loss: 23.4488 - mse: 8925.4600 - val_loss: 0.7523 - val_mse: 5.0673 - 713ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "159/159 - 1s - loss: 23.4479 - mse: 10521.8037 - val_loss: 0.6919 - val_mse: 4.3140 - 708ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "159/159 - 1s - loss: 20.7617 - mse: 6289.7300 - val_loss: 0.6398 - val_mse: 3.6946 - 710ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "159/159 - 1s - loss: 19.4520 - mse: 5765.6938 - val_loss: 0.5828 - val_mse: 3.0740 - 681ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "159/159 - 1s - loss: 19.4660 - mse: 7135.7886 - val_loss: 0.5424 - val_mse: 2.6700 - 671ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "159/159 - 1s - loss: 20.1726 - mse: 10351.6494 - val_loss: 0.5038 - val_mse: 2.3075 - 690ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 90 started****\n",
            "\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 3s 6ms/step - loss: 847.2434 - mse: 323176224.0000 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0172\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0176\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0173\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0088 - val_mse: 0.0176\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0171\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0102 - val_mse: 0.0203\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0171\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0175\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0092 - val_mse: 0.0183\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0088 - val_mse: 0.0177\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0089 - val_mse: 0.0178\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0171\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0090 - val_mse: 0.0181\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0103 - val_mse: 0.0206\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0093 - val_mse: 0.0186\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0090 - val_mse: 0.0181\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0090 - val_mse: 0.0181\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0171\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0090 - val_mse: 0.0180\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0174\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0097 - val_mse: 0.0194\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 1s 5ms/step - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 101/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0177 - 834ms/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0173 - 760ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0171 - 779ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 773ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 764ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 772ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "187/187 - 1s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0087 - val_mse: 0.0174 - 797ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0090 - val_mse: 0.0179 - 792ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 801ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0097 - val_mse: 0.0195 - 773ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 787ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0171 - 768ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 765ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 759ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 753ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 765ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 770ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 747ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 769ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 749ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0088 - val_mse: 0.0176 - 761ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0091 - val_mse: 0.0182 - 766ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 806ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 863ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0174 - 814ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0175 - 896ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0087 - val_mse: 0.0175 - 858ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 792ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 812ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0089 - val_mse: 0.0178 - 802ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 796ms/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 788ms/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 782ms/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 778ms/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 799ms/epoch - 4ms/step\n",
            "Epoch 136/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0096 - val_mse: 0.0193 - 796ms/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 800ms/epoch - 4ms/step\n",
            "Epoch 138/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 812ms/epoch - 4ms/step\n",
            "Epoch 139/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 844ms/epoch - 5ms/step\n",
            "Epoch 140/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0087 - val_mse: 0.0174 - 832ms/epoch - 4ms/step\n",
            "Epoch 141/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 822ms/epoch - 4ms/step\n",
            "Epoch 142/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 795ms/epoch - 4ms/step\n",
            "Epoch 143/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 777ms/epoch - 4ms/step\n",
            "Epoch 144/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0171 - 774ms/epoch - 4ms/step\n",
            "Epoch 145/400\n",
            "187/187 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 769ms/epoch - 4ms/step\n",
            "Epoch 146/400\n",
            "187/187 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 773ms/epoch - 4ms/step\n",
            "Epoch 147/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 759ms/epoch - 4ms/step\n",
            "Epoch 148/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 774ms/epoch - 4ms/step\n",
            "Epoch 149/400\n",
            "187/187 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 780ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 91 started****\n",
            "\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 3s 6ms/step - loss: 1734.7211 - mse: 28137690.0000 - val_loss: 697.4699 - val_mse: 2437193.5000\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1653.9221 - mse: 24197914.0000 - val_loss: 579.4822 - val_mse: 1678983.6250\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1560.3925 - mse: 22654778.0000 - val_loss: 463.3604 - val_mse: 1069390.5000\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1520.1033 - mse: 21031580.0000 - val_loss: 370.9485 - val_mse: 681985.8750\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1421.4253 - mse: 18199582.0000 - val_loss: 306.4328 - val_mse: 463168.9688\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1394.6571 - mse: 18286346.0000 - val_loss: 270.8282 - val_mse: 360708.4062\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1357.3187 - mse: 17218138.0000 - val_loss: 237.6336 - val_mse: 276778.5312\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1275.8037 - mse: 14481501.0000 - val_loss: 206.9269 - val_mse: 209112.1406\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1314.0619 - mse: 18601174.0000 - val_loss: 183.7502 - val_mse: 164668.2969\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1210.1515 - mse: 13721781.0000 - val_loss: 152.4679 - val_mse: 112425.6953\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1165.7722 - mse: 14175671.0000 - val_loss: 130.9312 - val_mse: 82078.2891\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1120.6992 - mse: 11307606.0000 - val_loss: 120.4890 - val_mse: 70114.8125\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1116.6711 - mse: 11893350.0000 - val_loss: 105.1969 - val_mse: 53525.9570\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1062.8511 - mse: 11547731.0000 - val_loss: 92.0364 - val_mse: 40805.5430\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1099.9515 - mse: 12517907.0000 - val_loss: 83.7033 - val_mse: 33661.1289\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1025.2222 - mse: 10868600.0000 - val_loss: 74.6604 - val_mse: 26621.7188\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 1002.2140 - mse: 9354982.0000 - val_loss: 68.8811 - val_mse: 22575.7539\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 973.2880 - mse: 8160011.5000 - val_loss: 62.2683 - val_mse: 18348.1387\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 957.9732 - mse: 9110922.0000 - val_loss: 48.1735 - val_mse: 10668.8330\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 954.1417 - mse: 10949843.0000 - val_loss: 35.9585 - val_mse: 5766.5063\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 970.1040 - mse: 9708115.0000 - val_loss: 29.3926 - val_mse: 3741.8933\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 905.8628 - mse: 7610852.0000 - val_loss: 20.2872 - val_mse: 1652.2659\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 895.3295 - mse: 7304444.0000 - val_loss: 23.8758 - val_mse: 2377.2166\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 879.9637 - mse: 7014091.0000 - val_loss: 26.9902 - val_mse: 3129.2979\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 867.7763 - mse: 7118497.0000 - val_loss: 18.8628 - val_mse: 1408.1893\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 857.9381 - mse: 6778539.0000 - val_loss: 21.1827 - val_mse: 1842.0966\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 857.2455 - mse: 7198820.0000 - val_loss: 16.2685 - val_mse: 1016.7043\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 818.5206 - mse: 6342105.0000 - val_loss: 15.4193 - val_mse: 900.0957\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 802.4573 - mse: 6866858.0000 - val_loss: 9.6513 - val_mse: 290.1779\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 838.5817 - mse: 6529196.0000 - val_loss: 3.4653 - val_mse: 36.0420\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 792.7418 - mse: 6140412.0000 - val_loss: 11.7859 - val_mse: 964.1618\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 800.0613 - mse: 5951339.0000 - val_loss: 16.2212 - val_mse: 1772.2467\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 787.6517 - mse: 5903278.0000 - val_loss: 15.7032 - val_mse: 1668.7384\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 784.5164 - mse: 6096211.5000 - val_loss: 13.1881 - val_mse: 1220.6942\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 780.5109 - mse: 5735831.0000 - val_loss: 9.9751 - val_mse: 720.2275\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 802.5580 - mse: 6055349.5000 - val_loss: 5.6839 - val_mse: 218.3703\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 766.3263 - mse: 6123396.5000 - val_loss: 11.4691 - val_mse: 998.5465\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 775.5797 - mse: 5994116.0000 - val_loss: 15.3697 - val_mse: 1638.1613\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 751.7017 - mse: 5159258.5000 - val_loss: 11.6420 - val_mse: 916.8156\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 740.6993 - mse: 5025205.0000 - val_loss: 8.9415 - val_mse: 558.7982\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 743.1806 - mse: 5310172.5000 - val_loss: 5.8760 - val_mse: 267.3543\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 743.5225 - mse: 5654291.0000 - val_loss: 4.5079 - val_mse: 156.3762\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 685.1469 - mse: 4427484.0000 - val_loss: 2.1549 - val_mse: 42.9852\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 714.0156 - mse: 4845917.5000 - val_loss: 1.2870 - val_mse: 17.2145\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 745.1880 - mse: 6014212.0000 - val_loss: 1.3252 - val_mse: 14.2058\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 682.3353 - mse: 4369301.0000 - val_loss: 0.8907 - val_mse: 8.1276\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 668.0018 - mse: 4022256.5000 - val_loss: 1.4478 - val_mse: 10.0197\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 689.6311 - mse: 4700026.0000 - val_loss: 2.5336 - val_mse: 34.6551\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 725.7187 - mse: 5142641.0000 - val_loss: 2.0935 - val_mse: 20.2953\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 666.4887 - mse: 4180198.7500 - val_loss: 2.7451 - val_mse: 47.0205\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 679.9808 - mse: 4488100.0000 - val_loss: 4.1016 - val_mse: 101.7181\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 695.8860 - mse: 5036706.5000 - val_loss: 7.8928 - val_mse: 334.7521\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 683.6439 - mse: 4721928.0000 - val_loss: 8.1418 - val_mse: 313.5159\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 676.6257 - mse: 4421411.5000 - val_loss: 9.0283 - val_mse: 388.6798\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 669.3166 - mse: 4026597.2500 - val_loss: 9.9607 - val_mse: 467.8861\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 643.1576 - mse: 3947004.7500 - val_loss: 8.4536 - val_mse: 336.4926\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 643.6393 - mse: 4213681.5000 - val_loss: 8.9084 - val_mse: 372.4820\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 662.5804 - mse: 4406979.0000 - val_loss: 8.9853 - val_mse: 385.0472\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 656.6534 - mse: 4607079.5000 - val_loss: 10.0452 - val_mse: 443.2563\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 666.0283 - mse: 4730528.5000 - val_loss: 11.4329 - val_mse: 587.8525\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 625.4497 - mse: 3782267.2500 - val_loss: 11.2815 - val_mse: 489.2053\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 613.4357 - mse: 3371369.2500 - val_loss: 11.4568 - val_mse: 565.2841\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 612.0607 - mse: 3426243.5000 - val_loss: 10.5464 - val_mse: 426.2883\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 606.8424 - mse: 3560318.0000 - val_loss: 10.0273 - val_mse: 377.2433\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 605.2275 - mse: 3329499.7500 - val_loss: 11.9613 - val_mse: 656.0661\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 600.0677 - mse: 3039674.7500 - val_loss: 11.8022 - val_mse: 688.9566\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 615.0751 - mse: 3593867.5000 - val_loss: 8.7702 - val_mse: 387.1256\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 625.4018 - mse: 3439288.7500 - val_loss: 9.4223 - val_mse: 445.5178\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 599.7245 - mse: 3553421.7500 - val_loss: 7.3477 - val_mse: 248.7277\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 595.6083 - mse: 3689458.5000 - val_loss: 8.3530 - val_mse: 329.5129\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 591.1949 - mse: 3486017.2500 - val_loss: 8.1717 - val_mse: 348.6971\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 579.9547 - mse: 2963908.7500 - val_loss: 8.1947 - val_mse: 370.9130\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 578.3846 - mse: 3416996.5000 - val_loss: 6.9134 - val_mse: 275.4553\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 558.5433 - mse: 2803303.0000 - val_loss: 6.1747 - val_mse: 217.6046\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 551.0259 - mse: 2623385.7500 - val_loss: 6.9298 - val_mse: 243.2815\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 567.8572 - mse: 2900162.5000 - val_loss: 7.0756 - val_mse: 229.9677\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 592.2133 - mse: 3882473.2500 - val_loss: 5.6717 - val_mse: 154.6741\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 559.2465 - mse: 3110044.0000 - val_loss: 4.9672 - val_mse: 136.3771\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 541.3845 - mse: 2661810.5000 - val_loss: 4.4336 - val_mse: 128.8780\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 547.2996 - mse: 2775922.2500 - val_loss: 1.4509 - val_mse: 21.2014\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 550.1884 - mse: 2586705.5000 - val_loss: 0.8713 - val_mse: 4.9446\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 550.1364 - mse: 3110646.7500 - val_loss: 0.6703 - val_mse: 5.2620\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 559.2935 - mse: 3054326.5000 - val_loss: 0.5719 - val_mse: 3.8514\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 544.0481 - mse: 2805155.5000 - val_loss: 0.8148 - val_mse: 4.8735\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 531.5792 - mse: 2941715.0000 - val_loss: 2.1045 - val_mse: 28.1268\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 535.2204 - mse: 2860106.5000 - val_loss: 2.5269 - val_mse: 39.9149\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 519.8870 - mse: 2540349.7500 - val_loss: 3.1884 - val_mse: 64.9387\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 537.7499 - mse: 3173521.2500 - val_loss: 3.4217 - val_mse: 73.4996\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 530.0382 - mse: 2702150.0000 - val_loss: 2.9085 - val_mse: 48.9049\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 527.2271 - mse: 2646408.2500 - val_loss: 1.5437 - val_mse: 15.7769\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 518.5056 - mse: 2665102.5000 - val_loss: 1.5361 - val_mse: 15.6020\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 531.3466 - mse: 2854541.7500 - val_loss: 1.7367 - val_mse: 19.9716\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 519.9835 - mse: 2786035.2500 - val_loss: 3.6488 - val_mse: 80.2476\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 502.5067 - mse: 2282785.5000 - val_loss: 2.5304 - val_mse: 40.1949\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 486.5435 - mse: 2342229.5000 - val_loss: 3.2081 - val_mse: 56.8195\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 486.5845 - mse: 2142079.2500 - val_loss: 3.6100 - val_mse: 71.3666\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 474.7725 - mse: 2268951.5000 - val_loss: 2.9378 - val_mse: 45.9077\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 482.0509 - mse: 2372443.0000 - val_loss: 2.6242 - val_mse: 37.8037\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 474.8074 - mse: 2212937.7500 - val_loss: 2.4280 - val_mse: 31.0141\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 494.6899 - mse: 2497748.7500 - val_loss: 0.3122 - val_mse: 0.7689\n",
            "Epoch 101/400\n",
            "165/165 - 1s - loss: 487.2840 - mse: 2578078.2500 - val_loss: 0.3222 - val_mse: 0.8091 - 749ms/epoch - 5ms/step\n",
            "Epoch 102/400\n",
            "165/165 - 1s - loss: 487.4354 - mse: 2257899.0000 - val_loss: 1.6616 - val_mse: 37.3467 - 700ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "165/165 - 1s - loss: 467.5387 - mse: 2251826.5000 - val_loss: 2.8125 - val_mse: 81.2170 - 686ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "165/165 - 1s - loss: 458.6873 - mse: 1992216.7500 - val_loss: 4.3417 - val_mse: 136.2674 - 690ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "165/165 - 1s - loss: 465.5085 - mse: 2139712.5000 - val_loss: 5.0860 - val_mse: 169.3167 - 691ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "165/165 - 1s - loss: 462.6249 - mse: 1988064.7500 - val_loss: 5.0775 - val_mse: 163.1371 - 682ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "165/165 - 1s - loss: 461.7935 - mse: 2135714.2500 - val_loss: 2.1391 - val_mse: 18.1718 - 697ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "165/165 - 1s - loss: 462.9828 - mse: 2272830.7500 - val_loss: 2.2289 - val_mse: 19.0136 - 682ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "165/165 - 1s - loss: 446.7981 - mse: 2107433.5000 - val_loss: 3.7327 - val_mse: 62.1468 - 691ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "165/165 - 1s - loss: 447.6044 - mse: 1890272.1250 - val_loss: 3.4876 - val_mse: 48.1524 - 688ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "165/165 - 1s - loss: 444.8938 - mse: 2011278.7500 - val_loss: 2.4577 - val_mse: 19.8179 - 678ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "165/165 - 1s - loss: 455.3198 - mse: 2001591.1250 - val_loss: 2.6556 - val_mse: 23.6107 - 702ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "165/165 - 1s - loss: 429.5972 - mse: 1654753.7500 - val_loss: 4.0961 - val_mse: 65.1472 - 709ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "165/165 - 1s - loss: 451.5244 - mse: 2019877.5000 - val_loss: 4.3528 - val_mse: 74.1488 - 721ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "165/165 - 1s - loss: 424.7671 - mse: 1609056.3750 - val_loss: 5.0077 - val_mse: 99.6127 - 728ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "165/165 - 1s - loss: 431.4650 - mse: 1632990.0000 - val_loss: 4.7235 - val_mse: 86.6360 - 737ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "165/165 - 1s - loss: 432.3515 - mse: 1860462.3750 - val_loss: 3.7610 - val_mse: 51.6155 - 715ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "165/165 - 1s - loss: 415.0358 - mse: 1538841.2500 - val_loss: 1.5463 - val_mse: 7.5581 - 699ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "165/165 - 1s - loss: 425.9742 - mse: 1698667.8750 - val_loss: 1.3117 - val_mse: 5.5679 - 680ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "165/165 - 1s - loss: 430.0221 - mse: 1763520.0000 - val_loss: 1.4145 - val_mse: 6.3797 - 685ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "165/165 - 1s - loss: 436.5004 - mse: 1837039.6250 - val_loss: 0.6451 - val_mse: 3.1400 - 692ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "165/165 - 1s - loss: 428.7722 - mse: 1911882.5000 - val_loss: 0.4783 - val_mse: 3.0492 - 681ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "165/165 - 1s - loss: 432.8384 - mse: 2056990.1250 - val_loss: 0.8766 - val_mse: 3.0733 - 679ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "165/165 - 1s - loss: 405.5462 - mse: 1603964.1250 - val_loss: 0.6136 - val_mse: 1.8484 - 687ms/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "165/165 - 1s - loss: 419.9273 - mse: 1772785.2500 - val_loss: 0.8235 - val_mse: 2.9119 - 691ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "165/165 - 1s - loss: 404.2081 - mse: 1571000.6250 - val_loss: 0.6201 - val_mse: 2.9320 - 681ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "165/165 - 1s - loss: 390.6237 - mse: 1480987.8750 - val_loss: 0.9697 - val_mse: 19.1178 - 674ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "165/165 - 1s - loss: 422.0468 - mse: 1742811.3750 - val_loss: 1.3432 - val_mse: 34.7323 - 681ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "165/165 - 1s - loss: 393.4459 - mse: 1453775.5000 - val_loss: 0.7076 - val_mse: 11.5992 - 683ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "165/165 - 1s - loss: 385.9675 - mse: 1400719.2500 - val_loss: 0.4329 - val_mse: 3.8828 - 689ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "165/165 - 1s - loss: 388.7591 - mse: 1626810.6250 - val_loss: 0.3713 - val_mse: 1.9953 - 705ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 92 started****\n",
            "\n",
            "Epoch 1/100\n",
            "336/336 [==============================] - 3s 5ms/step - loss: 474.1567 - mse: 3775830.7500 - val_loss: 11.6228 - val_mse: 732.4017\n",
            "Epoch 2/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 44.0868 - mse: 26154.6602 - val_loss: 3.7929 - val_mse: 87.6401\n",
            "Epoch 3/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 5.8404 - mse: 441.5018 - val_loss: 0.5517 - val_mse: 3.1367\n",
            "Epoch 4/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 2.8509 - mse: 153.5215 - val_loss: 1.0018 - val_mse: 8.2501\n",
            "Epoch 5/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 1.3098 - mse: 29.7107 - val_loss: 0.3078 - val_mse: 1.2055\n",
            "Epoch 6/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.8236 - mse: 15.9234 - val_loss: 0.1121 - val_mse: 0.3413\n",
            "Epoch 7/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.6895 - mse: 9.7333 - val_loss: 0.0406 - val_mse: 0.0847\n",
            "Epoch 8/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.3091 - mse: 2.9240 - val_loss: 0.1794 - val_mse: 0.5380\n",
            "Epoch 9/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.2045 - mse: 1.6758 - val_loss: 0.0058 - val_mse: 0.0116\n",
            "Epoch 10/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.1597 - mse: 1.1803 - val_loss: 0.0098 - val_mse: 0.0196\n",
            "Epoch 11/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.1226 - mse: 0.5629 - val_loss: 0.0243 - val_mse: 0.0487\n",
            "Epoch 12/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0521 - mse: 0.2510 - val_loss: 0.0274 - val_mse: 0.0550\n",
            "Epoch 13/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0559 - mse: 0.1944 - val_loss: 0.0054 - val_mse: 0.0107\n",
            "Epoch 14/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0391 - mse: 0.1188 - val_loss: 0.0244 - val_mse: 0.0536\n",
            "Epoch 15/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0368 - mse: 0.1247 - val_loss: 0.2683 - val_mse: 0.9261\n",
            "Epoch 16/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0720 - mse: 0.3183 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 17/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0117 - mse: 0.0266 - val_loss: 0.0070 - val_mse: 0.0140\n",
            "Epoch 18/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0069 - mse: 0.0138 - val_loss: 0.0228 - val_mse: 0.0477\n",
            "Epoch 19/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0097 - mse: 0.0202 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 20/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0644 - mse: 0.3660 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 21/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0069 - mse: 0.0140 - val_loss: 0.0200 - val_mse: 0.0400\n",
            "Epoch 22/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0659 - mse: 0.7394 - val_loss: 0.0056 - val_mse: 0.0111\n",
            "Epoch 23/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 24/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0048 - val_mse: 0.0095\n",
            "Epoch 25/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0051 - val_mse: 0.0101\n",
            "Epoch 26/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0052 - val_mse: 0.0105\n",
            "Epoch 27/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0055 - mse: 0.0109 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 28/100\n",
            "336/336 [==============================] - 2s 5ms/step - loss: 0.0075 - mse: 0.0154 - val_loss: 0.0052 - val_mse: 0.0103\n",
            "Epoch 29/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 30/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 31/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0121 - val_loss: 0.0051 - val_mse: 0.0103\n",
            "Epoch 32/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0047 - val_mse: 0.0093\n",
            "Epoch 33/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 34/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0045 - val_mse: 0.0090\n",
            "Epoch 35/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 36/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 37/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0047 - val_mse: 0.0095\n",
            "Epoch 38/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0083 - val_mse: 0.0167\n",
            "Epoch 39/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0061 - val_mse: 0.0123\n",
            "Epoch 40/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 41/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0044 - val_mse: 0.0089\n",
            "Epoch 42/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0036 - val_mse: 0.0073\n",
            "Epoch 43/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 44/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0121 - val_loss: 0.0045 - val_mse: 0.0091\n",
            "Epoch 45/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0050 - val_mse: 0.0099\n",
            "Epoch 46/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0068 - mse: 0.0135 - val_loss: 0.0081 - val_mse: 0.0163\n",
            "Epoch 47/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0054 - val_mse: 0.0109\n",
            "Epoch 48/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0066 - mse: 0.0131 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 49/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0062 - mse: 0.0125 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 50/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 51/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0060 - mse: 0.0119 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 52/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0060 - mse: 0.0121 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 53/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0047 - val_mse: 0.0093\n",
            "Epoch 54/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 55/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 56/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 57/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 58/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0045 - val_mse: 0.0090\n",
            "Epoch 59/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0051 - val_mse: 0.0102\n",
            "Epoch 60/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 61/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 62/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0117 - val_loss: 0.0050 - val_mse: 0.0099\n",
            "Epoch 63/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 64/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 65/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0064 - mse: 0.0127 - val_loss: 0.0047 - val_mse: 0.0095\n",
            "Epoch 66/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0053 - val_mse: 0.0106\n",
            "Epoch 67/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0052 - val_mse: 0.0104\n",
            "Epoch 68/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0054 - val_mse: 0.0108\n",
            "Epoch 69/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0063 - mse: 0.0125 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 70/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0054 - val_mse: 0.0107\n",
            "Epoch 71/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 72/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 73/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 74/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 75/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 76/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 77/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 78/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 79/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 80/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 81/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 82/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 83/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 84/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 85/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 86/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 87/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 88/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 89/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 90/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 91/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 92/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 93/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 94/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 95/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 96/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 97/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 98/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 99/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 100/100\n",
            "336/336 [==============================] - 1s 4ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 101/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 103/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 104/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 105/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 106/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 107/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 108/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 109/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 1s/epoch - 3ms/step\n",
            "Epoch 110/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 111/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 112/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 113/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 116/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 1s/epoch - 3ms/step\n",
            "Epoch 117/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 118/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 119/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 120/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 121/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 122/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 123/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 124/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 127/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 128/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 129/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 130/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 131/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 132/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 1s/epoch - 3ms/step\n",
            "Epoch 133/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 134/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 135/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 1s/epoch - 3ms/step\n",
            "Epoch 136/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 138/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 139/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 140/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 141/400\n",
            "336/336 - 1s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 142/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 143/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 144/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 145/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 146/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 147/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 4ms/step\n",
            "Epoch 148/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 149/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 150/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 151/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 152/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 153/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 154/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 155/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 156/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 157/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 158/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 4ms/step\n",
            "Epoch 159/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 160/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 161/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 1s/epoch - 4ms/step\n",
            "Epoch 162/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 163/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 1s/epoch - 3ms/step\n",
            "Epoch 164/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 165/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 166/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 167/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 168/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "Epoch 169/400\n",
            "336/336 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 3ms/step\n",
            "\n",
            "****Iteration number 93 started****\n",
            "\n",
            "Epoch 1/100\n",
            "99/99 [==============================] - 4s 7ms/step - loss: 1277.5399 - mse: 16716940.0000 - val_loss: 3.7748 - val_mse: 132.4621\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 987.0939 - mse: 9227048.0000 - val_loss: 55.0850 - val_mse: 15406.5488\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 813.8428 - mse: 5977142.0000 - val_loss: 35.4568 - val_mse: 6395.0015\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 716.1897 - mse: 5292208.0000 - val_loss: 104.1638 - val_mse: 56666.5547\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 624.4000 - mse: 4098396.7500 - val_loss: 105.4445 - val_mse: 57868.9648\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 560.7635 - mse: 3673013.5000 - val_loss: 106.1545 - val_mse: 58878.5625\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 461.6505 - mse: 2047371.2500 - val_loss: 68.7301 - val_mse: 26313.7266\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 408.1360 - mse: 1676316.2500 - val_loss: 43.5380 - val_mse: 10623.3594\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 363.4678 - mse: 1269038.3750 - val_loss: 39.0755 - val_mse: 8051.0479\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 337.4462 - mse: 1115054.5000 - val_loss: 29.0295 - val_mse: 5138.7847\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 283.4444 - mse: 811902.3750 - val_loss: 32.0173 - val_mse: 5480.6562\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 257.8244 - mse: 629602.5625 - val_loss: 28.2872 - val_mse: 4277.2124\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 229.2883 - mse: 510648.9062 - val_loss: 6.4729 - val_mse: 213.7144\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 203.7124 - mse: 414965.0000 - val_loss: 8.5220 - val_mse: 377.7160\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 183.7271 - mse: 316168.6875 - val_loss: 13.5181 - val_mse: 1028.5533\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 171.0554 - mse: 304680.7812 - val_loss: 7.2008 - val_mse: 307.7185\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 153.0776 - mse: 241237.8281 - val_loss: 7.1394 - val_mse: 291.6064\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 141.8571 - mse: 272857.6562 - val_loss: 11.1445 - val_mse: 723.8770\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 124.0011 - mse: 159151.5469 - val_loss: 8.1241 - val_mse: 365.5421\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 111.2126 - mse: 140023.1406 - val_loss: 8.5873 - val_mse: 431.4850\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 100.1990 - mse: 106480.3750 - val_loss: 6.5053 - val_mse: 278.2808\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 89.1039 - mse: 79636.6953 - val_loss: 5.4196 - val_mse: 200.4073\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 85.1493 - mse: 78967.0547 - val_loss: 5.8054 - val_mse: 219.2351\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 80.0349 - mse: 69262.3203 - val_loss: 5.1129 - val_mse: 172.1071\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 74.7226 - mse: 61250.9375 - val_loss: 5.7685 - val_mse: 214.1453\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 65.0187 - mse: 47105.4180 - val_loss: 5.4664 - val_mse: 193.2947\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 58.1544 - mse: 32948.5195 - val_loss: 5.5843 - val_mse: 192.8859\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 55.5337 - mse: 36120.3359 - val_loss: 5.1792 - val_mse: 174.6272\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 48.4302 - mse: 27633.9492 - val_loss: 4.0745 - val_mse: 113.0644\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 46.4798 - mse: 23603.0918 - val_loss: 3.8348 - val_mse: 101.4334\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 42.2434 - mse: 20190.8262 - val_loss: 3.0420 - val_mse: 66.5857\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 39.1680 - mse: 17815.0195 - val_loss: 2.7304 - val_mse: 55.0241\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 36.8430 - mse: 20995.1191 - val_loss: 2.0651 - val_mse: 32.9794\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 33.5608 - mse: 12929.3477 - val_loss: 1.5560 - val_mse: 19.8831\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 30.2921 - mse: 10000.7236 - val_loss: 1.5203 - val_mse: 19.1388\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 28.7849 - mse: 10667.6641 - val_loss: 1.1487 - val_mse: 11.5317\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 25.7966 - mse: 8613.7070 - val_loss: 0.8593 - val_mse: 6.8499\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 23.5635 - mse: 8220.7021 - val_loss: 0.6958 - val_mse: 4.7188\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 21.8774 - mse: 5876.5015 - val_loss: 0.5460 - val_mse: 3.0517\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 20.9273 - mse: 5829.1245 - val_loss: 0.3638 - val_mse: 1.4709\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 18.4679 - mse: 5631.7808 - val_loss: 0.2554 - val_mse: 0.7782\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 17.4245 - mse: 4992.3345 - val_loss: 0.1932 - val_mse: 0.4819\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 14.9568 - mse: 2843.1287 - val_loss: 0.1346 - val_mse: 0.2733\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 13.6295 - mse: 2513.2908 - val_loss: 0.1227 - val_mse: 0.2456\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 12.8475 - mse: 2522.4165 - val_loss: 0.1155 - val_mse: 0.2310\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 12.8654 - mse: 2538.3379 - val_loss: 0.1106 - val_mse: 0.2212\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 11.0906 - mse: 2562.9089 - val_loss: 0.1025 - val_mse: 0.2050\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 10.0845 - mse: 1824.7905 - val_loss: 0.0984 - val_mse: 0.1968\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 9.6697 - mse: 1804.5898 - val_loss: 0.0964 - val_mse: 0.1928\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 8.2621 - mse: 1122.8198 - val_loss: 0.0907 - val_mse: 0.1813\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 7.8483 - mse: 1051.0582 - val_loss: 0.0868 - val_mse: 0.1736\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 7.8318 - mse: 1764.9467 - val_loss: 0.0831 - val_mse: 0.1661\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 6.8175 - mse: 975.0845 - val_loss: 0.0788 - val_mse: 0.1576\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 6.3020 - mse: 888.9954 - val_loss: 0.0758 - val_mse: 0.1517\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 5.5449 - mse: 758.1201 - val_loss: 0.0697 - val_mse: 0.1395\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 5.2646 - mse: 761.4611 - val_loss: 0.0643 - val_mse: 0.1286\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 4.9059 - mse: 624.3184 - val_loss: 0.0575 - val_mse: 0.1150\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 4.4745 - mse: 583.7285 - val_loss: 0.0485 - val_mse: 0.0971\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 4.6400 - mse: 899.5728 - val_loss: 0.0429 - val_mse: 0.0857\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 3.9263 - mse: 613.2899 - val_loss: 0.0388 - val_mse: 0.0776\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 3.1361 - mse: 250.3927 - val_loss: 0.0330 - val_mse: 0.0660\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 3.2649 - mse: 288.1250 - val_loss: 0.0275 - val_mse: 0.0550\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 3.0493 - mse: 406.4157 - val_loss: 0.0307 - val_mse: 0.0613\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.8509 - mse: 482.1825 - val_loss: 0.0253 - val_mse: 0.0505\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3179 - mse: 131.1587 - val_loss: 0.0211 - val_mse: 0.0423\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3147 - mse: 203.1426 - val_loss: 0.0173 - val_mse: 0.0347\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.0021 - mse: 124.1467 - val_loss: 0.0119 - val_mse: 0.0237\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 1.9855 - mse: 310.8578 - val_loss: 0.0095 - val_mse: 0.0190\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 1.8114 - mse: 135.4148 - val_loss: 0.0092 - val_mse: 0.0184\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 1.8818 - mse: 344.1473 - val_loss: 0.0076 - val_mse: 0.0152\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 1.5717 - mse: 131.2430 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 1.4768 - mse: 162.3746 - val_loss: 0.0054 - val_mse: 0.0108\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 1.4481 - mse: 128.6511 - val_loss: 0.0058 - val_mse: 0.0115\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 1.3805 - mse: 120.8414 - val_loss: 0.0080 - val_mse: 0.0160\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 1.2186 - mse: 90.9433 - val_loss: 0.0055 - val_mse: 0.0110\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 1.0027 - mse: 64.0565 - val_loss: 0.0049 - val_mse: 0.0099\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 0s 5ms/step - loss: 1.0836 - mse: 196.8371 - val_loss: 0.0038 - val_mse: 0.0077\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.9549 - mse: 60.0325 - val_loss: 0.0051 - val_mse: 0.0101\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.8918 - mse: 62.6742 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.9152 - mse: 54.1958 - val_loss: 0.0052 - val_mse: 0.0105\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.6272 - mse: 37.7706 - val_loss: 0.0079 - val_mse: 0.0157\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.8327 - mse: 81.1609 - val_loss: 0.0051 - val_mse: 0.0102\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.8264 - mse: 77.4861 - val_loss: 0.0070 - val_mse: 0.0140\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4948 - mse: 17.7581 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.6664 - mse: 51.5405 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.5075 - mse: 23.0714 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4710 - mse: 28.7876 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4139 - mse: 16.0890 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4190 - mse: 14.1456 - val_loss: 0.0041 - val_mse: 0.0081\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4227 - mse: 17.3841 - val_loss: 0.0048 - val_mse: 0.0096\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.5417 - mse: 45.4857 - val_loss: 0.0063 - val_mse: 0.0126\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4100 - mse: 28.8853 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 0.3485 - mse: 20.4062 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.3650 - mse: 25.3331 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.3476 - mse: 20.4855 - val_loss: 0.0048 - val_mse: 0.0095\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.4532 - mse: 112.9013 - val_loss: 0.0049 - val_mse: 0.0097\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.2679 - mse: 10.9188 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.2089 - mse: 9.6582 - val_loss: 0.0057 - val_mse: 0.0115\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.2770 - mse: 26.3444 - val_loss: 0.0057 - val_mse: 0.0114\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 0.3049 - mse: 17.3816 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 101/400\n",
            "99/99 - 1s - loss: 0.2304 - mse: 14.6961 - val_loss: 0.0059 - val_mse: 0.0119 - 518ms/epoch - 5ms/step\n",
            "Epoch 102/400\n",
            "99/99 - 0s - loss: 0.2089 - mse: 17.6215 - val_loss: 0.0043 - val_mse: 0.0085 - 449ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "99/99 - 0s - loss: 0.1735 - mse: 6.6470 - val_loss: 0.0044 - val_mse: 0.0089 - 440ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "99/99 - 0s - loss: 0.1737 - mse: 4.7244 - val_loss: 0.0041 - val_mse: 0.0082 - 453ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "99/99 - 0s - loss: 0.2108 - mse: 19.4079 - val_loss: 0.0064 - val_mse: 0.0127 - 442ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "99/99 - 0s - loss: 0.1387 - mse: 2.6772 - val_loss: 0.0060 - val_mse: 0.0120 - 440ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "99/99 - 0s - loss: 0.1794 - mse: 7.4762 - val_loss: 0.0038 - val_mse: 0.0076 - 441ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "99/99 - 0s - loss: 0.1374 - mse: 3.8795 - val_loss: 0.0056 - val_mse: 0.0112 - 443ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "99/99 - 0s - loss: 0.1556 - mse: 8.4489 - val_loss: 0.0042 - val_mse: 0.0083 - 456ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "99/99 - 0s - loss: 0.1651 - mse: 9.0646 - val_loss: 0.0056 - val_mse: 0.0111 - 448ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "99/99 - 0s - loss: 0.1649 - mse: 13.1246 - val_loss: 0.0057 - val_mse: 0.0113 - 452ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "99/99 - 0s - loss: 0.1399 - mse: 7.0836 - val_loss: 0.0065 - val_mse: 0.0130 - 458ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "99/99 - 0s - loss: 0.2631 - mse: 97.1901 - val_loss: 0.0067 - val_mse: 0.0134 - 450ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "99/99 - 0s - loss: 0.1181 - mse: 3.0244 - val_loss: 0.0050 - val_mse: 0.0100 - 454ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "99/99 - 0s - loss: 0.1001 - mse: 2.8337 - val_loss: 0.0045 - val_mse: 0.0089 - 470ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "99/99 - 0s - loss: 0.0823 - mse: 1.6251 - val_loss: 0.0054 - val_mse: 0.0109 - 474ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "99/99 - 0s - loss: 0.0967 - mse: 2.7722 - val_loss: 0.0065 - val_mse: 0.0130 - 468ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "99/99 - 0s - loss: 0.0709 - mse: 1.7560 - val_loss: 0.0048 - val_mse: 0.0096 - 471ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "99/99 - 0s - loss: 0.0804 - mse: 1.4763 - val_loss: 0.0044 - val_mse: 0.0088 - 467ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "99/99 - 0s - loss: 0.1196 - mse: 8.0863 - val_loss: 0.0050 - val_mse: 0.0101 - 445ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "99/99 - 0s - loss: 0.1432 - mse: 19.8278 - val_loss: 0.0051 - val_mse: 0.0103 - 427ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "99/99 - 0s - loss: 0.0713 - mse: 1.4272 - val_loss: 0.0058 - val_mse: 0.0116 - 451ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "99/99 - 0s - loss: 0.0819 - mse: 1.6557 - val_loss: 0.0048 - val_mse: 0.0095 - 442ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "99/99 - 0s - loss: 0.0600 - mse: 1.6986 - val_loss: 0.0057 - val_mse: 0.0114 - 447ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "99/99 - 0s - loss: 0.0681 - mse: 2.1599 - val_loss: 0.0058 - val_mse: 0.0115 - 452ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "99/99 - 0s - loss: 0.0710 - mse: 2.2730 - val_loss: 0.0054 - val_mse: 0.0109 - 458ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "99/99 - 0s - loss: 0.0442 - mse: 0.3519 - val_loss: 0.0046 - val_mse: 0.0092 - 453ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "99/99 - 0s - loss: 0.0639 - mse: 1.4313 - val_loss: 0.0061 - val_mse: 0.0121 - 457ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "99/99 - 0s - loss: 0.0464 - mse: 0.5979 - val_loss: 0.0042 - val_mse: 0.0083 - 456ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "99/99 - 0s - loss: 0.0500 - mse: 1.2278 - val_loss: 0.0041 - val_mse: 0.0081 - 448ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "99/99 - 0s - loss: 0.0542 - mse: 1.8194 - val_loss: 0.0045 - val_mse: 0.0089 - 448ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "99/99 - 0s - loss: 0.0561 - mse: 2.3433 - val_loss: 0.0046 - val_mse: 0.0092 - 456ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "99/99 - 0s - loss: 0.0292 - mse: 0.2178 - val_loss: 0.0056 - val_mse: 0.0112 - 459ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "99/99 - 0s - loss: 0.0302 - mse: 0.4492 - val_loss: 0.0054 - val_mse: 0.0107 - 461ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "99/99 - 0s - loss: 0.0242 - mse: 0.1819 - val_loss: 0.0053 - val_mse: 0.0107 - 450ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "99/99 - 0s - loss: 0.0795 - mse: 7.1984 - val_loss: 0.0054 - val_mse: 0.0108 - 453ms/epoch - 5ms/step\n",
            "Epoch 137/400\n",
            "99/99 - 0s - loss: 0.0291 - mse: 0.2489 - val_loss: 0.0048 - val_mse: 0.0095 - 465ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 94 started****\n",
            "\n",
            "Epoch 1/100\n",
            "65/65 [==============================] - 4s 10ms/step - loss: 209.2164 - mse: 968937.6250 - val_loss: 0.1495 - val_mse: 0.2990\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 11.1062 - mse: 2476.0278 - val_loss: 0.0093 - val_mse: 0.0185\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 4.0238 - mse: 433.2996 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 2.3029 - mse: 202.8363 - val_loss: 0.0087 - val_mse: 0.0173\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 1.1745 - mse: 72.9703 - val_loss: 0.0085 - val_mse: 0.0170\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.7157 - mse: 51.2742 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.5663 - mse: 38.4857 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.5118 - mse: 38.5327 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.3580 - mse: 24.9776 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.2574 - mse: 11.6315 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.2365 - mse: 24.7528 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1533 - mse: 3.9749 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1265 - mse: 4.5195 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1111 - mse: 3.3699 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1230 - mse: 8.0267 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.1358 - mse: 6.9916 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0486 - mse: 0.5472 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0754 - mse: 3.1880 - val_loss: 0.0084 - val_mse: 0.0169\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0611 - mse: 1.4633 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0403 - mse: 0.4717 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0532 - mse: 0.5569 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0411 - mse: 0.5273 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0402 - mse: 0.7586 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0466 - mse: 1.1695 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0628 - mse: 2.0938 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0341 - mse: 0.3450 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0383 - mse: 0.5725 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0392 - mse: 0.7692 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0393 - mse: 1.0047 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0676 - mse: 5.6504 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0276 - mse: 0.3613 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0276 - mse: 0.3791 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0258 - mse: 0.2606 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0352 - mse: 1.4461 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0180 - mse: 0.0879 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0398 - mse: 4.5341 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0247 - mse: 0.2515 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0165 - mse: 0.1635 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0172 - mse: 0.0795 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0307 - mse: 0.5406 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0198 - mse: 0.3010 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 42/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0251 - mse: 0.5640 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 43/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0144 - mse: 0.0479 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 44/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0129 - mse: 0.0523 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 45/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0182 - mse: 0.1501 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 46/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0136 - mse: 0.0535 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 47/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0167 - mse: 0.1240 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 48/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0158 - mse: 0.0992 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 49/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0359 - mse: 1.3737 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 50/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0338 - mse: 4.4182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 51/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0137 - mse: 0.0561 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 52/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0135 - mse: 0.0803 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 53/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0116 - mse: 0.0328 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 54/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0184 - mse: 0.3296 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 55/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0133 - mse: 0.0452 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 56/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0142 - mse: 0.0925 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 57/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0116 - mse: 0.0397 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 58/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0105 - mse: 0.0267 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 59/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0137 - mse: 0.0870 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 60/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0185 - mse: 0.4003 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 61/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0104 - mse: 0.0243 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 62/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0187 - mse: 0.2428 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 63/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0107 - mse: 0.0259 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 64/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0198 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 65/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0230 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 66/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0119 - mse: 0.0541 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 67/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0216 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 68/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0214 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 69/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0116 - mse: 0.0764 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 70/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0224 - mse: 1.4027 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 71/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0107 - mse: 0.0261 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 72/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0117 - mse: 0.0684 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 73/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0093 - mse: 0.0196 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 74/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0141 - mse: 0.1919 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 75/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0138 - mse: 0.1243 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 76/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0095 - mse: 0.0238 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 77/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0154 - mse: 0.1136 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 78/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0347 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 79/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0215 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 80/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0316 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 81/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 82/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0249 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 83/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0094 - mse: 0.0210 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 84/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0110 - mse: 0.0454 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 85/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0191 - mse: 0.5598 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 86/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0292 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 87/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0210 - mse: 1.2963 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 88/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0099 - mse: 0.0242 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 89/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 90/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0094 - mse: 0.0202 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 91/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0107 - mse: 0.0504 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 92/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0090 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 93/100\n",
            "65/65 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0219 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 94/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 95/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 96/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 97/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0531 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 98/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0227 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 99/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0119 - mse: 0.0656 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 100/100\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0220 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 101/400\n",
            "65/65 - 0s - loss: 0.0095 - mse: 0.0236 - val_loss: 0.0084 - val_mse: 0.0167 - 415ms/epoch - 6ms/step\n",
            "Epoch 102/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 351ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "65/65 - 0s - loss: 0.0094 - mse: 0.0200 - val_loss: 0.0084 - val_mse: 0.0167 - 346ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 354ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "65/65 - 0s - loss: 0.0105 - mse: 0.0317 - val_loss: 0.0084 - val_mse: 0.0167 - 360ms/epoch - 6ms/step\n",
            "Epoch 106/400\n",
            "65/65 - 0s - loss: 0.0090 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 362ms/epoch - 6ms/step\n",
            "Epoch 107/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 364ms/epoch - 6ms/step\n",
            "Epoch 108/400\n",
            "65/65 - 0s - loss: 0.0114 - mse: 0.0849 - val_loss: 0.0084 - val_mse: 0.0168 - 354ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 353ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "65/65 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 344ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "65/65 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 359ms/epoch - 6ms/step\n",
            "Epoch 112/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 349ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 353ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 360ms/epoch - 6ms/step\n",
            "Epoch 115/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 346ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "65/65 - 0s - loss: 0.0090 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 340ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "65/65 - 0s - loss: 0.0132 - mse: 0.0823 - val_loss: 0.0084 - val_mse: 0.0167 - 344ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "65/65 - 0s - loss: 0.0091 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 347ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 352ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 370ms/epoch - 6ms/step\n",
            "Epoch 121/400\n",
            "65/65 - 0s - loss: 0.0090 - mse: 0.0190 - val_loss: 0.0084 - val_mse: 0.0167 - 368ms/epoch - 6ms/step\n",
            "Epoch 122/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 361ms/epoch - 6ms/step\n",
            "Epoch 123/400\n",
            "65/65 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 358ms/epoch - 6ms/step\n",
            "Epoch 124/400\n",
            "65/65 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 374ms/epoch - 6ms/step\n",
            "Epoch 125/400\n",
            "65/65 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 355ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 375ms/epoch - 6ms/step\n",
            "Epoch 127/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 365ms/epoch - 6ms/step\n",
            "Epoch 128/400\n",
            "65/65 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 357ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "65/65 - 0s - loss: 0.0091 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167 - 353ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 356ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "65/65 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 353ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "65/65 - 0s - loss: 0.0093 - mse: 0.0196 - val_loss: 0.0084 - val_mse: 0.0167 - 351ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 354ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "65/65 - 0s - loss: 0.0088 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 354ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 351ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "65/65 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 386ms/epoch - 6ms/step\n",
            "\n",
            "****Iteration number 95 started****\n",
            "\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 4s 8ms/step - loss: 1554.2499 - mse: 16977860.0000 - val_loss: 566.7048 - val_mse: 1610003.8750\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 1424.7913 - mse: 16281065.0000 - val_loss: 467.3091 - val_mse: 1093608.6250\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 1276.3684 - mse: 13288802.0000 - val_loss: 383.7535 - val_mse: 737142.8125\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 1164.9536 - mse: 10057986.0000 - val_loss: 332.6894 - val_mse: 553218.0000\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 1136.0699 - mse: 11706996.0000 - val_loss: 273.8599 - val_mse: 376426.2812\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 963.6814 - mse: 8108573.0000 - val_loss: 228.6631 - val_mse: 263719.3125\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 871.7051 - mse: 6903111.5000 - val_loss: 185.9299 - val_mse: 173152.0625\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 803.2117 - mse: 5786040.5000 - val_loss: 138.8652 - val_mse: 94683.1953\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 737.2372 - mse: 5296228.0000 - val_loss: 99.3160 - val_mse: 46909.4805\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 654.5121 - mse: 3537318.0000 - val_loss: 79.6230 - val_mse: 29931.4570\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 625.8026 - mse: 3549493.7500 - val_loss: 55.0122 - val_mse: 14948.5195\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 595.9845 - mse: 3217359.0000 - val_loss: 33.0127 - val_mse: 5327.0068\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 574.7751 - mse: 3159522.2500 - val_loss: 33.7894 - val_mse: 5534.4038\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 526.9844 - mse: 2438282.0000 - val_loss: 30.9105 - val_mse: 4649.3140\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 553.3036 - mse: 3098502.0000 - val_loss: 22.9867 - val_mse: 2561.2178\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 506.6914 - mse: 2461306.0000 - val_loss: 23.6204 - val_mse: 2532.0708\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 516.6550 - mse: 2951927.7500 - val_loss: 25.1499 - val_mse: 2844.7332\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 491.6819 - mse: 2388443.2500 - val_loss: 28.2573 - val_mse: 3776.7212\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 464.3284 - mse: 1980173.2500 - val_loss: 36.1995 - val_mse: 6701.4468\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 469.4449 - mse: 2269056.5000 - val_loss: 32.1848 - val_mse: 5622.1943\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 429.3092 - mse: 1975990.8750 - val_loss: 30.3222 - val_mse: 4879.1753\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 411.6171 - mse: 1574270.6250 - val_loss: 31.8397 - val_mse: 5398.4463\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 404.9977 - mse: 1640363.2500 - val_loss: 34.2198 - val_mse: 6059.3560\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 398.4037 - mse: 1634672.7500 - val_loss: 35.9780 - val_mse: 6608.3452\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 414.8380 - mse: 1813147.5000 - val_loss: 40.9525 - val_mse: 8625.1689\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 391.8463 - mse: 1694252.7500 - val_loss: 48.7147 - val_mse: 12172.8867\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 374.1132 - mse: 1415999.5000 - val_loss: 54.5325 - val_mse: 14946.8301\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 367.4387 - mse: 1369394.1250 - val_loss: 62.9358 - val_mse: 20031.1230\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 356.5812 - mse: 1280371.3750 - val_loss: 61.6697 - val_mse: 19361.7383\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 339.9188 - mse: 1084383.8750 - val_loss: 61.3318 - val_mse: 19436.4414\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 337.8277 - mse: 1147599.7500 - val_loss: 56.1830 - val_mse: 16467.8086\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 328.7180 - mse: 1092163.1250 - val_loss: 53.9727 - val_mse: 15308.6240\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 319.6314 - mse: 1023422.3750 - val_loss: 47.4398 - val_mse: 11944.8965\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 314.4454 - mse: 987444.5000 - val_loss: 55.5528 - val_mse: 16293.4404\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 306.7239 - mse: 938768.1250 - val_loss: 52.6975 - val_mse: 14733.9414\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 312.3324 - mse: 949224.4375 - val_loss: 53.2985 - val_mse: 14866.6904\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 301.4751 - mse: 839731.5625 - val_loss: 56.2522 - val_mse: 16343.2646\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 300.5047 - mse: 943661.6250 - val_loss: 49.3106 - val_mse: 12543.4219\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 295.9788 - mse: 896350.6250 - val_loss: 51.0964 - val_mse: 13423.5908\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 293.7841 - mse: 1008742.9375 - val_loss: 47.5552 - val_mse: 11713.0752\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 270.0932 - mse: 661147.0000 - val_loss: 46.8863 - val_mse: 11425.8447\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 278.1267 - mse: 784645.8750 - val_loss: 45.6287 - val_mse: 10857.8213\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 272.7434 - mse: 759689.6875 - val_loss: 41.1962 - val_mse: 8906.0576\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 262.7885 - mse: 715863.1250 - val_loss: 39.7345 - val_mse: 8309.8291\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 253.0410 - mse: 619389.4375 - val_loss: 33.8358 - val_mse: 6108.8662\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 250.6258 - mse: 621690.0625 - val_loss: 29.2798 - val_mse: 4652.6675\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 250.9536 - mse: 646209.3125 - val_loss: 29.0623 - val_mse: 4572.2476\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 246.9188 - mse: 581342.2500 - val_loss: 28.2655 - val_mse: 4319.2002\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 248.3178 - mse: 767120.6875 - val_loss: 21.3249 - val_mse: 2533.6790\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 240.6669 - mse: 560175.1875 - val_loss: 17.5107 - val_mse: 1725.1050\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 237.3953 - mse: 554457.2500 - val_loss: 17.4588 - val_mse: 1732.5112\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 221.2733 - mse: 452478.5938 - val_loss: 13.8350 - val_mse: 1104.3248\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 218.5468 - mse: 460729.3750 - val_loss: 10.9617 - val_mse: 736.5685\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 237.2091 - mse: 645451.9375 - val_loss: 7.1583 - val_mse: 378.1046\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 217.8983 - mse: 471865.8125 - val_loss: 10.4983 - val_mse: 703.1675\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 218.0860 - mse: 453776.8750 - val_loss: 9.7352 - val_mse: 620.1370\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 204.8418 - mse: 402978.6562 - val_loss: 14.1328 - val_mse: 1212.0060\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 205.3457 - mse: 417579.8438 - val_loss: 14.1466 - val_mse: 1226.0725\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 212.7694 - mse: 475173.5938 - val_loss: 10.9924 - val_mse: 774.4227\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 202.5225 - mse: 411268.6875 - val_loss: 10.6636 - val_mse: 728.5065\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 198.3701 - mse: 403844.6562 - val_loss: 10.1175 - val_mse: 659.1140\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 202.4478 - mse: 483064.5625 - val_loss: 7.8915 - val_mse: 427.8039\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 188.5265 - mse: 367784.2188 - val_loss: 8.4036 - val_mse: 467.7033\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 188.1797 - mse: 331118.4688 - val_loss: 8.7314 - val_mse: 497.1017\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 187.6792 - mse: 391487.8438 - val_loss: 9.8078 - val_mse: 610.7427\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 1s 7ms/step - loss: 186.8452 - mse: 378766.9688 - val_loss: 10.1247 - val_mse: 649.6362\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 183.2971 - mse: 341090.1562 - val_loss: 10.9260 - val_mse: 755.9500\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 172.6228 - mse: 278089.6562 - val_loss: 11.6426 - val_mse: 840.4618\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 172.5041 - mse: 297852.3125 - val_loss: 12.0298 - val_mse: 887.0950\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 164.4567 - mse: 262941.8750 - val_loss: 10.5459 - val_mse: 653.2347\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 161.1884 - mse: 249617.2969 - val_loss: 10.0055 - val_mse: 575.1309\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 161.9803 - mse: 249501.8438 - val_loss: 9.2600 - val_mse: 519.4887\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 165.9730 - mse: 307110.5938 - val_loss: 9.0869 - val_mse: 478.1517\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 164.8407 - mse: 291948.6875 - val_loss: 8.3720 - val_mse: 416.1743\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 168.6702 - mse: 321274.4062 - val_loss: 7.9456 - val_mse: 387.4842\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 154.1680 - mse: 260947.3438 - val_loss: 7.8518 - val_mse: 393.3381\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 144.8210 - mse: 207622.0938 - val_loss: 7.3178 - val_mse: 338.6723\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 146.7909 - mse: 216831.7500 - val_loss: 7.2094 - val_mse: 304.6953\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 144.4297 - mse: 195088.5625 - val_loss: 7.0359 - val_mse: 294.0305\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 149.2871 - mse: 256926.1406 - val_loss: 6.5019 - val_mse: 258.9930\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 141.7727 - mse: 181651.1719 - val_loss: 5.7558 - val_mse: 209.5157\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 141.6782 - mse: 234479.9062 - val_loss: 5.3908 - val_mse: 196.1059\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 138.6229 - mse: 230726.8594 - val_loss: 7.2159 - val_mse: 353.1689\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 127.9201 - mse: 143094.4688 - val_loss: 9.2469 - val_mse: 534.9747\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 130.8533 - mse: 163185.2188 - val_loss: 9.5094 - val_mse: 538.7106\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 124.4199 - mse: 150790.9375 - val_loss: 9.4376 - val_mse: 525.4119\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 124.1872 - mse: 156542.4531 - val_loss: 9.7511 - val_mse: 549.4378\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 130.4026 - mse: 176149.8594 - val_loss: 9.0727 - val_mse: 478.8257\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 126.7523 - mse: 163562.7344 - val_loss: 8.5617 - val_mse: 415.2453\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 124.5807 - mse: 164594.1406 - val_loss: 8.0219 - val_mse: 364.3389\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 123.7794 - mse: 164921.3281 - val_loss: 7.5463 - val_mse: 326.8621\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 117.7831 - mse: 127716.8281 - val_loss: 6.6107 - val_mse: 260.1686\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 120.8591 - mse: 156422.8281 - val_loss: 7.2379 - val_mse: 310.1977\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 123.8965 - mse: 196529.4062 - val_loss: 6.3134 - val_mse: 231.5948\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 115.1148 - mse: 127271.4453 - val_loss: 5.7592 - val_mse: 190.2824\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 111.1567 - mse: 114500.8125 - val_loss: 3.6270 - val_mse: 70.2182\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 113.2965 - mse: 128316.1172 - val_loss: 1.9720 - val_mse: 22.9865\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 110.7654 - mse: 134151.2812 - val_loss: 0.8037 - val_mse: 3.7008\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 111.1313 - mse: 130153.4766 - val_loss: 0.6139 - val_mse: 3.9916\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 102.2861 - mse: 97525.5000 - val_loss: 0.9983 - val_mse: 9.2558\n",
            "Epoch 101/400\n",
            "107/107 - 1s - loss: 102.3646 - mse: 101847.5547 - val_loss: 1.2305 - val_mse: 11.1844 - 615ms/epoch - 6ms/step\n",
            "Epoch 102/400\n",
            "107/107 - 1s - loss: 108.1817 - mse: 116374.6641 - val_loss: 1.1287 - val_mse: 9.5826 - 591ms/epoch - 6ms/step\n",
            "Epoch 103/400\n",
            "107/107 - 1s - loss: 101.2786 - mse: 105482.7344 - val_loss: 1.1310 - val_mse: 10.5864 - 593ms/epoch - 6ms/step\n",
            "Epoch 104/400\n",
            "107/107 - 1s - loss: 99.4888 - mse: 100292.3047 - val_loss: 1.3448 - val_mse: 14.3103 - 565ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "107/107 - 1s - loss: 97.3136 - mse: 86726.4141 - val_loss: 0.3910 - val_mse: 1.2205 - 563ms/epoch - 5ms/step\n",
            "Epoch 106/400\n",
            "107/107 - 1s - loss: 97.5153 - mse: 111251.2578 - val_loss: 0.3903 - val_mse: 1.2926 - 572ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "107/107 - 1s - loss: 99.0346 - mse: 105640.4219 - val_loss: 0.9617 - val_mse: 8.6033 - 537ms/epoch - 5ms/step\n",
            "Epoch 108/400\n",
            "107/107 - 1s - loss: 92.4655 - mse: 86145.2812 - val_loss: 1.3981 - val_mse: 14.6426 - 528ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "107/107 - 1s - loss: 93.7807 - mse: 85407.2031 - val_loss: 1.2306 - val_mse: 10.3689 - 538ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "107/107 - 1s - loss: 94.1088 - mse: 84784.8203 - val_loss: 1.1657 - val_mse: 9.6221 - 553ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "107/107 - 1s - loss: 89.5320 - mse: 85257.4766 - val_loss: 1.0645 - val_mse: 6.2172 - 551ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "107/107 - 1s - loss: 91.9312 - mse: 95238.9844 - val_loss: 0.9552 - val_mse: 5.4598 - 535ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "107/107 - 1s - loss: 87.2946 - mse: 82444.0703 - val_loss: 0.8642 - val_mse: 4.4151 - 546ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "107/107 - 1s - loss: 88.7098 - mse: 79743.2422 - val_loss: 1.3433 - val_mse: 14.4377 - 535ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "107/107 - 1s - loss: 80.7014 - mse: 58814.1758 - val_loss: 0.7711 - val_mse: 3.8537 - 537ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "107/107 - 1s - loss: 87.1840 - mse: 82164.0078 - val_loss: 0.9904 - val_mse: 7.9467 - 534ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "107/107 - 1s - loss: 84.9595 - mse: 86135.6094 - val_loss: 0.9282 - val_mse: 7.1019 - 548ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "107/107 - 1s - loss: 86.4595 - mse: 92689.1484 - val_loss: 1.3611 - val_mse: 15.9597 - 549ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "107/107 - 1s - loss: 83.2932 - mse: 71553.5312 - val_loss: 1.7895 - val_mse: 26.2143 - 560ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "107/107 - 1s - loss: 83.9555 - mse: 73567.3359 - val_loss: 2.6323 - val_mse: 51.0030 - 534ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "107/107 - 1s - loss: 79.2914 - mse: 62850.5000 - val_loss: 3.2055 - val_mse: 70.5199 - 542ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "107/107 - 1s - loss: 76.3878 - mse: 57310.5117 - val_loss: 3.9878 - val_mse: 92.9567 - 529ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "107/107 - 1s - loss: 78.0550 - mse: 62543.0820 - val_loss: 3.8884 - val_mse: 84.1773 - 521ms/epoch - 5ms/step\n",
            "Epoch 124/400\n",
            "107/107 - 1s - loss: 78.8046 - mse: 64402.5586 - val_loss: 3.7776 - val_mse: 80.0120 - 541ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "107/107 - 1s - loss: 74.5899 - mse: 72909.1641 - val_loss: 3.8737 - val_mse: 83.4199 - 542ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "107/107 - 1s - loss: 72.2948 - mse: 58692.5117 - val_loss: 3.6818 - val_mse: 75.4632 - 547ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "107/107 - 1s - loss: 71.3052 - mse: 55088.3789 - val_loss: 3.6715 - val_mse: 77.3563 - 560ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "107/107 - 1s - loss: 70.9225 - mse: 48113.6797 - val_loss: 3.5041 - val_mse: 71.8854 - 564ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "107/107 - 1s - loss: 72.1345 - mse: 56755.4023 - val_loss: 3.3895 - val_mse: 67.3514 - 548ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "107/107 - 1s - loss: 71.0089 - mse: 55994.0469 - val_loss: 3.6081 - val_mse: 70.7230 - 520ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "107/107 - 1s - loss: 71.6120 - mse: 52162.2539 - val_loss: 3.6710 - val_mse: 74.3666 - 505ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "107/107 - 1s - loss: 69.3182 - mse: 48427.4961 - val_loss: 3.8140 - val_mse: 78.6270 - 516ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "107/107 - 1s - loss: 70.0147 - mse: 57781.2930 - val_loss: 3.5874 - val_mse: 68.1944 - 514ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "107/107 - 1s - loss: 67.4998 - mse: 45593.3281 - val_loss: 3.3001 - val_mse: 57.9752 - 512ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "107/107 - 1s - loss: 65.0457 - mse: 38749.0352 - val_loss: 3.1689 - val_mse: 54.2510 - 520ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "107/107 - 1s - loss: 64.1923 - mse: 52344.0625 - val_loss: 2.9060 - val_mse: 44.7303 - 517ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 96 started****\n",
            "\n",
            "Epoch 1/100\n",
            "221/221 [==============================] - 3s 5ms/step - loss: 2018.8745 - mse: 34169748.0000 - val_loss: 1549.1910 - val_mse: 12440898.0000\n",
            "Epoch 2/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1735.3762 - mse: 25723684.0000 - val_loss: 1350.5481 - val_mse: 9480128.0000\n",
            "Epoch 3/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1535.4481 - mse: 20121036.0000 - val_loss: 1181.8672 - val_mse: 7276219.0000\n",
            "Epoch 4/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1466.9602 - mse: 19534302.0000 - val_loss: 1030.6071 - val_mse: 5549502.5000\n",
            "Epoch 5/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1354.7273 - mse: 16659910.0000 - val_loss: 892.1310 - val_mse: 4170822.2500\n",
            "Epoch 6/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1214.4303 - mse: 13098254.0000 - val_loss: 773.3641 - val_mse: 3146833.2500\n",
            "Epoch 7/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1150.9242 - mse: 13512933.0000 - val_loss: 672.4205 - val_mse: 2394813.2500\n",
            "Epoch 8/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 1030.3489 - mse: 10235335.0000 - val_loss: 580.7291 - val_mse: 1796814.2500\n",
            "Epoch 9/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 951.7100 - mse: 8736259.0000 - val_loss: 493.5875 - val_mse: 1307684.1250\n",
            "Epoch 10/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 923.7188 - mse: 8207498.5000 - val_loss: 416.8280 - val_mse: 938377.3750\n",
            "Epoch 11/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 885.4677 - mse: 7297831.0000 - val_loss: 346.1117 - val_mse: 653291.6875\n",
            "Epoch 12/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 815.7761 - mse: 6324684.0000 - val_loss: 291.1104 - val_mse: 466106.9062\n",
            "Epoch 13/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 779.8088 - mse: 6061221.5000 - val_loss: 229.4940 - val_mse: 296802.3438\n",
            "Epoch 14/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 757.1093 - mse: 7108967.0000 - val_loss: 184.1960 - val_mse: 195828.5156\n",
            "Epoch 15/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 710.4763 - mse: 5051081.0000 - val_loss: 130.9455 - val_mse: 105677.4141\n",
            "Epoch 16/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 695.6100 - mse: 5140499.5000 - val_loss: 96.0304 - val_mse: 60962.2734\n",
            "Epoch 17/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 681.0532 - mse: 4759428.5000 - val_loss: 54.6753 - val_mse: 23158.6035\n",
            "Epoch 18/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 676.6758 - mse: 4687872.5000 - val_loss: 21.2852 - val_mse: 4727.1528\n",
            "Epoch 19/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 621.1259 - mse: 3553738.7500 - val_loss: 6.5873 - val_mse: 318.8548\n",
            "Epoch 20/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 607.3409 - mse: 3796592.7500 - val_loss: 11.2236 - val_mse: 858.5725\n",
            "Epoch 21/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 600.7719 - mse: 3805603.5000 - val_loss: 4.6064 - val_mse: 177.0152\n",
            "Epoch 22/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 587.2081 - mse: 3399980.5000 - val_loss: 2.3617 - val_mse: 23.2845\n",
            "Epoch 23/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 570.1720 - mse: 3241018.7500 - val_loss: 3.8568 - val_mse: 128.4827\n",
            "Epoch 24/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 568.5854 - mse: 3330037.0000 - val_loss: 2.3932 - val_mse: 17.2170\n",
            "Epoch 25/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 557.7404 - mse: 3064913.2500 - val_loss: 7.8690 - val_mse: 300.4356\n",
            "Epoch 26/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 540.1838 - mse: 2754520.7500 - val_loss: 7.7591 - val_mse: 380.5335\n",
            "Epoch 27/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 540.6248 - mse: 2872239.7500 - val_loss: 13.0781 - val_mse: 839.0892\n",
            "Epoch 28/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 538.7566 - mse: 2962861.0000 - val_loss: 19.6132 - val_mse: 1919.6075\n",
            "Epoch 29/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 536.6637 - mse: 2812025.2500 - val_loss: 23.8524 - val_mse: 2828.8491\n",
            "Epoch 30/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 502.7071 - mse: 2388977.7500 - val_loss: 25.3427 - val_mse: 3155.0090\n",
            "Epoch 31/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 511.4601 - mse: 2706570.0000 - val_loss: 25.3190 - val_mse: 3183.0359\n",
            "Epoch 32/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 513.0793 - mse: 2569111.7500 - val_loss: 26.8383 - val_mse: 3580.8865\n",
            "Epoch 33/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 526.0533 - mse: 3006716.7500 - val_loss: 27.8517 - val_mse: 3865.0281\n",
            "Epoch 34/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 507.1069 - mse: 2495555.5000 - val_loss: 29.5570 - val_mse: 4351.8911\n",
            "Epoch 35/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 505.0522 - mse: 2589741.5000 - val_loss: 31.0994 - val_mse: 4808.3257\n",
            "Epoch 36/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 482.4104 - mse: 2269653.7500 - val_loss: 32.0048 - val_mse: 5170.4717\n",
            "Epoch 37/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 485.4351 - mse: 2683711.2500 - val_loss: 35.8659 - val_mse: 6741.0273\n",
            "Epoch 38/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 478.2798 - mse: 2463732.0000 - val_loss: 36.1716 - val_mse: 6735.4614\n",
            "Epoch 39/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 490.7252 - mse: 2418352.2500 - val_loss: 35.7402 - val_mse: 6155.0488\n",
            "Epoch 40/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 469.8940 - mse: 2211504.0000 - val_loss: 36.9100 - val_mse: 6606.5508\n",
            "Epoch 41/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 477.7122 - mse: 2321092.0000 - val_loss: 37.8901 - val_mse: 6887.0947\n",
            "Epoch 42/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 481.4563 - mse: 2529319.5000 - val_loss: 40.7222 - val_mse: 7934.0942\n",
            "Epoch 43/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 468.3527 - mse: 2142257.5000 - val_loss: 37.7889 - val_mse: 6718.5015\n",
            "Epoch 44/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 465.8427 - mse: 2161965.0000 - val_loss: 36.4459 - val_mse: 6278.2583\n",
            "Epoch 45/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 465.5403 - mse: 2102944.7500 - val_loss: 34.2309 - val_mse: 5583.9243\n",
            "Epoch 46/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 468.7425 - mse: 2262059.0000 - val_loss: 32.1530 - val_mse: 4962.1821\n",
            "Epoch 47/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 446.2982 - mse: 1839570.0000 - val_loss: 34.0052 - val_mse: 5569.0210\n",
            "Epoch 48/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 439.2896 - mse: 1868735.5000 - val_loss: 34.2167 - val_mse: 5732.1074\n",
            "Epoch 49/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 453.0771 - mse: 1966759.0000 - val_loss: 37.0035 - val_mse: 6799.5757\n",
            "Epoch 50/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 428.6996 - mse: 1663024.0000 - val_loss: 37.9202 - val_mse: 7200.0859\n",
            "Epoch 51/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 408.0673 - mse: 1548254.5000 - val_loss: 35.5951 - val_mse: 6444.8560\n",
            "Epoch 52/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 411.7617 - mse: 1594425.0000 - val_loss: 37.3324 - val_mse: 7111.6377\n",
            "Epoch 53/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 438.3062 - mse: 1908836.2500 - val_loss: 39.8752 - val_mse: 8258.7207\n",
            "Epoch 54/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 430.1780 - mse: 1835077.2500 - val_loss: 40.8209 - val_mse: 8686.2881\n",
            "Epoch 55/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 426.0669 - mse: 1729429.1250 - val_loss: 41.4999 - val_mse: 8961.7217\n",
            "Epoch 56/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 422.9353 - mse: 1843202.6250 - val_loss: 41.2084 - val_mse: 8851.3135\n",
            "Epoch 57/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 411.4773 - mse: 1509268.8750 - val_loss: 40.7895 - val_mse: 8709.7500\n",
            "Epoch 58/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 412.1057 - mse: 1691842.2500 - val_loss: 40.9288 - val_mse: 8766.9531\n",
            "Epoch 59/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 413.1271 - mse: 1583234.8750 - val_loss: 42.1721 - val_mse: 9296.9561\n",
            "Epoch 60/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 428.4341 - mse: 1664176.5000 - val_loss: 40.0611 - val_mse: 8408.7568\n",
            "Epoch 61/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 417.1943 - mse: 1667901.1250 - val_loss: 39.9943 - val_mse: 8381.2852\n",
            "Epoch 62/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 400.2350 - mse: 1521710.1250 - val_loss: 39.1042 - val_mse: 8021.0742\n",
            "Epoch 63/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 404.2398 - mse: 1689756.0000 - val_loss: 38.4511 - val_mse: 7764.1826\n",
            "Epoch 64/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 388.8523 - mse: 1417271.7500 - val_loss: 42.0248 - val_mse: 9247.0557\n",
            "Epoch 65/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 411.1809 - mse: 1654618.5000 - val_loss: 44.0571 - val_mse: 10103.4814\n",
            "Epoch 66/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 398.7518 - mse: 1683747.3750 - val_loss: 43.7129 - val_mse: 9992.7500\n",
            "Epoch 67/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 397.7929 - mse: 1570198.0000 - val_loss: 43.4559 - val_mse: 9876.5908\n",
            "Epoch 68/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 389.6827 - mse: 1417918.6250 - val_loss: 43.9497 - val_mse: 10098.8721\n",
            "Epoch 69/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 375.8683 - mse: 1454314.5000 - val_loss: 41.7917 - val_mse: 9151.3027\n",
            "Epoch 70/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 382.4189 - mse: 1391764.8750 - val_loss: 39.6124 - val_mse: 8243.7744\n",
            "Epoch 71/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 371.1764 - mse: 1312153.8750 - val_loss: 37.0023 - val_mse: 7223.1694\n",
            "Epoch 72/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 367.5773 - mse: 1238746.0000 - val_loss: 38.4583 - val_mse: 7788.8965\n",
            "Epoch 73/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 371.8515 - mse: 1263478.5000 - val_loss: 36.8300 - val_mse: 7152.3564\n",
            "Epoch 74/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 394.3295 - mse: 1616723.2500 - val_loss: 36.5068 - val_mse: 7014.1890\n",
            "Epoch 75/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 364.3448 - mse: 1258712.6250 - val_loss: 34.6156 - val_mse: 6306.8740\n",
            "Epoch 76/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 369.5435 - mse: 1425542.3750 - val_loss: 37.2768 - val_mse: 7286.2598\n",
            "Epoch 77/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 369.5383 - mse: 1258019.1250 - val_loss: 38.4563 - val_mse: 7741.5747\n",
            "Epoch 78/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 354.4373 - mse: 1113165.7500 - val_loss: 36.2301 - val_mse: 6891.0986\n",
            "Epoch 79/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 355.8137 - mse: 1220888.5000 - val_loss: 34.9683 - val_mse: 6438.2324\n",
            "Epoch 80/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 368.2498 - mse: 1386110.1250 - val_loss: 36.2592 - val_mse: 6904.8838\n",
            "Epoch 81/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 369.0394 - mse: 1366598.2500 - val_loss: 35.0992 - val_mse: 6481.7520\n",
            "Epoch 82/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 340.1227 - mse: 1048228.7500 - val_loss: 34.0413 - val_mse: 6096.8350\n",
            "Epoch 83/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 349.8299 - mse: 1234675.5000 - val_loss: 34.8363 - val_mse: 6368.5786\n",
            "Epoch 84/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 336.2014 - mse: 1057418.7500 - val_loss: 30.2341 - val_mse: 4820.6250\n",
            "Epoch 85/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 332.9778 - mse: 1052544.3750 - val_loss: 30.1860 - val_mse: 4806.1353\n",
            "Epoch 86/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 341.4774 - mse: 1116771.3750 - val_loss: 28.3472 - val_mse: 4251.8164\n",
            "Epoch 87/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 347.6501 - mse: 1200763.8750 - val_loss: 28.9646 - val_mse: 4434.5181\n",
            "Epoch 88/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 331.2299 - mse: 1030607.1250 - val_loss: 27.6246 - val_mse: 4044.9368\n",
            "Epoch 89/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 323.1885 - mse: 961323.9375 - val_loss: 25.6413 - val_mse: 3498.2161\n",
            "Epoch 90/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 334.9825 - mse: 1062990.0000 - val_loss: 26.2538 - val_mse: 3670.3499\n",
            "Epoch 91/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 335.5439 - mse: 1053865.3750 - val_loss: 24.7297 - val_mse: 3261.8259\n",
            "Epoch 92/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 327.2380 - mse: 1063244.7500 - val_loss: 24.1950 - val_mse: 3129.9880\n",
            "Epoch 93/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 322.6983 - mse: 917539.1250 - val_loss: 25.0387 - val_mse: 3343.4045\n",
            "Epoch 94/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 323.5603 - mse: 1001052.7500 - val_loss: 25.8323 - val_mse: 3556.0027\n",
            "Epoch 95/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 324.7957 - mse: 1042535.0625 - val_loss: 24.8252 - val_mse: 3290.3196\n",
            "Epoch 96/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 322.0678 - mse: 967187.3125 - val_loss: 24.9042 - val_mse: 3310.3975\n",
            "Epoch 97/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 314.8529 - mse: 973150.3750 - val_loss: 25.2487 - val_mse: 3402.5459\n",
            "Epoch 98/100\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 318.6510 - mse: 928820.2500 - val_loss: 24.5965 - val_mse: 3230.3242\n",
            "Epoch 99/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 310.1218 - mse: 923887.8750 - val_loss: 23.7765 - val_mse: 3025.6375\n",
            "Epoch 100/100\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 315.5370 - mse: 943440.7500 - val_loss: 21.3645 - val_mse: 2453.8113\n",
            "Epoch 101/400\n",
            "221/221 - 1s - loss: 321.2332 - mse: 1189952.5000 - val_loss: 22.8438 - val_mse: 2789.8025 - 889ms/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "221/221 - 1s - loss: 308.2701 - mse: 873027.0625 - val_loss: 22.9387 - val_mse: 2815.1638 - 808ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "221/221 - 1s - loss: 305.5816 - mse: 909398.6875 - val_loss: 23.3976 - val_mse: 2924.1858 - 800ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "221/221 - 1s - loss: 304.8576 - mse: 920249.4375 - val_loss: 20.3553 - val_mse: 2225.4612 - 811ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "221/221 - 1s - loss: 296.9503 - mse: 880675.1875 - val_loss: 19.2608 - val_mse: 1997.1562 - 810ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "221/221 - 1s - loss: 298.0500 - mse: 815530.2500 - val_loss: 19.3480 - val_mse: 2014.8043 - 826ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "221/221 - 1s - loss: 298.8155 - mse: 878266.1875 - val_loss: 19.8943 - val_mse: 2127.1646 - 816ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "221/221 - 1s - loss: 284.2393 - mse: 753694.2500 - val_loss: 18.6539 - val_mse: 1880.2439 - 808ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "221/221 - 1s - loss: 289.0847 - mse: 775255.0625 - val_loss: 17.5267 - val_mse: 1664.4928 - 805ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "221/221 - 1s - loss: 285.4850 - mse: 890296.0625 - val_loss: 15.1691 - val_mse: 1232.6583 - 811ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "221/221 - 1s - loss: 292.1756 - mse: 1000917.1875 - val_loss: 15.8141 - val_mse: 1337.9644 - 802ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "221/221 - 1s - loss: 292.4879 - mse: 989667.7500 - val_loss: 11.3710 - val_mse: 694.6421 - 796ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "221/221 - 1s - loss: 278.6440 - mse: 916007.3750 - val_loss: 9.5183 - val_mse: 493.1571 - 835ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "221/221 - 1s - loss: 279.3424 - mse: 825481.8750 - val_loss: 7.9283 - val_mse: 344.1507 - 855ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "221/221 - 1s - loss: 286.7803 - mse: 812195.5000 - val_loss: 7.8753 - val_mse: 344.8671 - 855ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "221/221 - 1s - loss: 274.8708 - mse: 695853.0625 - val_loss: 10.7392 - val_mse: 626.9791 - 814ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "221/221 - 1s - loss: 281.5424 - mse: 796889.0000 - val_loss: 10.0393 - val_mse: 550.8387 - 798ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "221/221 - 1s - loss: 272.7756 - mse: 697675.5625 - val_loss: 10.6049 - val_mse: 606.6563 - 807ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "221/221 - 1s - loss: 278.3818 - mse: 785322.2500 - val_loss: 7.9713 - val_mse: 376.1925 - 801ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "221/221 - 1s - loss: 266.6536 - mse: 701486.1250 - val_loss: 10.0253 - val_mse: 539.8242 - 801ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "221/221 - 1s - loss: 275.2919 - mse: 751248.7500 - val_loss: 8.5755 - val_mse: 397.9720 - 803ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "221/221 - 1s - loss: 268.0115 - mse: 715892.7500 - val_loss: 8.9321 - val_mse: 496.1937 - 815ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "221/221 - 1s - loss: 267.3826 - mse: 653924.5000 - val_loss: 8.7316 - val_mse: 477.0246 - 817ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "221/221 - 1s - loss: 276.6457 - mse: 762006.3750 - val_loss: 9.2124 - val_mse: 523.1585 - 814ms/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "221/221 - 1s - loss: 263.8812 - mse: 745908.5625 - val_loss: 9.2624 - val_mse: 532.0707 - 800ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "221/221 - 1s - loss: 249.6896 - mse: 575612.0000 - val_loss: 9.5001 - val_mse: 531.4799 - 802ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "221/221 - 1s - loss: 260.2812 - mse: 717237.9375 - val_loss: 8.8381 - val_mse: 456.6189 - 812ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "221/221 - 1s - loss: 251.7020 - mse: 583201.6875 - val_loss: 7.6136 - val_mse: 371.1295 - 847ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "221/221 - 1s - loss: 252.6338 - mse: 599477.8125 - val_loss: 7.7180 - val_mse: 379.9373 - 833ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "221/221 - 1s - loss: 254.5518 - mse: 666743.1875 - val_loss: 7.0152 - val_mse: 269.1791 - 835ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "221/221 - 1s - loss: 253.2319 - mse: 661231.3125 - val_loss: 5.1154 - val_mse: 145.7701 - 828ms/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "221/221 - 1s - loss: 257.1084 - mse: 665032.4375 - val_loss: 5.1281 - val_mse: 147.9459 - 810ms/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "221/221 - 1s - loss: 240.5158 - mse: 560305.0625 - val_loss: 4.5356 - val_mse: 131.4499 - 801ms/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "221/221 - 1s - loss: 245.9954 - mse: 637395.9375 - val_loss: 4.5022 - val_mse: 132.7204 - 807ms/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "221/221 - 1s - loss: 239.0857 - mse: 559450.3125 - val_loss: 5.1461 - val_mse: 173.2548 - 800ms/epoch - 4ms/step\n",
            "Epoch 136/400\n",
            "221/221 - 1s - loss: 232.3683 - mse: 509311.7188 - val_loss: 4.7270 - val_mse: 148.8216 - 812ms/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "221/221 - 1s - loss: 242.4912 - mse: 569049.1875 - val_loss: 5.5239 - val_mse: 197.2825 - 815ms/epoch - 4ms/step\n",
            "Epoch 138/400\n",
            "221/221 - 1s - loss: 234.1325 - mse: 545615.5000 - val_loss: 4.6471 - val_mse: 141.2548 - 828ms/epoch - 4ms/step\n",
            "Epoch 139/400\n",
            "221/221 - 1s - loss: 234.8284 - mse: 519372.3125 - val_loss: 2.6665 - val_mse: 50.2983 - 820ms/epoch - 4ms/step\n",
            "Epoch 140/400\n",
            "221/221 - 1s - loss: 235.5343 - mse: 524442.6875 - val_loss: 3.2615 - val_mse: 72.8522 - 809ms/epoch - 4ms/step\n",
            "Epoch 141/400\n",
            "221/221 - 1s - loss: 227.2705 - mse: 497377.9688 - val_loss: 4.0423 - val_mse: 111.0293 - 806ms/epoch - 4ms/step\n",
            "Epoch 142/400\n",
            "221/221 - 1s - loss: 231.9226 - mse: 518381.7812 - val_loss: 4.5298 - val_mse: 136.6816 - 792ms/epoch - 4ms/step\n",
            "Epoch 143/400\n",
            "221/221 - 1s - loss: 236.6098 - mse: 642922.0000 - val_loss: 4.9565 - val_mse: 160.1578 - 850ms/epoch - 4ms/step\n",
            "Epoch 144/400\n",
            "221/221 - 1s - loss: 222.4205 - mse: 493419.2812 - val_loss: 5.0411 - val_mse: 167.2429 - 850ms/epoch - 4ms/step\n",
            "Epoch 145/400\n",
            "221/221 - 1s - loss: 230.8018 - mse: 513372.0000 - val_loss: 6.4059 - val_mse: 254.4248 - 850ms/epoch - 4ms/step\n",
            "Epoch 146/400\n",
            "221/221 - 1s - loss: 222.3772 - mse: 474614.2812 - val_loss: 6.7043 - val_mse: 280.6993 - 855ms/epoch - 4ms/step\n",
            "Epoch 147/400\n",
            "221/221 - 1s - loss: 222.4579 - mse: 501880.2500 - val_loss: 6.1040 - val_mse: 228.0656 - 821ms/epoch - 4ms/step\n",
            "Epoch 148/400\n",
            "221/221 - 1s - loss: 218.7085 - mse: 483669.1875 - val_loss: 5.8056 - val_mse: 206.0197 - 811ms/epoch - 4ms/step\n",
            "Epoch 149/400\n",
            "221/221 - 1s - loss: 230.8140 - mse: 594431.8750 - val_loss: 5.3405 - val_mse: 161.6060 - 807ms/epoch - 4ms/step\n",
            "Epoch 150/400\n",
            "221/221 - 1s - loss: 207.7605 - mse: 436221.6875 - val_loss: 4.7812 - val_mse: 134.2095 - 818ms/epoch - 4ms/step\n",
            "Epoch 151/400\n",
            "221/221 - 1s - loss: 221.3457 - mse: 519001.6875 - val_loss: 5.9618 - val_mse: 204.6942 - 812ms/epoch - 4ms/step\n",
            "Epoch 152/400\n",
            "221/221 - 1s - loss: 210.1149 - mse: 462562.9375 - val_loss: 6.9009 - val_mse: 285.3004 - 825ms/epoch - 4ms/step\n",
            "Epoch 153/400\n",
            "221/221 - 1s - loss: 206.5930 - mse: 387931.4688 - val_loss: 7.7890 - val_mse: 354.8107 - 825ms/epoch - 4ms/step\n",
            "Epoch 154/400\n",
            "221/221 - 1s - loss: 213.0139 - mse: 487356.1875 - val_loss: 6.3589 - val_mse: 238.0983 - 810ms/epoch - 4ms/step\n",
            "Epoch 155/400\n",
            "221/221 - 1s - loss: 211.7222 - mse: 451783.7188 - val_loss: 6.1707 - val_mse: 231.4679 - 802ms/epoch - 4ms/step\n",
            "Epoch 156/400\n",
            "221/221 - 1s - loss: 211.6563 - mse: 472394.1562 - val_loss: 6.3586 - val_mse: 244.8658 - 808ms/epoch - 4ms/step\n",
            "Epoch 157/400\n",
            "221/221 - 1s - loss: 198.1787 - mse: 374496.5000 - val_loss: 5.6011 - val_mse: 185.8133 - 810ms/epoch - 4ms/step\n",
            "Epoch 158/400\n",
            "221/221 - 1s - loss: 201.1398 - mse: 384663.6875 - val_loss: 6.0080 - val_mse: 218.8216 - 808ms/epoch - 4ms/step\n",
            "Epoch 159/400\n",
            "221/221 - 1s - loss: 191.5162 - mse: 330048.5312 - val_loss: 5.6948 - val_mse: 196.8028 - 841ms/epoch - 4ms/step\n",
            "Epoch 160/400\n",
            "221/221 - 1s - loss: 196.4292 - mse: 385197.6875 - val_loss: 5.4744 - val_mse: 183.1065 - 855ms/epoch - 4ms/step\n",
            "Epoch 161/400\n",
            "221/221 - 1s - loss: 199.1003 - mse: 403762.3438 - val_loss: 6.8197 - val_mse: 274.9920 - 876ms/epoch - 4ms/step\n",
            "Epoch 162/400\n",
            "221/221 - 1s - loss: 194.5814 - mse: 387445.4375 - val_loss: 6.9204 - val_mse: 283.3123 - 818ms/epoch - 4ms/step\n",
            "Epoch 163/400\n",
            "221/221 - 1s - loss: 200.3408 - mse: 388623.3750 - val_loss: 6.9248 - val_mse: 283.1252 - 816ms/epoch - 4ms/step\n",
            "Epoch 164/400\n",
            "221/221 - 1s - loss: 195.6756 - mse: 391029.0625 - val_loss: 6.7221 - val_mse: 271.2744 - 813ms/epoch - 4ms/step\n",
            "Epoch 165/400\n",
            "221/221 - 1s - loss: 196.1614 - mse: 412798.3438 - val_loss: 5.1666 - val_mse: 167.0840 - 833ms/epoch - 4ms/step\n",
            "Epoch 166/400\n",
            "221/221 - 1s - loss: 195.3430 - mse: 377842.1875 - val_loss: 5.8569 - val_mse: 203.8004 - 824ms/epoch - 4ms/step\n",
            "Epoch 167/400\n",
            "221/221 - 1s - loss: 186.1697 - mse: 343662.5625 - val_loss: 5.9197 - val_mse: 207.5390 - 823ms/epoch - 4ms/step\n",
            "Epoch 168/400\n",
            "221/221 - 1s - loss: 186.7345 - mse: 363290.5000 - val_loss: 4.6359 - val_mse: 132.0088 - 813ms/epoch - 4ms/step\n",
            "Epoch 169/400\n",
            "221/221 - 1s - loss: 190.0094 - mse: 359440.1875 - val_loss: 5.0124 - val_mse: 158.3199 - 822ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 97 started****\n",
            "\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 4s 10ms/step - loss: 640.6372 - mse: 28293368.0000 - val_loss: 0.1066 - val_mse: 0.2132\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.2102 - mse: 1.8321 - val_loss: 0.0105 - val_mse: 0.0210\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0413 - mse: 1.0039 - val_loss: 0.0058 - val_mse: 0.0115\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0298 - val_loss: 0.0058 - val_mse: 0.0117\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0204 - mse: 0.2447 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0200 - mse: 0.2711 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0228 - val_loss: 0.0054 - val_mse: 0.0108\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0198 - val_loss: 0.0054 - val_mse: 0.0109\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0299 - val_loss: 0.0052 - val_mse: 0.0104\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0110 - mse: 0.0848 - val_loss: 0.0050 - val_mse: 0.0100\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0551 - val_loss: 0.0053 - val_mse: 0.0105\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0136 - mse: 0.1000 - val_loss: 0.0049 - val_mse: 0.0099\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0449 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0078 - mse: 0.0166 - val_loss: 0.0046 - val_mse: 0.0093\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0085 - mse: 0.0189 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0185 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0067 - mse: 0.0133 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0147 - val_loss: 0.0045 - val_mse: 0.0089\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0116 - mse: 0.1681 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0228 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0079 - mse: 0.0194 - val_loss: 0.0044 - val_mse: 0.0087\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0081 - mse: 0.0283 - val_loss: 0.0044 - val_mse: 0.0088\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0123 - val_loss: 0.0042 - val_mse: 0.0085\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0134 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0072 - mse: 0.0161 - val_loss: 0.0041 - val_mse: 0.0083\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0144 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0071 - mse: 0.0191 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0259 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0076 - mse: 0.0218 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0066 - mse: 0.0155 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0063 - mse: 0.0131 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0133 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0140 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0039 - val_mse: 0.0077\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0801 - val_loss: 0.0038 - val_mse: 0.0075\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0082 - mse: 0.0665 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0040 - val_mse: 0.0079\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0113 - val_loss: 0.0039 - val_mse: 0.0078\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0039 - val_mse: 0.0079\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0038 - val_mse: 0.0077\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0121 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0111 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0069 - mse: 0.0271 - val_loss: 0.0039 - val_mse: 0.0077\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0037 - val_mse: 0.0075\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0109 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0109 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 0.0110 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0126 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0150 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0101 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0125 - val_loss: 0.0050 - val_mse: 0.0099\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0115 - val_loss: 0.0039 - val_mse: 0.0079\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0117 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0103 - val_loss: 0.0037 - val_mse: 0.0073\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0035 - val_mse: 0.0071\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0048 - val_mse: 0.0095\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0109 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0099 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0091 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0099 - val_loss: 0.0034 - val_mse: 0.0069\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0097 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0034 - val_mse: 0.0068\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0095 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0169 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0047 - mse: 0.0094 - val_loss: 0.0033 - val_mse: 0.0067\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0092 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0047 - mse: 0.0093 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0030 - val_mse: 0.0059\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0087 - val_loss: 0.0031 - val_mse: 0.0063\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0088 - val_loss: 0.0031 - val_mse: 0.0061\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0096 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0042 - mse: 0.0083 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 0.0231 - val_loss: 0.0034 - val_mse: 0.0068\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0031 - val_mse: 0.0061\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 101/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0030 - val_mse: 0.0059 - 342ms/epoch - 7ms/step\n",
            "Epoch 102/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0030 - val_mse: 0.0061 - 266ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0029 - val_mse: 0.0059 - 268ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0031 - val_mse: 0.0062 - 269ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0031 - val_mse: 0.0062 - 261ms/epoch - 5ms/step\n",
            "Epoch 106/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0030 - val_mse: 0.0059 - 261ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0029 - val_mse: 0.0058 - 268ms/epoch - 5ms/step\n",
            "Epoch 108/400\n",
            "50/50 - 0s - loss: 0.0046 - mse: 0.0104 - val_loss: 0.0030 - val_mse: 0.0059 - 258ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0031 - val_mse: 0.0061 - 262ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "50/50 - 0s - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0030 - val_mse: 0.0059 - 257ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0033 - val_mse: 0.0067 - 255ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0030 - val_mse: 0.0060 - 259ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0030 - val_mse: 0.0061 - 259ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0081 - val_loss: 0.0029 - val_mse: 0.0059 - 258ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0030 - val_mse: 0.0060 - 258ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0079 - val_loss: 0.0029 - val_mse: 0.0059 - 257ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0029 - val_mse: 0.0057 - 272ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "50/50 - 0s - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0031 - val_mse: 0.0061 - 258ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "50/50 - 0s - loss: 0.0061 - mse: 0.0352 - val_loss: 0.0041 - val_mse: 0.0082 - 252ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "50/50 - 0s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0043 - val_mse: 0.0087 - 265ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "50/50 - 0s - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0031 - val_mse: 0.0061 - 268ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0032 - val_mse: 0.0064 - 259ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "50/50 - 0s - loss: 0.0044 - mse: 0.0087 - val_loss: 0.0033 - val_mse: 0.0065 - 257ms/epoch - 5ms/step\n",
            "Epoch 124/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0031 - val_mse: 0.0062 - 261ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0030 - val_mse: 0.0061 - 256ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0031 - val_mse: 0.0061 - 248ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0032 - val_mse: 0.0064 - 250ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0081 - val_loss: 0.0032 - val_mse: 0.0064 - 251ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "50/50 - 0s - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0032 - val_mse: 0.0064 - 260ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0031 - val_mse: 0.0062 - 255ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0030 - val_mse: 0.0059 - 265ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0031 - val_mse: 0.0063 - 265ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0030 - val_mse: 0.0060 - 268ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0030 - val_mse: 0.0061 - 262ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0032 - val_mse: 0.0065 - 268ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "50/50 - 0s - loss: 0.0053 - mse: 0.0106 - val_loss: 0.0066 - val_mse: 0.0132 - 281ms/epoch - 6ms/step\n",
            "Epoch 137/400\n",
            "50/50 - 0s - loss: 0.0086 - mse: 0.0187 - val_loss: 0.0063 - val_mse: 0.0125 - 271ms/epoch - 5ms/step\n",
            "Epoch 138/400\n",
            "50/50 - 0s - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0042 - val_mse: 0.0084 - 275ms/epoch - 6ms/step\n",
            "Epoch 139/400\n",
            "50/50 - 0s - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0033 - val_mse: 0.0067 - 265ms/epoch - 5ms/step\n",
            "Epoch 140/400\n",
            "50/50 - 0s - loss: 0.0044 - mse: 0.0089 - val_loss: 0.0032 - val_mse: 0.0064 - 274ms/epoch - 5ms/step\n",
            "Epoch 141/400\n",
            "50/50 - 0s - loss: 0.0043 - mse: 0.0086 - val_loss: 0.0032 - val_mse: 0.0064 - 267ms/epoch - 5ms/step\n",
            "Epoch 142/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0032 - val_mse: 0.0065 - 261ms/epoch - 5ms/step\n",
            "Epoch 143/400\n",
            "50/50 - 0s - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0032 - val_mse: 0.0065 - 258ms/epoch - 5ms/step\n",
            "Epoch 144/400\n",
            "50/50 - 0s - loss: 0.0042 - mse: 0.0085 - val_loss: 0.0031 - val_mse: 0.0061 - 263ms/epoch - 5ms/step\n",
            "Epoch 145/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0083 - val_loss: 0.0031 - val_mse: 0.0061 - 261ms/epoch - 5ms/step\n",
            "Epoch 146/400\n",
            "50/50 - 0s - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0030 - val_mse: 0.0061 - 264ms/epoch - 5ms/step\n",
            "Epoch 147/400\n",
            "50/50 - 0s - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0031 - val_mse: 0.0063 - 279ms/epoch - 6ms/step\n",
            "\n",
            "****Iteration number 98 started****\n",
            "\n",
            "Epoch 1/100\n",
            "57/57 [==============================] - 4s 9ms/step - loss: 542.5558 - mse: 2292291.7500 - val_loss: 324.4513 - val_mse: 534376.1875\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 526.5121 - mse: 2481263.5000 - val_loss: 303.9771 - val_mse: 469039.3438\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 494.8010 - mse: 2062564.5000 - val_loss: 284.8040 - val_mse: 411896.3750\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 484.5840 - mse: 2045936.1250 - val_loss: 265.1993 - val_mse: 357126.4375\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 469.7778 - mse: 1916774.5000 - val_loss: 246.4772 - val_mse: 308451.5000\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 437.9262 - mse: 1523419.2500 - val_loss: 228.0514 - val_mse: 264251.1250\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 423.6170 - mse: 1501036.5000 - val_loss: 210.3348 - val_mse: 224790.3906\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 401.8990 - mse: 1314012.0000 - val_loss: 194.0036 - val_mse: 191346.8125\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 397.9657 - mse: 1387652.7500 - val_loss: 178.2402 - val_mse: 161517.8906\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 379.4984 - mse: 1296100.5000 - val_loss: 164.0270 - val_mse: 136538.7656\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 381.2691 - mse: 1364262.6250 - val_loss: 150.6569 - val_mse: 115096.7344\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 341.8237 - mse: 985778.8750 - val_loss: 138.1735 - val_mse: 96695.9453\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 352.2649 - mse: 1164233.3750 - val_loss: 127.2752 - val_mse: 82750.1953\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 330.1111 - mse: 990195.7500 - val_loss: 114.6943 - val_mse: 67305.4219\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 318.8867 - mse: 911411.6250 - val_loss: 103.4787 - val_mse: 55094.3672\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 300.0936 - mse: 779539.0000 - val_loss: 90.9577 - val_mse: 42720.0273\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 292.9135 - mse: 867954.0000 - val_loss: 79.3651 - val_mse: 32730.0801\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 291.3679 - mse: 707010.8125 - val_loss: 68.5945 - val_mse: 24319.3457\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 272.4589 - mse: 646349.0000 - val_loss: 59.4131 - val_mse: 18392.9004\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 280.7404 - mse: 802622.8750 - val_loss: 50.1926 - val_mse: 13088.0850\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 262.5938 - mse: 649566.9375 - val_loss: 44.3002 - val_mse: 10205.6641\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 250.8771 - mse: 620345.0000 - val_loss: 39.3205 - val_mse: 8059.6162\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 255.5731 - mse: 624385.7500 - val_loss: 34.7828 - val_mse: 6335.1567\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 248.4733 - mse: 600155.6250 - val_loss: 32.3064 - val_mse: 5466.5591\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 229.1497 - mse: 447022.7188 - val_loss: 29.8568 - val_mse: 4691.6641\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 229.6040 - mse: 475121.0938 - val_loss: 27.3245 - val_mse: 3949.4712\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 219.5715 - mse: 443791.5938 - val_loss: 24.9673 - val_mse: 3317.7249\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 218.7782 - mse: 483041.7500 - val_loss: 22.6390 - val_mse: 2742.5044\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 220.7580 - mse: 463475.4062 - val_loss: 20.0627 - val_mse: 2171.8135\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 211.4185 - mse: 431005.6562 - val_loss: 16.9154 - val_mse: 1560.3585\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 204.2994 - mse: 414823.1562 - val_loss: 14.4026 - val_mse: 1152.3173\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 200.3767 - mse: 388806.7500 - val_loss: 12.4199 - val_mse: 872.8033\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 203.0783 - mse: 425210.4688 - val_loss: 11.3589 - val_mse: 742.8447\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 186.3119 - mse: 319593.7500 - val_loss: 10.3626 - val_mse: 625.4204\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 189.1987 - mse: 347483.7812 - val_loss: 9.5534 - val_mse: 544.4133\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 191.8419 - mse: 370237.4062 - val_loss: 9.7678 - val_mse: 567.5817\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 181.1334 - mse: 325786.5625 - val_loss: 9.0871 - val_mse: 495.1070\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 179.8079 - mse: 310110.9062 - val_loss: 8.8045 - val_mse: 470.0713\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 180.7132 - mse: 348330.3750 - val_loss: 8.9775 - val_mse: 498.1284\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 171.7123 - mse: 304996.1562 - val_loss: 9.5233 - val_mse: 566.2502\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 168.6665 - mse: 268748.8125 - val_loss: 10.5244 - val_mse: 684.4195\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 171.9597 - mse: 277007.5312 - val_loss: 10.6800 - val_mse: 676.1529\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 166.9494 - mse: 294851.4375 - val_loss: 9.6046 - val_mse: 533.1088\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 168.4317 - mse: 270836.3438 - val_loss: 7.7938 - val_mse: 347.4992\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 162.6960 - mse: 265453.7500 - val_loss: 6.1366 - val_mse: 216.8785\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 161.7048 - mse: 305188.9062 - val_loss: 4.5038 - val_mse: 123.9696\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 156.6853 - mse: 252570.8594 - val_loss: 3.4705 - val_mse: 82.9393\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 151.8829 - mse: 231077.5625 - val_loss: 3.1264 - val_mse: 74.2153\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 149.6983 - mse: 220038.9375 - val_loss: 2.7557 - val_mse: 60.0802\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 156.1302 - mse: 267042.5312 - val_loss: 2.6579 - val_mse: 56.1147\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 151.7716 - mse: 207179.2812 - val_loss: 2.4416 - val_mse: 48.1969\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 145.7686 - mse: 220308.0625 - val_loss: 2.3762 - val_mse: 45.6540\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 150.4368 - mse: 234790.4219 - val_loss: 2.3863 - val_mse: 44.3139\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 140.0784 - mse: 180910.4375 - val_loss: 2.2272 - val_mse: 37.7094\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 147.1440 - mse: 221356.4219 - val_loss: 1.6515 - val_mse: 19.5849\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 144.0438 - mse: 209625.1094 - val_loss: 1.0356 - val_mse: 7.5154\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 144.6595 - mse: 217427.1719 - val_loss: 0.7142 - val_mse: 3.8622\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 145.7449 - mse: 238833.0000 - val_loss: 0.6406 - val_mse: 3.2317\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 140.7534 - mse: 194504.9844 - val_loss: 0.6401 - val_mse: 2.0165\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 135.9104 - mse: 169600.3906 - val_loss: 0.6535 - val_mse: 1.4764\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132.3164 - mse: 168020.2031 - val_loss: 0.7965 - val_mse: 1.7753\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 137.3249 - mse: 195333.9844 - val_loss: 1.0272 - val_mse: 2.6407\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 136.5901 - mse: 218909.7969 - val_loss: 1.3309 - val_mse: 4.5959\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133.7732 - mse: 180371.0156 - val_loss: 1.6395 - val_mse: 7.5732\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134.3143 - mse: 173152.9844 - val_loss: 1.5291 - val_mse: 6.4595\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130.5999 - mse: 155158.4375 - val_loss: 1.7323 - val_mse: 8.7638\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131.9015 - mse: 189424.0000 - val_loss: 2.0492 - val_mse: 13.0277\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 127.7341 - mse: 169329.3125 - val_loss: 2.0799 - val_mse: 13.0085\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 126.6999 - mse: 153406.2812 - val_loss: 2.1909 - val_mse: 14.2740\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133.1527 - mse: 210578.6562 - val_loss: 2.4101 - val_mse: 18.0805\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129.3457 - mse: 171114.7500 - val_loss: 2.6284 - val_mse: 22.2309\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132.7187 - mse: 191658.9062 - val_loss: 2.6362 - val_mse: 22.0471\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 122.7325 - mse: 163758.9531 - val_loss: 2.5847 - val_mse: 20.7385\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 126.6523 - mse: 172038.9375 - val_loss: 2.7489 - val_mse: 23.9800\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 126.3989 - mse: 153204.5469 - val_loss: 2.7250 - val_mse: 23.3559\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128.3615 - mse: 167075.8906 - val_loss: 3.0083 - val_mse: 29.7618\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 124.5400 - mse: 171755.0312 - val_loss: 3.0136 - val_mse: 29.9168\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 123.4214 - mse: 145478.0625 - val_loss: 3.0811 - val_mse: 31.7710\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 125.2120 - mse: 153376.8906 - val_loss: 3.0506 - val_mse: 31.1965\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 120.5292 - mse: 143750.2500 - val_loss: 3.3734 - val_mse: 39.4055\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 118.9135 - mse: 133137.8594 - val_loss: 3.5936 - val_mse: 45.8802\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 121.9608 - mse: 164342.0000 - val_loss: 4.1721 - val_mse: 65.2107\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 116.8139 - mse: 140321.9375 - val_loss: 4.3146 - val_mse: 70.8062\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 117.3221 - mse: 148401.6406 - val_loss: 4.5244 - val_mse: 79.0320\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 118.9200 - mse: 145096.7188 - val_loss: 4.8819 - val_mse: 94.5350\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 119.2098 - mse: 156832.2500 - val_loss: 5.1166 - val_mse: 105.3556\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 118.9375 - mse: 128887.4922 - val_loss: 4.6600 - val_mse: 84.7936\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 117.3102 - mse: 147021.3125 - val_loss: 4.5029 - val_mse: 79.1031\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 117.5278 - mse: 136484.5938 - val_loss: 4.4075 - val_mse: 76.0517\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 116.7627 - mse: 132016.5156 - val_loss: 4.4651 - val_mse: 78.4060\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 109.9645 - mse: 124940.4297 - val_loss: 4.8055 - val_mse: 92.0888\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 112.0996 - mse: 126540.4844 - val_loss: 5.0510 - val_mse: 103.4474\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 114.8601 - mse: 129651.7422 - val_loss: 5.0812 - val_mse: 104.9847\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 110.9302 - mse: 126088.3750 - val_loss: 5.0448 - val_mse: 103.4115\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 112.5980 - mse: 133277.5781 - val_loss: 5.1536 - val_mse: 108.5433\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 109.3878 - mse: 118125.6016 - val_loss: 4.9005 - val_mse: 96.7071\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 112.4477 - mse: 132688.9844 - val_loss: 4.8755 - val_mse: 96.0033\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 111.8000 - mse: 118984.9141 - val_loss: 4.8131 - val_mse: 93.4359\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 111.2191 - mse: 119739.3828 - val_loss: 4.9466 - val_mse: 99.2417\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 108.6899 - mse: 111414.5703 - val_loss: 5.1962 - val_mse: 110.9845\n",
            "Epoch 101/400\n",
            "57/57 - 0s - loss: 111.3665 - mse: 135432.7344 - val_loss: 5.1674 - val_mse: 109.6506 - 349ms/epoch - 6ms/step\n",
            "Epoch 102/400\n",
            "57/57 - 0s - loss: 107.6613 - mse: 137796.5625 - val_loss: 5.3113 - val_mse: 116.8258 - 286ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "57/57 - 0s - loss: 105.4645 - mse: 111469.1953 - val_loss: 5.4706 - val_mse: 124.9439 - 287ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "57/57 - 0s - loss: 107.2153 - mse: 117375.8594 - val_loss: 5.8881 - val_mse: 148.1723 - 289ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "57/57 - 0s - loss: 110.0464 - mse: 138458.5625 - val_loss: 5.7747 - val_mse: 141.0598 - 281ms/epoch - 5ms/step\n",
            "Epoch 106/400\n",
            "57/57 - 0s - loss: 105.2674 - mse: 117295.3672 - val_loss: 5.8099 - val_mse: 143.1992 - 284ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "57/57 - 0s - loss: 104.7973 - mse: 105275.9062 - val_loss: 5.8350 - val_mse: 144.9341 - 286ms/epoch - 5ms/step\n",
            "Epoch 108/400\n",
            "57/57 - 0s - loss: 101.0652 - mse: 94996.7734 - val_loss: 5.8383 - val_mse: 145.4017 - 292ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "57/57 - 0s - loss: 104.7569 - mse: 105910.1641 - val_loss: 5.9956 - val_mse: 155.7287 - 295ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "57/57 - 0s - loss: 105.4515 - mse: 109711.6406 - val_loss: 6.2324 - val_mse: 172.1772 - 290ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "57/57 - 0s - loss: 99.0921 - mse: 89820.3438 - val_loss: 6.2653 - val_mse: 175.0116 - 290ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "57/57 - 0s - loss: 101.3012 - mse: 98839.3438 - val_loss: 6.2428 - val_mse: 174.0065 - 285ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "57/57 - 0s - loss: 103.8642 - mse: 111798.2266 - val_loss: 6.3665 - val_mse: 182.0606 - 283ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "57/57 - 0s - loss: 101.0655 - mse: 102658.4922 - val_loss: 6.3129 - val_mse: 178.8326 - 291ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "57/57 - 0s - loss: 101.5126 - mse: 109128.1094 - val_loss: 6.1491 - val_mse: 169.4773 - 287ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "57/57 - 0s - loss: 100.5247 - mse: 98402.4766 - val_loss: 6.0809 - val_mse: 165.6277 - 280ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "57/57 - 0s - loss: 105.4363 - mse: 120600.9375 - val_loss: 5.9997 - val_mse: 161.1888 - 288ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "57/57 - 0s - loss: 103.0979 - mse: 116529.3281 - val_loss: 5.9409 - val_mse: 158.1072 - 289ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "57/57 - 0s - loss: 99.5875 - mse: 106738.5938 - val_loss: 5.7323 - val_mse: 146.5627 - 285ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "57/57 - 0s - loss: 98.3897 - mse: 96894.5000 - val_loss: 5.6552 - val_mse: 142.4482 - 293ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "57/57 - 0s - loss: 99.8182 - mse: 111871.7109 - val_loss: 5.4333 - val_mse: 130.9379 - 294ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "57/57 - 0s - loss: 99.0976 - mse: 96049.7422 - val_loss: 5.4198 - val_mse: 130.4379 - 299ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "57/57 - 0s - loss: 99.3994 - mse: 97791.8438 - val_loss: 5.2784 - val_mse: 123.3235 - 288ms/epoch - 5ms/step\n",
            "Epoch 124/400\n",
            "57/57 - 0s - loss: 96.6607 - mse: 87202.3281 - val_loss: 5.2378 - val_mse: 121.5365 - 290ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "57/57 - 0s - loss: 94.7070 - mse: 104228.3984 - val_loss: 5.1898 - val_mse: 119.4450 - 289ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "57/57 - 0s - loss: 97.2028 - mse: 108462.5156 - val_loss: 5.0519 - val_mse: 112.9473 - 283ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "57/57 - 0s - loss: 97.2765 - mse: 104010.2812 - val_loss: 4.8879 - val_mse: 105.5912 - 293ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "57/57 - 0s - loss: 96.1369 - mse: 95936.9453 - val_loss: 4.7920 - val_mse: 101.4025 - 289ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "57/57 - 0s - loss: 94.9484 - mse: 81890.5703 - val_loss: 4.8731 - val_mse: 104.9996 - 285ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "57/57 - 0s - loss: 92.5727 - mse: 79663.9531 - val_loss: 4.9461 - val_mse: 108.6744 - 285ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "57/57 - 0s - loss: 97.1937 - mse: 105300.7188 - val_loss: 4.9194 - val_mse: 107.9514 - 290ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "57/57 - 0s - loss: 99.6166 - mse: 114248.7422 - val_loss: 5.0483 - val_mse: 113.2313 - 286ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "57/57 - 0s - loss: 95.1864 - mse: 100647.1797 - val_loss: 5.0120 - val_mse: 111.6721 - 308ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "57/57 - 0s - loss: 94.0326 - mse: 92446.7891 - val_loss: 5.0715 - val_mse: 114.7995 - 303ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "57/57 - 0s - loss: 92.1814 - mse: 93271.0234 - val_loss: 5.1035 - val_mse: 116.2898 - 305ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "57/57 - 0s - loss: 89.3317 - mse: 82039.0156 - val_loss: 5.1299 - val_mse: 117.8055 - 304ms/epoch - 5ms/step\n",
            "Epoch 137/400\n",
            "57/57 - 0s - loss: 97.3783 - mse: 106533.4922 - val_loss: 5.0577 - val_mse: 114.2406 - 299ms/epoch - 5ms/step\n",
            "Epoch 138/400\n",
            "57/57 - 0s - loss: 92.8760 - mse: 81956.3672 - val_loss: 5.0197 - val_mse: 111.8757 - 300ms/epoch - 5ms/step\n",
            "Epoch 139/400\n",
            "57/57 - 0s - loss: 87.9131 - mse: 67751.7812 - val_loss: 4.9103 - val_mse: 106.6301 - 305ms/epoch - 5ms/step\n",
            "Epoch 140/400\n",
            "57/57 - 0s - loss: 94.5134 - mse: 92243.3750 - val_loss: 4.9761 - val_mse: 108.9956 - 323ms/epoch - 6ms/step\n",
            "Epoch 141/400\n",
            "57/57 - 0s - loss: 91.2274 - mse: 95031.3672 - val_loss: 4.8886 - val_mse: 104.8374 - 307ms/epoch - 5ms/step\n",
            "Epoch 142/400\n",
            "57/57 - 0s - loss: 86.8347 - mse: 71787.7344 - val_loss: 4.7166 - val_mse: 96.7577 - 296ms/epoch - 5ms/step\n",
            "Epoch 143/400\n",
            "57/57 - 0s - loss: 88.4359 - mse: 78494.3438 - val_loss: 4.7020 - val_mse: 95.4370 - 292ms/epoch - 5ms/step\n",
            "Epoch 144/400\n",
            "57/57 - 0s - loss: 88.8865 - mse: 79013.3281 - val_loss: 4.6174 - val_mse: 91.4891 - 286ms/epoch - 5ms/step\n",
            "Epoch 145/400\n",
            "57/57 - 0s - loss: 89.8634 - mse: 85626.4922 - val_loss: 4.6025 - val_mse: 90.6269 - 289ms/epoch - 5ms/step\n",
            "Epoch 146/400\n",
            "57/57 - 0s - loss: 90.4939 - mse: 94422.4375 - val_loss: 4.5642 - val_mse: 89.0162 - 290ms/epoch - 5ms/step\n",
            "Epoch 147/400\n",
            "57/57 - 0s - loss: 84.8595 - mse: 73335.3281 - val_loss: 4.4309 - val_mse: 83.3605 - 292ms/epoch - 5ms/step\n",
            "Epoch 148/400\n",
            "57/57 - 0s - loss: 87.8993 - mse: 77306.6719 - val_loss: 4.3459 - val_mse: 80.3031 - 290ms/epoch - 5ms/step\n",
            "Epoch 149/400\n",
            "57/57 - 0s - loss: 87.1610 - mse: 76591.5469 - val_loss: 4.2783 - val_mse: 78.0367 - 291ms/epoch - 5ms/step\n",
            "Epoch 150/400\n",
            "57/57 - 0s - loss: 84.5288 - mse: 80050.4219 - val_loss: 4.2603 - val_mse: 76.9275 - 289ms/epoch - 5ms/step\n",
            "Epoch 151/400\n",
            "57/57 - 0s - loss: 85.5977 - mse: 79650.5547 - val_loss: 4.1420 - val_mse: 72.5382 - 299ms/epoch - 5ms/step\n",
            "Epoch 152/400\n",
            "57/57 - 0s - loss: 88.6219 - mse: 79545.5156 - val_loss: 4.2660 - val_mse: 76.5924 - 286ms/epoch - 5ms/step\n",
            "Epoch 153/400\n",
            "57/57 - 0s - loss: 87.1420 - mse: 76286.9609 - val_loss: 4.3999 - val_mse: 81.3064 - 286ms/epoch - 5ms/step\n",
            "Epoch 154/400\n",
            "57/57 - 0s - loss: 88.5885 - mse: 93082.5703 - val_loss: 4.5224 - val_mse: 85.9620 - 288ms/epoch - 5ms/step\n",
            "Epoch 155/400\n",
            "57/57 - 0s - loss: 85.0145 - mse: 70118.4844 - val_loss: 4.5267 - val_mse: 86.0197 - 289ms/epoch - 5ms/step\n",
            "Epoch 156/400\n",
            "57/57 - 0s - loss: 84.3712 - mse: 77429.6250 - val_loss: 4.4698 - val_mse: 82.9483 - 285ms/epoch - 5ms/step\n",
            "Epoch 157/400\n",
            "57/57 - 0s - loss: 86.8199 - mse: 87162.1484 - val_loss: 4.4358 - val_mse: 81.7703 - 293ms/epoch - 5ms/step\n",
            "Epoch 158/400\n",
            "57/57 - 0s - loss: 87.7116 - mse: 84292.6484 - val_loss: 4.4152 - val_mse: 81.1715 - 288ms/epoch - 5ms/step\n",
            "Epoch 159/400\n",
            "57/57 - 0s - loss: 79.6483 - mse: 62591.6836 - val_loss: 4.5633 - val_mse: 86.6452 - 290ms/epoch - 5ms/step\n",
            "Epoch 160/400\n",
            "57/57 - 0s - loss: 85.5651 - mse: 69395.2188 - val_loss: 4.7547 - val_mse: 94.2340 - 292ms/epoch - 5ms/step\n",
            "Epoch 161/400\n",
            "57/57 - 0s - loss: 83.9480 - mse: 76833.5156 - val_loss: 4.8001 - val_mse: 96.7246 - 291ms/epoch - 5ms/step\n",
            "Epoch 162/400\n",
            "57/57 - 0s - loss: 85.2685 - mse: 88525.2031 - val_loss: 4.8427 - val_mse: 97.9379 - 293ms/epoch - 5ms/step\n",
            "Epoch 163/400\n",
            "57/57 - 0s - loss: 81.1999 - mse: 65274.3750 - val_loss: 4.9152 - val_mse: 100.7343 - 287ms/epoch - 5ms/step\n",
            "Epoch 164/400\n",
            "57/57 - 0s - loss: 83.4976 - mse: 68368.3359 - val_loss: 4.7950 - val_mse: 95.1533 - 290ms/epoch - 5ms/step\n",
            "Epoch 165/400\n",
            "57/57 - 0s - loss: 82.1440 - mse: 68041.1094 - val_loss: 4.7957 - val_mse: 95.0266 - 288ms/epoch - 5ms/step\n",
            "Epoch 166/400\n",
            "57/57 - 0s - loss: 82.1479 - mse: 70001.8359 - val_loss: 4.8302 - val_mse: 95.1596 - 280ms/epoch - 5ms/step\n",
            "Epoch 167/400\n",
            "57/57 - 0s - loss: 80.2617 - mse: 61735.2695 - val_loss: 4.8897 - val_mse: 97.2843 - 282ms/epoch - 5ms/step\n",
            "Epoch 168/400\n",
            "57/57 - 0s - loss: 80.3401 - mse: 67150.3047 - val_loss: 4.9654 - val_mse: 101.3062 - 295ms/epoch - 5ms/step\n",
            "Epoch 169/400\n",
            "57/57 - 0s - loss: 83.1156 - mse: 75471.7734 - val_loss: 4.8162 - val_mse: 94.1439 - 286ms/epoch - 5ms/step\n",
            "Epoch 170/400\n",
            "57/57 - 0s - loss: 79.7209 - mse: 67944.6016 - val_loss: 5.1005 - val_mse: 107.8220 - 290ms/epoch - 5ms/step\n",
            "Epoch 171/400\n",
            "57/57 - 0s - loss: 78.7257 - mse: 70608.6016 - val_loss: 4.9376 - val_mse: 100.0943 - 294ms/epoch - 5ms/step\n",
            "Epoch 172/400\n",
            "57/57 - 0s - loss: 76.8250 - mse: 58621.7227 - val_loss: 4.7233 - val_mse: 90.3393 - 289ms/epoch - 5ms/step\n",
            "Epoch 173/400\n",
            "57/57 - 0s - loss: 82.1405 - mse: 83466.0938 - val_loss: 4.5520 - val_mse: 82.4275 - 289ms/epoch - 5ms/step\n",
            "Epoch 174/400\n",
            "57/57 - 0s - loss: 80.6422 - mse: 65029.1992 - val_loss: 4.5934 - val_mse: 84.0240 - 284ms/epoch - 5ms/step\n",
            "Epoch 175/400\n",
            "57/57 - 0s - loss: 76.9917 - mse: 57418.4219 - val_loss: 4.3593 - val_mse: 74.0899 - 290ms/epoch - 5ms/step\n",
            "Epoch 176/400\n",
            "57/57 - 0s - loss: 79.4194 - mse: 70809.3359 - val_loss: 4.1317 - val_mse: 66.8377 - 299ms/epoch - 5ms/step\n",
            "Epoch 177/400\n",
            "57/57 - 0s - loss: 80.0297 - mse: 64976.3477 - val_loss: 3.8978 - val_mse: 59.6827 - 299ms/epoch - 5ms/step\n",
            "Epoch 178/400\n",
            "57/57 - 0s - loss: 76.6234 - mse: 58268.4023 - val_loss: 3.9525 - val_mse: 61.4500 - 291ms/epoch - 5ms/step\n",
            "Epoch 179/400\n",
            "57/57 - 0s - loss: 76.3731 - mse: 60740.7539 - val_loss: 3.9430 - val_mse: 60.7705 - 297ms/epoch - 5ms/step\n",
            "Epoch 180/400\n",
            "57/57 - 0s - loss: 76.3251 - mse: 58131.8281 - val_loss: 3.8691 - val_mse: 58.4912 - 290ms/epoch - 5ms/step\n",
            "Epoch 181/400\n",
            "57/57 - 0s - loss: 76.2273 - mse: 58045.4297 - val_loss: 3.8441 - val_mse: 57.9326 - 293ms/epoch - 5ms/step\n",
            "Epoch 182/400\n",
            "57/57 - 0s - loss: 76.3940 - mse: 55046.6328 - val_loss: 3.9099 - val_mse: 59.8596 - 291ms/epoch - 5ms/step\n",
            "Epoch 183/400\n",
            "57/57 - 0s - loss: 73.6637 - mse: 54904.5742 - val_loss: 4.0148 - val_mse: 62.8680 - 302ms/epoch - 5ms/step\n",
            "Epoch 184/400\n",
            "57/57 - 0s - loss: 80.4486 - mse: 67758.4062 - val_loss: 4.0097 - val_mse: 62.6499 - 291ms/epoch - 5ms/step\n",
            "Epoch 185/400\n",
            "57/57 - 0s - loss: 74.1377 - mse: 52716.4961 - val_loss: 4.0461 - val_mse: 63.1549 - 281ms/epoch - 5ms/step\n",
            "Epoch 186/400\n",
            "57/57 - 0s - loss: 78.0158 - mse: 61595.2031 - val_loss: 3.9609 - val_mse: 59.8370 - 276ms/epoch - 5ms/step\n",
            "Epoch 187/400\n",
            "57/57 - 0s - loss: 79.6456 - mse: 74511.3750 - val_loss: 3.9952 - val_mse: 60.4233 - 275ms/epoch - 5ms/step\n",
            "Epoch 188/400\n",
            "57/57 - 0s - loss: 72.1171 - mse: 53053.8867 - val_loss: 3.9025 - val_mse: 57.2401 - 284ms/epoch - 5ms/step\n",
            "Epoch 189/400\n",
            "57/57 - 0s - loss: 74.8627 - mse: 60427.8945 - val_loss: 3.9227 - val_mse: 58.0481 - 279ms/epoch - 5ms/step\n",
            "Epoch 190/400\n",
            "57/57 - 0s - loss: 74.1066 - mse: 58691.3672 - val_loss: 4.0008 - val_mse: 59.7521 - 279ms/epoch - 5ms/step\n",
            "Epoch 191/400\n",
            "57/57 - 0s - loss: 74.6717 - mse: 55786.3086 - val_loss: 4.0467 - val_mse: 60.8930 - 276ms/epoch - 5ms/step\n",
            "Epoch 192/400\n",
            "57/57 - 0s - loss: 75.1909 - mse: 57798.3672 - val_loss: 4.2619 - val_mse: 67.3195 - 289ms/epoch - 5ms/step\n",
            "Epoch 193/400\n",
            "57/57 - 0s - loss: 74.0989 - mse: 65679.2812 - val_loss: 4.2144 - val_mse: 65.5624 - 279ms/epoch - 5ms/step\n",
            "Epoch 194/400\n",
            "57/57 - 0s - loss: 71.8911 - mse: 53068.9844 - val_loss: 4.1521 - val_mse: 62.9984 - 282ms/epoch - 5ms/step\n",
            "Epoch 195/400\n",
            "57/57 - 0s - loss: 73.6363 - mse: 73537.1484 - val_loss: 4.0817 - val_mse: 60.5193 - 287ms/epoch - 5ms/step\n",
            "Epoch 196/400\n",
            "57/57 - 0s - loss: 71.1508 - mse: 55198.4609 - val_loss: 3.9466 - val_mse: 55.9892 - 288ms/epoch - 5ms/step\n",
            "Epoch 197/400\n",
            "57/57 - 0s - loss: 74.7502 - mse: 59096.5898 - val_loss: 3.8867 - val_mse: 54.1439 - 285ms/epoch - 5ms/step\n",
            "Epoch 198/400\n",
            "57/57 - 0s - loss: 73.9105 - mse: 56446.3594 - val_loss: 3.9164 - val_mse: 54.8603 - 281ms/epoch - 5ms/step\n",
            "Epoch 199/400\n",
            "57/57 - 0s - loss: 72.0900 - mse: 49569.3281 - val_loss: 3.8358 - val_mse: 52.8430 - 289ms/epoch - 5ms/step\n",
            "Epoch 200/400\n",
            "57/57 - 0s - loss: 69.0438 - mse: 48302.0703 - val_loss: 3.8460 - val_mse: 53.0645 - 282ms/epoch - 5ms/step\n",
            "Epoch 201/400\n",
            "57/57 - 0s - loss: 71.7123 - mse: 53567.5547 - val_loss: 3.8906 - val_mse: 53.8800 - 280ms/epoch - 5ms/step\n",
            "Epoch 202/400\n",
            "57/57 - 0s - loss: 71.9304 - mse: 50830.8438 - val_loss: 3.9620 - val_mse: 55.7785 - 287ms/epoch - 5ms/step\n",
            "Epoch 203/400\n",
            "57/57 - 0s - loss: 70.9988 - mse: 49960.4844 - val_loss: 3.8627 - val_mse: 52.9275 - 285ms/epoch - 5ms/step\n",
            "Epoch 204/400\n",
            "57/57 - 0s - loss: 68.9822 - mse: 52973.8516 - val_loss: 4.1107 - val_mse: 60.5920 - 285ms/epoch - 5ms/step\n",
            "Epoch 205/400\n",
            "57/57 - 0s - loss: 71.2346 - mse: 49280.4219 - val_loss: 4.2156 - val_mse: 63.8630 - 280ms/epoch - 5ms/step\n",
            "Epoch 206/400\n",
            "57/57 - 0s - loss: 70.2920 - mse: 47113.3945 - val_loss: 4.2706 - val_mse: 65.8026 - 284ms/epoch - 5ms/step\n",
            "Epoch 207/400\n",
            "57/57 - 0s - loss: 69.4461 - mse: 45184.0000 - val_loss: 4.6636 - val_mse: 80.8252 - 278ms/epoch - 5ms/step\n",
            "Epoch 208/400\n",
            "57/57 - 0s - loss: 68.6087 - mse: 42814.4375 - val_loss: 4.7241 - val_mse: 83.7385 - 281ms/epoch - 5ms/step\n",
            "Epoch 209/400\n",
            "57/57 - 0s - loss: 69.7584 - mse: 47765.2812 - val_loss: 4.6588 - val_mse: 80.9001 - 286ms/epoch - 5ms/step\n",
            "Epoch 210/400\n",
            "57/57 - 0s - loss: 66.2852 - mse: 42763.7930 - val_loss: 4.7751 - val_mse: 86.4392 - 293ms/epoch - 5ms/step\n",
            "Epoch 211/400\n",
            "57/57 - 0s - loss: 70.8340 - mse: 53794.2812 - val_loss: 4.8946 - val_mse: 92.9643 - 291ms/epoch - 5ms/step\n",
            "Epoch 212/400\n",
            "57/57 - 0s - loss: 67.8563 - mse: 47714.5820 - val_loss: 4.7695 - val_mse: 87.7394 - 289ms/epoch - 5ms/step\n",
            "Epoch 213/400\n",
            "57/57 - 0s - loss: 71.2820 - mse: 54740.7227 - val_loss: 4.7429 - val_mse: 86.8270 - 290ms/epoch - 5ms/step\n",
            "Epoch 214/400\n",
            "57/57 - 0s - loss: 68.1657 - mse: 52496.5312 - val_loss: 4.6197 - val_mse: 81.6560 - 291ms/epoch - 5ms/step\n",
            "Epoch 215/400\n",
            "57/57 - 0s - loss: 67.7195 - mse: 52655.2578 - val_loss: 4.6125 - val_mse: 81.2707 - 297ms/epoch - 5ms/step\n",
            "Epoch 216/400\n",
            "57/57 - 0s - loss: 70.1394 - mse: 55727.6367 - val_loss: 4.5027 - val_mse: 76.6080 - 293ms/epoch - 5ms/step\n",
            "Epoch 217/400\n",
            "57/57 - 0s - loss: 70.3766 - mse: 50596.6445 - val_loss: 4.4776 - val_mse: 75.9217 - 292ms/epoch - 5ms/step\n",
            "Epoch 218/400\n",
            "57/57 - 0s - loss: 66.7956 - mse: 43884.1016 - val_loss: 4.5963 - val_mse: 80.8045 - 283ms/epoch - 5ms/step\n",
            "Epoch 219/400\n",
            "57/57 - 0s - loss: 68.4839 - mse: 47237.7578 - val_loss: 4.5890 - val_mse: 80.3415 - 296ms/epoch - 5ms/step\n",
            "Epoch 220/400\n",
            "57/57 - 0s - loss: 64.0817 - mse: 38816.7969 - val_loss: 4.4429 - val_mse: 73.8785 - 295ms/epoch - 5ms/step\n",
            "Epoch 221/400\n",
            "57/57 - 0s - loss: 67.5041 - mse: 50405.7305 - val_loss: 4.5747 - val_mse: 79.9694 - 289ms/epoch - 5ms/step\n",
            "Epoch 222/400\n",
            "57/57 - 0s - loss: 64.3800 - mse: 39475.1523 - val_loss: 4.4514 - val_mse: 74.8885 - 304ms/epoch - 5ms/step\n",
            "Epoch 223/400\n",
            "57/57 - 0s - loss: 66.7346 - mse: 43005.1523 - val_loss: 4.2954 - val_mse: 68.6629 - 292ms/epoch - 5ms/step\n",
            "Epoch 224/400\n",
            "57/57 - 0s - loss: 67.6309 - mse: 48807.5234 - val_loss: 4.3507 - val_mse: 70.6389 - 296ms/epoch - 5ms/step\n",
            "Epoch 225/400\n",
            "57/57 - 0s - loss: 66.5002 - mse: 47653.0039 - val_loss: 4.5699 - val_mse: 79.9201 - 293ms/epoch - 5ms/step\n",
            "Epoch 226/400\n",
            "57/57 - 0s - loss: 67.4689 - mse: 50163.1562 - val_loss: 4.5082 - val_mse: 77.1364 - 290ms/epoch - 5ms/step\n",
            "Epoch 227/400\n",
            "57/57 - 0s - loss: 63.8873 - mse: 39063.7031 - val_loss: 4.5170 - val_mse: 77.6706 - 306ms/epoch - 5ms/step\n",
            "Epoch 228/400\n",
            "57/57 - 0s - loss: 65.8672 - mse: 51798.0508 - val_loss: 4.4882 - val_mse: 76.7099 - 282ms/epoch - 5ms/step\n",
            "Epoch 229/400\n",
            "57/57 - 0s - loss: 64.6157 - mse: 42516.2344 - val_loss: 4.4932 - val_mse: 77.1732 - 291ms/epoch - 5ms/step\n",
            "\n",
            "****Iteration number 99 started****\n",
            "\n",
            "Epoch 1/100\n",
            "80/80 [==============================] - 2s 6ms/step - loss: 2629.3726 - mse: 63369748.0000 - val_loss: 87.6304 - val_mse: 40763.1250\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1739.0182 - mse: 27978288.0000 - val_loss: 24.4221 - val_mse: 3137.1345\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1460.6152 - mse: 20187818.0000 - val_loss: 16.7897 - val_mse: 1641.5016\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1229.4392 - mse: 14711548.0000 - val_loss: 27.5223 - val_mse: 4050.6509\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1027.2747 - mse: 10697659.0000 - val_loss: 15.0144 - val_mse: 1239.8088\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 905.4593 - mse: 7863691.5000 - val_loss: 1.9492 - val_mse: 21.8467\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 835.6451 - mse: 6480364.5000 - val_loss: 2.3164 - val_mse: 33.8378\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 719.2429 - mse: 4884797.0000 - val_loss: 0.5939 - val_mse: 2.0638\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 632.4498 - mse: 4118100.2500 - val_loss: 12.1829 - val_mse: 869.9237\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 552.0281 - mse: 3143938.2500 - val_loss: 0.3273 - val_mse: 0.6610\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 497.0067 - mse: 2468789.5000 - val_loss: 2.6832 - val_mse: 49.4721\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 434.5095 - mse: 2143526.5000 - val_loss: 2.5484 - val_mse: 31.6394\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 387.4444 - mse: 1624637.5000 - val_loss: 3.4515 - val_mse: 58.3349\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 320.2524 - mse: 963472.2500 - val_loss: 4.3342 - val_mse: 85.4148\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 289.6726 - mse: 801453.8750 - val_loss: 0.7419 - val_mse: 2.9691\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 247.3182 - mse: 591429.3125 - val_loss: 0.7085 - val_mse: 2.4449\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 213.0569 - mse: 464528.7812 - val_loss: 2.6114 - val_mse: 46.9281\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 198.2316 - mse: 382335.5000 - val_loss: 0.4031 - val_mse: 1.3803\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 171.4282 - mse: 317742.7188 - val_loss: 1.1635 - val_mse: 6.6834\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 146.3604 - mse: 207184.2031 - val_loss: 1.7597 - val_mse: 22.4398\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 131.0566 - mse: 165199.8438 - val_loss: 1.5102 - val_mse: 10.6940\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 115.1445 - mse: 139445.5469 - val_loss: 3.7448 - val_mse: 88.3726\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 102.9095 - mse: 112003.2188 - val_loss: 1.1908 - val_mse: 7.2099\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 83.5430 - mse: 64480.2148 - val_loss: 0.1077 - val_mse: 0.2255\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 73.5816 - mse: 53229.0078 - val_loss: 2.3082 - val_mse: 40.0745\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 62.8862 - mse: 43921.8203 - val_loss: 2.0870 - val_mse: 35.5625\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 53.5914 - mse: 28711.7305 - val_loss: 1.8641 - val_mse: 26.9804\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 46.5880 - mse: 24318.5742 - val_loss: 0.5480 - val_mse: 2.9659\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 38.8252 - mse: 15843.9580 - val_loss: 0.1402 - val_mse: 0.2863\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 33.6131 - mse: 13691.6846 - val_loss: 0.5010 - val_mse: 2.6803\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 28.5528 - mse: 10280.0449 - val_loss: 0.7972 - val_mse: 4.6987\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 23.8988 - mse: 7499.9766 - val_loss: 0.1367 - val_mse: 0.2918\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 18.7187 - mse: 4064.7358 - val_loss: 0.1031 - val_mse: 0.2317\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 15.2383 - mse: 2623.3777 - val_loss: 0.0900 - val_mse: 0.1958\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 12.5991 - mse: 1781.1091 - val_loss: 0.1268 - val_mse: 0.3133\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 11.3769 - mse: 1515.5759 - val_loss: 0.0592 - val_mse: 0.1185\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 8.6406 - mse: 942.4591 - val_loss: 0.0808 - val_mse: 0.1780\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 7.5828 - mse: 746.3198 - val_loss: 0.3074 - val_mse: 1.3353\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 6.0233 - mse: 502.3878 - val_loss: 0.4774 - val_mse: 2.4957\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.8762 - mse: 305.4055 - val_loss: 0.5022 - val_mse: 2.9643\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 3.8513 - mse: 208.6388 - val_loss: 0.0232 - val_mse: 0.0464\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 2.8663 - mse: 119.9623 - val_loss: 0.0246 - val_mse: 0.0493\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 2.2502 - mse: 83.6053 - val_loss: 0.0327 - val_mse: 0.0654\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1.5744 - mse: 35.7496 - val_loss: 0.0178 - val_mse: 0.0356\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 1.0908 - mse: 24.3412 - val_loss: 0.0232 - val_mse: 0.0498\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.6627 - mse: 9.5081 - val_loss: 0.0232 - val_mse: 0.0463\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2998 - mse: 2.1426 - val_loss: 0.0213 - val_mse: 0.0425\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1520 - mse: 0.9460 - val_loss: 0.0200 - val_mse: 0.0401\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0967 - mse: 0.3557 - val_loss: 0.0184 - val_mse: 0.0368\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0635 - mse: 0.1850 - val_loss: 0.0178 - val_mse: 0.0356\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0569 - mse: 0.1601 - val_loss: 0.0158 - val_mse: 0.0316\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.1100 - mse: 0.5654 - val_loss: 0.0297 - val_mse: 0.0601\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1265 - mse: 0.5813 - val_loss: 0.0151 - val_mse: 0.0303\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0789 - mse: 0.2833 - val_loss: 0.0244 - val_mse: 0.0488\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0803 - mse: 0.2882 - val_loss: 0.0189 - val_mse: 0.0377\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0855 - mse: 0.3221 - val_loss: 0.0130 - val_mse: 0.0259\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.1267 - mse: 0.6405 - val_loss: 0.0131 - val_mse: 0.0263\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.1124 - mse: 0.5280 - val_loss: 0.0154 - val_mse: 0.0307\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0915 - mse: 0.4004 - val_loss: 0.0154 - val_mse: 0.0308\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0742 - mse: 0.3150 - val_loss: 0.0104 - val_mse: 0.0208\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0755 - mse: 0.2996 - val_loss: 0.0135 - val_mse: 0.0270\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0546 - mse: 0.2165 - val_loss: 0.0177 - val_mse: 0.0355\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.1053 - mse: 0.4163 - val_loss: 0.0102 - val_mse: 0.0205\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0483 - mse: 0.1387 - val_loss: 0.0089 - val_mse: 0.0178\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0918 - mse: 0.3781 - val_loss: 0.0090 - val_mse: 0.0179\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1273 - mse: 0.8752 - val_loss: 0.0091 - val_mse: 0.0182\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1084 - mse: 0.5996 - val_loss: 0.0089 - val_mse: 0.0177\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1134 - mse: 0.5389 - val_loss: 0.0076 - val_mse: 0.0153\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0461 - mse: 0.1452 - val_loss: 0.0094 - val_mse: 0.0188\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0630 - mse: 0.2108 - val_loss: 0.0085 - val_mse: 0.0169\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0442 - mse: 0.1517 - val_loss: 0.0077 - val_mse: 0.0155\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0357 - mse: 0.1147 - val_loss: 0.0059 - val_mse: 0.0118\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0899 - mse: 0.3816 - val_loss: 0.0083 - val_mse: 0.0166\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0634 - mse: 0.2481 - val_loss: 0.0062 - val_mse: 0.0123\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0598 - mse: 0.2246 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0896 - mse: 0.4263 - val_loss: 0.0070 - val_mse: 0.0140\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0545 - mse: 0.2135 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0491 - val_loss: 0.0059 - val_mse: 0.0117\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0404 - mse: 0.1278 - val_loss: 0.0055 - val_mse: 0.0111\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0885 - mse: 0.5010 - val_loss: 0.0062 - val_mse: 0.0124\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0678 - mse: 0.2720 - val_loss: 0.0072 - val_mse: 0.0144\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0782 - mse: 0.3867 - val_loss: 0.0061 - val_mse: 0.0123\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0416 - mse: 0.1278 - val_loss: 0.0055 - val_mse: 0.0109\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0347 - mse: 0.1134 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0446 - mse: 0.1434 - val_loss: 0.0052 - val_mse: 0.0105\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0283 - mse: 0.0795 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1058 - mse: 0.5132 - val_loss: 0.0047 - val_mse: 0.0095\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0783 - mse: 0.3535 - val_loss: 0.0065 - val_mse: 0.0129\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0342 - mse: 0.1044 - val_loss: 0.0047 - val_mse: 0.0094\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1177 - mse: 0.7645 - val_loss: 0.0038 - val_mse: 0.0076\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0795 - mse: 0.3574 - val_loss: 0.0050 - val_mse: 0.0099\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0565 - mse: 0.2131 - val_loss: 0.0098 - val_mse: 0.0195\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0573 - mse: 0.2335 - val_loss: 0.0053 - val_mse: 0.0106\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0722 - mse: 0.3429 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0587 - mse: 0.2257 - val_loss: 0.0043 - val_mse: 0.0086\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0389 - mse: 0.1174 - val_loss: 0.0049 - val_mse: 0.0097\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0320 - mse: 0.1003 - val_loss: 0.0043 - val_mse: 0.0085\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0498 - mse: 0.2060 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0693 - mse: 0.3173 - val_loss: 0.0045 - val_mse: 0.0090\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0366 - mse: 0.1099 - val_loss: 0.0061 - val_mse: 0.0121\n",
            "Epoch 101/400\n",
            "80/80 - 0s - loss: 0.0940 - mse: 0.6764 - val_loss: 0.0042 - val_mse: 0.0085 - 365ms/epoch - 5ms/step\n",
            "Epoch 102/400\n",
            "80/80 - 0s - loss: 0.0866 - mse: 0.4562 - val_loss: 0.0035 - val_mse: 0.0070 - 306ms/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "80/80 - 0s - loss: 0.0435 - mse: 0.1478 - val_loss: 0.0115 - val_mse: 0.0229 - 303ms/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "80/80 - 0s - loss: 0.0679 - mse: 0.2801 - val_loss: 0.0039 - val_mse: 0.0078 - 306ms/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "80/80 - 0s - loss: 0.0126 - mse: 0.0271 - val_loss: 0.0053 - val_mse: 0.0106 - 309ms/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "80/80 - 0s - loss: 0.0598 - mse: 0.3143 - val_loss: 0.0041 - val_mse: 0.0081 - 315ms/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "80/80 - 0s - loss: 0.1322 - mse: 0.6893 - val_loss: 0.0035 - val_mse: 0.0069 - 309ms/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "80/80 - 0s - loss: 0.0366 - mse: 0.1173 - val_loss: 0.0040 - val_mse: 0.0080 - 312ms/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "80/80 - 0s - loss: 0.0474 - mse: 0.1835 - val_loss: 0.0055 - val_mse: 0.0109 - 318ms/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "80/80 - 0s - loss: 0.0561 - mse: 0.2163 - val_loss: 0.0036 - val_mse: 0.0072 - 313ms/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "80/80 - 0s - loss: 0.0499 - mse: 0.1759 - val_loss: 0.0048 - val_mse: 0.0096 - 309ms/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "80/80 - 0s - loss: 0.0437 - mse: 0.1533 - val_loss: 0.0047 - val_mse: 0.0094 - 303ms/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "80/80 - 0s - loss: 0.0267 - mse: 0.0760 - val_loss: 0.0044 - val_mse: 0.0088 - 314ms/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "80/80 - 0s - loss: 0.0240 - mse: 0.0615 - val_loss: 0.0033 - val_mse: 0.0066 - 311ms/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "80/80 - 0s - loss: 0.0566 - mse: 0.2744 - val_loss: 0.0040 - val_mse: 0.0080 - 309ms/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "80/80 - 0s - loss: 0.0467 - mse: 0.1989 - val_loss: 0.0051 - val_mse: 0.0102 - 307ms/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "80/80 - 0s - loss: 0.0326 - mse: 0.1049 - val_loss: 0.0045 - val_mse: 0.0090 - 298ms/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "80/80 - 0s - loss: 0.0276 - mse: 0.0982 - val_loss: 0.0033 - val_mse: 0.0065 - 301ms/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "80/80 - 0s - loss: 0.0529 - mse: 0.2037 - val_loss: 0.0043 - val_mse: 0.0087 - 306ms/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "80/80 - 0s - loss: 0.0493 - mse: 0.1865 - val_loss: 0.0056 - val_mse: 0.0112 - 310ms/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "80/80 - 0s - loss: 0.0383 - mse: 0.1132 - val_loss: 0.0032 - val_mse: 0.0063 - 306ms/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "80/80 - 0s - loss: 0.0492 - mse: 0.1694 - val_loss: 0.0041 - val_mse: 0.0083 - 297ms/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "80/80 - 0s - loss: 0.0276 - mse: 0.0767 - val_loss: 0.0032 - val_mse: 0.0064 - 305ms/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "80/80 - 0s - loss: 0.0281 - mse: 0.0845 - val_loss: 0.0034 - val_mse: 0.0067 - 297ms/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "80/80 - 0s - loss: 0.0304 - mse: 0.0962 - val_loss: 0.0032 - val_mse: 0.0064 - 305ms/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "80/80 - 0s - loss: 0.0659 - mse: 0.3006 - val_loss: 0.0032 - val_mse: 0.0064 - 304ms/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "80/80 - 0s - loss: 0.0386 - mse: 0.1375 - val_loss: 0.0041 - val_mse: 0.0082 - 305ms/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "80/80 - 0s - loss: 0.0162 - mse: 0.0390 - val_loss: 0.0051 - val_mse: 0.0103 - 305ms/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "80/80 - 0s - loss: 0.0189 - mse: 0.0563 - val_loss: 0.0031 - val_mse: 0.0062 - 312ms/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "80/80 - 0s - loss: 0.0182 - mse: 0.0490 - val_loss: 0.0034 - val_mse: 0.0068 - 305ms/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "80/80 - 0s - loss: 0.0164 - mse: 0.0447 - val_loss: 0.0037 - val_mse: 0.0075 - 299ms/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "80/80 - 0s - loss: 0.0212 - mse: 0.0638 - val_loss: 0.0043 - val_mse: 0.0086 - 311ms/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "80/80 - 0s - loss: 0.0424 - mse: 0.1439 - val_loss: 0.0037 - val_mse: 0.0073 - 321ms/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "80/80 - 0s - loss: 0.0229 - mse: 0.0633 - val_loss: 0.0037 - val_mse: 0.0074 - 313ms/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "80/80 - 0s - loss: 0.0293 - mse: 0.0957 - val_loss: 0.0035 - val_mse: 0.0070 - 311ms/epoch - 4ms/step\n",
            "Epoch 136/400\n",
            "80/80 - 0s - loss: 0.0135 - mse: 0.0313 - val_loss: 0.0033 - val_mse: 0.0066 - 322ms/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "80/80 - 0s - loss: 0.0166 - mse: 0.0417 - val_loss: 0.0035 - val_mse: 0.0070 - 312ms/epoch - 4ms/step\n",
            "Epoch 138/400\n",
            "80/80 - 0s - loss: 0.0356 - mse: 0.1034 - val_loss: 0.0027 - val_mse: 0.0055 - 315ms/epoch - 4ms/step\n",
            "Epoch 139/400\n",
            "80/80 - 0s - loss: 0.0538 - mse: 0.2171 - val_loss: 0.0044 - val_mse: 0.0087 - 321ms/epoch - 4ms/step\n",
            "Epoch 140/400\n",
            "80/80 - 0s - loss: 0.0184 - mse: 0.0532 - val_loss: 0.0045 - val_mse: 0.0090 - 326ms/epoch - 4ms/step\n",
            "Epoch 141/400\n",
            "80/80 - 0s - loss: 0.0280 - mse: 0.1091 - val_loss: 0.0033 - val_mse: 0.0065 - 303ms/epoch - 4ms/step\n",
            "Epoch 142/400\n",
            "80/80 - 0s - loss: 0.0227 - mse: 0.0626 - val_loss: 0.0029 - val_mse: 0.0058 - 306ms/epoch - 4ms/step\n",
            "Epoch 143/400\n",
            "80/80 - 0s - loss: 0.0346 - mse: 0.1158 - val_loss: 0.0034 - val_mse: 0.0069 - 306ms/epoch - 4ms/step\n",
            "Epoch 144/400\n",
            "80/80 - 0s - loss: 0.0212 - mse: 0.0593 - val_loss: 0.0033 - val_mse: 0.0067 - 315ms/epoch - 4ms/step\n",
            "Epoch 145/400\n",
            "80/80 - 0s - loss: 0.0265 - mse: 0.0728 - val_loss: 0.0039 - val_mse: 0.0079 - 314ms/epoch - 4ms/step\n",
            "Epoch 146/400\n",
            "80/80 - 0s - loss: 0.0249 - mse: 0.0663 - val_loss: 0.0034 - val_mse: 0.0069 - 303ms/epoch - 4ms/step\n",
            "Epoch 147/400\n",
            "80/80 - 0s - loss: 0.0113 - mse: 0.0239 - val_loss: 0.0035 - val_mse: 0.0070 - 299ms/epoch - 4ms/step\n",
            "Epoch 148/400\n",
            "80/80 - 0s - loss: 0.0178 - mse: 0.0470 - val_loss: 0.0027 - val_mse: 0.0054 - 314ms/epoch - 4ms/step\n",
            "Epoch 149/400\n",
            "80/80 - 0s - loss: 0.0155 - mse: 0.0398 - val_loss: 0.0039 - val_mse: 0.0079 - 307ms/epoch - 4ms/step\n",
            "Epoch 150/400\n",
            "80/80 - 0s - loss: 0.0111 - mse: 0.0256 - val_loss: 0.0029 - val_mse: 0.0058 - 300ms/epoch - 4ms/step\n",
            "Epoch 151/400\n",
            "80/80 - 0s - loss: 0.0150 - mse: 0.0391 - val_loss: 0.0036 - val_mse: 0.0073 - 299ms/epoch - 4ms/step\n",
            "Epoch 152/400\n",
            "80/80 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0034 - val_mse: 0.0068 - 302ms/epoch - 4ms/step\n",
            "Epoch 153/400\n",
            "80/80 - 0s - loss: 0.0138 - mse: 0.0363 - val_loss: 0.0028 - val_mse: 0.0056 - 302ms/epoch - 4ms/step\n",
            "Epoch 154/400\n",
            "80/80 - 0s - loss: 0.0376 - mse: 0.1373 - val_loss: 0.0030 - val_mse: 0.0061 - 308ms/epoch - 4ms/step\n",
            "Epoch 155/400\n",
            "80/80 - 0s - loss: 0.0128 - mse: 0.0299 - val_loss: 0.0039 - val_mse: 0.0078 - 306ms/epoch - 4ms/step\n",
            "Epoch 156/400\n",
            "80/80 - 0s - loss: 0.0186 - mse: 0.0496 - val_loss: 0.0032 - val_mse: 0.0064 - 302ms/epoch - 4ms/step\n",
            "Epoch 157/400\n",
            "80/80 - 0s - loss: 0.0409 - mse: 0.1572 - val_loss: 0.0033 - val_mse: 0.0066 - 295ms/epoch - 4ms/step\n",
            "Epoch 158/400\n",
            "80/80 - 0s - loss: 0.0126 - mse: 0.0276 - val_loss: 0.0030 - val_mse: 0.0061 - 309ms/epoch - 4ms/step\n",
            "Epoch 159/400\n",
            "80/80 - 0s - loss: 0.0077 - mse: 0.0165 - val_loss: 0.0029 - val_mse: 0.0059 - 306ms/epoch - 4ms/step\n",
            "Epoch 160/400\n",
            "80/80 - 0s - loss: 0.0070 - mse: 0.0142 - val_loss: 0.0032 - val_mse: 0.0065 - 301ms/epoch - 4ms/step\n",
            "Epoch 161/400\n",
            "80/80 - 0s - loss: 0.0051 - mse: 0.0102 - val_loss: 0.0033 - val_mse: 0.0067 - 297ms/epoch - 4ms/step\n",
            "Epoch 162/400\n",
            "80/80 - 0s - loss: 0.0049 - mse: 0.0097 - val_loss: 0.0035 - val_mse: 0.0070 - 307ms/epoch - 4ms/step\n",
            "Epoch 163/400\n",
            "80/80 - 0s - loss: 0.0109 - mse: 0.0260 - val_loss: 0.0028 - val_mse: 0.0056 - 297ms/epoch - 4ms/step\n",
            "Epoch 164/400\n",
            "80/80 - 0s - loss: 0.0064 - mse: 0.0130 - val_loss: 0.0030 - val_mse: 0.0060 - 301ms/epoch - 4ms/step\n",
            "Epoch 165/400\n",
            "80/80 - 0s - loss: 0.0053 - mse: 0.0108 - val_loss: 0.0030 - val_mse: 0.0060 - 306ms/epoch - 4ms/step\n",
            "Epoch 166/400\n",
            "80/80 - 0s - loss: 0.0130 - mse: 0.0319 - val_loss: 0.0031 - val_mse: 0.0061 - 311ms/epoch - 4ms/step\n",
            "Epoch 167/400\n",
            "80/80 - 0s - loss: 0.0287 - mse: 0.0916 - val_loss: 0.0038 - val_mse: 0.0076 - 306ms/epoch - 4ms/step\n",
            "Epoch 168/400\n",
            "80/80 - 0s - loss: 0.0082 - mse: 0.0173 - val_loss: 0.0032 - val_mse: 0.0064 - 309ms/epoch - 4ms/step\n",
            "Epoch 169/400\n",
            "80/80 - 0s - loss: 0.0055 - mse: 0.0110 - val_loss: 0.0033 - val_mse: 0.0066 - 311ms/epoch - 4ms/step\n",
            "Epoch 170/400\n",
            "80/80 - 0s - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0028 - val_mse: 0.0057 - 308ms/epoch - 4ms/step\n",
            "Epoch 171/400\n",
            "80/80 - 0s - loss: 0.0059 - mse: 0.0120 - val_loss: 0.0030 - val_mse: 0.0060 - 316ms/epoch - 4ms/step\n",
            "Epoch 172/400\n",
            "80/80 - 0s - loss: 0.0051 - mse: 0.0102 - val_loss: 0.0031 - val_mse: 0.0062 - 303ms/epoch - 4ms/step\n",
            "Epoch 173/400\n",
            "80/80 - 0s - loss: 0.0046 - mse: 0.0093 - val_loss: 0.0030 - val_mse: 0.0059 - 313ms/epoch - 4ms/step\n",
            "Epoch 174/400\n",
            "80/80 - 0s - loss: 0.0049 - mse: 0.0098 - val_loss: 0.0029 - val_mse: 0.0058 - 315ms/epoch - 4ms/step\n",
            "Epoch 175/400\n",
            "80/80 - 0s - loss: 0.0102 - mse: 0.0237 - val_loss: 0.0027 - val_mse: 0.0055 - 334ms/epoch - 4ms/step\n",
            "Epoch 176/400\n",
            "80/80 - 0s - loss: 0.0080 - mse: 0.0167 - val_loss: 0.0032 - val_mse: 0.0064 - 328ms/epoch - 4ms/step\n",
            "Epoch 177/400\n",
            "80/80 - 0s - loss: 0.0048 - mse: 0.0097 - val_loss: 0.0029 - val_mse: 0.0057 - 320ms/epoch - 4ms/step\n",
            "Epoch 178/400\n",
            "80/80 - 0s - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0029 - val_mse: 0.0058 - 331ms/epoch - 4ms/step\n",
            "\n",
            "****Iteration number 100 started****\n",
            "\n",
            "Epoch 1/100\n",
            "39/39 [==============================] - 4s 11ms/step - loss: 265.6690 - mse: 1447167.6250 - val_loss: 0.6980 - val_mse: 2.2339\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.4281 - mse: 1351.9818 - val_loss: 0.1182 - val_mse: 0.2364\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.8457 - mse: 181.9741 - val_loss: 0.0481 - val_mse: 0.0962\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9475 - mse: 112.1148 - val_loss: 0.0119 - val_mse: 0.0238\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.5871 - mse: 45.5604 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.4752 - mse: 42.4449 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.4999 - mse: 145.3329 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.3396 - mse: 43.9545 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2175 - mse: 11.5413 - val_loss: 0.0084 - val_mse: 0.0168\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.3335 - mse: 39.8149 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2117 - mse: 11.7716 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0964 - mse: 2.2789 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1576 - mse: 10.2971 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0597 - mse: 0.8780 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0898 - mse: 10.8554 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0391 - mse: 0.3936 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0635 - mse: 1.1612 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0925 - mse: 7.9151 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0474 - mse: 1.0752 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0641 - mse: 2.0268 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0784 - mse: 9.5228 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0530 - mse: 1.4079 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0474 - mse: 1.9587 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0487 - mse: 3.6088 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0478 - mse: 1.6771 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0237 - mse: 0.1876 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0905 - mse: 19.2462 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0457 - mse: 1.5881 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0362 - mse: 1.9791 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0236 - mse: 0.2077 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0506 - mse: 8.7635 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0349 - mse: 0.9827 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0387 - mse: 1.7519 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0541 - mse: 9.0843 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0191 - mse: 0.2037 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0383 - mse: 2.6694 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0368 - mse: 1.0813 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0192 - mse: 0.1367 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0325 - mse: 0.8995 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0148 - mse: 0.1092 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0437 - mse: 3.2086 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0242 - mse: 0.5969 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0220 - mse: 1.1019 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0297 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0312 - mse: 1.8880 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1733 - mse: 187.4447 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0334 - mse: 3.4788 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0142 - mse: 0.0604 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0132 - mse: 0.0790 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0118 - mse: 0.0315 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0177 - mse: 0.1399 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0148 - mse: 0.0933 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0167 - mse: 0.2795 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0145 - mse: 0.1331 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0152 - mse: 0.1554 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0185 - mse: 0.2779 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0157 - mse: 0.1767 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0252 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0201 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0136 - mse: 0.0593 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0156 - mse: 0.1255 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0146 - mse: 0.1324 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0174 - mse: 0.4956 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0233 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0122 - mse: 0.0458 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0118 - mse: 0.0876 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0138 - mse: 0.0908 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0249 - mse: 1.4320 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0331 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0211 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0250 - mse: 2.0360 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0248 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0348 - mse: 3.4811 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0166 - mse: 0.3343 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0127 - mse: 0.0806 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0220 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0132 - mse: 0.1104 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0115 - mse: 0.0441 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0217 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0231 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0088 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0200 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0118 - mse: 0.0790 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0210 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0128 - mse: 0.1607 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0159 - mse: 0.4229 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0198 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0106 - mse: 0.0395 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167\n",
            "Epoch 101/400\n",
            "39/39 - 0s - loss: 0.0093 - mse: 0.0202 - val_loss: 0.0084 - val_mse: 0.0168 - 256ms/epoch - 7ms/step\n",
            "Epoch 102/400\n",
            "39/39 - 0s - loss: 0.0096 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 103/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 104/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 195ms/epoch - 5ms/step\n",
            "Epoch 105/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 106/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 197ms/epoch - 5ms/step\n",
            "Epoch 107/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 108/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 210ms/epoch - 5ms/step\n",
            "Epoch 109/400\n",
            "39/39 - 0s - loss: 0.0095 - mse: 0.0245 - val_loss: 0.0084 - val_mse: 0.0167 - 203ms/epoch - 5ms/step\n",
            "Epoch 110/400\n",
            "39/39 - 0s - loss: 0.0092 - mse: 0.0194 - val_loss: 0.0084 - val_mse: 0.0167 - 204ms/epoch - 5ms/step\n",
            "Epoch 111/400\n",
            "39/39 - 0s - loss: 0.0122 - mse: 0.1266 - val_loss: 0.0084 - val_mse: 0.0167 - 201ms/epoch - 5ms/step\n",
            "Epoch 112/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 113/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 114/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 115/400\n",
            "39/39 - 0s - loss: 0.0090 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 116/400\n",
            "39/39 - 0s - loss: 0.0117 - mse: 0.0536 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 117/400\n",
            "39/39 - 0s - loss: 0.0094 - mse: 0.0221 - val_loss: 0.0084 - val_mse: 0.0167 - 204ms/epoch - 5ms/step\n",
            "Epoch 118/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 203ms/epoch - 5ms/step\n",
            "Epoch 119/400\n",
            "39/39 - 0s - loss: 0.0093 - mse: 0.0220 - val_loss: 0.0084 - val_mse: 0.0167 - 201ms/epoch - 5ms/step\n",
            "Epoch 120/400\n",
            "39/39 - 0s - loss: 0.0092 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 195ms/epoch - 5ms/step\n",
            "Epoch 121/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 202ms/epoch - 5ms/step\n",
            "Epoch 122/400\n",
            "39/39 - 0s - loss: 0.0099 - mse: 0.0309 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 123/400\n",
            "39/39 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 5ms/step\n",
            "Epoch 124/400\n",
            "39/39 - 0s - loss: 0.0132 - mse: 0.1903 - val_loss: 0.0084 - val_mse: 0.0167 - 195ms/epoch - 5ms/step\n",
            "Epoch 125/400\n",
            "39/39 - 0s - loss: 0.0094 - mse: 0.0233 - val_loss: 0.0084 - val_mse: 0.0167 - 211ms/epoch - 5ms/step\n",
            "Epoch 126/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 204ms/epoch - 5ms/step\n",
            "Epoch 127/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 209ms/epoch - 5ms/step\n",
            "Epoch 128/400\n",
            "39/39 - 0s - loss: 0.0092 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167 - 207ms/epoch - 5ms/step\n",
            "Epoch 129/400\n",
            "39/39 - 0s - loss: 0.0091 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 204ms/epoch - 5ms/step\n",
            "Epoch 130/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 205ms/epoch - 5ms/step\n",
            "Epoch 131/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 205ms/epoch - 5ms/step\n",
            "Epoch 132/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 5ms/step\n",
            "Epoch 133/400\n",
            "39/39 - 0s - loss: 0.0104 - mse: 0.0446 - val_loss: 0.0084 - val_mse: 0.0167 - 202ms/epoch - 5ms/step\n",
            "Epoch 134/400\n",
            "39/39 - 0s - loss: 0.0093 - mse: 0.0199 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 135/400\n",
            "39/39 - 0s - loss: 0.0129 - mse: 0.1301 - val_loss: 0.0084 - val_mse: 0.0167 - 195ms/epoch - 5ms/step\n",
            "Epoch 136/400\n",
            "39/39 - 0s - loss: 0.0092 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 137/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 138/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 139/400\n",
            "39/39 - 0s - loss: 0.0090 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0168 - 208ms/epoch - 5ms/step\n",
            "Epoch 140/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 197ms/epoch - 5ms/step\n",
            "Epoch 141/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 197ms/epoch - 5ms/step\n",
            "Epoch 142/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 209ms/epoch - 5ms/step\n",
            "Epoch 143/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 5ms/step\n",
            "Epoch 144/400\n",
            "39/39 - 0s - loss: 0.0092 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 145/400\n",
            "39/39 - 0s - loss: 0.0090 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 203ms/epoch - 5ms/step\n",
            "Epoch 146/400\n",
            "39/39 - 0s - loss: 0.0090 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 206ms/epoch - 5ms/step\n",
            "Epoch 147/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 209ms/epoch - 5ms/step\n",
            "Epoch 148/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 5ms/step\n",
            "Epoch 149/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 215ms/epoch - 6ms/step\n",
            "Epoch 150/400\n",
            "39/39 - 0s - loss: 0.0102 - mse: 0.0293 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 6ms/step\n",
            "Epoch 151/400\n",
            "39/39 - 0s - loss: 0.0089 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 208ms/epoch - 5ms/step\n",
            "Epoch 152/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 207ms/epoch - 5ms/step\n",
            "Epoch 153/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 208ms/epoch - 5ms/step\n",
            "Epoch 154/400\n",
            "39/39 - 0s - loss: 0.0107 - mse: 0.0548 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 6ms/step\n",
            "Epoch 155/400\n",
            "39/39 - 0s - loss: 0.0102 - mse: 0.0346 - val_loss: 0.0084 - val_mse: 0.0167 - 204ms/epoch - 5ms/step\n",
            "Epoch 156/400\n",
            "39/39 - 0s - loss: 0.0136 - mse: 0.2081 - val_loss: 0.0084 - val_mse: 0.0167 - 207ms/epoch - 5ms/step\n",
            "Epoch 157/400\n",
            "39/39 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 5ms/step\n",
            "Epoch 158/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 206ms/epoch - 5ms/step\n",
            "Epoch 159/400\n",
            "39/39 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168 - 207ms/epoch - 5ms/step\n",
            "Epoch 160/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 161/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 5ms/step\n",
            "Epoch 162/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 5ms/step\n",
            "Epoch 163/400\n",
            "39/39 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 193ms/epoch - 5ms/step\n",
            "Epoch 164/400\n",
            "39/39 - 0s - loss: 0.0106 - mse: 0.0538 - val_loss: 0.0084 - val_mse: 0.0168 - 198ms/epoch - 5ms/step\n",
            "Epoch 165/400\n",
            "39/39 - 0s - loss: 0.0196 - mse: 1.0166 - val_loss: 0.0084 - val_mse: 0.0168 - 189ms/epoch - 5ms/step\n",
            "Epoch 166/400\n",
            "39/39 - 0s - loss: 0.0115 - mse: 0.0879 - val_loss: 0.0084 - val_mse: 0.0167 - 194ms/epoch - 5ms/step\n",
            "Epoch 167/400\n",
            "39/39 - 0s - loss: 0.0093 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167 - 198ms/epoch - 5ms/step\n",
            "Epoch 168/400\n",
            "39/39 - 0s - loss: 0.0093 - mse: 0.0213 - val_loss: 0.0084 - val_mse: 0.0168 - 199ms/epoch - 5ms/step\n",
            "Epoch 169/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 202ms/epoch - 5ms/step\n",
            "Epoch 170/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 203ms/epoch - 5ms/step\n",
            "Epoch 171/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 196ms/epoch - 5ms/step\n",
            "Epoch 172/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 200ms/epoch - 5ms/step\n",
            "Epoch 173/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 197ms/epoch - 5ms/step\n",
            "Epoch 174/400\n",
            "39/39 - 0s - loss: 0.0091 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 199ms/epoch - 5ms/step\n",
            "Epoch 175/400\n",
            "39/39 - 0s - loss: 0.0096 - mse: 0.0254 - val_loss: 0.0084 - val_mse: 0.0168 - 195ms/epoch - 5ms/step\n",
            "Epoch 176/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 202ms/epoch - 5ms/step\n",
            "Epoch 177/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 206ms/epoch - 5ms/step\n",
            "Epoch 178/400\n",
            "39/39 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 203ms/epoch - 5ms/step\n",
            "Epoch 179/400\n",
            "39/39 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 201ms/epoch - 5ms/step\n",
            "Epoch 180/400\n",
            "39/39 - 0s - loss: 0.0113 - mse: 0.0808 - val_loss: 0.0084 - val_mse: 0.0167 - 209ms/epoch - 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train SVR - from random samples\n",
        "    # models: 25% learning curve - final_val_loss\n",
        "#-----------------------------------------------------------\n",
        "    # Create a sampler\n",
        "sampler = Lhs(lhs_type=\"classic\", criterion=None)\n",
        "    # Sample \"n_samples\" points from the search space\n",
        "samples = sampler.generate(space, n_samples=100)\n",
        "    # Convert samples to list of dictionaries\n",
        "random_datasets = [{dim.name: sample[i] for i, dim in enumerate(space)} for sample in samples]\n",
        "    # Initialize the lists to store the results\n",
        "val_losses_25pct = []\n",
        "final_val_losses = []\n",
        "\n",
        "iters = 0\n",
        "    # Train each model and record the results\n",
        "for params in random_datasets:\n",
        "        # Create and compile the model\n",
        "    number_of_layers = params['number_of_layers']\n",
        "    layer_nodes = [params[f'layer_{i+1}_nodes'] for i in range(number_of_layers)]\n",
        "\n",
        "    f_g_net = SumNet(\n",
        "        layer_nodes=layer_nodes,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        activation=params['activation'],\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        optimizer=params['optimizer'],\n",
        "        loss_function=params['loss_function']\n",
        "    )\n",
        "\n",
        "    print(\"\\n****Iteration number {} started****\\n\".format(iters+1))\n",
        "\n",
        "    iters=iters+1\n",
        "        # Train the model\n",
        "    history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                        epochs=int(params['epochs']*0.25),\n",
        "                        batch_size=params['batch_size'],\n",
        "                        validation_data=(input_data_val, y_val), verbose=1)\n",
        "\n",
        "        # Record the 25% val_loss\n",
        "    val_losses_25pct.append(history.history['val_loss'])\n",
        "\n",
        "    # Continue training to 100%\n",
        "    history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                        epochs=params['epochs'],\n",
        "                        batch_size=params['batch_size'],\n",
        "                        validation_data=(input_data_val, y_val),\n",
        "                        verbose=2, callbacks=[early_stopping],\n",
        "                        initial_epoch=int(params['epochs']*0.25))\n",
        "\n",
        "    # Record the final val_loss\n",
        "    final_val_losses.append(history.history['val_loss'][-1])\n",
        "\n",
        "# Train the NuSVR model\n",
        "Learning_Curve_train = np.array(val_losses_25pct)\n",
        "Model_Performance_train = np.array(final_val_losses)\n",
        "\n",
        "estimator = pretrain_Estimator(\n",
        "    Learning_Curve_train,\n",
        "    Model_Performance_train)\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcPCoGr7SDUi"
      },
      "source": [
        "# 6. Define Objective Function\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tN781_I6SDb8"
      },
      "outputs": [],
      "source": [
        "# Function: Objective Function\n",
        "from joblib import load\n",
        "estimator = load('estimator.joblib')\n",
        "#-----------------------------------------------------------\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    # User Input for Performance estimation\n",
        "    threshold=0.00015\n",
        "    epoch_rate=0.25 # When the model to be estimated\n",
        "    #-------------------------------------------------------\n",
        "\n",
        "    number_of_layers = params['number_of_layers']\n",
        "    layer_nodes = [params[f'layer_{i+1}_nodes'] for i in range(number_of_layers)]\n",
        "\n",
        "    f_g_net = SumNet(\n",
        "        layer_nodes=layer_nodes,\n",
        "        learning_rate=params['learning_rate'],\n",
        "        activation=params['activation'],\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        optimizer=params['optimizer'],\n",
        "        loss_function=params['loss_function']\n",
        "    )\n",
        "\n",
        "    # Print the model structure\n",
        "    print_model(params, layer_nodes)\n",
        "\n",
        "    val_mse = []\n",
        "    for epoch in range(params['epochs']):\n",
        "        history = f_g_net.model.fit(input_data_train, y_train,\n",
        "                            epochs=1,\n",
        "                            batch_size=params['batch_size'],\n",
        "                            validation_data=(input_data_val, y_val),\n",
        "                            callbacks=[early_stopping],verbose=2)\n",
        "        val_mse.append(history.history['val_mse'][-1])\n",
        "\n",
        "        if epoch == int(params['epochs'] * epoch_rate-1):\n",
        "            predicted_performance = predict_final_performance(val_mse, estimator)\n",
        "            print(\"\\nPredicted Performance: {}\\n\".format(predicted_performance))\n",
        "\n",
        "            # Plot actual vs. predicted learning curve\n",
        "            #show_plot(params, val_mse, epoch_rate, predicted_performance, toshow=False)\n",
        "\n",
        "            if predicted_performance >= threshold:\n",
        "                break\n",
        "\n",
        "    return val_mse[-1]\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIDSxiT2SEcZ"
      },
      "source": [
        "# 7. Run BOwGP\n",
        "\n",
        "---\n",
        "\n",
        "But each model's performance would be estimated by NuSVR,\n",
        "we've trained right before above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2TO8Q82SEkm",
        "outputId": "6f2ad3ea-4686-4636-e520-955bc243d0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "34/34 - 0s - loss: 190.6174 - mse: 359522.5938 - val_loss: 13.1033 - val_mse: 1148.0763 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 184.7071 - mse: 326572.7500 - val_loss: 10.3004 - val_mse: 678.5649 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 189.7172 - mse: 350701.0625 - val_loss: 7.6990 - val_mse: 374.1938 - 260ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 182.4484 - mse: 325432.3750 - val_loss: 5.6942 - val_mse: 182.0242 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 177.7415 - mse: 286712.4688 - val_loss: 4.7232 - val_mse: 87.9119 - 256ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 175.5967 - mse: 263031.8750 - val_loss: 4.9552 - val_mse: 80.1354 - 255ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 180.9464 - mse: 334171.5000 - val_loss: 6.4360 - val_mse: 134.2519 - 256ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 176.4232 - mse: 274029.0312 - val_loss: 8.1321 - val_mse: 203.9877 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 172.1022 - mse: 289180.7188 - val_loss: 9.8559 - val_mse: 309.4788 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 163.0312 - mse: 233435.7969 - val_loss: 12.0946 - val_mse: 510.9393 - 252ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 176.4444 - mse: 318497.5938 - val_loss: 13.9309 - val_mse: 736.5158 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 170.6597 - mse: 304960.5938 - val_loss: 15.2642 - val_mse: 925.4909 - 260ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 169.8094 - mse: 256139.6094 - val_loss: 15.7383 - val_mse: 995.0700 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 167.4252 - mse: 261947.0156 - val_loss: 15.9148 - val_mse: 1020.0262 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 165.2235 - mse: 261487.5156 - val_loss: 17.2253 - val_mse: 1194.4399 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 159.2258 - mse: 226354.7031 - val_loss: 19.4542 - val_mse: 1568.0038 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 174.0232 - mse: 314127.3438 - val_loss: 22.7841 - val_mse: 2303.7969 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 166.0956 - mse: 264825.7812 - val_loss: 23.7679 - val_mse: 2606.5415 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 161.7048 - mse: 253013.3906 - val_loss: 24.4668 - val_mse: 2919.7505 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 155.1420 - mse: 259144.1875 - val_loss: 24.0716 - val_mse: 2858.7529 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 155.2777 - mse: 213545.8906 - val_loss: 23.2871 - val_mse: 2678.0759 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 161.4069 - mse: 299821.4375 - val_loss: 23.9107 - val_mse: 2839.2458 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 160.5703 - mse: 248539.3125 - val_loss: 24.3790 - val_mse: 2981.6892 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 153.7759 - mse: 229909.3281 - val_loss: 23.2821 - val_mse: 2739.3030 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 157.6390 - mse: 253892.9844 - val_loss: 21.9500 - val_mse: 2443.9785 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 152.0911 - mse: 211845.1250 - val_loss: 22.3498 - val_mse: 2529.8953 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 152.4560 - mse: 211197.3438 - val_loss: 24.1358 - val_mse: 2969.2666 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 150.0968 - mse: 229350.5625 - val_loss: 23.9605 - val_mse: 2915.1716 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 144.1618 - mse: 206351.4531 - val_loss: 24.9925 - val_mse: 3148.6199 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 146.5802 - mse: 203656.2656 - val_loss: 25.4967 - val_mse: 3261.1843 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 144.3862 - mse: 195963.6562 - val_loss: 24.8512 - val_mse: 3130.4102 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 141.5487 - mse: 190370.7656 - val_loss: 24.5513 - val_mse: 3069.6382 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 147.3884 - mse: 212689.6250 - val_loss: 26.1792 - val_mse: 3467.1257 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 143.8368 - mse: 200620.0781 - val_loss: 25.1494 - val_mse: 3218.1846 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 148.4496 - mse: 236082.9688 - val_loss: 25.0509 - val_mse: 3192.7656 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 142.7722 - mse: 178783.8906 - val_loss: 24.8434 - val_mse: 3076.6521 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 145.0022 - mse: 203206.5781 - val_loss: 24.3078 - val_mse: 2818.0027 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 136.7205 - mse: 176006.5156 - val_loss: 25.6096 - val_mse: 3081.2542 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 141.3825 - mse: 199749.8125 - val_loss: 26.9508 - val_mse: 3348.6074 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 137.1411 - mse: 195770.8906 - val_loss: 26.6669 - val_mse: 3269.4507 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 133.7366 - mse: 165587.4844 - val_loss: 26.5511 - val_mse: 3241.0183 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 138.0119 - mse: 226044.7031 - val_loss: 27.5328 - val_mse: 3508.6113 - 255ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 134.2120 - mse: 187226.2188 - val_loss: 25.7859 - val_mse: 3060.1060 - 252ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 134.4134 - mse: 179855.9219 - val_loss: 26.9890 - val_mse: 3372.1130 - 254ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 131.1655 - mse: 173956.3281 - val_loss: 26.2348 - val_mse: 3203.8511 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 131.3047 - mse: 184197.9688 - val_loss: 25.5160 - val_mse: 3050.3027 - 261ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 127.4485 - mse: 148125.4688 - val_loss: 26.7180 - val_mse: 3355.7339 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 125.9488 - mse: 148327.1094 - val_loss: 27.2429 - val_mse: 3514.9910 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 127.7501 - mse: 182661.5938 - val_loss: 27.1115 - val_mse: 3498.8000 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 129.0690 - mse: 169669.6875 - val_loss: 27.9099 - val_mse: 3726.5046 - 252ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 131.5639 - mse: 187230.3125 - val_loss: 29.1093 - val_mse: 4073.6223 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 126.7357 - mse: 169009.7188 - val_loss: 29.1180 - val_mse: 4090.0762 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 128.2655 - mse: 227993.4688 - val_loss: 28.5464 - val_mse: 3938.1633 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 117.2794 - mse: 130461.8906 - val_loss: 29.7279 - val_mse: 4253.0776 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 120.8648 - mse: 140614.2188 - val_loss: 28.4976 - val_mse: 3938.2517 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 124.0799 - mse: 159593.7500 - val_loss: 28.7969 - val_mse: 3992.2329 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 117.0099 - mse: 130769.0859 - val_loss: 28.5230 - val_mse: 3913.2551 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 118.5493 - mse: 145296.7500 - val_loss: 28.1585 - val_mse: 3820.9958 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 118.3113 - mse: 132353.8594 - val_loss: 28.2479 - val_mse: 3870.7065 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 111.7083 - mse: 108740.3828 - val_loss: 28.8380 - val_mse: 4135.2964 - 239ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 168 ended. Search finished for the next optimal point.\n",
            "Time taken: 42.1119\n",
            "Function value obtained: 4135.2964\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 169 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [86, 126]\n",
            "Learning Rate: 5.486438594558241e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.18802990091818675\n",
            "Batch Size: 254\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 674.0386 - mse: 3819378.5000 - val_loss: 172.2219 - val_mse: 153389.8594 - 3s/epoch - 76ms/step\n",
            "34/34 - 0s - loss: 634.0618 - mse: 3743683.7500 - val_loss: 143.0341 - val_mse: 105928.8672 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 614.4998 - mse: 3216807.2500 - val_loss: 100.6691 - val_mse: 52771.2148 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 606.3356 - mse: 3330486.0000 - val_loss: 82.6129 - val_mse: 35425.7461 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 559.8309 - mse: 2670386.7500 - val_loss: 75.5746 - val_mse: 29679.0957 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 527.8622 - mse: 2473025.7500 - val_loss: 68.9337 - val_mse: 24786.7500 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 517.9795 - mse: 2310462.5000 - val_loss: 67.1826 - val_mse: 23560.2324 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 496.9566 - mse: 2085136.8750 - val_loss: 64.0730 - val_mse: 21447.2773 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 467.6328 - mse: 1851776.8750 - val_loss: 66.0322 - val_mse: 22752.1016 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 457.1060 - mse: 1815539.7500 - val_loss: 59.4609 - val_mse: 18461.3164 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 450.4062 - mse: 1836165.3750 - val_loss: 57.1157 - val_mse: 17034.4727 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 433.7892 - mse: 1604009.0000 - val_loss: 57.6135 - val_mse: 17413.6172 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 401.6318 - mse: 1616993.8750 - val_loss: 54.2302 - val_mse: 15534.8613 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 387.7891 - mse: 1342352.7500 - val_loss: 55.7688 - val_mse: 16478.3574 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 375.2282 - mse: 1278973.5000 - val_loss: 49.1941 - val_mse: 12897.1240 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 355.9118 - mse: 1129387.5000 - val_loss: 43.9674 - val_mse: 10354.1875 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 354.7040 - mse: 1191639.7500 - val_loss: 39.7230 - val_mse: 8514.3115 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 329.1352 - mse: 993417.0625 - val_loss: 36.1618 - val_mse: 7130.5859 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 327.4450 - mse: 1098861.7500 - val_loss: 31.2243 - val_mse: 5362.3560 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 309.5631 - mse: 995991.1875 - val_loss: 28.5819 - val_mse: 4506.2861 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 298.7506 - mse: 851058.3750 - val_loss: 27.9672 - val_mse: 4373.2905 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 292.1465 - mse: 780870.9375 - val_loss: 24.6917 - val_mse: 3476.3682 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 287.0802 - mse: 742819.5625 - val_loss: 20.4478 - val_mse: 2512.5220 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 295.9108 - mse: 861560.6250 - val_loss: 16.7876 - val_mse: 1690.0118 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 279.5785 - mse: 753260.1250 - val_loss: 14.7555 - val_mse: 1232.8156 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 272.6596 - mse: 733660.7500 - val_loss: 13.9207 - val_mse: 1047.2264 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 263.1432 - mse: 712931.3750 - val_loss: 14.2838 - val_mse: 1114.8645 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 263.6205 - mse: 650265.5000 - val_loss: 14.3840 - val_mse: 1272.9634 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 258.6613 - mse: 684684.1250 - val_loss: 11.7206 - val_mse: 891.2055 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 257.1470 - mse: 646382.1250 - val_loss: 8.7199 - val_mse: 446.4735 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 250.7905 - mse: 592619.3125 - val_loss: 6.9869 - val_mse: 231.5932 - 216ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 261.8755 - mse: 671845.5000 - val_loss: 11.5414 - val_mse: 755.7477 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 266.0588 - mse: 852345.1250 - val_loss: 9.5116 - val_mse: 539.0418 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 246.1482 - mse: 618471.8750 - val_loss: 8.2418 - val_mse: 472.6345 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 244.5706 - mse: 604433.5000 - val_loss: 6.1671 - val_mse: 353.1451 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 239.2742 - mse: 531087.0625 - val_loss: 3.4345 - val_mse: 139.5442 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 243.3581 - mse: 618862.8125 - val_loss: 2.3491 - val_mse: 64.6816 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 241.8864 - mse: 567478.5625 - val_loss: 1.6571 - val_mse: 9.8971 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 238.9625 - mse: 606902.1250 - val_loss: 1.6867 - val_mse: 10.0844 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 242.7878 - mse: 592966.6250 - val_loss: 3.1333 - val_mse: 31.8362 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 241.3358 - mse: 699290.4375 - val_loss: 4.1089 - val_mse: 60.5082 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 236.0740 - mse: 676626.6250 - val_loss: 6.9179 - val_mse: 202.2613 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 248.6710 - mse: 691209.4375 - val_loss: 9.7386 - val_mse: 426.5338 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 242.1867 - mse: 592743.6250 - val_loss: 10.0752 - val_mse: 462.9267 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 235.9730 - mse: 535856.3750 - val_loss: 9.8914 - val_mse: 447.1335 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 234.2588 - mse: 548026.8750 - val_loss: 10.7894 - val_mse: 497.4447 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 237.7970 - mse: 562493.6875 - val_loss: 11.1633 - val_mse: 532.2535 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 231.7581 - mse: 549085.5625 - val_loss: 13.2457 - val_mse: 847.3265 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 226.5015 - mse: 496129.5625 - val_loss: 9.7109 - val_mse: 398.7978 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 227.4301 - mse: 535190.4375 - val_loss: 8.7765 - val_mse: 330.4961 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 229.0593 - mse: 483808.8125 - val_loss: 7.4898 - val_mse: 248.8501 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 227.1144 - mse: 511716.8125 - val_loss: 5.8603 - val_mse: 169.7190 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 225.2840 - mse: 479349.0625 - val_loss: 6.5168 - val_mse: 206.3050 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 226.7027 - mse: 474312.5625 - val_loss: 7.3681 - val_mse: 268.0168 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 235.3129 - mse: 593925.6250 - val_loss: 8.2202 - val_mse: 326.4450 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 233.2321 - mse: 650837.5625 - val_loss: 8.6008 - val_mse: 323.3238 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 227.0000 - mse: 524504.6250 - val_loss: 8.7972 - val_mse: 344.9175 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 218.4780 - mse: 454210.5000 - val_loss: 7.4501 - val_mse: 284.9473 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 218.6946 - mse: 507190.2188 - val_loss: 7.3902 - val_mse: 277.3245 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 220.8698 - mse: 453069.0625 - val_loss: 7.6921 - val_mse: 290.4642 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 222.6199 - mse: 594079.5000 - val_loss: 9.2360 - val_mse: 434.2198 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 213.1539 - mse: 468512.2500 - val_loss: 7.8245 - val_mse: 312.7585 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 216.3132 - mse: 466392.4062 - val_loss: 7.3494 - val_mse: 278.3425 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 214.3234 - mse: 437496.9688 - val_loss: 8.7652 - val_mse: 361.9286 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 211.8921 - mse: 421094.5000 - val_loss: 7.8643 - val_mse: 316.6898 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 218.8552 - mse: 495491.6562 - val_loss: 7.8754 - val_mse: 310.9882 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 210.2586 - mse: 386529.8125 - val_loss: 7.5312 - val_mse: 247.8053 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 213.0587 - mse: 466827.6562 - val_loss: 7.1797 - val_mse: 229.0639 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 209.0108 - mse: 424074.0625 - val_loss: 7.9548 - val_mse: 270.9353 - 217ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 215.2703 - mse: 462654.9688 - val_loss: 8.1098 - val_mse: 280.9046 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 208.4262 - mse: 424716.4375 - val_loss: 7.4589 - val_mse: 275.3460 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 209.4578 - mse: 422853.6562 - val_loss: 6.8564 - val_mse: 223.9001 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 212.5495 - mse: 496922.2500 - val_loss: 6.4876 - val_mse: 201.3036 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 203.8105 - mse: 424778.8750 - val_loss: 6.7100 - val_mse: 215.9934 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 207.7305 - mse: 411869.0938 - val_loss: 5.0417 - val_mse: 123.0099 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 209.5596 - mse: 420090.3750 - val_loss: 4.4870 - val_mse: 98.3826 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 208.1892 - mse: 449889.8438 - val_loss: 3.8310 - val_mse: 71.3936 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 209.0304 - mse: 497819.6250 - val_loss: 4.3279 - val_mse: 91.2014 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 209.7049 - mse: 460808.8125 - val_loss: 6.4089 - val_mse: 196.6161 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 199.8148 - mse: 424791.0312 - val_loss: 5.7757 - val_mse: 159.0212 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 203.7620 - mse: 379825.5625 - val_loss: 4.5733 - val_mse: 99.7236 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 196.9230 - mse: 394317.1875 - val_loss: 5.2632 - val_mse: 135.8158 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 195.9771 - mse: 337287.3125 - val_loss: 6.3731 - val_mse: 194.4076 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 200.8076 - mse: 398754.3438 - val_loss: 6.5459 - val_mse: 215.4000 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 196.6379 - mse: 366820.6250 - val_loss: 6.9836 - val_mse: 239.3630 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 201.3838 - mse: 369609.9062 - val_loss: 5.4204 - val_mse: 138.3339 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 192.5934 - mse: 344006.7812 - val_loss: 4.3653 - val_mse: 92.6764 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 196.4987 - mse: 389870.2188 - val_loss: 3.9630 - val_mse: 76.3416 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 191.7151 - mse: 341718.3438 - val_loss: 4.2490 - val_mse: 84.3231 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 194.2277 - mse: 354611.4375 - val_loss: 3.7863 - val_mse: 65.7625 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 191.8168 - mse: 352349.4062 - val_loss: 3.1021 - val_mse: 45.4334 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 193.4469 - mse: 382966.5938 - val_loss: 1.5295 - val_mse: 10.8672 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 190.9719 - mse: 329342.5312 - val_loss: 2.6844 - val_mse: 34.1377 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 183.8753 - mse: 317658.9688 - val_loss: 2.9366 - val_mse: 41.5126 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 191.5831 - mse: 369061.0312 - val_loss: 3.3239 - val_mse: 53.5838 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 192.2343 - mse: 337053.8750 - val_loss: 3.2279 - val_mse: 50.5839 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 188.6171 - mse: 345490.2500 - val_loss: 4.4959 - val_mse: 94.0728 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 185.3243 - mse: 324839.7500 - val_loss: 5.7179 - val_mse: 160.7472 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 199.9305 - mse: 424278.3750 - val_loss: 6.0776 - val_mse: 172.9852 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 191.7667 - mse: 398467.6250 - val_loss: 5.2146 - val_mse: 127.8924 - 227ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 169 ended. Search finished for the next optimal point.\n",
            "Time taken: 37.8298\n",
            "Function value obtained: 127.8924\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 170 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [40, 125]\n",
            "Learning Rate: 5.715075927950088e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.13991406328686606\n",
            "Batch Size: 255\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 621.7332 - mse: 3205970.0000 - val_loss: 54.0128 - val_mse: 17073.8945 - 3s/epoch - 86ms/step\n",
            "33/33 - 0s - loss: 601.4250 - mse: 3115760.7500 - val_loss: 67.8995 - val_mse: 26110.1309 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 570.3812 - mse: 2903482.2500 - val_loss: 73.9527 - val_mse: 30381.7969 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 550.1625 - mse: 2797448.7500 - val_loss: 69.6513 - val_mse: 26823.9609 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 522.9011 - mse: 2207442.2500 - val_loss: 70.3431 - val_mse: 27305.0137 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 530.7255 - mse: 2493204.5000 - val_loss: 67.2478 - val_mse: 24871.7695 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 492.7882 - mse: 2278950.0000 - val_loss: 62.6025 - val_mse: 21475.6055 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 493.7776 - mse: 2158407.0000 - val_loss: 55.4602 - val_mse: 16827.7305 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 459.3274 - mse: 1875419.1250 - val_loss: 50.9065 - val_mse: 14159.5938 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 454.8685 - mse: 1918271.7500 - val_loss: 43.6589 - val_mse: 10441.6543 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 435.1245 - mse: 1726953.3750 - val_loss: 37.3503 - val_mse: 7740.1650 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 432.0287 - mse: 1721989.8750 - val_loss: 31.3249 - val_mse: 5481.4048 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 415.3884 - mse: 1653454.8750 - val_loss: 27.7938 - val_mse: 4304.9819 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 411.0027 - mse: 1628276.6250 - val_loss: 25.2860 - val_mse: 3534.4058 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 390.4005 - mse: 1381950.1250 - val_loss: 21.7526 - val_mse: 2666.0151 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 385.5031 - mse: 1366970.2500 - val_loss: 19.0352 - val_mse: 2035.1709 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 376.4017 - mse: 1311838.5000 - val_loss: 14.5418 - val_mse: 1199.5830 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 367.3442 - mse: 1277504.0000 - val_loss: 14.3183 - val_mse: 1166.3043 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 350.1825 - mse: 1251623.2500 - val_loss: 12.2297 - val_mse: 861.2823 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 365.2659 - mse: 1579041.8750 - val_loss: 10.3974 - val_mse: 628.9824 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 337.7094 - mse: 1022197.5625 - val_loss: 11.8605 - val_mse: 808.7333 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 343.9071 - mse: 1098513.3750 - val_loss: 14.3568 - val_mse: 1159.1145 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 340.3734 - mse: 1058395.0000 - val_loss: 17.4605 - val_mse: 1855.0481 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 335.6361 - mse: 1156815.8750 - val_loss: 12.4106 - val_mse: 1137.1619 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 300.8214 - mse: 815761.0000 - val_loss: 3.8866 - val_mse: 116.2930 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 307.7843 - mse: 937669.5625 - val_loss: 4.5743 - val_mse: 46.8643 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 312.7912 - mse: 955676.8750 - val_loss: 7.9916 - val_mse: 206.2803 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 297.2016 - mse: 767219.0625 - val_loss: 10.3573 - val_mse: 412.5924 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 303.1126 - mse: 890165.0625 - val_loss: 12.3768 - val_mse: 728.0813 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 288.8768 - mse: 781313.1875 - val_loss: 15.9918 - val_mse: 1271.3890 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 288.7618 - mse: 708234.3125 - val_loss: 17.0458 - val_mse: 1510.9697 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 287.9666 - mse: 812224.5625 - val_loss: 15.3114 - val_mse: 1191.7990 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 285.3764 - mse: 822505.8125 - val_loss: 13.3068 - val_mse: 880.7725 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 294.5104 - mse: 957380.1250 - val_loss: 12.8135 - val_mse: 683.2785 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 268.4676 - mse: 744756.5000 - val_loss: 12.8890 - val_mse: 748.4811 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 263.1942 - mse: 639514.0625 - val_loss: 11.5314 - val_mse: 605.8182 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 272.5660 - mse: 737455.5625 - val_loss: 10.8411 - val_mse: 461.6002 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 285.4400 - mse: 1012613.1875 - val_loss: 9.3705 - val_mse: 345.7338 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 280.6918 - mse: 826152.5000 - val_loss: 8.3379 - val_mse: 246.4824 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 266.3637 - mse: 681231.3125 - val_loss: 5.6716 - val_mse: 130.0207 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 257.6617 - mse: 567420.3125 - val_loss: 5.4570 - val_mse: 90.0592 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 266.0367 - mse: 768980.5625 - val_loss: 5.9509 - val_mse: 101.8722 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 274.9190 - mse: 821385.5000 - val_loss: 3.7893 - val_mse: 34.8241 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 264.0108 - mse: 764048.7500 - val_loss: 1.6247 - val_mse: 5.9320 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 255.0242 - mse: 651182.5625 - val_loss: 0.5108 - val_mse: 1.2167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 267.2898 - mse: 731500.7500 - val_loss: 1.1683 - val_mse: 5.0097 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 253.9323 - mse: 687946.1250 - val_loss: 1.3252 - val_mse: 8.9527 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 266.8781 - mse: 701784.6875 - val_loss: 1.7166 - val_mse: 14.3365 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 245.7198 - mse: 596431.2500 - val_loss: 1.9805 - val_mse: 22.9596 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 248.4329 - mse: 565601.0000 - val_loss: 2.2431 - val_mse: 29.5250 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 253.5912 - mse: 629943.6250 - val_loss: 3.2188 - val_mse: 82.0025 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 255.7214 - mse: 757377.3750 - val_loss: 4.0429 - val_mse: 133.9850 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 245.0716 - mse: 591485.2500 - val_loss: 4.4093 - val_mse: 151.4855 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 253.3458 - mse: 626748.5625 - val_loss: 4.6783 - val_mse: 172.8335 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 244.2747 - mse: 601845.5000 - val_loss: 5.1504 - val_mse: 207.9660 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 258.5443 - mse: 791223.1250 - val_loss: 6.9206 - val_mse: 340.3786 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 238.5221 - mse: 520148.7812 - val_loss: 7.8584 - val_mse: 432.5021 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 235.1059 - mse: 550780.4375 - val_loss: 9.1645 - val_mse: 551.6407 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 253.3928 - mse: 700572.1875 - val_loss: 6.7265 - val_mse: 335.0789 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 248.9577 - mse: 717428.9375 - val_loss: 7.8603 - val_mse: 435.7604 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 246.4791 - mse: 653448.3750 - val_loss: 9.4952 - val_mse: 565.5672 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 236.1312 - mse: 542160.0625 - val_loss: 8.8198 - val_mse: 491.0614 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 247.2212 - mse: 615919.0625 - val_loss: 9.1204 - val_mse: 507.4929 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 234.0522 - mse: 537648.5625 - val_loss: 9.2793 - val_mse: 490.5488 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 235.7728 - mse: 591376.9375 - val_loss: 8.7227 - val_mse: 418.8317 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 234.6278 - mse: 578680.2500 - val_loss: 7.7995 - val_mse: 361.3801 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 233.4008 - mse: 550249.6250 - val_loss: 7.0208 - val_mse: 285.9803 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 234.5329 - mse: 537443.4375 - val_loss: 6.3489 - val_mse: 263.4319 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 227.4605 - mse: 493879.2812 - val_loss: 6.7269 - val_mse: 270.4438 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 237.8584 - mse: 609034.1250 - val_loss: 6.0246 - val_mse: 254.9872 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 223.8514 - mse: 471495.1875 - val_loss: 5.6633 - val_mse: 243.0377 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 240.8166 - mse: 644781.5000 - val_loss: 6.1364 - val_mse: 284.8518 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 227.4560 - mse: 520504.9375 - val_loss: 5.5230 - val_mse: 237.7782 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 219.3595 - mse: 489700.6562 - val_loss: 6.0274 - val_mse: 262.6049 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 225.6658 - mse: 521514.1875 - val_loss: 7.0353 - val_mse: 317.2924 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 226.5257 - mse: 526534.5625 - val_loss: 6.0513 - val_mse: 280.9611 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 221.0474 - mse: 474373.0000 - val_loss: 6.5440 - val_mse: 322.4441 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 220.2821 - mse: 457275.5000 - val_loss: 8.4802 - val_mse: 453.5644 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 223.5014 - mse: 506198.3438 - val_loss: 8.4495 - val_mse: 447.3893 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 233.0264 - mse: 564029.8125 - val_loss: 5.7451 - val_mse: 257.4958 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 218.5741 - mse: 469521.2188 - val_loss: 3.8447 - val_mse: 130.3042 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 227.0661 - mse: 518412.8125 - val_loss: 4.3923 - val_mse: 160.5152 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 222.6186 - mse: 471384.0000 - val_loss: 6.2628 - val_mse: 290.5984 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 220.9799 - mse: 545023.8125 - val_loss: 5.8915 - val_mse: 262.1312 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 215.7953 - mse: 447396.0000 - val_loss: 6.1237 - val_mse: 279.9037 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 223.6081 - mse: 532779.9375 - val_loss: 4.2066 - val_mse: 146.2138 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 211.2642 - mse: 464366.6875 - val_loss: 3.1797 - val_mse: 88.7789 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 207.3488 - mse: 406811.6875 - val_loss: 2.9853 - val_mse: 79.6241 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 219.4577 - mse: 469710.5312 - val_loss: 3.1540 - val_mse: 86.1573 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 204.7924 - mse: 389756.0312 - val_loss: 2.1179 - val_mse: 40.5983 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 198.6362 - mse: 345958.6562 - val_loss: 4.7137 - val_mse: 162.3554 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 208.4460 - mse: 456349.7500 - val_loss: 3.5280 - val_mse: 95.4742 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 201.7825 - mse: 405358.0312 - val_loss: 0.7350 - val_mse: 5.1280 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 210.8893 - mse: 450431.5625 - val_loss: 2.5407 - val_mse: 26.9811 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 211.3368 - mse: 447014.7188 - val_loss: 0.7225 - val_mse: 4.7064 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 197.5984 - mse: 363037.8438 - val_loss: 4.2053 - val_mse: 79.3661 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 206.9506 - mse: 467269.3750 - val_loss: 4.6378 - val_mse: 98.0269 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 204.4528 - mse: 430521.2812 - val_loss: 3.0188 - val_mse: 40.3299 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 204.2261 - mse: 428658.0000 - val_loss: 1.5541 - val_mse: 10.0279 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 205.7758 - mse: 398213.1562 - val_loss: 1.6505 - val_mse: 11.5845 - 218ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 170 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.3637\n",
            "Function value obtained: 11.5845\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 171 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [114, 83]\n",
            "Learning Rate: 0.00018433306628247635\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.25679008657533026\n",
            "Batch Size: 186\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 500.7428 - mse: 2823978.5000 - val_loss: 7.5950 - val_mse: 267.7608 - 3s/epoch - 57ms/step\n",
            "46/46 - 0s - loss: 315.2537 - mse: 951323.8750 - val_loss: 17.3369 - val_mse: 1585.4589 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 262.0424 - mse: 712161.8750 - val_loss: 11.4059 - val_mse: 639.3185 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 214.7585 - mse: 453382.0000 - val_loss: 4.0968 - val_mse: 90.7149 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 175.6948 - mse: 315651.0000 - val_loss: 16.7171 - val_mse: 1407.6379 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 156.3121 - mse: 254737.8438 - val_loss: 26.8331 - val_mse: 3543.0173 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 124.4856 - mse: 149547.8438 - val_loss: 18.1749 - val_mse: 1573.3483 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 106.5918 - mse: 108578.8438 - val_loss: 27.2329 - val_mse: 3755.2222 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 88.3864 - mse: 78133.1406 - val_loss: 25.0708 - val_mse: 3072.9465 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 82.2758 - mse: 73215.7422 - val_loss: 27.5977 - val_mse: 3696.7996 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 67.5209 - mse: 43885.0977 - val_loss: 14.9067 - val_mse: 1046.1818 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 58.5490 - mse: 35076.5898 - val_loss: 18.2401 - val_mse: 1593.3706 - 260ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 49.9288 - mse: 25032.4668 - val_loss: 13.7447 - val_mse: 924.7320 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 46.2173 - mse: 24565.3984 - val_loss: 4.9800 - val_mse: 120.3084 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 39.5438 - mse: 17030.7520 - val_loss: 2.0485 - val_mse: 20.1332 - 261ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 34.4480 - mse: 13213.0098 - val_loss: 0.6392 - val_mse: 3.7281 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 29.8987 - mse: 12126.8604 - val_loss: 1.7941 - val_mse: 25.1072 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 27.3925 - mse: 10544.3594 - val_loss: 0.7975 - val_mse: 5.7225 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 23.2497 - mse: 6413.0737 - val_loss: 0.4331 - val_mse: 1.8078 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 20.7712 - mse: 4404.6670 - val_loss: 0.4402 - val_mse: 1.8927 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 18.1841 - mse: 3966.9294 - val_loss: 0.5112 - val_mse: 2.5370 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 16.0912 - mse: 3339.1628 - val_loss: 0.5527 - val_mse: 2.9619 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 14.4850 - mse: 3544.6262 - val_loss: 0.3527 - val_mse: 1.2823 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 12.4421 - mse: 2638.9565 - val_loss: 0.3469 - val_mse: 1.2571 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 10.8558 - mse: 1861.1136 - val_loss: 0.2659 - val_mse: 0.7764 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 9.1312 - mse: 1515.9006 - val_loss: 0.2716 - val_mse: 0.8215 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 8.0055 - mse: 1382.1989 - val_loss: 0.1807 - val_mse: 0.4051 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 6.5161 - mse: 782.6123 - val_loss: 0.1387 - val_mse: 0.2775 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 5.8956 - mse: 880.6497 - val_loss: 0.1360 - val_mse: 0.2720 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 5.7319 - mse: 839.2706 - val_loss: 0.1272 - val_mse: 0.2544 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 4.1819 - mse: 560.6893 - val_loss: 0.1242 - val_mse: 0.2485 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 4.4424 - mse: 808.1104 - val_loss: 0.1163 - val_mse: 0.2327 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.3218 - mse: 305.7791 - val_loss: 0.1140 - val_mse: 0.2280 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.0654 - mse: 374.4267 - val_loss: 0.1118 - val_mse: 0.2235 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.6717 - mse: 382.6032 - val_loss: 0.1035 - val_mse: 0.2071 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.5953 - mse: 537.6289 - val_loss: 0.1029 - val_mse: 0.2059 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.2495 - mse: 250.1773 - val_loss: 0.0964 - val_mse: 0.1929 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.0677 - mse: 285.0848 - val_loss: 0.0924 - val_mse: 0.1848 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.7381 - mse: 207.0701 - val_loss: 0.0879 - val_mse: 0.1759 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.6081 - mse: 187.2244 - val_loss: 0.0833 - val_mse: 0.1667 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.3408 - mse: 103.4826 - val_loss: 0.0802 - val_mse: 0.1603 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.2517 - mse: 112.8170 - val_loss: 0.0764 - val_mse: 0.1528 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.1635 - mse: 135.9672 - val_loss: 0.0727 - val_mse: 0.1455 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.2049 - mse: 169.5194 - val_loss: 0.0713 - val_mse: 0.1427 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.9410 - mse: 71.1746 - val_loss: 0.0689 - val_mse: 0.1377 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.0065 - mse: 107.0494 - val_loss: 0.0647 - val_mse: 0.1294 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7938 - mse: 58.1877 - val_loss: 0.0629 - val_mse: 0.1258 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.9233 - mse: 94.4905 - val_loss: 0.0605 - val_mse: 0.1210 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.9066 - mse: 133.6030 - val_loss: 0.0558 - val_mse: 0.1117 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.6738 - mse: 48.2129 - val_loss: 0.0545 - val_mse: 0.1090 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7487 - mse: 67.4866 - val_loss: 0.0522 - val_mse: 0.1043 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7212 - mse: 121.7323 - val_loss: 0.0492 - val_mse: 0.0984 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7381 - mse: 106.6946 - val_loss: 0.0476 - val_mse: 0.0951 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5530 - mse: 75.5609 - val_loss: 0.0452 - val_mse: 0.0905 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5982 - mse: 90.1360 - val_loss: 0.0433 - val_mse: 0.0867 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5981 - mse: 88.5434 - val_loss: 0.0419 - val_mse: 0.0838 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4484 - mse: 25.6123 - val_loss: 0.0408 - val_mse: 0.0816 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5238 - mse: 85.5152 - val_loss: 0.0382 - val_mse: 0.0764 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5271 - mse: 110.3787 - val_loss: 0.0382 - val_mse: 0.0764 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4023 - mse: 24.2252 - val_loss: 0.0350 - val_mse: 0.0701 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3810 - mse: 37.5728 - val_loss: 0.0335 - val_mse: 0.0669 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4070 - mse: 45.8462 - val_loss: 0.0321 - val_mse: 0.0641 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4668 - mse: 73.9473 - val_loss: 0.0307 - val_mse: 0.0614 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3681 - mse: 32.3944 - val_loss: 0.0295 - val_mse: 0.0590 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2491 - mse: 20.3879 - val_loss: 0.0281 - val_mse: 0.0563 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2023 - mse: 6.3307 - val_loss: 0.0269 - val_mse: 0.0539 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3856 - mse: 57.3224 - val_loss: 0.0258 - val_mse: 0.0516 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3835 - mse: 53.2417 - val_loss: 0.0247 - val_mse: 0.0494 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2946 - mse: 38.9033 - val_loss: 0.0237 - val_mse: 0.0474 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1736 - mse: 7.9035 - val_loss: 0.0226 - val_mse: 0.0453 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2731 - mse: 27.3955 - val_loss: 0.0216 - val_mse: 0.0433 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3531 - mse: 69.7295 - val_loss: 0.0207 - val_mse: 0.0415 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2845 - mse: 29.0553 - val_loss: 0.0199 - val_mse: 0.0398 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2387 - mse: 15.5673 - val_loss: 0.0192 - val_mse: 0.0384 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2690 - mse: 31.2219 - val_loss: 0.0182 - val_mse: 0.0364 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1622 - mse: 8.2911 - val_loss: 0.0175 - val_mse: 0.0350 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1482 - mse: 6.9049 - val_loss: 0.0170 - val_mse: 0.0340 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2128 - mse: 15.3535 - val_loss: 0.0164 - val_mse: 0.0327 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2521 - mse: 63.8303 - val_loss: 0.0156 - val_mse: 0.0313 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2224 - mse: 53.1007 - val_loss: 0.0150 - val_mse: 0.0299 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1665 - mse: 12.8721 - val_loss: 0.0143 - val_mse: 0.0286 - 276ms/epoch - 6ms/step\n",
            "46/46 - 1s - loss: 0.1940 - mse: 14.6367 - val_loss: 0.0156 - val_mse: 0.0312 - 831ms/epoch - 18ms/step\n",
            "46/46 - 0s - loss: 0.1595 - mse: 9.4552 - val_loss: 0.0131 - val_mse: 0.0263 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1083 - mse: 11.1040 - val_loss: 0.0127 - val_mse: 0.0254 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2113 - mse: 34.8762 - val_loss: 0.0119 - val_mse: 0.0239 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1969 - mse: 31.1271 - val_loss: 0.0120 - val_mse: 0.0240 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1587 - mse: 20.0189 - val_loss: 0.0116 - val_mse: 0.0232 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1043 - mse: 11.8102 - val_loss: 0.0112 - val_mse: 0.0224 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1376 - mse: 9.7321 - val_loss: 0.0112 - val_mse: 0.0223 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1266 - mse: 26.8705 - val_loss: 0.0107 - val_mse: 0.0214 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0666 - mse: 3.1757 - val_loss: 0.0103 - val_mse: 0.0206 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1244 - mse: 10.3549 - val_loss: 0.0106 - val_mse: 0.0213 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1217 - mse: 9.7312 - val_loss: 0.0100 - val_mse: 0.0200 - 301ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0427 - mse: 0.7486 - val_loss: 0.0106 - val_mse: 0.0212 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0831 - mse: 1.5784 - val_loss: 0.0095 - val_mse: 0.0190 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.2141 - mse: 98.2363 - val_loss: 0.0095 - val_mse: 0.0190 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0763 - mse: 3.3776 - val_loss: 0.0093 - val_mse: 0.0186 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0736 - mse: 2.6414 - val_loss: 0.0090 - val_mse: 0.0180 - 319ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.1494 - mse: 20.0196 - val_loss: 0.0091 - val_mse: 0.0182 - 301ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0478 - mse: 0.8352 - val_loss: 0.0090 - val_mse: 0.0180 - 313ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 171 ended. Search finished for the next optimal point.\n",
            "Time taken: 43.8607\n",
            "Function value obtained: 0.0180\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 172 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [79, 97]\n",
            "Learning Rate: 5.075408627711673e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.22066353620038773\n",
            "Batch Size: 185\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 1107.2063 - mse: 9198189.0000 - val_loss: 651.4545 - val_mse: 2135951.7500 - 3s/epoch - 60ms/step\n",
            "46/46 - 0s - loss: 1003.6913 - mse: 8433707.0000 - val_loss: 548.0011 - val_mse: 1510967.5000 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 902.5560 - mse: 6452098.5000 - val_loss: 459.0408 - val_mse: 1057547.6250 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 843.4977 - mse: 6099247.5000 - val_loss: 378.3043 - val_mse: 715959.2500 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 780.5720 - mse: 4934119.5000 - val_loss: 309.0838 - val_mse: 478709.8750 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 708.5296 - mse: 3943394.5000 - val_loss: 247.2639 - val_mse: 304098.7812 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 665.7621 - mse: 3887477.7500 - val_loss: 202.6323 - val_mse: 204791.1406 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 615.7355 - mse: 3265274.0000 - val_loss: 168.4073 - val_mse: 141789.5312 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 552.7344 - mse: 2548212.2500 - val_loss: 139.1933 - val_mse: 97480.2109 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 532.8029 - mse: 2491799.5000 - val_loss: 108.7941 - val_mse: 59281.4102 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 496.5345 - mse: 2136347.2500 - val_loss: 78.0236 - val_mse: 30082.2500 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 477.7116 - mse: 1918609.1250 - val_loss: 54.3972 - val_mse: 14302.6797 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 467.1833 - mse: 1940209.7500 - val_loss: 38.0411 - val_mse: 6843.0913 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 444.2274 - mse: 1891635.5000 - val_loss: 28.5379 - val_mse: 3981.8804 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 431.7332 - mse: 1617238.1250 - val_loss: 19.7005 - val_mse: 1883.5522 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 428.6770 - mse: 1653937.5000 - val_loss: 11.6884 - val_mse: 643.1454 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 416.6894 - mse: 1887025.2500 - val_loss: 3.6186 - val_mse: 54.0529 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 402.3225 - mse: 1547574.6250 - val_loss: 6.0889 - val_mse: 260.3906 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 399.2954 - mse: 1569974.3750 - val_loss: 10.3404 - val_mse: 732.7601 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 381.0225 - mse: 1359669.5000 - val_loss: 18.4260 - val_mse: 2152.4460 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 389.1507 - mse: 1650952.7500 - val_loss: 24.8463 - val_mse: 3605.6440 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 377.2944 - mse: 1506276.6250 - val_loss: 26.8560 - val_mse: 3972.6016 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 363.1376 - mse: 1184900.5000 - val_loss: 25.0313 - val_mse: 3495.5891 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 377.3476 - mse: 1492324.1250 - val_loss: 26.9481 - val_mse: 4172.6968 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 361.4181 - mse: 1208116.5000 - val_loss: 29.2171 - val_mse: 4448.8735 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 338.9297 - mse: 1003677.8750 - val_loss: 22.6983 - val_mse: 2448.4905 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 348.1636 - mse: 1274338.7500 - val_loss: 12.9256 - val_mse: 571.5869 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 338.3963 - mse: 1056786.7500 - val_loss: 8.2676 - val_mse: 190.5275 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 327.5358 - mse: 954807.6875 - val_loss: 5.0995 - val_mse: 182.4826 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 339.1440 - mse: 1094031.8750 - val_loss: 11.6227 - val_mse: 981.7040 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 332.5710 - mse: 1127013.6250 - val_loss: 16.6301 - val_mse: 1740.8364 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 316.9198 - mse: 922778.7500 - val_loss: 16.7281 - val_mse: 1668.4868 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 320.4485 - mse: 967127.9375 - val_loss: 13.1507 - val_mse: 947.3625 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 328.3981 - mse: 995208.6875 - val_loss: 10.1123 - val_mse: 527.0289 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 300.4412 - mse: 803271.2500 - val_loss: 8.1656 - val_mse: 334.5778 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 306.8553 - mse: 843346.3125 - val_loss: 4.5122 - val_mse: 100.4562 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 314.2102 - mse: 982761.8125 - val_loss: 1.4957 - val_mse: 9.9418 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 313.2856 - mse: 967155.8750 - val_loss: 1.0511 - val_mse: 5.2806 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 305.7909 - mse: 884090.1250 - val_loss: 1.0137 - val_mse: 4.8280 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 312.8943 - mse: 1116618.3750 - val_loss: 0.8524 - val_mse: 3.4276 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 305.7405 - mse: 926472.2500 - val_loss: 1.0549 - val_mse: 8.5212 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 297.7913 - mse: 904425.5000 - val_loss: 1.8227 - val_mse: 24.3359 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 287.8142 - mse: 746751.0625 - val_loss: 3.6261 - val_mse: 86.4115 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 289.5963 - mse: 796623.1250 - val_loss: 4.1800 - val_mse: 107.5952 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 276.5137 - mse: 666913.7500 - val_loss: 5.0109 - val_mse: 152.1869 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 289.4944 - mse: 843019.0000 - val_loss: 5.4116 - val_mse: 176.2261 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 278.1874 - mse: 753063.3750 - val_loss: 5.0878 - val_mse: 148.3961 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 277.6124 - mse: 758765.1875 - val_loss: 4.2220 - val_mse: 97.5887 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 290.3202 - mse: 849653.3750 - val_loss: 2.1243 - val_mse: 23.0551 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 270.2614 - mse: 688215.2500 - val_loss: 2.1066 - val_mse: 22.6626 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 280.2197 - mse: 754242.1875 - val_loss: 1.1303 - val_mse: 7.7031 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 271.9373 - mse: 706814.4375 - val_loss: 1.2672 - val_mse: 9.6912 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 263.5831 - mse: 657073.9375 - val_loss: 2.2239 - val_mse: 30.9754 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 256.1349 - mse: 626922.5625 - val_loss: 2.9754 - val_mse: 59.6737 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 275.8867 - mse: 886194.8125 - val_loss: 4.8495 - val_mse: 143.9335 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 261.5614 - mse: 748579.2500 - val_loss: 5.3882 - val_mse: 171.9313 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 250.2412 - mse: 579324.5625 - val_loss: 5.7477 - val_mse: 188.6946 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 244.7804 - mse: 577484.3750 - val_loss: 6.9425 - val_mse: 257.3199 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 254.4715 - mse: 719198.7500 - val_loss: 10.1407 - val_mse: 578.5243 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 242.2452 - mse: 584886.3125 - val_loss: 15.8062 - val_mse: 1422.8390 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 251.8498 - mse: 658945.1250 - val_loss: 19.5242 - val_mse: 2172.8049 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 242.0018 - mse: 533365.0625 - val_loss: 24.4010 - val_mse: 3364.6064 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 236.0507 - mse: 506533.5000 - val_loss: 27.8738 - val_mse: 4435.1294 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 230.7373 - mse: 537886.3750 - val_loss: 31.4031 - val_mse: 5643.6992 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 225.9162 - mse: 486055.0000 - val_loss: 30.2141 - val_mse: 5271.9072 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 242.9322 - mse: 588956.1250 - val_loss: 30.0614 - val_mse: 5217.1450 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 229.6888 - mse: 492405.2188 - val_loss: 29.1301 - val_mse: 4895.5474 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 229.8660 - mse: 493831.1562 - val_loss: 26.9578 - val_mse: 4209.1460 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 236.3105 - mse: 565036.3750 - val_loss: 25.3614 - val_mse: 3720.1106 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 223.7165 - mse: 512446.7188 - val_loss: 25.0866 - val_mse: 3596.3423 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 218.9092 - mse: 483115.1875 - val_loss: 26.7575 - val_mse: 4072.4534 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 221.9734 - mse: 501939.9688 - val_loss: 26.4374 - val_mse: 4041.7800 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 217.2545 - mse: 465453.0312 - val_loss: 27.0927 - val_mse: 4259.3003 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 220.3913 - mse: 477692.9688 - val_loss: 26.4291 - val_mse: 4197.7046 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 218.5876 - mse: 470320.8125 - val_loss: 26.9403 - val_mse: 4324.8101 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 218.7113 - mse: 451781.7812 - val_loss: 24.8142 - val_mse: 3800.3389 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 213.0712 - mse: 455623.3750 - val_loss: 24.3831 - val_mse: 3675.4661 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 209.9812 - mse: 431684.0312 - val_loss: 25.9030 - val_mse: 3968.6660 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 212.2100 - mse: 414842.9688 - val_loss: 25.9009 - val_mse: 3994.5786 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 217.0354 - mse: 501683.2188 - val_loss: 26.3276 - val_mse: 4062.3262 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 208.6265 - mse: 416391.3125 - val_loss: 27.5041 - val_mse: 4401.1392 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 206.5335 - mse: 422076.4688 - val_loss: 28.4753 - val_mse: 4770.3862 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 207.1286 - mse: 403664.7500 - val_loss: 27.7957 - val_mse: 4628.4380 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 206.7771 - mse: 439855.6562 - val_loss: 26.7010 - val_mse: 4174.7422 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 205.8180 - mse: 433056.7812 - val_loss: 27.1290 - val_mse: 4202.4531 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 205.0000 - mse: 419030.0625 - val_loss: 26.6248 - val_mse: 4051.3577 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 205.2236 - mse: 377821.7812 - val_loss: 27.1647 - val_mse: 4209.2485 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 200.3773 - mse: 377779.2188 - val_loss: 27.8934 - val_mse: 4465.4209 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 197.0694 - mse: 367422.8438 - val_loss: 29.1892 - val_mse: 4875.4351 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 206.0138 - mse: 581551.8750 - val_loss: 29.2184 - val_mse: 4861.6235 - 258ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 196.0044 - mse: 382259.5312 - val_loss: 29.5782 - val_mse: 4949.6938 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 194.4738 - mse: 343108.7500 - val_loss: 28.7488 - val_mse: 4800.3467 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 193.7848 - mse: 389195.3750 - val_loss: 26.8940 - val_mse: 4428.8345 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 184.4331 - mse: 328071.8125 - val_loss: 25.3311 - val_mse: 3966.1206 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 191.6668 - mse: 396445.1875 - val_loss: 27.9025 - val_mse: 4633.0576 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 196.0460 - mse: 352980.1250 - val_loss: 28.4535 - val_mse: 4695.5361 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 188.1673 - mse: 322874.8438 - val_loss: 27.0611 - val_mse: 4397.1338 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 182.7107 - mse: 308618.0938 - val_loss: 23.9022 - val_mse: 3506.8809 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 180.8268 - mse: 299979.1875 - val_loss: 20.6367 - val_mse: 2666.7759 - 259ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 181.4269 - mse: 309573.2188 - val_loss: 23.0444 - val_mse: 3272.1714 - 270ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 172 ended. Search finished for the next optimal point.\n",
            "Time taken: 43.7619\n",
            "Function value obtained: 3272.1714\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 173 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [63, 63]\n",
            "Learning Rate: 2.2365434286810137e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45473707206451924\n",
            "Batch Size: 59\n",
            "----------------------------------------\n",
            "143/143 - 3s - loss: 2289.0625 - mse: 49289996.0000 - val_loss: 332.8500 - val_mse: 547751.0625 - 3s/epoch - 21ms/step\n",
            "143/143 - 1s - loss: 2251.1997 - mse: 49491000.0000 - val_loss: 320.5289 - val_mse: 509186.2812 - 645ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2298.8953 - mse: 50689548.0000 - val_loss: 308.8663 - val_mse: 474701.4688 - 645ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2142.8308 - mse: 42037120.0000 - val_loss: 300.4269 - val_mse: 448317.5938 - 638ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2139.5925 - mse: 44199988.0000 - val_loss: 289.0306 - val_mse: 413977.3438 - 635ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2104.0037 - mse: 41999876.0000 - val_loss: 283.5092 - val_mse: 398115.9688 - 639ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2144.5215 - mse: 46446516.0000 - val_loss: 275.7171 - val_mse: 378276.8750 - 644ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2067.1213 - mse: 37720512.0000 - val_loss: 270.1313 - val_mse: 363999.6250 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2055.7476 - mse: 42364024.0000 - val_loss: 266.8912 - val_mse: 355102.1875 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2161.7734 - mse: 48764876.0000 - val_loss: 259.7651 - val_mse: 330304.0625 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1957.7402 - mse: 38780096.0000 - val_loss: 246.3479 - val_mse: 292041.4062 - 633ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1938.5809 - mse: 34264676.0000 - val_loss: 234.9490 - val_mse: 263636.5312 - 645ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2050.7261 - mse: 43639732.0000 - val_loss: 219.6440 - val_mse: 227239.2344 - 666ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1955.2891 - mse: 42916728.0000 - val_loss: 203.0978 - val_mse: 189687.3438 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1970.7893 - mse: 42682176.0000 - val_loss: 188.7014 - val_mse: 163212.5469 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1902.3141 - mse: 34896448.0000 - val_loss: 178.8079 - val_mse: 147334.1719 - 681ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1935.3705 - mse: 41280792.0000 - val_loss: 169.7678 - val_mse: 133774.0938 - 640ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1821.5582 - mse: 30756630.0000 - val_loss: 160.6474 - val_mse: 121142.8750 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2009.5439 - mse: 42861272.0000 - val_loss: 153.1325 - val_mse: 110565.2422 - 649ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1947.3826 - mse: 49147504.0000 - val_loss: 144.8165 - val_mse: 102131.1875 - 639ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1880.6752 - mse: 36838336.0000 - val_loss: 141.7848 - val_mse: 101928.1094 - 649ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1901.1543 - mse: 38550836.0000 - val_loss: 142.1553 - val_mse: 106782.8203 - 632ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1827.3239 - mse: 31300766.0000 - val_loss: 144.1642 - val_mse: 113622.1719 - 639ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1782.6002 - mse: 30035242.0000 - val_loss: 147.3109 - val_mse: 120726.3047 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1921.9283 - mse: 42191556.0000 - val_loss: 147.3138 - val_mse: 122028.5000 - 638ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1811.9061 - mse: 29605604.0000 - val_loss: 154.1613 - val_mse: 135301.8125 - 637ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1729.7410 - mse: 28536968.0000 - val_loss: 156.2100 - val_mse: 139637.2344 - 633ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1654.6467 - mse: 24199790.0000 - val_loss: 161.3702 - val_mse: 148917.0938 - 638ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1754.9681 - mse: 29706536.0000 - val_loss: 164.4981 - val_mse: 153839.9531 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1780.3275 - mse: 34574156.0000 - val_loss: 167.8774 - val_mse: 158215.5469 - 647ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1646.8395 - mse: 25387286.0000 - val_loss: 170.8646 - val_mse: 162166.2031 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1679.2001 - mse: 28492546.0000 - val_loss: 172.0531 - val_mse: 164265.7031 - 666ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1788.4338 - mse: 32581448.0000 - val_loss: 170.3509 - val_mse: 161323.0000 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1663.7582 - mse: 27931146.0000 - val_loss: 170.5620 - val_mse: 161902.7812 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1673.3053 - mse: 31990328.0000 - val_loss: 169.7579 - val_mse: 160518.4062 - 1s/epoch - 8ms/step\n",
            "143/143 - 1s - loss: 1706.8353 - mse: 32739310.0000 - val_loss: 175.3127 - val_mse: 171056.5000 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1664.4849 - mse: 30650616.0000 - val_loss: 176.0428 - val_mse: 172341.5625 - 663ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1651.4003 - mse: 26428292.0000 - val_loss: 176.8522 - val_mse: 172680.4062 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1690.5822 - mse: 29489608.0000 - val_loss: 177.8421 - val_mse: 173340.4688 - 669ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1602.2844 - mse: 23278394.0000 - val_loss: 177.8560 - val_mse: 171429.1719 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1627.0713 - mse: 25015918.0000 - val_loss: 179.1759 - val_mse: 171767.5000 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1633.2496 - mse: 28191234.0000 - val_loss: 178.2092 - val_mse: 168524.7812 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1571.6359 - mse: 27135934.0000 - val_loss: 175.0594 - val_mse: 162324.3594 - 653ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1573.5546 - mse: 22144096.0000 - val_loss: 173.7836 - val_mse: 159507.7969 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1631.7804 - mse: 26002336.0000 - val_loss: 170.9771 - val_mse: 154173.0156 - 661ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1597.3713 - mse: 23229820.0000 - val_loss: 168.0242 - val_mse: 148711.0312 - 658ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1541.1212 - mse: 22926546.0000 - val_loss: 165.9720 - val_mse: 144976.7812 - 690ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1580.0530 - mse: 26114108.0000 - val_loss: 163.6487 - val_mse: 140995.4688 - 693ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1532.9237 - mse: 22694572.0000 - val_loss: 162.9763 - val_mse: 139976.7500 - 695ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1520.7642 - mse: 20856894.0000 - val_loss: 160.8312 - val_mse: 136289.6250 - 674ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1606.4529 - mse: 25208336.0000 - val_loss: 161.1101 - val_mse: 136876.0781 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1520.5786 - mse: 21283944.0000 - val_loss: 161.3801 - val_mse: 137515.3594 - 661ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1561.4530 - mse: 25264610.0000 - val_loss: 159.1902 - val_mse: 134106.0000 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1543.8882 - mse: 25507968.0000 - val_loss: 159.7673 - val_mse: 135556.6406 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1540.0389 - mse: 21394242.0000 - val_loss: 160.4918 - val_mse: 138138.6406 - 677ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1466.2068 - mse: 20147918.0000 - val_loss: 159.2978 - val_mse: 136974.7344 - 679ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1455.8292 - mse: 18941344.0000 - val_loss: 156.3396 - val_mse: 132352.1875 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1490.0656 - mse: 20383558.0000 - val_loss: 156.7693 - val_mse: 133826.5469 - 668ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1524.2257 - mse: 26266640.0000 - val_loss: 152.0143 - val_mse: 126124.8828 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1505.0684 - mse: 23604344.0000 - val_loss: 152.1263 - val_mse: 126699.1719 - 652ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1456.0035 - mse: 21926126.0000 - val_loss: 152.0276 - val_mse: 126684.2578 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1462.9441 - mse: 19290924.0000 - val_loss: 153.8500 - val_mse: 129475.6875 - 654ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1440.8431 - mse: 20096856.0000 - val_loss: 153.0073 - val_mse: 128005.2891 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1490.0741 - mse: 22897340.0000 - val_loss: 150.1573 - val_mse: 123414.2344 - 688ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1484.6935 - mse: 24611896.0000 - val_loss: 149.3128 - val_mse: 122071.1016 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1462.2761 - mse: 22673432.0000 - val_loss: 150.4668 - val_mse: 123957.5703 - 693ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1456.1359 - mse: 23170628.0000 - val_loss: 147.9118 - val_mse: 119955.5703 - 653ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1418.1017 - mse: 19340638.0000 - val_loss: 146.9790 - val_mse: 118586.4062 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1452.2096 - mse: 22758058.0000 - val_loss: 146.7668 - val_mse: 118286.1484 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1412.2684 - mse: 19195178.0000 - val_loss: 148.7186 - val_mse: 121425.2812 - 658ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1351.0105 - mse: 17286486.0000 - val_loss: 146.0934 - val_mse: 117264.3906 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1428.0854 - mse: 20637400.0000 - val_loss: 145.3830 - val_mse: 116147.1719 - 650ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1366.7054 - mse: 19171106.0000 - val_loss: 146.3573 - val_mse: 117640.2656 - 653ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1384.9674 - mse: 19869884.0000 - val_loss: 144.2078 - val_mse: 114303.9922 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1386.9363 - mse: 19560754.0000 - val_loss: 142.6610 - val_mse: 111652.1172 - 649ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1356.1423 - mse: 17973624.0000 - val_loss: 141.6812 - val_mse: 110018.1875 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1347.6312 - mse: 17479712.0000 - val_loss: 140.5208 - val_mse: 108061.7109 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1354.7747 - mse: 17970902.0000 - val_loss: 138.8936 - val_mse: 105391.0938 - 647ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1325.0592 - mse: 18084526.0000 - val_loss: 139.1818 - val_mse: 105737.8281 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1302.1821 - mse: 15412843.0000 - val_loss: 137.9998 - val_mse: 103602.9531 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1340.1383 - mse: 18264072.0000 - val_loss: 136.3061 - val_mse: 100979.9141 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1361.1550 - mse: 18744538.0000 - val_loss: 134.5429 - val_mse: 98516.9531 - 697ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1277.8425 - mse: 15790020.0000 - val_loss: 132.7262 - val_mse: 95870.0781 - 682ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1317.8112 - mse: 17296250.0000 - val_loss: 129.4880 - val_mse: 91149.1719 - 647ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1376.1395 - mse: 19733196.0000 - val_loss: 126.6439 - val_mse: 87349.8984 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1294.5339 - mse: 16082140.0000 - val_loss: 126.6639 - val_mse: 87053.0234 - 638ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1241.4751 - mse: 15850963.0000 - val_loss: 125.9052 - val_mse: 85898.3438 - 631ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1299.5177 - mse: 17874746.0000 - val_loss: 122.9545 - val_mse: 82078.7422 - 645ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1283.4799 - mse: 15365139.0000 - val_loss: 120.9899 - val_mse: 79674.0000 - 636ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1276.2053 - mse: 18831744.0000 - val_loss: 119.7921 - val_mse: 78118.8750 - 668ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1239.2583 - mse: 13998163.0000 - val_loss: 116.9203 - val_mse: 74473.7344 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1252.8427 - mse: 15510557.0000 - val_loss: 114.5718 - val_mse: 71671.2812 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1237.0811 - mse: 14245545.0000 - val_loss: 112.8105 - val_mse: 69639.2422 - 660ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1233.2257 - mse: 15137355.0000 - val_loss: 111.4714 - val_mse: 67803.9375 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1261.7903 - mse: 13542587.0000 - val_loss: 108.5652 - val_mse: 64466.5000 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1271.6106 - mse: 15256986.0000 - val_loss: 109.5289 - val_mse: 65525.3945 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1233.5839 - mse: 15036198.0000 - val_loss: 108.0638 - val_mse: 63817.1797 - 690ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1200.1007 - mse: 14214373.0000 - val_loss: 107.6006 - val_mse: 63213.4414 - 717ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1191.0114 - mse: 13488970.0000 - val_loss: 106.8111 - val_mse: 62317.4883 - 699ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1221.7616 - mse: 14785548.0000 - val_loss: 105.3332 - val_mse: 60787.0000 - 687ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 173 ended. Search finished for the next optimal point.\n",
            "Time taken: 82.6954\n",
            "Function value obtained: 60787.0000\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 174 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [94, 121]\n",
            "Learning Rate: 5.563054861730474e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45209803599502296\n",
            "Batch Size: 57\n",
            "----------------------------------------\n",
            "148/148 - 3s - loss: 1923.7032 - mse: 37370380.0000 - val_loss: 192.5740 - val_mse: 193238.0938 - 3s/epoch - 21ms/step\n",
            "148/148 - 1s - loss: 1871.5846 - mse: 34506728.0000 - val_loss: 154.4418 - val_mse: 125462.1797 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1742.4030 - mse: 30937134.0000 - val_loss: 113.1224 - val_mse: 68437.4844 - 708ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1634.8513 - mse: 27042558.0000 - val_loss: 89.8816 - val_mse: 43892.5664 - 718ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1553.4795 - mse: 22263684.0000 - val_loss: 52.5781 - val_mse: 15774.2500 - 725ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1487.0352 - mse: 21529414.0000 - val_loss: 35.2650 - val_mse: 7476.7793 - 713ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1355.7683 - mse: 14654618.0000 - val_loss: 15.8613 - val_mse: 1807.1626 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1328.3330 - mse: 17387546.0000 - val_loss: 7.2444 - val_mse: 158.2268 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1276.6912 - mse: 14440492.0000 - val_loss: 4.8130 - val_mse: 62.0787 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1210.0071 - mse: 14341171.0000 - val_loss: 3.1022 - val_mse: 81.0931 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1272.8438 - mse: 16772803.0000 - val_loss: 4.9049 - val_mse: 65.0038 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1152.5508 - mse: 12355846.0000 - val_loss: 2.7337 - val_mse: 50.9815 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1138.3729 - mse: 13737395.0000 - val_loss: 7.1215 - val_mse: 158.1870 - 690ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1150.0182 - mse: 13844945.0000 - val_loss: 9.7650 - val_mse: 338.2790 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1112.9417 - mse: 13476440.0000 - val_loss: 9.3963 - val_mse: 311.1768 - 691ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1080.0750 - mse: 11840512.0000 - val_loss: 5.6494 - val_mse: 330.9830 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1014.7266 - mse: 9449094.0000 - val_loss: 4.9667 - val_mse: 260.2171 - 698ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1030.0304 - mse: 10070655.0000 - val_loss: 9.0122 - val_mse: 671.2484 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 983.9101 - mse: 8821522.0000 - val_loss: 7.8292 - val_mse: 553.2787 - 692ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1004.5840 - mse: 10135648.0000 - val_loss: 8.4646 - val_mse: 617.7653 - 711ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1015.7298 - mse: 10002519.0000 - val_loss: 16.0833 - val_mse: 1656.3739 - 711ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1000.9200 - mse: 11291552.0000 - val_loss: 13.9636 - val_mse: 1384.1902 - 720ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 969.2367 - mse: 9576593.0000 - val_loss: 15.0359 - val_mse: 1530.0942 - 712ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 970.2144 - mse: 9668922.0000 - val_loss: 9.9734 - val_mse: 828.1756 - 691ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 930.0518 - mse: 9082743.0000 - val_loss: 7.3466 - val_mse: 513.1974 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 927.1840 - mse: 8731962.0000 - val_loss: 3.6377 - val_mse: 160.2471 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 921.2822 - mse: 8094271.0000 - val_loss: 8.7270 - val_mse: 654.9237 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 908.2343 - mse: 8391495.0000 - val_loss: 10.4034 - val_mse: 842.5117 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 864.2115 - mse: 7310568.0000 - val_loss: 11.1175 - val_mse: 917.7690 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 874.6703 - mse: 8205589.5000 - val_loss: 10.1995 - val_mse: 794.4393 - 694ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 852.5740 - mse: 7449434.5000 - val_loss: 15.8590 - val_mse: 1564.1320 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 867.9259 - mse: 8427652.0000 - val_loss: 19.5815 - val_mse: 2228.2107 - 687ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 864.6331 - mse: 8008346.0000 - val_loss: 19.5612 - val_mse: 2051.2148 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 765.4050 - mse: 4957932.0000 - val_loss: 16.6542 - val_mse: 1656.9827 - 697ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 836.6166 - mse: 6505102.0000 - val_loss: 15.8495 - val_mse: 1458.3134 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 844.8888 - mse: 6729919.5000 - val_loss: 17.6107 - val_mse: 1713.9784 - 714ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 803.3965 - mse: 6172528.0000 - val_loss: 16.5212 - val_mse: 1537.2635 - 705ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 782.6022 - mse: 5644674.0000 - val_loss: 16.6792 - val_mse: 1563.9985 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 758.8480 - mse: 5780423.0000 - val_loss: 18.3899 - val_mse: 1786.5328 - 729ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 712.5278 - mse: 4403965.5000 - val_loss: 18.8251 - val_mse: 1885.2557 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 779.8080 - mse: 6300805.5000 - val_loss: 16.5247 - val_mse: 1458.3214 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 727.6294 - mse: 5134042.0000 - val_loss: 14.9706 - val_mse: 1313.2430 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 762.0573 - mse: 5916316.5000 - val_loss: 14.5550 - val_mse: 1144.9375 - 690ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 709.6948 - mse: 5212742.0000 - val_loss: 15.6043 - val_mse: 1340.8536 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 721.1620 - mse: 5295383.0000 - val_loss: 14.1009 - val_mse: 1055.2466 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 696.4538 - mse: 4613092.5000 - val_loss: 13.3865 - val_mse: 966.8663 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 680.2990 - mse: 4154448.7500 - val_loss: 13.0886 - val_mse: 972.4963 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 681.7238 - mse: 5041948.0000 - val_loss: 10.1849 - val_mse: 659.9214 - 698ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 699.6372 - mse: 5040742.5000 - val_loss: 11.3694 - val_mse: 769.3707 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 659.7954 - mse: 4237742.5000 - val_loss: 10.7083 - val_mse: 645.8976 - 698ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 652.6527 - mse: 4090904.2500 - val_loss: 8.4733 - val_mse: 477.5882 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 643.6931 - mse: 4174366.2500 - val_loss: 4.3550 - val_mse: 151.8760 - 702ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 635.3020 - mse: 4006063.7500 - val_loss: 3.9053 - val_mse: 120.3108 - 721ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 628.9080 - mse: 3674493.0000 - val_loss: 3.5317 - val_mse: 98.8939 - 711ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 617.3625 - mse: 3509342.5000 - val_loss: 2.7042 - val_mse: 58.1368 - 722ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 628.2448 - mse: 4015473.2500 - val_loss: 1.3055 - val_mse: 9.4281 - 685ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 612.9727 - mse: 3626238.7500 - val_loss: 2.2718 - val_mse: 41.5825 - 699ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 596.5029 - mse: 3731408.7500 - val_loss: 4.2359 - val_mse: 136.1858 - 694ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 573.5931 - mse: 3139589.5000 - val_loss: 1.8452 - val_mse: 27.8282 - 704ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 582.2221 - mse: 3343784.7500 - val_loss: 1.2128 - val_mse: 6.7280 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 579.9348 - mse: 3337969.0000 - val_loss: 1.8856 - val_mse: 12.9585 - 699ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 580.5855 - mse: 3199810.0000 - val_loss: 3.2217 - val_mse: 41.6533 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 554.4301 - mse: 3459164.5000 - val_loss: 4.5645 - val_mse: 93.7612 - 703ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 533.2409 - mse: 2576939.7500 - val_loss: 3.9752 - val_mse: 74.2479 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 582.5613 - mse: 3962665.2500 - val_loss: 3.5473 - val_mse: 54.1480 - 707ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 543.4766 - mse: 3029618.7500 - val_loss: 2.9366 - val_mse: 34.3448 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 527.9132 - mse: 2616700.5000 - val_loss: 2.6599 - val_mse: 32.7511 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 530.7466 - mse: 2612885.2500 - val_loss: 2.9178 - val_mse: 42.4537 - 712ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 499.4250 - mse: 2182287.0000 - val_loss: 2.2484 - val_mse: 23.4790 - 732ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 533.3030 - mse: 2945085.0000 - val_loss: 1.8375 - val_mse: 17.3192 - 730ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 514.2363 - mse: 2759395.7500 - val_loss: 1.1240 - val_mse: 6.0985 - 718ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 493.8332 - mse: 2379043.2500 - val_loss: 1.2108 - val_mse: 7.7215 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 508.8358 - mse: 2532337.0000 - val_loss: 0.9419 - val_mse: 4.1665 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 488.3997 - mse: 2219310.0000 - val_loss: 1.2816 - val_mse: 6.0421 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 450.0184 - mse: 1818069.7500 - val_loss: 1.0887 - val_mse: 6.3165 - 705ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 481.8686 - mse: 2281816.5000 - val_loss: 1.6404 - val_mse: 10.3291 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 466.6238 - mse: 2080504.1250 - val_loss: 2.2994 - val_mse: 26.6955 - 694ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 452.9053 - mse: 2056265.6250 - val_loss: 2.2605 - val_mse: 21.8152 - 709ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 454.0530 - mse: 1929204.3750 - val_loss: 1.6759 - val_mse: 10.3319 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 443.0963 - mse: 1711378.5000 - val_loss: 1.8371 - val_mse: 14.2578 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 450.2461 - mse: 2073085.8750 - val_loss: 2.7566 - val_mse: 36.0862 - 699ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 462.7431 - mse: 2095556.1250 - val_loss: 1.9684 - val_mse: 21.8781 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 449.6260 - mse: 1873804.6250 - val_loss: 1.3175 - val_mse: 11.0515 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 431.4185 - mse: 1778316.5000 - val_loss: 0.8872 - val_mse: 5.0245 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 433.7633 - mse: 2008708.3750 - val_loss: 1.0629 - val_mse: 4.6015 - 717ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 412.3662 - mse: 1674374.1250 - val_loss: 0.8199 - val_mse: 4.1264 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 409.6532 - mse: 1614088.8750 - val_loss: 0.6834 - val_mse: 3.8546 - 701ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 401.1078 - mse: 1557501.6250 - val_loss: 0.9595 - val_mse: 6.8880 - 692ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 394.1962 - mse: 1343384.2500 - val_loss: 0.4370 - val_mse: 1.7613 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 391.6879 - mse: 1467798.7500 - val_loss: 1.9176 - val_mse: 16.3285 - 690ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 403.8047 - mse: 1545242.8750 - val_loss: 0.5732 - val_mse: 3.9031 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 385.2014 - mse: 1595015.2500 - val_loss: 0.4790 - val_mse: 3.0953 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 374.6611 - mse: 1281113.3750 - val_loss: 1.3407 - val_mse: 13.0501 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 375.8855 - mse: 1320614.2500 - val_loss: 0.5285 - val_mse: 4.6138 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 368.4146 - mse: 1345093.3750 - val_loss: 2.0705 - val_mse: 22.1293 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 370.7278 - mse: 1422283.3750 - val_loss: 1.9005 - val_mse: 16.1094 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 369.4815 - mse: 1446046.5000 - val_loss: 2.1182 - val_mse: 24.2120 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 367.9214 - mse: 1379190.3750 - val_loss: 1.2991 - val_mse: 12.4386 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 359.1703 - mse: 1222545.6250 - val_loss: 1.1699 - val_mse: 7.0456 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 351.5237 - mse: 1261299.1250 - val_loss: 1.3951 - val_mse: 10.8986 - 670ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 174 ended. Search finished for the next optimal point.\n",
            "Time taken: 86.5255\n",
            "Function value obtained: 10.8986\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 175 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [108, 111]\n",
            "Learning Rate: 5.2753742232116275e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4702498571070595\n",
            "Batch Size: 53\n",
            "----------------------------------------\n",
            "159/159 - 4s - loss: 1751.9797 - mse: 31587628.0000 - val_loss: 2.9597 - val_mse: 17.2798 - 4s/epoch - 24ms/step\n",
            "159/159 - 1s - loss: 1658.0938 - mse: 26412996.0000 - val_loss: 5.8647 - val_mse: 221.7761 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1619.1162 - mse: 24051028.0000 - val_loss: 6.8144 - val_mse: 347.8945 - 735ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1574.9436 - mse: 22314732.0000 - val_loss: 7.3669 - val_mse: 419.3636 - 742ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1584.2731 - mse: 23540464.0000 - val_loss: 16.6993 - val_mse: 1675.3698 - 735ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1604.1658 - mse: 27430494.0000 - val_loss: 22.6163 - val_mse: 3082.4495 - 739ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1448.5371 - mse: 19625752.0000 - val_loss: 27.4843 - val_mse: 4533.2178 - 768ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1462.9879 - mse: 20624906.0000 - val_loss: 27.6116 - val_mse: 4344.2749 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1450.2589 - mse: 19443032.0000 - val_loss: 49.7269 - val_mse: 14192.2393 - 784ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1441.7311 - mse: 19458336.0000 - val_loss: 38.1197 - val_mse: 7882.5015 - 718ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1399.5018 - mse: 18612026.0000 - val_loss: 36.9881 - val_mse: 8324.5127 - 735ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1413.7058 - mse: 19010318.0000 - val_loss: 56.9877 - val_mse: 18790.2305 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1372.9539 - mse: 18025484.0000 - val_loss: 60.7477 - val_mse: 20267.6895 - 728ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1346.8507 - mse: 17435958.0000 - val_loss: 57.7570 - val_mse: 18262.7305 - 717ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1370.1211 - mse: 21671314.0000 - val_loss: 53.2179 - val_mse: 15702.6875 - 715ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 1336.0638 - mse: 16324101.0000 - val_loss: 53.1418 - val_mse: 15601.0859 - 727ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1337.2739 - mse: 16533058.0000 - val_loss: 57.5753 - val_mse: 18285.1836 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1317.2301 - mse: 17998390.0000 - val_loss: 60.5311 - val_mse: 20251.5859 - 724ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1277.5830 - mse: 15362588.0000 - val_loss: 63.6868 - val_mse: 22937.3184 - 734ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1259.9117 - mse: 15787822.0000 - val_loss: 63.5060 - val_mse: 22651.5391 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1260.7499 - mse: 17183766.0000 - val_loss: 61.4134 - val_mse: 21287.0391 - 724ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1225.7900 - mse: 14455751.0000 - val_loss: 64.1528 - val_mse: 23044.9492 - 757ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1226.3756 - mse: 14442795.0000 - val_loss: 64.6198 - val_mse: 23129.0410 - 753ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1232.8556 - mse: 17895858.0000 - val_loss: 62.9213 - val_mse: 21995.6855 - 744ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1200.5005 - mse: 17456544.0000 - val_loss: 61.3283 - val_mse: 21198.5215 - 736ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1124.7880 - mse: 11551582.0000 - val_loss: 60.9415 - val_mse: 20909.3223 - 725ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1148.7046 - mse: 12482296.0000 - val_loss: 58.9737 - val_mse: 19617.6504 - 725ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1163.9352 - mse: 13206048.0000 - val_loss: 46.4335 - val_mse: 12707.6924 - 715ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 1127.3817 - mse: 13204068.0000 - val_loss: 44.7624 - val_mse: 11800.1758 - 720ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1090.6626 - mse: 11391353.0000 - val_loss: 44.3382 - val_mse: 11454.1104 - 717ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1093.7611 - mse: 11248042.0000 - val_loss: 50.5991 - val_mse: 14148.7646 - 717ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1033.8030 - mse: 10493467.0000 - val_loss: 48.3739 - val_mse: 12381.4131 - 729ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1060.9464 - mse: 11884754.0000 - val_loss: 43.3832 - val_mse: 9815.3545 - 710ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 1050.7589 - mse: 11544702.0000 - val_loss: 42.4792 - val_mse: 9426.7031 - 713ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 1021.6547 - mse: 11821510.0000 - val_loss: 42.5924 - val_mse: 9541.5713 - 724ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1054.5594 - mse: 11929776.0000 - val_loss: 45.1263 - val_mse: 10852.4180 - 725ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 992.7257 - mse: 9290339.0000 - val_loss: 43.0773 - val_mse: 9952.1426 - 716ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1002.5035 - mse: 10892412.0000 - val_loss: 39.1828 - val_mse: 8266.4268 - 746ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 1019.9297 - mse: 12498811.0000 - val_loss: 32.3876 - val_mse: 5538.1968 - 754ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 937.7759 - mse: 7844721.0000 - val_loss: 32.0876 - val_mse: 5465.8896 - 756ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 941.0260 - mse: 8550102.0000 - val_loss: 27.0513 - val_mse: 3885.6226 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 986.1271 - mse: 9626158.0000 - val_loss: 21.8774 - val_mse: 2571.6921 - 717ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 941.0101 - mse: 8436987.0000 - val_loss: 25.9241 - val_mse: 3589.7468 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 929.8920 - mse: 7864831.0000 - val_loss: 31.7464 - val_mse: 5433.6899 - 727ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 915.4283 - mse: 7934220.0000 - val_loss: 30.8532 - val_mse: 5028.5425 - 712ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 942.7358 - mse: 8831173.0000 - val_loss: 30.2295 - val_mse: 4822.1758 - 710ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 865.3741 - mse: 7372885.5000 - val_loss: 33.0279 - val_mse: 5732.1357 - 729ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 895.2888 - mse: 8058321.5000 - val_loss: 34.9096 - val_mse: 6373.5679 - 735ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 891.6108 - mse: 8765585.0000 - val_loss: 35.0150 - val_mse: 6775.9922 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 855.9297 - mse: 8328170.0000 - val_loss: 33.2682 - val_mse: 5932.0889 - 734ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 868.2964 - mse: 7423044.0000 - val_loss: 35.4778 - val_mse: 6893.6094 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 827.5966 - mse: 6862392.0000 - val_loss: 34.5546 - val_mse: 6628.0679 - 748ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 840.0318 - mse: 6517401.5000 - val_loss: 34.7679 - val_mse: 6680.2661 - 744ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 792.2180 - mse: 6493840.0000 - val_loss: 35.4604 - val_mse: 6978.5073 - 773ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 805.8714 - mse: 7136000.0000 - val_loss: 38.3393 - val_mse: 8098.7036 - 747ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 842.3253 - mse: 7799751.0000 - val_loss: 36.5459 - val_mse: 7391.8374 - 792ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 779.1337 - mse: 6620428.5000 - val_loss: 36.5449 - val_mse: 7359.2979 - 749ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 790.2531 - mse: 6912592.0000 - val_loss: 36.4753 - val_mse: 7348.4048 - 732ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 731.4454 - mse: 4976466.5000 - val_loss: 37.4520 - val_mse: 7647.1240 - 732ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 772.5910 - mse: 5718478.0000 - val_loss: 36.1428 - val_mse: 7032.7710 - 733ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 755.8499 - mse: 5769683.5000 - val_loss: 34.6529 - val_mse: 6430.6104 - 732ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 710.1780 - mse: 4626529.0000 - val_loss: 30.5352 - val_mse: 5108.9663 - 723ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 707.4324 - mse: 4700357.5000 - val_loss: 28.8134 - val_mse: 4599.8179 - 742ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 726.1385 - mse: 6044005.5000 - val_loss: 25.7081 - val_mse: 3691.8511 - 745ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 758.3799 - mse: 5909000.5000 - val_loss: 27.9080 - val_mse: 4217.9277 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 689.3677 - mse: 4884127.0000 - val_loss: 30.6469 - val_mse: 5020.2241 - 750ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 695.0186 - mse: 4731521.0000 - val_loss: 27.0908 - val_mse: 3922.7566 - 729ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 697.0908 - mse: 4754262.0000 - val_loss: 25.6671 - val_mse: 3612.9978 - 743ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 676.8164 - mse: 5149477.5000 - val_loss: 24.4329 - val_mse: 3266.9485 - 760ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 667.6339 - mse: 4158715.5000 - val_loss: 25.0271 - val_mse: 3394.1125 - 760ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 656.8898 - mse: 4243418.0000 - val_loss: 25.0774 - val_mse: 3367.3757 - 771ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 656.0269 - mse: 4525641.5000 - val_loss: 23.8923 - val_mse: 3057.5559 - 730ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 650.7433 - mse: 4316005.5000 - val_loss: 23.9689 - val_mse: 3073.4324 - 735ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 629.7333 - mse: 4317423.5000 - val_loss: 21.2622 - val_mse: 2456.9131 - 730ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 636.5105 - mse: 4156555.7500 - val_loss: 22.5869 - val_mse: 2743.9290 - 733ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 619.1458 - mse: 3836239.7500 - val_loss: 20.3983 - val_mse: 2279.1780 - 750ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 626.1277 - mse: 4183721.0000 - val_loss: 20.6450 - val_mse: 2307.1477 - 730ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 598.1218 - mse: 3244058.5000 - val_loss: 20.8806 - val_mse: 2395.5354 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 626.0929 - mse: 3848755.5000 - val_loss: 21.0545 - val_mse: 2439.2827 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 585.8077 - mse: 3337996.0000 - val_loss: 19.9219 - val_mse: 2200.7297 - 728ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 585.7294 - mse: 3327542.5000 - val_loss: 18.3771 - val_mse: 1898.7117 - 718ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 579.3624 - mse: 3437056.5000 - val_loss: 21.5801 - val_mse: 2642.8799 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 597.0919 - mse: 3904289.0000 - val_loss: 19.1770 - val_mse: 2108.9221 - 716ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 546.9829 - mse: 3269845.0000 - val_loss: 15.1241 - val_mse: 1304.3365 - 749ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 568.1979 - mse: 3202190.7500 - val_loss: 15.5551 - val_mse: 1414.3279 - 754ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 563.8038 - mse: 3347623.2500 - val_loss: 19.8709 - val_mse: 2225.2214 - 758ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 535.5377 - mse: 2747916.0000 - val_loss: 20.4764 - val_mse: 2355.1172 - 758ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 536.3840 - mse: 3001120.0000 - val_loss: 23.3823 - val_mse: 3036.4143 - 758ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 532.6512 - mse: 2502581.0000 - val_loss: 22.1466 - val_mse: 2721.4624 - 736ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 516.0547 - mse: 2504336.2500 - val_loss: 20.7724 - val_mse: 2384.1990 - 741ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 541.6328 - mse: 3242211.0000 - val_loss: 19.0543 - val_mse: 2019.8339 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 518.1539 - mse: 2674992.7500 - val_loss: 16.4965 - val_mse: 1520.2894 - 723ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 507.6107 - mse: 2768876.5000 - val_loss: 13.4609 - val_mse: 1044.4138 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 519.1110 - mse: 2849947.7500 - val_loss: 14.5437 - val_mse: 1210.8130 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 500.0571 - mse: 2527502.5000 - val_loss: 16.2406 - val_mse: 1502.5785 - 722ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 460.5838 - mse: 1955097.1250 - val_loss: 14.4839 - val_mse: 1213.7350 - 711ms/epoch - 4ms/step\n",
            "159/159 - 1s - loss: 482.4396 - mse: 2309843.5000 - val_loss: 13.2653 - val_mse: 1032.5892 - 719ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 474.7510 - mse: 2295934.0000 - val_loss: 11.8407 - val_mse: 833.5909 - 718ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 465.4294 - mse: 1980486.1250 - val_loss: 9.2341 - val_mse: 527.2563 - 718ms/epoch - 5ms/step\n",
            "159/159 - 1s - loss: 479.1154 - mse: 2330816.0000 - val_loss: 8.2451 - val_mse: 433.2740 - 750ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 175 ended. Search finished for the next optimal point.\n",
            "Time taken: 90.4060\n",
            "Function value obtained: 433.2740\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 176 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [45, 111]\n",
            "Learning Rate: 6.520425395737839e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4857150205626736\n",
            "Batch Size: 60\n",
            "----------------------------------------\n",
            "140/140 - 3s - loss: 3249.9785 - mse: 102151696.0000 - val_loss: 1193.3815 - val_mse: 7297725.5000 - 3s/epoch - 21ms/step\n",
            "140/140 - 1s - loss: 2912.7708 - mse: 83343536.0000 - val_loss: 970.3535 - val_mse: 4828088.5000 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2778.8386 - mse: 87878056.0000 - val_loss: 792.5590 - val_mse: 3223390.7500 - 636ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2578.2253 - mse: 67810176.0000 - val_loss: 645.6713 - val_mse: 2144922.7500 - 609ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2417.0793 - mse: 63227208.0000 - val_loss: 519.7040 - val_mse: 1392678.7500 - 623ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2425.5515 - mse: 70684088.0000 - val_loss: 419.2336 - val_mse: 907404.3125 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2254.3511 - mse: 51892368.0000 - val_loss: 339.2990 - val_mse: 596458.3125 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2110.4695 - mse: 41344248.0000 - val_loss: 282.0904 - val_mse: 412515.5000 - 652ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1982.8124 - mse: 41406628.0000 - val_loss: 238.4865 - val_mse: 295386.0625 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2000.7688 - mse: 39946512.0000 - val_loss: 199.0508 - val_mse: 205373.5938 - 657ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1994.9309 - mse: 41342468.0000 - val_loss: 180.8322 - val_mse: 169888.8125 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1905.3038 - mse: 38863044.0000 - val_loss: 167.7869 - val_mse: 145936.7344 - 614ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1812.9813 - mse: 32468444.0000 - val_loss: 165.2406 - val_mse: 141313.8125 - 623ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1777.5140 - mse: 31402974.0000 - val_loss: 147.2684 - val_mse: 112285.6484 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1782.9503 - mse: 31071870.0000 - val_loss: 143.6076 - val_mse: 106731.1328 - 622ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1728.0625 - mse: 30451850.0000 - val_loss: 132.3213 - val_mse: 90457.2812 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1707.2478 - mse: 29957670.0000 - val_loss: 130.2484 - val_mse: 87503.9766 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1705.3619 - mse: 32013582.0000 - val_loss: 123.2829 - val_mse: 78336.1250 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1630.6173 - mse: 29045366.0000 - val_loss: 113.4010 - val_mse: 66005.5547 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1589.7435 - mse: 24171184.0000 - val_loss: 113.1690 - val_mse: 66732.9375 - 638ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1589.0734 - mse: 24907560.0000 - val_loss: 105.5575 - val_mse: 58349.2656 - 625ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1598.1334 - mse: 24712600.0000 - val_loss: 93.9152 - val_mse: 46311.9336 - 640ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1542.2842 - mse: 22768556.0000 - val_loss: 82.9582 - val_mse: 36518.4102 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1479.0349 - mse: 22540462.0000 - val_loss: 76.9334 - val_mse: 31826.6523 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1531.6464 - mse: 23743074.0000 - val_loss: 66.3549 - val_mse: 23849.3418 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1425.1510 - mse: 18965534.0000 - val_loss: 58.3805 - val_mse: 18433.8789 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1487.1683 - mse: 23000790.0000 - val_loss: 50.6925 - val_mse: 13717.3721 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1449.3252 - mse: 21478476.0000 - val_loss: 47.2631 - val_mse: 11865.2178 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1418.9888 - mse: 21679720.0000 - val_loss: 39.8358 - val_mse: 8468.7939 - 618ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1365.6631 - mse: 17584368.0000 - val_loss: 33.5942 - val_mse: 5872.6587 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1355.5187 - mse: 19096972.0000 - val_loss: 32.3532 - val_mse: 5244.1064 - 630ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1339.5287 - mse: 16825968.0000 - val_loss: 32.1915 - val_mse: 6080.2017 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1370.5519 - mse: 18492740.0000 - val_loss: 26.6390 - val_mse: 4659.2222 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1295.1987 - mse: 17764082.0000 - val_loss: 28.0630 - val_mse: 5043.6201 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1330.1602 - mse: 19109066.0000 - val_loss: 22.1322 - val_mse: 3329.9021 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1290.2627 - mse: 16696878.0000 - val_loss: 11.9850 - val_mse: 1198.6404 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1225.8098 - mse: 14362727.0000 - val_loss: 7.3404 - val_mse: 557.8497 - 633ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1240.6666 - mse: 15154319.0000 - val_loss: 2.3206 - val_mse: 36.1192 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1252.7965 - mse: 17861908.0000 - val_loss: 2.9989 - val_mse: 28.5678 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1184.2953 - mse: 13372148.0000 - val_loss: 2.4399 - val_mse: 20.7259 - 630ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1176.4330 - mse: 14399594.0000 - val_loss: 1.9842 - val_mse: 15.7246 - 635ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1190.4280 - mse: 15789662.0000 - val_loss: 3.0417 - val_mse: 29.5295 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1128.6121 - mse: 14438437.0000 - val_loss: 2.4922 - val_mse: 22.0012 - 651ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1124.4720 - mse: 12424572.0000 - val_loss: 6.7580 - val_mse: 164.8418 - 654ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1159.7494 - mse: 12404684.0000 - val_loss: 11.1498 - val_mse: 577.0709 - 659ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1092.3798 - mse: 11985414.0000 - val_loss: 11.4125 - val_mse: 639.3613 - 679ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1100.3772 - mse: 12471571.0000 - val_loss: 12.9823 - val_mse: 798.4839 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1086.2891 - mse: 11321441.0000 - val_loss: 11.4287 - val_mse: 624.4788 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1091.3773 - mse: 13892930.0000 - val_loss: 15.0560 - val_mse: 1089.6511 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1086.1559 - mse: 11196812.0000 - val_loss: 18.3299 - val_mse: 1916.3438 - 638ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1010.0149 - mse: 9802488.0000 - val_loss: 19.6130 - val_mse: 2602.1372 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1022.0729 - mse: 10240384.0000 - val_loss: 15.7543 - val_mse: 1538.6825 - 625ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1024.1713 - mse: 10220111.0000 - val_loss: 15.7142 - val_mse: 1532.3007 - 633ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1005.6852 - mse: 10660006.0000 - val_loss: 14.8886 - val_mse: 1389.2157 - 625ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1064.6504 - mse: 13481394.0000 - val_loss: 16.7943 - val_mse: 1738.7166 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 966.7003 - mse: 10776191.0000 - val_loss: 16.6173 - val_mse: 1717.1921 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 920.7802 - mse: 7292703.0000 - val_loss: 17.6027 - val_mse: 1927.7866 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 995.3299 - mse: 9964893.0000 - val_loss: 18.4370 - val_mse: 2099.7905 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 964.3439 - mse: 9137893.0000 - val_loss: 16.1512 - val_mse: 1650.3234 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 957.8284 - mse: 9650145.0000 - val_loss: 13.3637 - val_mse: 1112.9235 - 630ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 983.3939 - mse: 15164328.0000 - val_loss: 12.0486 - val_mse: 853.2294 - 659ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 958.7086 - mse: 10542139.0000 - val_loss: 12.1693 - val_mse: 896.2240 - 677ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 897.3923 - mse: 9142787.0000 - val_loss: 13.7034 - val_mse: 1142.1543 - 666ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 884.4044 - mse: 7746931.5000 - val_loss: 12.4685 - val_mse: 931.7010 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 916.7902 - mse: 9406881.0000 - val_loss: 10.2005 - val_mse: 562.3337 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 918.0300 - mse: 9637118.0000 - val_loss: 9.9305 - val_mse: 469.9095 - 651ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 874.7697 - mse: 8257034.5000 - val_loss: 10.1270 - val_mse: 460.3843 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 843.2527 - mse: 7126694.0000 - val_loss: 13.2785 - val_mse: 730.3018 - 646ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 847.2347 - mse: 6636433.5000 - val_loss: 15.2265 - val_mse: 999.3041 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 845.0919 - mse: 7388379.0000 - val_loss: 17.5141 - val_mse: 1321.4124 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 815.2087 - mse: 6979315.5000 - val_loss: 18.3845 - val_mse: 1442.2406 - 640ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 796.5261 - mse: 5863034.0000 - val_loss: 18.4758 - val_mse: 1444.8638 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 840.3906 - mse: 7430281.0000 - val_loss: 18.7579 - val_mse: 1484.2057 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 784.2816 - mse: 6836809.5000 - val_loss: 17.7164 - val_mse: 1313.9823 - 658ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 757.6307 - mse: 5970705.5000 - val_loss: 21.9247 - val_mse: 2134.3347 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 783.1378 - mse: 6117923.0000 - val_loss: 22.4636 - val_mse: 2283.2793 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 789.0796 - mse: 6571855.0000 - val_loss: 20.0543 - val_mse: 1779.5315 - 681ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 761.0480 - mse: 5734372.0000 - val_loss: 19.2640 - val_mse: 1634.7601 - 644ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 762.3373 - mse: 5894616.5000 - val_loss: 18.4574 - val_mse: 1493.9719 - 660ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 732.2878 - mse: 5055916.0000 - val_loss: 19.5421 - val_mse: 1712.1539 - 646ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 741.6543 - mse: 5600196.5000 - val_loss: 21.3418 - val_mse: 2173.2017 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 756.9263 - mse: 6554502.0000 - val_loss: 22.1434 - val_mse: 2424.7900 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 714.9063 - mse: 5212841.5000 - val_loss: 21.5380 - val_mse: 2293.5288 - 630ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 705.7101 - mse: 4761124.0000 - val_loss: 20.4225 - val_mse: 2041.9304 - 635ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 704.4310 - mse: 5263006.0000 - val_loss: 16.9696 - val_mse: 1394.0172 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 745.5423 - mse: 5541432.5000 - val_loss: 18.6854 - val_mse: 1713.8275 - 623ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 693.1420 - mse: 4260380.0000 - val_loss: 19.1724 - val_mse: 1843.1329 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 649.7664 - mse: 4088381.2500 - val_loss: 18.0826 - val_mse: 1634.2560 - 610ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 668.3074 - mse: 4443270.0000 - val_loss: 19.6234 - val_mse: 1987.0867 - 639ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 674.7818 - mse: 4669112.0000 - val_loss: 19.9337 - val_mse: 2074.1040 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 690.5023 - mse: 5075203.0000 - val_loss: 18.8447 - val_mse: 1918.1287 - 646ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 646.4080 - mse: 4437292.5000 - val_loss: 17.0007 - val_mse: 1524.2839 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 635.1041 - mse: 4197323.5000 - val_loss: 17.2797 - val_mse: 1589.8389 - 623ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 634.6425 - mse: 3793942.5000 - val_loss: 17.9916 - val_mse: 1736.5350 - 661ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 648.5142 - mse: 4468081.0000 - val_loss: 18.5601 - val_mse: 1818.0549 - 651ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 650.8580 - mse: 4396590.0000 - val_loss: 16.6029 - val_mse: 1483.2325 - 653ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 589.9299 - mse: 3162915.7500 - val_loss: 16.2817 - val_mse: 1442.4801 - 679ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 620.2393 - mse: 4030396.0000 - val_loss: 16.3219 - val_mse: 1421.1830 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 592.9889 - mse: 3332898.7500 - val_loss: 15.9036 - val_mse: 1402.9060 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 604.2236 - mse: 3923052.2500 - val_loss: 17.7257 - val_mse: 1739.1300 - 624ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 176 ended. Search finished for the next optimal point.\n",
            "Time taken: 80.3904\n",
            "Function value obtained: 1739.1300\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 177 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 95]\n",
            "Learning Rate: 1.9431062870454007e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45534153980349334\n",
            "Batch Size: 59\n",
            "----------------------------------------\n",
            "143/143 - 3s - loss: 3778.1355 - mse: 143772960.0000 - val_loss: 342.9623 - val_mse: 572705.6875 - 3s/epoch - 21ms/step\n",
            "143/143 - 1s - loss: 3770.1572 - mse: 145638928.0000 - val_loss: 339.2948 - val_mse: 559898.8750 - 692ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3789.7136 - mse: 145762800.0000 - val_loss: 327.9479 - val_mse: 521684.1250 - 663ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3707.7612 - mse: 138483680.0000 - val_loss: 320.1630 - val_mse: 496076.5938 - 668ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3515.8708 - mse: 128066040.0000 - val_loss: 322.9428 - val_mse: 502113.6250 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3451.8906 - mse: 108179456.0000 - val_loss: 317.4258 - val_mse: 483840.4375 - 644ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3314.9885 - mse: 94058320.0000 - val_loss: 305.2242 - val_mse: 445733.3750 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3398.7393 - mse: 109205472.0000 - val_loss: 296.3777 - val_mse: 418693.7812 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3434.5757 - mse: 111421256.0000 - val_loss: 289.3690 - val_mse: 397628.8750 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3360.6201 - mse: 108634112.0000 - val_loss: 281.9948 - val_mse: 377372.9062 - 649ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3447.1245 - mse: 121902696.0000 - val_loss: 271.4605 - val_mse: 349150.0312 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3460.7397 - mse: 109896864.0000 - val_loss: 278.4611 - val_mse: 368608.8125 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3434.8682 - mse: 123328416.0000 - val_loss: 272.2522 - val_mse: 352304.5938 - 644ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3312.4758 - mse: 106051264.0000 - val_loss: 267.9486 - val_mse: 341706.2500 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3353.4299 - mse: 119577192.0000 - val_loss: 268.5593 - val_mse: 343632.8438 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3239.4531 - mse: 103684544.0000 - val_loss: 268.3687 - val_mse: 343332.6875 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3193.2583 - mse: 87975920.0000 - val_loss: 259.6111 - val_mse: 320829.8438 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3090.7268 - mse: 93672280.0000 - val_loss: 249.9879 - val_mse: 296947.9062 - 689ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3279.7747 - mse: 102544176.0000 - val_loss: 245.7331 - val_mse: 286754.7188 - 685ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3238.5042 - mse: 102920984.0000 - val_loss: 242.3761 - val_mse: 278604.8125 - 683ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3114.9038 - mse: 97987536.0000 - val_loss: 235.4168 - val_mse: 262294.8750 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3177.1218 - mse: 110920088.0000 - val_loss: 232.4208 - val_mse: 255366.3438 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3110.2900 - mse: 94313032.0000 - val_loss: 236.0484 - val_mse: 263743.7188 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3096.5798 - mse: 107597112.0000 - val_loss: 226.9684 - val_mse: 243263.1406 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 3190.0542 - mse: 110811392.0000 - val_loss: 214.6464 - val_mse: 216655.3281 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2921.4155 - mse: 73271664.0000 - val_loss: 211.2289 - val_mse: 209571.8906 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2957.8884 - mse: 79828848.0000 - val_loss: 208.4104 - val_mse: 203542.0469 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2860.6296 - mse: 68892920.0000 - val_loss: 205.8594 - val_mse: 198643.9531 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2937.9565 - mse: 77889264.0000 - val_loss: 196.6897 - val_mse: 181256.5469 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2840.5613 - mse: 73898912.0000 - val_loss: 182.8427 - val_mse: 156358.3281 - 650ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2850.2961 - mse: 78424128.0000 - val_loss: 187.4235 - val_mse: 164288.4531 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2938.2632 - mse: 85128584.0000 - val_loss: 184.8093 - val_mse: 159797.1562 - 652ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2805.0483 - mse: 72704808.0000 - val_loss: 178.6042 - val_mse: 149336.3438 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2870.5798 - mse: 85679760.0000 - val_loss: 167.3555 - val_mse: 130306.2734 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2863.0640 - mse: 84156640.0000 - val_loss: 164.1531 - val_mse: 125408.2812 - 686ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2727.8188 - mse: 67370216.0000 - val_loss: 156.7029 - val_mse: 113591.2344 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2874.3462 - mse: 80055632.0000 - val_loss: 146.3418 - val_mse: 98694.1953 - 691ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2726.3979 - mse: 73214776.0000 - val_loss: 140.5977 - val_mse: 90809.6719 - 700ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2782.4490 - mse: 75424184.0000 - val_loss: 126.8153 - val_mse: 73230.0938 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2802.1238 - mse: 77846712.0000 - val_loss: 121.0050 - val_mse: 66436.8047 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2787.6704 - mse: 79457976.0000 - val_loss: 117.2730 - val_mse: 62280.5547 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2883.7688 - mse: 87699080.0000 - val_loss: 112.9377 - val_mse: 57543.0703 - 661ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2556.9382 - mse: 56439828.0000 - val_loss: 102.3886 - val_mse: 46940.8906 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2878.9050 - mse: 98596824.0000 - val_loss: 100.9863 - val_mse: 45606.1758 - 658ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2767.9128 - mse: 74438200.0000 - val_loss: 98.1360 - val_mse: 42946.4922 - 655ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2611.4814 - mse: 60906284.0000 - val_loss: 97.7904 - val_mse: 42621.0781 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2778.0813 - mse: 89764136.0000 - val_loss: 92.4738 - val_mse: 37943.3945 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2643.8965 - mse: 71677104.0000 - val_loss: 92.1175 - val_mse: 37609.8711 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2641.7937 - mse: 65269568.0000 - val_loss: 89.2888 - val_mse: 35198.0156 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2677.5864 - mse: 80841872.0000 - val_loss: 78.9539 - val_mse: 27138.6191 - 660ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2658.1946 - mse: 67303184.0000 - val_loss: 83.3640 - val_mse: 30429.7461 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2690.1223 - mse: 73925152.0000 - val_loss: 80.5359 - val_mse: 28280.1367 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2594.4268 - mse: 76010568.0000 - val_loss: 78.2598 - val_mse: 26645.7695 - 698ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2652.6443 - mse: 69639888.0000 - val_loss: 71.7563 - val_mse: 22162.5273 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2529.6953 - mse: 65982780.0000 - val_loss: 64.5453 - val_mse: 17808.8027 - 693ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2559.8467 - mse: 60114160.0000 - val_loss: 59.5488 - val_mse: 15290.4590 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2566.4541 - mse: 65874808.0000 - val_loss: 59.3997 - val_mse: 15180.8730 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2584.7915 - mse: 67421592.0000 - val_loss: 55.1966 - val_mse: 13172.7891 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2513.0388 - mse: 53322740.0000 - val_loss: 53.2181 - val_mse: 12150.0713 - 688ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2596.3025 - mse: 66703044.0000 - val_loss: 50.2495 - val_mse: 11037.2373 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2552.4404 - mse: 68805496.0000 - val_loss: 47.0244 - val_mse: 9798.2002 - 705ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2514.4453 - mse: 69829776.0000 - val_loss: 44.2014 - val_mse: 8678.2510 - 677ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2490.2029 - mse: 59264724.0000 - val_loss: 43.6844 - val_mse: 8538.5879 - 683ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2515.9072 - mse: 67631088.0000 - val_loss: 41.4530 - val_mse: 7680.8213 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2462.9702 - mse: 57827512.0000 - val_loss: 44.8755 - val_mse: 8673.8477 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2494.9536 - mse: 58919908.0000 - val_loss: 43.0719 - val_mse: 8071.2534 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2466.6880 - mse: 55175984.0000 - val_loss: 41.7944 - val_mse: 7607.7910 - 668ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2450.9011 - mse: 62259548.0000 - val_loss: 39.2853 - val_mse: 6748.7266 - 683ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2395.7024 - mse: 52363452.0000 - val_loss: 37.3069 - val_mse: 6192.7554 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2456.1255 - mse: 55691680.0000 - val_loss: 35.6504 - val_mse: 5655.3560 - 689ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2447.9988 - mse: 63373684.0000 - val_loss: 33.9093 - val_mse: 5173.9004 - 690ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2401.6599 - mse: 56356904.0000 - val_loss: 35.7330 - val_mse: 5317.5889 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2378.0840 - mse: 50587204.0000 - val_loss: 39.8576 - val_mse: 6286.2017 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2313.4565 - mse: 50303488.0000 - val_loss: 38.1442 - val_mse: 5741.3716 - 651ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2395.2686 - mse: 58737160.0000 - val_loss: 36.2391 - val_mse: 5204.0098 - 638ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2365.2727 - mse: 54151332.0000 - val_loss: 37.1359 - val_mse: 5373.7109 - 642ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2412.8933 - mse: 54292616.0000 - val_loss: 37.8766 - val_mse: 5555.0225 - 646ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2356.9844 - mse: 57572416.0000 - val_loss: 33.4717 - val_mse: 4398.5400 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2443.4834 - mse: 65545364.0000 - val_loss: 32.7426 - val_mse: 4218.0542 - 654ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2335.1299 - mse: 56459948.0000 - val_loss: 30.1965 - val_mse: 3639.5969 - 637ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2250.8518 - mse: 46169204.0000 - val_loss: 29.9757 - val_mse: 3556.3218 - 634ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2250.9336 - mse: 42850744.0000 - val_loss: 32.7576 - val_mse: 4197.9033 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2309.0476 - mse: 52726072.0000 - val_loss: 30.7901 - val_mse: 3766.4919 - 639ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2295.4346 - mse: 52843096.0000 - val_loss: 33.0845 - val_mse: 4268.7397 - 634ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2420.2019 - mse: 54708640.0000 - val_loss: 31.9068 - val_mse: 3967.8049 - 653ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2285.6929 - mse: 50518708.0000 - val_loss: 31.6225 - val_mse: 3904.0530 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2174.5857 - mse: 45006000.0000 - val_loss: 31.0160 - val_mse: 3744.3914 - 669ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2217.6816 - mse: 49791200.0000 - val_loss: 31.7493 - val_mse: 3865.6841 - 682ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2231.0610 - mse: 46443464.0000 - val_loss: 33.0880 - val_mse: 4132.6318 - 668ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2151.6387 - mse: 48340292.0000 - val_loss: 29.9005 - val_mse: 3475.1096 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2230.8472 - mse: 50479088.0000 - val_loss: 27.7133 - val_mse: 3025.1958 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2289.6416 - mse: 58134188.0000 - val_loss: 27.4336 - val_mse: 2911.3811 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 2223.5706 - mse: 55943164.0000 - val_loss: 27.9467 - val_mse: 3023.3291 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2249.3203 - mse: 49954244.0000 - val_loss: 29.3473 - val_mse: 3207.4971 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2191.3362 - mse: 49492916.0000 - val_loss: 28.3431 - val_mse: 2940.4229 - 653ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2242.0037 - mse: 52426716.0000 - val_loss: 28.7624 - val_mse: 3008.5979 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2215.5266 - mse: 50728508.0000 - val_loss: 27.9210 - val_mse: 2847.6287 - 658ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2166.3540 - mse: 47081708.0000 - val_loss: 27.2530 - val_mse: 2756.0132 - 650ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2155.5588 - mse: 44789500.0000 - val_loss: 27.1133 - val_mse: 2725.5527 - 652ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 2157.3547 - mse: 45660900.0000 - val_loss: 26.7908 - val_mse: 2703.8940 - 649ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 177 ended. Search finished for the next optimal point.\n",
            "Time taken: 82.4051\n",
            "Function value obtained: 2703.8940\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 178 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [76, 86]\n",
            "Learning Rate: 0.00017103442384499345\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.1575801970916635\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 510.5936 - mse: 2482356.0000 - val_loss: 4.2872 - val_mse: 76.7958 - 3s/epoch - 77ms/step\n",
            "33/33 - 0s - loss: 286.5461 - mse: 867592.6250 - val_loss: 9.4634 - val_mse: 468.2697 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 255.0160 - mse: 760460.6250 - val_loss: 6.9424 - val_mse: 291.3297 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 225.6892 - mse: 547952.0625 - val_loss: 10.1307 - val_mse: 579.2708 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 194.5601 - mse: 370641.8750 - val_loss: 6.4418 - val_mse: 249.4110 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 178.6793 - mse: 411086.1562 - val_loss: 10.9312 - val_mse: 754.7324 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 152.3946 - mse: 223475.6875 - val_loss: 2.8379 - val_mse: 57.9760 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 142.2940 - mse: 196072.1094 - val_loss: 5.9261 - val_mse: 172.5680 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 122.1373 - mse: 124871.5234 - val_loss: 2.6415 - val_mse: 51.3246 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 118.2066 - mse: 154643.9375 - val_loss: 3.0080 - val_mse: 63.1481 - 226ms/epoch - 7ms/step\n",
            "33/33 - 1s - loss: 102.3776 - mse: 114302.3984 - val_loss: 0.5463 - val_mse: 1.7393 - 748ms/epoch - 23ms/step\n",
            "33/33 - 0s - loss: 92.2452 - mse: 88517.3594 - val_loss: 0.4730 - val_mse: 1.3047 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 87.5353 - mse: 80047.5312 - val_loss: 2.2833 - val_mse: 26.2053 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 76.7681 - mse: 53125.8125 - val_loss: 1.5243 - val_mse: 18.8845 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 70.1819 - mse: 49272.7383 - val_loss: 11.1265 - val_mse: 725.5897 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 64.2088 - mse: 46925.6133 - val_loss: 0.5955 - val_mse: 2.1761 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 61.1442 - mse: 41948.2305 - val_loss: 1.9931 - val_mse: 22.8686 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 55.7842 - mse: 34032.4648 - val_loss: 2.9760 - val_mse: 44.8795 - 256ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 51.4295 - mse: 25956.6211 - val_loss: 7.8686 - val_mse: 315.0541 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 48.1883 - mse: 25063.0137 - val_loss: 4.4135 - val_mse: 101.2015 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 41.3859 - mse: 18917.7891 - val_loss: 0.4496 - val_mse: 1.3040 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 41.9457 - mse: 22525.3613 - val_loss: 3.3834 - val_mse: 60.4195 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 35.4834 - mse: 13462.5186 - val_loss: 4.3586 - val_mse: 94.4869 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 34.3298 - mse: 12933.7832 - val_loss: 4.2562 - val_mse: 100.4017 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 32.5757 - mse: 12106.5674 - val_loss: 1.6551 - val_mse: 15.2506 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 28.7299 - mse: 9909.6885 - val_loss: 2.8157 - val_mse: 43.1521 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 28.3213 - mse: 9152.1191 - val_loss: 1.3947 - val_mse: 11.7309 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 26.0212 - mse: 7194.1880 - val_loss: 0.5118 - val_mse: 1.5029 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 24.0385 - mse: 8049.2881 - val_loss: 1.1802 - val_mse: 7.7206 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 22.1827 - mse: 6499.1313 - val_loss: 0.6093 - val_mse: 1.7630 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 19.7848 - mse: 4465.5093 - val_loss: 0.9099 - val_mse: 4.9703 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 19.5549 - mse: 4693.4287 - val_loss: 1.0094 - val_mse: 5.4518 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 18.3459 - mse: 4698.3164 - val_loss: 0.2143 - val_mse: 0.4286 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 17.9329 - mse: 4634.6011 - val_loss: 0.6617 - val_mse: 2.3262 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 16.3908 - mse: 3633.8372 - val_loss: 0.3654 - val_mse: 0.7939 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 14.6609 - mse: 2370.5500 - val_loss: 0.5930 - val_mse: 1.6918 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 14.8538 - mse: 3300.2156 - val_loss: 0.6275 - val_mse: 2.0063 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 13.1567 - mse: 2717.8318 - val_loss: 0.2242 - val_mse: 0.4484 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 12.2297 - mse: 1771.0808 - val_loss: 0.3163 - val_mse: 0.6507 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 11.1968 - mse: 1772.0341 - val_loss: 0.2925 - val_mse: 0.7086 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 9.9919 - mse: 1223.7129 - val_loss: 0.2370 - val_mse: 0.5160 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 10.4405 - mse: 1734.2616 - val_loss: 0.2692 - val_mse: 0.8548 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 9.3276 - mse: 1387.5417 - val_loss: 0.2507 - val_mse: 0.7449 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 8.4025 - mse: 996.5463 - val_loss: 0.1916 - val_mse: 0.4716 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 7.3617 - mse: 717.8847 - val_loss: 0.2934 - val_mse: 0.9925 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 7.0645 - mse: 828.1957 - val_loss: 0.1444 - val_mse: 0.3073 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 6.9874 - mse: 1055.9208 - val_loss: 0.2218 - val_mse: 0.6222 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 6.1306 - mse: 717.6005 - val_loss: 0.2188 - val_mse: 0.6128 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 5.6280 - mse: 532.0057 - val_loss: 0.1420 - val_mse: 0.3080 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 5.4848 - mse: 633.2101 - val_loss: 0.1157 - val_mse: 0.2325 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 4.8965 - mse: 471.8421 - val_loss: 0.1088 - val_mse: 0.2176 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 4.4637 - mse: 361.8583 - val_loss: 0.1064 - val_mse: 0.2128 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 4.2311 - mse: 410.6152 - val_loss: 0.1110 - val_mse: 0.2236 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 4.2292 - mse: 522.0063 - val_loss: 0.1035 - val_mse: 0.2070 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.6674 - mse: 285.4610 - val_loss: 0.0992 - val_mse: 0.1984 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.6046 - mse: 304.3479 - val_loss: 0.0992 - val_mse: 0.1984 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3.1717 - mse: 240.9610 - val_loss: 0.0943 - val_mse: 0.1886 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.8027 - mse: 166.2383 - val_loss: 0.0981 - val_mse: 0.1962 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.9749 - mse: 242.0172 - val_loss: 0.0942 - val_mse: 0.1884 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.5720 - mse: 183.2143 - val_loss: 0.0881 - val_mse: 0.1762 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.4194 - mse: 269.8272 - val_loss: 0.0848 - val_mse: 0.1695 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.1504 - mse: 131.1538 - val_loss: 0.0881 - val_mse: 0.1763 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2.2705 - mse: 156.5574 - val_loss: 0.0832 - val_mse: 0.1663 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.9915 - mse: 115.0388 - val_loss: 0.0813 - val_mse: 0.1626 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.8780 - mse: 174.7986 - val_loss: 0.0775 - val_mse: 0.1549 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.7925 - mse: 103.7854 - val_loss: 0.0773 - val_mse: 0.1545 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.6724 - mse: 129.5052 - val_loss: 0.0699 - val_mse: 0.1398 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.6937 - mse: 180.7859 - val_loss: 0.0695 - val_mse: 0.1390 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.5625 - mse: 122.1368 - val_loss: 0.0659 - val_mse: 0.1317 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.3494 - mse: 71.9963 - val_loss: 0.0754 - val_mse: 0.1508 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.3640 - mse: 94.9370 - val_loss: 0.0616 - val_mse: 0.1232 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.2616 - mse: 66.1950 - val_loss: 0.0600 - val_mse: 0.1200 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.3349 - mse: 100.1295 - val_loss: 0.0589 - val_mse: 0.1178 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.2108 - mse: 71.5075 - val_loss: 0.0564 - val_mse: 0.1128 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.0682 - mse: 64.1369 - val_loss: 0.0552 - val_mse: 0.1104 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1.0209 - mse: 57.8622 - val_loss: 0.0549 - val_mse: 0.1098 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.9782 - mse: 53.5189 - val_loss: 0.0511 - val_mse: 0.1022 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.9182 - mse: 49.8458 - val_loss: 0.0500 - val_mse: 0.1001 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.9663 - mse: 60.4295 - val_loss: 0.0480 - val_mse: 0.0961 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.8329 - mse: 51.9510 - val_loss: 0.0466 - val_mse: 0.0932 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.9130 - mse: 53.6355 - val_loss: 0.0453 - val_mse: 0.0907 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.7054 - mse: 54.7530 - val_loss: 0.0442 - val_mse: 0.0884 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6369 - mse: 30.4738 - val_loss: 0.0434 - val_mse: 0.0867 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.7765 - mse: 58.4333 - val_loss: 0.0412 - val_mse: 0.0824 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6377 - mse: 28.3116 - val_loss: 0.0408 - val_mse: 0.0816 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6501 - mse: 33.0740 - val_loss: 0.0386 - val_mse: 0.0771 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6177 - mse: 50.7925 - val_loss: 0.0374 - val_mse: 0.0749 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.5596 - mse: 23.8610 - val_loss: 0.0364 - val_mse: 0.0727 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.5140 - mse: 28.6690 - val_loss: 0.0352 - val_mse: 0.0703 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4708 - mse: 15.1746 - val_loss: 0.0342 - val_mse: 0.0684 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.6084 - mse: 98.8699 - val_loss: 0.0330 - val_mse: 0.0660 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4486 - mse: 18.2666 - val_loss: 0.0319 - val_mse: 0.0639 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.5089 - mse: 35.0724 - val_loss: 0.0312 - val_mse: 0.0623 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4554 - mse: 25.0672 - val_loss: 0.0300 - val_mse: 0.0600 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4307 - mse: 18.4430 - val_loss: 0.0292 - val_mse: 0.0584 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3607 - mse: 14.6047 - val_loss: 0.0282 - val_mse: 0.0564 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3929 - mse: 21.2474 - val_loss: 0.0274 - val_mse: 0.0548 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4279 - mse: 35.5255 - val_loss: 0.0264 - val_mse: 0.0529 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.2891 - mse: 12.4323 - val_loss: 0.0256 - val_mse: 0.0511 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3778 - mse: 19.0351 - val_loss: 0.0249 - val_mse: 0.0498 - 226ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 178 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.8930\n",
            "Function value obtained: 0.0498\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 179 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [94]\n",
            "Learning Rate: 1.152132396296407e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4407992809061658\n",
            "Batch Size: 58\n",
            "----------------------------------------\n",
            "145/145 - 2s - loss: 1787.2432 - mse: 32706486.0000 - val_loss: 559.0939 - val_mse: 1542403.3750 - 2s/epoch - 15ms/step\n",
            "145/145 - 1s - loss: 1626.9729 - mse: 25649196.0000 - val_loss: 336.3554 - val_mse: 555214.5625 - 597ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1507.9545 - mse: 23312754.0000 - val_loss: 199.9732 - val_mse: 196527.8438 - 602ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1446.8915 - mse: 22347778.0000 - val_loss: 79.2731 - val_mse: 29279.9531 - 610ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1367.0195 - mse: 18824086.0000 - val_loss: 15.2322 - val_mse: 1067.4058 - 583ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1351.1825 - mse: 18777958.0000 - val_loss: 62.3772 - val_mse: 22695.5742 - 581ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1344.8010 - mse: 21822650.0000 - val_loss: 103.3991 - val_mse: 58746.3359 - 580ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1235.1508 - mse: 13785034.0000 - val_loss: 132.7950 - val_mse: 94714.3047 - 583ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1261.0537 - mse: 15191780.0000 - val_loss: 141.4922 - val_mse: 106555.6797 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1221.4487 - mse: 12885512.0000 - val_loss: 136.3927 - val_mse: 98271.7266 - 611ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1191.1661 - mse: 13696885.0000 - val_loss: 152.5141 - val_mse: 119622.9766 - 602ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1173.6328 - mse: 13379923.0000 - val_loss: 150.1393 - val_mse: 115792.0312 - 606ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1173.3229 - mse: 13814562.0000 - val_loss: 150.6338 - val_mse: 117067.3906 - 589ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1098.5519 - mse: 9907765.0000 - val_loss: 138.9381 - val_mse: 100031.0078 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1084.5443 - mse: 11225582.0000 - val_loss: 138.5442 - val_mse: 99363.7109 - 590ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1095.6593 - mse: 10929816.0000 - val_loss: 141.7459 - val_mse: 103183.9297 - 581ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1041.2020 - mse: 9821227.0000 - val_loss: 143.8295 - val_mse: 105565.3438 - 589ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1090.4557 - mse: 11840815.0000 - val_loss: 145.6899 - val_mse: 107292.1875 - 591ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1091.3655 - mse: 11638476.0000 - val_loss: 140.1608 - val_mse: 100910.2031 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1081.3134 - mse: 13032478.0000 - val_loss: 122.8921 - val_mse: 78721.7422 - 581ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1065.6178 - mse: 11637561.0000 - val_loss: 129.5266 - val_mse: 86642.0547 - 575ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 994.9538 - mse: 10230048.0000 - val_loss: 115.7182 - val_mse: 70780.4141 - 579ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 982.3296 - mse: 8233477.0000 - val_loss: 94.1702 - val_mse: 47311.9219 - 587ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1005.4664 - mse: 8845387.0000 - val_loss: 107.9700 - val_mse: 61779.5625 - 591ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1015.7886 - mse: 9790525.0000 - val_loss: 107.2760 - val_mse: 60987.0234 - 591ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 977.3650 - mse: 9107216.0000 - val_loss: 113.5148 - val_mse: 67920.4766 - 592ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 999.5765 - mse: 9791261.0000 - val_loss: 104.8782 - val_mse: 58405.6641 - 590ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 975.3521 - mse: 8714249.0000 - val_loss: 95.6160 - val_mse: 48705.4961 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 948.4878 - mse: 8476374.0000 - val_loss: 76.4307 - val_mse: 31443.4473 - 619ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 950.3262 - mse: 9659777.0000 - val_loss: 61.4694 - val_mse: 20635.1113 - 630ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 947.7169 - mse: 9632195.0000 - val_loss: 56.9911 - val_mse: 17843.9082 - 624ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 913.5174 - mse: 7263727.5000 - val_loss: 49.8198 - val_mse: 13827.1201 - 586ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 948.1840 - mse: 9574007.0000 - val_loss: 52.0652 - val_mse: 14992.0664 - 589ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 914.1897 - mse: 8095784.5000 - val_loss: 58.4312 - val_mse: 18658.2949 - 614ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 909.8720 - mse: 8190680.0000 - val_loss: 52.9914 - val_mse: 15473.6348 - 619ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 876.8824 - mse: 7797606.5000 - val_loss: 51.0084 - val_mse: 14312.4121 - 618ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 884.8263 - mse: 7787536.5000 - val_loss: 71.4383 - val_mse: 27436.2383 - 630ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 842.0741 - mse: 7125453.5000 - val_loss: 53.9247 - val_mse: 15857.1543 - 604ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 884.9805 - mse: 7015782.0000 - val_loss: 53.2383 - val_mse: 15473.5586 - 603ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 848.8165 - mse: 6941706.0000 - val_loss: 42.4600 - val_mse: 10066.2461 - 615ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 856.3882 - mse: 6996794.0000 - val_loss: 39.4574 - val_mse: 8721.8252 - 621ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 845.4601 - mse: 7005578.5000 - val_loss: 36.6276 - val_mse: 7592.1758 - 605ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 829.1158 - mse: 6517078.0000 - val_loss: 25.1727 - val_mse: 3776.1963 - 626ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 815.9537 - mse: 6377831.0000 - val_loss: 20.8023 - val_mse: 2667.9780 - 618ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 820.0295 - mse: 6418686.0000 - val_loss: 20.3134 - val_mse: 2549.2380 - 603ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 780.5592 - mse: 6015932.0000 - val_loss: 14.4793 - val_mse: 1366.7223 - 635ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 811.3190 - mse: 6046223.0000 - val_loss: 13.6618 - val_mse: 1219.9474 - 664ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 806.4408 - mse: 6102289.5000 - val_loss: 4.2267 - val_mse: 108.2000 - 643ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 776.4683 - mse: 6465566.5000 - val_loss: 10.6075 - val_mse: 718.1746 - 628ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 792.7017 - mse: 5846473.0000 - val_loss: 12.2049 - val_mse: 957.7977 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 738.1516 - mse: 5092486.5000 - val_loss: 9.7633 - val_mse: 625.0557 - 616ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 756.4333 - mse: 5563465.5000 - val_loss: 4.7330 - val_mse: 140.0071 - 603ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 731.9091 - mse: 4641797.0000 - val_loss: 3.3635 - val_mse: 57.7913 - 625ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 750.9158 - mse: 5199556.5000 - val_loss: 3.4870 - val_mse: 70.6028 - 619ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 773.6362 - mse: 6913738.5000 - val_loss: 4.7395 - val_mse: 138.6273 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 736.4267 - mse: 5269096.5000 - val_loss: 3.6792 - val_mse: 60.7892 - 607ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 712.9786 - mse: 4839291.5000 - val_loss: 7.3885 - val_mse: 355.2109 - 615ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 709.4097 - mse: 4577078.0000 - val_loss: 3.7424 - val_mse: 60.3642 - 611ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 681.2226 - mse: 4025534.7500 - val_loss: 5.9680 - val_mse: 169.7511 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 704.0458 - mse: 5231055.0000 - val_loss: 4.3134 - val_mse: 95.4814 - 622ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 674.4247 - mse: 4243462.5000 - val_loss: 9.4561 - val_mse: 583.1411 - 608ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 672.1771 - mse: 3963121.0000 - val_loss: 8.0874 - val_mse: 424.1393 - 620ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 633.5682 - mse: 3813879.2500 - val_loss: 6.2693 - val_mse: 249.2796 - 627ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 677.7068 - mse: 5286652.0000 - val_loss: 4.6514 - val_mse: 97.5065 - 625ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 640.5894 - mse: 3517502.7500 - val_loss: 3.2158 - val_mse: 38.8349 - 636ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 647.9388 - mse: 4161514.5000 - val_loss: 4.3368 - val_mse: 80.6786 - 627ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 650.4286 - mse: 4475493.5000 - val_loss: 3.0756 - val_mse: 33.7437 - 641ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 647.6403 - mse: 4069626.0000 - val_loss: 2.9224 - val_mse: 31.8576 - 617ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 660.4230 - mse: 4487951.5000 - val_loss: 3.2981 - val_mse: 41.4540 - 614ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 594.3073 - mse: 3189822.5000 - val_loss: 7.1485 - val_mse: 257.0039 - 613ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 618.7639 - mse: 3451642.5000 - val_loss: 7.5494 - val_mse: 274.1999 - 614ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 609.4672 - mse: 3548718.2500 - val_loss: 7.2774 - val_mse: 246.3911 - 618ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 590.2137 - mse: 3017275.5000 - val_loss: 12.8002 - val_mse: 849.6568 - 618ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 608.4758 - mse: 3538993.2500 - val_loss: 12.4685 - val_mse: 803.9659 - 623ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 609.1990 - mse: 3598372.0000 - val_loss: 10.7231 - val_mse: 617.0010 - 616ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 577.9661 - mse: 3584075.7500 - val_loss: 10.9142 - val_mse: 653.1459 - 608ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 577.9330 - mse: 3144019.7500 - val_loss: 9.1459 - val_mse: 451.8113 - 614ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 605.0308 - mse: 3631126.0000 - val_loss: 5.8798 - val_mse: 169.6956 - 606ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 570.8998 - mse: 3514532.7500 - val_loss: 2.9491 - val_mse: 33.0981 - 607ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 579.6625 - mse: 3128748.2500 - val_loss: 3.0371 - val_mse: 40.0423 - 603ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 531.3862 - mse: 2634281.7500 - val_loss: 6.8770 - val_mse: 297.5687 - 600ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 556.3982 - mse: 3164428.0000 - val_loss: 3.0749 - val_mse: 44.7833 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 543.8585 - mse: 3269218.7500 - val_loss: 3.3716 - val_mse: 44.9943 - 617ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 530.6863 - mse: 2483551.0000 - val_loss: 3.2928 - val_mse: 44.6547 - 620ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 534.2954 - mse: 2705366.7500 - val_loss: 8.3990 - val_mse: 389.8798 - 614ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 496.9351 - mse: 2356887.0000 - val_loss: 7.5713 - val_mse: 305.1948 - 626ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 501.3453 - mse: 2384744.0000 - val_loss: 4.4607 - val_mse: 93.9565 - 603ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 513.5916 - mse: 2722431.5000 - val_loss: 3.1525 - val_mse: 40.8663 - 596ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 489.7505 - mse: 2100081.5000 - val_loss: 3.3367 - val_mse: 48.8174 - 592ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 507.0396 - mse: 2342023.2500 - val_loss: 5.9453 - val_mse: 226.7375 - 609ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 506.6825 - mse: 2856789.7500 - val_loss: 6.0297 - val_mse: 231.9936 - 609ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 474.3167 - mse: 2009975.3750 - val_loss: 3.9739 - val_mse: 94.0453 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 492.4465 - mse: 2397795.5000 - val_loss: 5.0444 - val_mse: 162.8100 - 604ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 469.7566 - mse: 2157884.0000 - val_loss: 6.1121 - val_mse: 239.1320 - 600ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 477.0712 - mse: 2131738.5000 - val_loss: 3.1275 - val_mse: 39.2666 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 466.3515 - mse: 2143170.2500 - val_loss: 7.0013 - val_mse: 251.4744 - 608ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 486.6620 - mse: 2589325.2500 - val_loss: 5.4828 - val_mse: 146.5515 - 598ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 463.9839 - mse: 1993190.1250 - val_loss: 3.9571 - val_mse: 95.7017 - 586ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 463.8161 - mse: 2317409.2500 - val_loss: 3.4238 - val_mse: 50.2954 - 591ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 437.5268 - mse: 1806016.2500 - val_loss: 2.3787 - val_mse: 21.1207 - 601ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 179 ended. Search finished for the next optimal point.\n",
            "Time taken: 77.1309\n",
            "Function value obtained: 21.1207\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 180 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [89, 84, 119]\n",
            "Learning Rate: 0.00047558029760797757\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.456129902886719\n",
            "Batch Size: 58\n",
            "----------------------------------------\n",
            "145/145 - 4s - loss: 792.7571 - mse: 8567333.0000 - val_loss: 14.0807 - val_mse: 999.7987 - 4s/epoch - 31ms/step\n",
            "145/145 - 1s - loss: 269.9991 - mse: 771837.3125 - val_loss: 2.1166 - val_mse: 36.1107 - 737ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 151.9067 - mse: 234551.3594 - val_loss: 0.7962 - val_mse: 5.3695 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 97.9357 - mse: 102772.0703 - val_loss: 0.2735 - val_mse: 0.6855 - 756ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 67.6694 - mse: 48074.1875 - val_loss: 0.1291 - val_mse: 0.2582 - 781ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 50.5712 - mse: 27434.0293 - val_loss: 0.2681 - val_mse: 0.6578 - 800ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 36.5397 - mse: 14355.5146 - val_loss: 0.1081 - val_mse: 0.2162 - 813ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 27.7972 - mse: 8904.0098 - val_loss: 0.0970 - val_mse: 0.1941 - 793ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 20.8061 - mse: 4699.7266 - val_loss: 0.0771 - val_mse: 0.1543 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 18.0180 - mse: 5328.0132 - val_loss: 0.0620 - val_mse: 0.1240 - 753ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 13.1276 - mse: 2080.5500 - val_loss: 0.0464 - val_mse: 0.0927 - 767ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 11.0409 - mse: 1951.2388 - val_loss: 0.0319 - val_mse: 0.0638 - 765ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 8.2276 - mse: 959.6011 - val_loss: 0.0239 - val_mse: 0.0478 - 762ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 6.7136 - mse: 667.1437 - val_loss: 0.0154 - val_mse: 0.0308 - 768ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 5.7585 - mse: 727.9029 - val_loss: 0.0117 - val_mse: 0.0234 - 757ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.4422 - mse: 386.0643 - val_loss: 0.0098 - val_mse: 0.0195 - 758ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 3.3304 - mse: 247.5974 - val_loss: 0.0087 - val_mse: 0.0174 - 747ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2.7019 - mse: 200.0513 - val_loss: 0.0084 - val_mse: 0.0167 - 738ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2.3346 - mse: 179.8557 - val_loss: 0.0084 - val_mse: 0.0168 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.8239 - mse: 80.5650 - val_loss: 0.0084 - val_mse: 0.0167 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.7089 - mse: 93.2379 - val_loss: 0.0084 - val_mse: 0.0167 - 771ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.6197 - mse: 102.8941 - val_loss: 0.0084 - val_mse: 0.0167 - 765ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.1354 - mse: 54.7291 - val_loss: 0.0084 - val_mse: 0.0167 - 778ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.0279 - mse: 53.6549 - val_loss: 0.0084 - val_mse: 0.0167 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1.0058 - mse: 68.3073 - val_loss: 0.0084 - val_mse: 0.0167 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.8676 - mse: 69.0655 - val_loss: 0.0084 - val_mse: 0.0167 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.7142 - mse: 58.4057 - val_loss: 0.0084 - val_mse: 0.0167 - 752ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.5343 - mse: 22.5963 - val_loss: 0.0084 - val_mse: 0.0167 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.5614 - mse: 21.1156 - val_loss: 0.0084 - val_mse: 0.0167 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.4529 - mse: 13.5456 - val_loss: 0.0084 - val_mse: 0.0167 - 761ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.3649 - mse: 17.1495 - val_loss: 0.0084 - val_mse: 0.0167 - 756ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.3203 - mse: 13.4683 - val_loss: 0.0084 - val_mse: 0.0167 - 746ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.3003 - mse: 10.5473 - val_loss: 0.0084 - val_mse: 0.0167 - 755ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.2614 - mse: 10.2824 - val_loss: 0.0084 - val_mse: 0.0167 - 752ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.2558 - mse: 10.7458 - val_loss: 0.0084 - val_mse: 0.0167 - 764ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.2143 - mse: 8.5992 - val_loss: 0.0084 - val_mse: 0.0167 - 788ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.2060 - mse: 7.9292 - val_loss: 0.0084 - val_mse: 0.0167 - 782ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1797 - mse: 6.1309 - val_loss: 0.0084 - val_mse: 0.0167 - 785ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1672 - mse: 5.2998 - val_loss: 0.0084 - val_mse: 0.0167 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1349 - mse: 3.2488 - val_loss: 0.0084 - val_mse: 0.0167 - 767ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1145 - mse: 3.0674 - val_loss: 0.0084 - val_mse: 0.0167 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1346 - mse: 2.9167 - val_loss: 0.0084 - val_mse: 0.0167 - 756ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0828 - mse: 1.8099 - val_loss: 0.0084 - val_mse: 0.0167 - 753ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1285 - mse: 4.0958 - val_loss: 0.0084 - val_mse: 0.0167 - 753ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0614 - mse: 0.4990 - val_loss: 0.0084 - val_mse: 0.0167 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1287 - mse: 5.0425 - val_loss: 0.0084 - val_mse: 0.0167 - 743ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.1002 - mse: 2.3342 - val_loss: 0.0084 - val_mse: 0.0167 - 740ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0650 - mse: 0.9808 - val_loss: 0.0084 - val_mse: 0.0167 - 780ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0749 - mse: 1.5128 - val_loss: 0.0084 - val_mse: 0.0167 - 757ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0788 - mse: 3.2116 - val_loss: 0.0084 - val_mse: 0.0168 - 771ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0657 - mse: 1.2313 - val_loss: 0.0084 - val_mse: 0.0168 - 796ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0442 - mse: 0.6002 - val_loss: 0.0084 - val_mse: 0.0167 - 802ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 0.0664 - mse: 4.1747 - val_loss: 0.0084 - val_mse: 0.0167 - 783ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0596 - mse: 1.2968 - val_loss: 0.0084 - val_mse: 0.0167 - 736ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0625 - mse: 3.0324 - val_loss: 0.0084 - val_mse: 0.0167 - 729ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0630 - mse: 3.5175 - val_loss: 0.0084 - val_mse: 0.0167 - 728ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0331 - mse: 0.2912 - val_loss: 0.0084 - val_mse: 0.0167 - 722ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0303 - mse: 0.2953 - val_loss: 0.0084 - val_mse: 0.0167 - 715ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0256 - mse: 0.1084 - val_loss: 0.0084 - val_mse: 0.0167 - 722ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0295 - mse: 0.2426 - val_loss: 0.0084 - val_mse: 0.0167 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0315 - mse: 0.4306 - val_loss: 0.0084 - val_mse: 0.0167 - 748ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0305 - mse: 0.4457 - val_loss: 0.0084 - val_mse: 0.0167 - 748ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0383 - mse: 0.7861 - val_loss: 0.0084 - val_mse: 0.0167 - 732ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0355 - mse: 0.5357 - val_loss: 0.0084 - val_mse: 0.0167 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0285 - mse: 0.5750 - val_loss: 0.0084 - val_mse: 0.0167 - 727ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0296 - mse: 0.5162 - val_loss: 0.0084 - val_mse: 0.0167 - 758ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0168 - mse: 0.0857 - val_loss: 0.0084 - val_mse: 0.0167 - 754ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0199 - mse: 0.1314 - val_loss: 0.0084 - val_mse: 0.0167 - 758ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0162 - mse: 0.1152 - val_loss: 0.0084 - val_mse: 0.0168 - 737ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0125 - mse: 0.0321 - val_loss: 0.0084 - val_mse: 0.0167 - 720ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0198 - mse: 0.2936 - val_loss: 0.0084 - val_mse: 0.0167 - 717ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0301 - mse: 0.5129 - val_loss: 0.0084 - val_mse: 0.0167 - 734ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0219 - mse: 0.3382 - val_loss: 0.0084 - val_mse: 0.0167 - 724ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0172 - mse: 0.1161 - val_loss: 0.0084 - val_mse: 0.0167 - 724ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0227 - mse: 0.4104 - val_loss: 0.0084 - val_mse: 0.0168 - 727ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0283 - mse: 0.5408 - val_loss: 0.0084 - val_mse: 0.0167 - 729ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0112 - mse: 0.0340 - val_loss: 0.0084 - val_mse: 0.0167 - 739ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0151 - mse: 0.1076 - val_loss: 0.0084 - val_mse: 0.0167 - 738ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0143 - mse: 0.0650 - val_loss: 0.0084 - val_mse: 0.0167 - 718ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0108 - mse: 0.0313 - val_loss: 0.0084 - val_mse: 0.0167 - 755ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0156 - mse: 0.1312 - val_loss: 0.0084 - val_mse: 0.0167 - 764ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 780ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0140 - mse: 0.0771 - val_loss: 0.0084 - val_mse: 0.0167 - 761ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0100 - mse: 0.0263 - val_loss: 0.0084 - val_mse: 0.0167 - 756ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0135 - mse: 0.1036 - val_loss: 0.0084 - val_mse: 0.0168 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0101 - mse: 0.0228 - val_loss: 0.0084 - val_mse: 0.0167 - 734ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0096 - mse: 0.0209 - val_loss: 0.0084 - val_mse: 0.0167 - 736ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0126 - mse: 0.0519 - val_loss: 0.0084 - val_mse: 0.0167 - 732ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0117 - mse: 0.0340 - val_loss: 0.0084 - val_mse: 0.0167 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0108 - mse: 0.0282 - val_loss: 0.0084 - val_mse: 0.0168 - 726ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0136 - mse: 0.0717 - val_loss: 0.0084 - val_mse: 0.0167 - 730ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0109 - mse: 0.0405 - val_loss: 0.0084 - val_mse: 0.0167 - 736ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0101 - mse: 0.0267 - val_loss: 0.0084 - val_mse: 0.0167 - 734ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0127 - mse: 0.0757 - val_loss: 0.0084 - val_mse: 0.0167 - 725ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0109 - mse: 0.0293 - val_loss: 0.0084 - val_mse: 0.0167 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0106 - mse: 0.0282 - val_loss: 0.0084 - val_mse: 0.0167 - 738ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0096 - mse: 0.0215 - val_loss: 0.0084 - val_mse: 0.0167 - 776ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0099 - mse: 0.0237 - val_loss: 0.0084 - val_mse: 0.0167 - 770ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0110 - mse: 0.0334 - val_loss: 0.0084 - val_mse: 0.0167 - 777ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 0.0142 - mse: 0.1227 - val_loss: 0.0084 - val_mse: 0.0167 - 739ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 180 ended. Search finished for the next optimal point.\n",
            "Time taken: 93.0280\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 181 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [67, 80]\n",
            "Learning Rate: 2.249071629544356e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4486717543137151\n",
            "Batch Size: 58\n",
            "----------------------------------------\n",
            "145/145 - 3s - loss: 2793.2549 - mse: 79336424.0000 - val_loss: 905.2786 - val_mse: 4135081.2500 - 3s/epoch - 21ms/step\n",
            "145/145 - 1s - loss: 2761.6340 - mse: 77864576.0000 - val_loss: 828.1512 - val_mse: 3460440.7500 - 697ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2566.2922 - mse: 64262672.0000 - val_loss: 758.2275 - val_mse: 2900335.7500 - 681ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2470.3970 - mse: 66881968.0000 - val_loss: 696.8920 - val_mse: 2449243.0000 - 693ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2517.9446 - mse: 65809452.0000 - val_loss: 635.1788 - val_mse: 2033719.6250 - 679ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2506.4883 - mse: 59779040.0000 - val_loss: 580.8107 - val_mse: 1699218.6250 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2240.4285 - mse: 43809724.0000 - val_loss: 533.6652 - val_mse: 1433376.3750 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2376.5222 - mse: 59025144.0000 - val_loss: 493.3410 - val_mse: 1224427.1250 - 654ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2312.3979 - mse: 49910448.0000 - val_loss: 452.1615 - val_mse: 1029208.5000 - 630ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2141.2871 - mse: 43196576.0000 - val_loss: 417.3799 - val_mse: 877837.1875 - 643ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2223.0220 - mse: 44215152.0000 - val_loss: 384.5444 - val_mse: 745120.8750 - 640ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2198.7771 - mse: 49730448.0000 - val_loss: 349.9223 - val_mse: 617102.4375 - 646ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2178.4021 - mse: 52566752.0000 - val_loss: 318.9980 - val_mse: 512627.8125 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1997.5194 - mse: 37162624.0000 - val_loss: 294.7015 - val_mse: 437490.5000 - 644ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2027.0748 - mse: 40869580.0000 - val_loss: 267.6626 - val_mse: 360966.9375 - 638ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1953.3660 - mse: 37764320.0000 - val_loss: 245.9276 - val_mse: 304799.5625 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 2011.8650 - mse: 38331596.0000 - val_loss: 224.7449 - val_mse: 254734.3594 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1906.7849 - mse: 37201044.0000 - val_loss: 205.7634 - val_mse: 213293.7031 - 638ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1905.8024 - mse: 36961980.0000 - val_loss: 187.5649 - val_mse: 176866.9688 - 679ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1763.3994 - mse: 28476424.0000 - val_loss: 171.4657 - val_mse: 147629.8906 - 678ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1859.6179 - mse: 35686132.0000 - val_loss: 156.7759 - val_mse: 123278.3203 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1766.8372 - mse: 30107404.0000 - val_loss: 140.7878 - val_mse: 99420.6016 - 669ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1687.5994 - mse: 26678530.0000 - val_loss: 128.6774 - val_mse: 82964.4531 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1812.1283 - mse: 33327944.0000 - val_loss: 117.4989 - val_mse: 69098.0000 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1675.3275 - mse: 25124860.0000 - val_loss: 106.2424 - val_mse: 56300.5039 - 658ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1608.7386 - mse: 23197142.0000 - val_loss: 95.8670 - val_mse: 45672.3945 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1675.2517 - mse: 26577714.0000 - val_loss: 84.5020 - val_mse: 35367.2969 - 655ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1713.5859 - mse: 29114048.0000 - val_loss: 72.6538 - val_mse: 26007.4238 - 667ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1669.4376 - mse: 26885408.0000 - val_loss: 62.3961 - val_mse: 19163.7949 - 648ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1648.7812 - mse: 29244908.0000 - val_loss: 52.5446 - val_mse: 13415.4434 - 667ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1660.8085 - mse: 28774534.0000 - val_loss: 42.8278 - val_mse: 8915.1133 - 655ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1605.2744 - mse: 24914416.0000 - val_loss: 36.4563 - val_mse: 6537.3755 - 646ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1607.1096 - mse: 27601218.0000 - val_loss: 33.1724 - val_mse: 5801.2100 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1586.8071 - mse: 26844006.0000 - val_loss: 31.5373 - val_mse: 5324.0112 - 652ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1544.0894 - mse: 23448324.0000 - val_loss: 28.2572 - val_mse: 3796.2583 - 652ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1504.6674 - mse: 21803494.0000 - val_loss: 20.4507 - val_mse: 1836.6147 - 667ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1517.9707 - mse: 21424078.0000 - val_loss: 7.7375 - val_mse: 146.4297 - 686ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1529.6805 - mse: 24991202.0000 - val_loss: 8.8012 - val_mse: 774.4252 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1519.5029 - mse: 26422336.0000 - val_loss: 17.5219 - val_mse: 1948.8412 - 675ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1415.8936 - mse: 19262456.0000 - val_loss: 16.7241 - val_mse: 1369.4186 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1468.8372 - mse: 21052666.0000 - val_loss: 14.2864 - val_mse: 893.2428 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1446.9435 - mse: 19549262.0000 - val_loss: 10.9857 - val_mse: 415.1038 - 645ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1387.2866 - mse: 18731310.0000 - val_loss: 6.0903 - val_mse: 85.5936 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1371.2799 - mse: 21252404.0000 - val_loss: 3.8163 - val_mse: 28.0680 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1405.1940 - mse: 21194120.0000 - val_loss: 2.4580 - val_mse: 18.1841 - 652ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1375.1804 - mse: 18070658.0000 - val_loss: 3.5544 - val_mse: 87.5304 - 644ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 1390.7883 - mse: 18618308.0000 - val_loss: 3.1659 - val_mse: 69.0689 - 1s/epoch - 8ms/step\n",
            "145/145 - 1s - loss: 1395.0132 - mse: 22658522.0000 - val_loss: 3.1100 - val_mse: 86.0838 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1355.8915 - mse: 19524776.0000 - val_loss: 4.4401 - val_mse: 176.5970 - 676ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1344.3008 - mse: 18757536.0000 - val_loss: 6.5894 - val_mse: 348.6716 - 676ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1333.8956 - mse: 16058318.0000 - val_loss: 8.7207 - val_mse: 576.7535 - 681ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1349.7306 - mse: 17389354.0000 - val_loss: 8.2151 - val_mse: 507.0523 - 685ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1340.2581 - mse: 18639866.0000 - val_loss: 7.7377 - val_mse: 433.7374 - 707ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1320.7456 - mse: 19970212.0000 - val_loss: 8.6834 - val_mse: 507.0656 - 712ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1257.0143 - mse: 16159738.0000 - val_loss: 8.7473 - val_mse: 513.8052 - 714ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1288.6354 - mse: 17173162.0000 - val_loss: 8.7575 - val_mse: 523.5275 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1239.0222 - mse: 15626206.0000 - val_loss: 9.5269 - val_mse: 618.3484 - 669ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1257.2848 - mse: 15430374.0000 - val_loss: 9.6320 - val_mse: 647.6893 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1269.6771 - mse: 15597260.0000 - val_loss: 11.3739 - val_mse: 878.4110 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1287.8180 - mse: 18282290.0000 - val_loss: 12.8479 - val_mse: 1079.1923 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1254.2146 - mse: 16691519.0000 - val_loss: 10.3915 - val_mse: 722.8418 - 675ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1265.7126 - mse: 17422108.0000 - val_loss: 10.3139 - val_mse: 684.7098 - 672ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1239.1067 - mse: 16871028.0000 - val_loss: 8.8625 - val_mse: 512.4633 - 673ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1199.4951 - mse: 14255700.0000 - val_loss: 8.3599 - val_mse: 447.7155 - 671ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1235.5681 - mse: 16054667.0000 - val_loss: 7.0376 - val_mse: 309.0713 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1208.2461 - mse: 16005582.0000 - val_loss: 6.8473 - val_mse: 286.5322 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1203.7805 - mse: 13883429.0000 - val_loss: 6.1401 - val_mse: 217.3364 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1188.5123 - mse: 15280073.0000 - val_loss: 6.2939 - val_mse: 220.2160 - 666ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1173.8379 - mse: 13359000.0000 - val_loss: 6.4700 - val_mse: 221.5916 - 696ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1159.6021 - mse: 13618261.0000 - val_loss: 6.5310 - val_mse: 225.1957 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1127.1334 - mse: 12478782.0000 - val_loss: 8.2198 - val_mse: 355.7636 - 693ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1169.4380 - mse: 15396152.0000 - val_loss: 8.5147 - val_mse: 372.9056 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1132.4136 - mse: 12643198.0000 - val_loss: 7.9346 - val_mse: 313.3790 - 669ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1131.3024 - mse: 12608303.0000 - val_loss: 10.5404 - val_mse: 571.2339 - 657ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1145.2869 - mse: 13034623.0000 - val_loss: 8.2963 - val_mse: 337.2452 - 668ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1109.0729 - mse: 11267556.0000 - val_loss: 7.2468 - val_mse: 251.0116 - 672ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1116.8843 - mse: 11917787.0000 - val_loss: 3.4397 - val_mse: 46.6390 - 683ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1138.9525 - mse: 12387909.0000 - val_loss: 2.8370 - val_mse: 30.9632 - 677ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1156.1444 - mse: 14060425.0000 - val_loss: 2.3257 - val_mse: 21.3064 - 676ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1099.2650 - mse: 11389116.0000 - val_loss: 1.8070 - val_mse: 13.9288 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1122.2834 - mse: 13186482.0000 - val_loss: 2.8684 - val_mse: 38.8399 - 679ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1095.4106 - mse: 11190186.0000 - val_loss: 2.9770 - val_mse: 40.8728 - 696ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1057.2212 - mse: 11942607.0000 - val_loss: 7.4134 - val_mse: 358.6045 - 673ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1100.7574 - mse: 13427018.0000 - val_loss: 6.3968 - val_mse: 278.3388 - 675ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1072.2273 - mse: 10904719.0000 - val_loss: 7.8647 - val_mse: 433.0244 - 706ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1096.0658 - mse: 12457267.0000 - val_loss: 9.7999 - val_mse: 675.1891 - 691ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1046.2058 - mse: 11139075.0000 - val_loss: 8.3102 - val_mse: 507.4854 - 687ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1058.7716 - mse: 10705683.0000 - val_loss: 7.8581 - val_mse: 464.1247 - 704ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1078.4138 - mse: 11757050.0000 - val_loss: 11.6759 - val_mse: 983.4754 - 667ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1043.9927 - mse: 11095918.0000 - val_loss: 12.0435 - val_mse: 1053.4324 - 667ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1068.2675 - mse: 13209291.0000 - val_loss: 12.8658 - val_mse: 1201.4554 - 675ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1014.7284 - mse: 9652042.0000 - val_loss: 11.6840 - val_mse: 1021.5526 - 668ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1015.0307 - mse: 11693652.0000 - val_loss: 11.1639 - val_mse: 953.1651 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1024.0000 - mse: 10547336.0000 - val_loss: 15.1769 - val_mse: 1678.1530 - 656ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 973.2263 - mse: 8829408.0000 - val_loss: 16.4261 - val_mse: 1948.0620 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 988.8694 - mse: 9691026.0000 - val_loss: 20.7141 - val_mse: 2980.6694 - 654ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1010.9233 - mse: 11673468.0000 - val_loss: 18.0322 - val_mse: 2350.6704 - 664ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1014.5037 - mse: 11570186.0000 - val_loss: 19.6985 - val_mse: 2775.7822 - 688ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1024.3470 - mse: 10482984.0000 - val_loss: 16.6768 - val_mse: 2092.7805 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 970.3814 - mse: 9024940.0000 - val_loss: 17.2594 - val_mse: 2240.6938 - 668ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 181 ended. Search finished for the next optimal point.\n",
            "Time taken: 83.9934\n",
            "Function value obtained: 2240.6938\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 182 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [52, 106]\n",
            "Learning Rate: 5.157297463602255e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4379636339065292\n",
            "Batch Size: 62\n",
            "----------------------------------------\n",
            "136/136 - 3s - loss: 2516.1719 - mse: 68802888.0000 - val_loss: 32.7477 - val_mse: 7202.6353 - 3s/epoch - 22ms/step\n",
            "136/136 - 1s - loss: 2459.6553 - mse: 63332216.0000 - val_loss: 42.4246 - val_mse: 13254.7119 - 610ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 2388.5986 - mse: 76117216.0000 - val_loss: 33.4476 - val_mse: 7447.4253 - 611ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 2204.5754 - mse: 50860500.0000 - val_loss: 42.3032 - val_mse: 13834.4297 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 2272.7590 - mse: 53994112.0000 - val_loss: 60.1903 - val_mse: 28267.9766 - 610ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1984.3395 - mse: 35852384.0000 - val_loss: 84.0468 - val_mse: 50919.5312 - 608ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 2106.0349 - mse: 49778424.0000 - val_loss: 112.1421 - val_mse: 83382.0547 - 600ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 2077.8176 - mse: 46840356.0000 - val_loss: 128.2345 - val_mse: 100995.5156 - 622ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 2090.6602 - mse: 46266708.0000 - val_loss: 117.5169 - val_mse: 83517.7578 - 617ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1996.5320 - mse: 39078832.0000 - val_loss: 112.8166 - val_mse: 74670.6953 - 650ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1919.7371 - mse: 34005104.0000 - val_loss: 107.3258 - val_mse: 65221.2188 - 631ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1911.9053 - mse: 37030380.0000 - val_loss: 93.7189 - val_mse: 48662.9375 - 639ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1947.7661 - mse: 42515604.0000 - val_loss: 87.4897 - val_mse: 43739.4492 - 627ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1903.8361 - mse: 40757464.0000 - val_loss: 92.3105 - val_mse: 49454.8672 - 603ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1920.6250 - mse: 39855340.0000 - val_loss: 90.2091 - val_mse: 45901.2422 - 624ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1752.9811 - mse: 32123864.0000 - val_loss: 82.3226 - val_mse: 37994.8398 - 613ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1880.5238 - mse: 39494036.0000 - val_loss: 81.2841 - val_mse: 36712.7773 - 612ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1783.3469 - mse: 32785004.0000 - val_loss: 69.1534 - val_mse: 26602.5664 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1756.4905 - mse: 30081388.0000 - val_loss: 72.2172 - val_mse: 28716.9707 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1704.5714 - mse: 28100404.0000 - val_loss: 61.9568 - val_mse: 21163.8262 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1708.2509 - mse: 26578428.0000 - val_loss: 52.1757 - val_mse: 15025.8008 - 617ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1708.9620 - mse: 28165108.0000 - val_loss: 53.3730 - val_mse: 15630.2637 - 619ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1661.4314 - mse: 26484232.0000 - val_loss: 52.4658 - val_mse: 15049.2852 - 635ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1630.3588 - mse: 24750476.0000 - val_loss: 46.6850 - val_mse: 11949.3545 - 619ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1644.9363 - mse: 26295186.0000 - val_loss: 35.4985 - val_mse: 6766.1055 - 610ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1508.2152 - mse: 20628824.0000 - val_loss: 28.6001 - val_mse: 4324.2246 - 622ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1615.7329 - mse: 26153826.0000 - val_loss: 26.9098 - val_mse: 3834.5769 - 603ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1530.1425 - mse: 21350926.0000 - val_loss: 23.3786 - val_mse: 2922.7676 - 630ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1579.7758 - mse: 29257246.0000 - val_loss: 19.8334 - val_mse: 2172.7971 - 638ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1583.4830 - mse: 27558772.0000 - val_loss: 18.3978 - val_mse: 1867.2723 - 663ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1503.2594 - mse: 21239510.0000 - val_loss: 18.8964 - val_mse: 1957.5665 - 645ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1489.3215 - mse: 23320886.0000 - val_loss: 16.9372 - val_mse: 1563.9995 - 612ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1477.4951 - mse: 23852682.0000 - val_loss: 15.1982 - val_mse: 1277.8641 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1483.3210 - mse: 22921040.0000 - val_loss: 10.5767 - val_mse: 627.5249 - 647ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1528.5421 - mse: 24794626.0000 - val_loss: 8.2811 - val_mse: 389.1443 - 613ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1455.2072 - mse: 24699938.0000 - val_loss: 6.2790 - val_mse: 227.4202 - 605ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1466.1769 - mse: 22998532.0000 - val_loss: 6.2085 - val_mse: 223.1308 - 615ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1440.8159 - mse: 22683494.0000 - val_loss: 4.4284 - val_mse: 66.3242 - 612ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1380.3519 - mse: 19619232.0000 - val_loss: 4.7357 - val_mse: 78.1412 - 612ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1456.9376 - mse: 21860598.0000 - val_loss: 5.2586 - val_mse: 106.7130 - 614ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1386.3339 - mse: 21023054.0000 - val_loss: 6.2169 - val_mse: 155.8652 - 619ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1361.3341 - mse: 20783182.0000 - val_loss: 12.4547 - val_mse: 706.3040 - 611ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1398.4972 - mse: 20867726.0000 - val_loss: 9.7314 - val_mse: 417.5645 - 613ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1362.4668 - mse: 19686624.0000 - val_loss: 15.7743 - val_mse: 1183.1814 - 623ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1349.2111 - mse: 17671488.0000 - val_loss: 11.1576 - val_mse: 576.3730 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1318.5886 - mse: 18561942.0000 - val_loss: 8.5755 - val_mse: 339.3051 - 632ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1324.7300 - mse: 18224184.0000 - val_loss: 10.4651 - val_mse: 527.7545 - 652ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1336.4102 - mse: 27149852.0000 - val_loss: 14.8281 - val_mse: 1087.0973 - 640ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1288.2120 - mse: 16777726.0000 - val_loss: 11.7272 - val_mse: 694.3815 - 641ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1315.9023 - mse: 18283540.0000 - val_loss: 18.9900 - val_mse: 1793.9436 - 617ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1268.7965 - mse: 16191610.0000 - val_loss: 16.2254 - val_mse: 1323.5266 - 621ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1299.8152 - mse: 16354301.0000 - val_loss: 18.5989 - val_mse: 1705.3961 - 633ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1214.4113 - mse: 17808678.0000 - val_loss: 16.9821 - val_mse: 1443.3678 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1236.9974 - mse: 14283568.0000 - val_loss: 17.0075 - val_mse: 1451.1720 - 626ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1143.1178 - mse: 11372805.0000 - val_loss: 18.2012 - val_mse: 1656.7000 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1253.0376 - mse: 17535948.0000 - val_loss: 19.1810 - val_mse: 1859.2599 - 608ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1200.7300 - mse: 14537510.0000 - val_loss: 17.5618 - val_mse: 1629.6700 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1152.1156 - mse: 12824007.0000 - val_loss: 17.3624 - val_mse: 1563.3567 - 612ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1163.4938 - mse: 13895522.0000 - val_loss: 16.9716 - val_mse: 1440.3246 - 622ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1132.1416 - mse: 11946890.0000 - val_loss: 14.7348 - val_mse: 1094.5717 - 599ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1161.0126 - mse: 14446326.0000 - val_loss: 13.5257 - val_mse: 961.2988 - 611ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1055.4414 - mse: 9530216.0000 - val_loss: 12.6446 - val_mse: 823.0255 - 607ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 1140.5203 - mse: 13074760.0000 - val_loss: 10.9938 - val_mse: 650.6643 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1119.3853 - mse: 13363100.0000 - val_loss: 10.7635 - val_mse: 646.2324 - 650ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1056.7303 - mse: 10488272.0000 - val_loss: 10.6431 - val_mse: 636.6779 - 643ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1100.1514 - mse: 13570923.0000 - val_loss: 13.9556 - val_mse: 1100.3229 - 639ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1109.4878 - mse: 12449885.0000 - val_loss: 16.2623 - val_mse: 1466.5714 - 625ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1025.7738 - mse: 10204888.0000 - val_loss: 12.6849 - val_mse: 914.0281 - 614ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1079.4889 - mse: 11801121.0000 - val_loss: 14.0666 - val_mse: 1119.4624 - 626ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1014.6215 - mse: 9813426.0000 - val_loss: 14.2383 - val_mse: 1112.9852 - 624ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1056.3383 - mse: 10702256.0000 - val_loss: 14.0877 - val_mse: 1104.4788 - 650ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1026.8625 - mse: 11441654.0000 - val_loss: 13.0478 - val_mse: 925.3621 - 652ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1044.5663 - mse: 10982822.0000 - val_loss: 12.9485 - val_mse: 926.4603 - 615ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 950.7983 - mse: 9443548.0000 - val_loss: 12.9277 - val_mse: 942.4960 - 617ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 966.3359 - mse: 8417753.0000 - val_loss: 12.2762 - val_mse: 870.7313 - 624ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1018.3906 - mse: 11194994.0000 - val_loss: 12.6867 - val_mse: 927.1130 - 617ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 971.6053 - mse: 9194753.0000 - val_loss: 13.8475 - val_mse: 1103.8989 - 604ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 956.7133 - mse: 9235347.0000 - val_loss: 12.4836 - val_mse: 905.0614 - 612ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 940.0305 - mse: 8382376.5000 - val_loss: 14.0707 - val_mse: 1146.8398 - 614ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 975.4058 - mse: 10286694.0000 - val_loss: 12.1057 - val_mse: 857.9470 - 609ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 937.2640 - mse: 8834070.0000 - val_loss: 9.9304 - val_mse: 572.3907 - 621ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 901.3912 - mse: 8352065.0000 - val_loss: 9.4497 - val_mse: 526.1454 - 636ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 919.0964 - mse: 7893830.0000 - val_loss: 7.2398 - val_mse: 322.1708 - 648ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 878.9839 - mse: 7430189.5000 - val_loss: 7.3720 - val_mse: 329.8674 - 638ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 876.2756 - mse: 7412501.5000 - val_loss: 8.8147 - val_mse: 450.6824 - 625ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 920.4086 - mse: 8776709.0000 - val_loss: 9.7632 - val_mse: 559.2469 - 612ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 896.1649 - mse: 8109057.5000 - val_loss: 6.9322 - val_mse: 288.7359 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 902.6565 - mse: 7702206.5000 - val_loss: 7.6084 - val_mse: 350.5576 - 623ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 894.0531 - mse: 8409068.0000 - val_loss: 9.8294 - val_mse: 591.7437 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 876.5678 - mse: 8283911.5000 - val_loss: 9.5725 - val_mse: 548.5584 - 612ms/epoch - 4ms/step\n",
            "136/136 - 1s - loss: 824.6277 - mse: 6161601.0000 - val_loss: 9.0959 - val_mse: 486.0420 - 621ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 836.2595 - mse: 7943191.5000 - val_loss: 9.2837 - val_mse: 506.2350 - 616ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 896.6384 - mse: 10606375.0000 - val_loss: 9.7800 - val_mse: 565.1311 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 835.2671 - mse: 7686054.5000 - val_loss: 10.8439 - val_mse: 689.1555 - 628ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 784.0852 - mse: 5476602.0000 - val_loss: 9.7280 - val_mse: 557.8379 - 631ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 826.4581 - mse: 6687326.5000 - val_loss: 9.2569 - val_mse: 507.6489 - 626ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 825.8524 - mse: 7088568.0000 - val_loss: 8.6449 - val_mse: 445.4384 - 623ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 786.3828 - mse: 5791608.5000 - val_loss: 7.0385 - val_mse: 300.3650 - 618ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 768.6068 - mse: 5724737.0000 - val_loss: 5.6211 - val_mse: 203.1710 - 625ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 783.0557 - mse: 6634872.5000 - val_loss: 6.3159 - val_mse: 249.6179 - 645ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 182 ended. Search finished for the next optimal point.\n",
            "Time taken: 78.7688\n",
            "Function value obtained: 249.6179\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 183 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [35, 83]\n",
            "Learning Rate: 3.6587076222862426e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.47288129969440584\n",
            "Batch Size: 57\n",
            "----------------------------------------\n",
            "148/148 - 4s - loss: 2619.3665 - mse: 77959376.0000 - val_loss: 296.4756 - val_mse: 417172.3750 - 4s/epoch - 25ms/step\n",
            "148/148 - 1s - loss: 2534.3428 - mse: 63748832.0000 - val_loss: 294.4812 - val_mse: 414967.0625 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2440.1470 - mse: 60697884.0000 - val_loss: 288.3929 - val_mse: 399040.5625 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2431.7876 - mse: 61768664.0000 - val_loss: 284.6371 - val_mse: 388659.0938 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2430.2876 - mse: 57804128.0000 - val_loss: 278.9232 - val_mse: 372495.5625 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2378.9502 - mse: 54464384.0000 - val_loss: 278.7758 - val_mse: 374478.4688 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2306.1990 - mse: 52658312.0000 - val_loss: 270.5493 - val_mse: 353257.2188 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2261.6106 - mse: 52594824.0000 - val_loss: 262.8349 - val_mse: 333483.4062 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2292.0793 - mse: 54837144.0000 - val_loss: 260.0085 - val_mse: 326553.0312 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2225.8530 - mse: 54745704.0000 - val_loss: 253.7114 - val_mse: 311137.0000 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2240.8665 - mse: 52207068.0000 - val_loss: 246.8099 - val_mse: 296075.0938 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2070.7812 - mse: 49582576.0000 - val_loss: 241.6843 - val_mse: 287007.8438 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2129.8828 - mse: 50455688.0000 - val_loss: 232.7629 - val_mse: 270057.4375 - 653ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2027.4425 - mse: 38364436.0000 - val_loss: 219.9520 - val_mse: 241642.4219 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2153.6929 - mse: 49463820.0000 - val_loss: 204.0094 - val_mse: 207172.6406 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2062.6736 - mse: 46882048.0000 - val_loss: 192.8327 - val_mse: 184568.7344 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2034.3291 - mse: 42425040.0000 - val_loss: 179.8985 - val_mse: 160056.5469 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2018.6887 - mse: 44029988.0000 - val_loss: 164.3699 - val_mse: 132503.6250 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 2062.8296 - mse: 45262676.0000 - val_loss: 151.7406 - val_mse: 112577.4297 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1954.0724 - mse: 40269844.0000 - val_loss: 144.9124 - val_mse: 103972.7891 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1968.5251 - mse: 40951876.0000 - val_loss: 132.0910 - val_mse: 87088.8047 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1887.9572 - mse: 35449396.0000 - val_loss: 121.4541 - val_mse: 73528.2578 - 701ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1887.1967 - mse: 33880268.0000 - val_loss: 109.3627 - val_mse: 59671.1523 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1844.9230 - mse: 37213992.0000 - val_loss: 95.0830 - val_mse: 45162.8906 - 697ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1892.1731 - mse: 39807116.0000 - val_loss: 80.1819 - val_mse: 32033.5469 - 704ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1842.6320 - mse: 36992732.0000 - val_loss: 66.3235 - val_mse: 21818.1289 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1811.4619 - mse: 31076370.0000 - val_loss: 53.8772 - val_mse: 14344.4590 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1797.2869 - mse: 36765792.0000 - val_loss: 43.4906 - val_mse: 9308.1338 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1743.2274 - mse: 32587038.0000 - val_loss: 29.8551 - val_mse: 4243.8633 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1709.5925 - mse: 27921194.0000 - val_loss: 23.9942 - val_mse: 2718.6919 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1763.2424 - mse: 32506110.0000 - val_loss: 16.7617 - val_mse: 1292.7909 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1717.1152 - mse: 29895256.0000 - val_loss: 10.3837 - val_mse: 482.4779 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1744.6140 - mse: 30896276.0000 - val_loss: 6.1394 - val_mse: 168.3743 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1670.5950 - mse: 28739244.0000 - val_loss: 2.3228 - val_mse: 20.8288 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1648.6417 - mse: 28081344.0000 - val_loss: 1.3693 - val_mse: 14.4639 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1731.2694 - mse: 32038908.0000 - val_loss: 4.6790 - val_mse: 154.8459 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1653.3370 - mse: 31142692.0000 - val_loss: 8.4030 - val_mse: 455.8185 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1686.5763 - mse: 31591682.0000 - val_loss: 14.2862 - val_mse: 1223.9333 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1656.4980 - mse: 30094920.0000 - val_loss: 20.7050 - val_mse: 2417.4980 - 698ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1562.8241 - mse: 25575384.0000 - val_loss: 24.7400 - val_mse: 3338.9355 - 694ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1580.7324 - mse: 27044868.0000 - val_loss: 28.1932 - val_mse: 4276.4746 - 732ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1582.1212 - mse: 24507120.0000 - val_loss: 31.3888 - val_mse: 5255.4058 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1530.0107 - mse: 24449056.0000 - val_loss: 33.4790 - val_mse: 5948.0200 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1477.3014 - mse: 20296154.0000 - val_loss: 35.5922 - val_mse: 6691.6040 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1605.1011 - mse: 27468026.0000 - val_loss: 39.4652 - val_mse: 8215.7100 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1503.8522 - mse: 23754622.0000 - val_loss: 41.7892 - val_mse: 9303.3301 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1489.3035 - mse: 24614308.0000 - val_loss: 43.8730 - val_mse: 10290.7500 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1455.4932 - mse: 22884746.0000 - val_loss: 47.4043 - val_mse: 11957.9199 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1438.3845 - mse: 19489304.0000 - val_loss: 50.6208 - val_mse: 13625.3037 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1401.6371 - mse: 17993412.0000 - val_loss: 52.5399 - val_mse: 14648.3340 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1416.4750 - mse: 18115396.0000 - val_loss: 54.9333 - val_mse: 15980.7275 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1423.4509 - mse: 19139886.0000 - val_loss: 58.2712 - val_mse: 17942.2695 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1382.3219 - mse: 18643394.0000 - val_loss: 59.8570 - val_mse: 18923.4180 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1445.6199 - mse: 21885296.0000 - val_loss: 62.6239 - val_mse: 20743.4297 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1384.6572 - mse: 19189274.0000 - val_loss: 64.8370 - val_mse: 22404.5508 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1407.6653 - mse: 20203878.0000 - val_loss: 69.3019 - val_mse: 25853.1191 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1379.1442 - mse: 18990166.0000 - val_loss: 71.1490 - val_mse: 27309.4844 - 698ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1350.8068 - mse: 21894168.0000 - val_loss: 74.5417 - val_mse: 29993.7148 - 685ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1314.5984 - mse: 17357854.0000 - val_loss: 76.5513 - val_mse: 31626.8984 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1297.5791 - mse: 15119657.0000 - val_loss: 78.8737 - val_mse: 33469.1875 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1303.8403 - mse: 16662608.0000 - val_loss: 80.8696 - val_mse: 35017.4688 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1311.2294 - mse: 16599374.0000 - val_loss: 81.8421 - val_mse: 35697.5312 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1298.2198 - mse: 17140074.0000 - val_loss: 84.8932 - val_mse: 38147.6211 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1284.8943 - mse: 15333564.0000 - val_loss: 85.3143 - val_mse: 38432.1992 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1338.9200 - mse: 18861034.0000 - val_loss: 87.2756 - val_mse: 40057.0547 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1271.9646 - mse: 16371947.0000 - val_loss: 88.0982 - val_mse: 40764.1250 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1247.1067 - mse: 14791874.0000 - val_loss: 88.4716 - val_mse: 41069.9883 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1255.6908 - mse: 14917427.0000 - val_loss: 88.9231 - val_mse: 41335.1953 - 687ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1253.8657 - mse: 19177480.0000 - val_loss: 90.5294 - val_mse: 42439.2500 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1172.4564 - mse: 14140207.0000 - val_loss: 91.4914 - val_mse: 43277.5352 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1187.5480 - mse: 13441402.0000 - val_loss: 90.2276 - val_mse: 41944.1992 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1183.1362 - mse: 14350188.0000 - val_loss: 89.7815 - val_mse: 41605.8359 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1175.2626 - mse: 13827302.0000 - val_loss: 89.2579 - val_mse: 40786.9102 - 701ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1185.2014 - mse: 15147514.0000 - val_loss: 90.2843 - val_mse: 41651.8750 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1165.7700 - mse: 14699208.0000 - val_loss: 91.3730 - val_mse: 42645.3438 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1186.0369 - mse: 14187841.0000 - val_loss: 92.9588 - val_mse: 44145.0430 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1147.8271 - mse: 13024040.0000 - val_loss: 91.5853 - val_mse: 42855.3242 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1176.8928 - mse: 13441847.0000 - val_loss: 92.1707 - val_mse: 43524.5742 - 682ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1172.1354 - mse: 13864948.0000 - val_loss: 92.9713 - val_mse: 44414.8164 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1135.0626 - mse: 14739656.0000 - val_loss: 92.8027 - val_mse: 44289.6562 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1125.2188 - mse: 12233924.0000 - val_loss: 93.6528 - val_mse: 45499.6758 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1171.2260 - mse: 14411561.0000 - val_loss: 93.9489 - val_mse: 45909.5547 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1178.3579 - mse: 16363094.0000 - val_loss: 94.9559 - val_mse: 47070.5469 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1136.2518 - mse: 14202687.0000 - val_loss: 95.8845 - val_mse: 48124.1602 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1109.2782 - mse: 14149978.0000 - val_loss: 96.8811 - val_mse: 49169.8945 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1067.7047 - mse: 11467818.0000 - val_loss: 97.1595 - val_mse: 49426.7617 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1107.8086 - mse: 13552979.0000 - val_loss: 95.8418 - val_mse: 48144.7031 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1097.2006 - mse: 12570407.0000 - val_loss: 95.4608 - val_mse: 47729.8828 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1089.1877 - mse: 11985651.0000 - val_loss: 95.7955 - val_mse: 47979.7617 - 703ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1018.6027 - mse: 10779064.0000 - val_loss: 95.2895 - val_mse: 47374.4883 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1055.6969 - mse: 11433771.0000 - val_loss: 97.2036 - val_mse: 49133.2383 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 977.2131 - mse: 9661896.0000 - val_loss: 96.1616 - val_mse: 48167.1797 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1040.8152 - mse: 10525332.0000 - val_loss: 95.8748 - val_mse: 47824.6680 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1020.7798 - mse: 12209685.0000 - val_loss: 95.9839 - val_mse: 47902.4766 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 977.7004 - mse: 10282136.0000 - val_loss: 95.4619 - val_mse: 47259.4258 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 978.2677 - mse: 9632678.0000 - val_loss: 93.9863 - val_mse: 45738.9141 - 666ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 994.4164 - mse: 9974641.0000 - val_loss: 92.9768 - val_mse: 44467.9805 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 946.4509 - mse: 8413565.0000 - val_loss: 92.6983 - val_mse: 43694.3594 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1009.0655 - mse: 10100517.0000 - val_loss: 92.3011 - val_mse: 43130.7969 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 965.2719 - mse: 9876074.0000 - val_loss: 92.3331 - val_mse: 42988.0000 - 668ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 183 ended. Search finished for the next optimal point.\n",
            "Time taken: 84.2694\n",
            "Function value obtained: 42988.0000\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 184 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [119, 118]\n",
            "Learning Rate: 1.0522371963114895e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4637923408197743\n",
            "Batch Size: 59\n",
            "----------------------------------------\n",
            "143/143 - 3s - loss: 1926.2920 - mse: 36364476.0000 - val_loss: 277.2231 - val_mse: 396962.1875 - 3s/epoch - 21ms/step\n",
            "143/143 - 1s - loss: 1804.3875 - mse: 32598162.0000 - val_loss: 250.7569 - val_mse: 325461.8438 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1803.7482 - mse: 28311100.0000 - val_loss: 232.1448 - val_mse: 279188.5938 - 634ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1788.2749 - mse: 29756202.0000 - val_loss: 221.7034 - val_mse: 254575.2812 - 644ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1743.0742 - mse: 30491310.0000 - val_loss: 213.4325 - val_mse: 236168.0000 - 650ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1686.0823 - mse: 26005240.0000 - val_loss: 198.2947 - val_mse: 204642.7656 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1635.1729 - mse: 23653750.0000 - val_loss: 187.4300 - val_mse: 183585.1875 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1647.7972 - mse: 26833298.0000 - val_loss: 175.0187 - val_mse: 160395.9531 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1636.6202 - mse: 28255438.0000 - val_loss: 157.2656 - val_mse: 129624.4844 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1554.0646 - mse: 22199030.0000 - val_loss: 148.5897 - val_mse: 116252.3438 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1550.0190 - mse: 22876728.0000 - val_loss: 141.4283 - val_mse: 105622.6875 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1549.6471 - mse: 23829334.0000 - val_loss: 130.3276 - val_mse: 89850.1172 - 694ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1536.5078 - mse: 21490874.0000 - val_loss: 126.7585 - val_mse: 85248.9141 - 701ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1534.3798 - mse: 23214564.0000 - val_loss: 119.1714 - val_mse: 75760.6641 - 690ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1504.0909 - mse: 23085140.0000 - val_loss: 111.4797 - val_mse: 66549.3984 - 694ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1491.0524 - mse: 22705230.0000 - val_loss: 101.9257 - val_mse: 55902.1875 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1483.3257 - mse: 22470900.0000 - val_loss: 97.0161 - val_mse: 50552.9688 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1453.3428 - mse: 20875904.0000 - val_loss: 94.3475 - val_mse: 47725.7539 - 674ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1377.1528 - mse: 19125732.0000 - val_loss: 87.5920 - val_mse: 41302.1367 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1355.6667 - mse: 16872152.0000 - val_loss: 82.0814 - val_mse: 36430.3438 - 684ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1408.1138 - mse: 19976864.0000 - val_loss: 81.4977 - val_mse: 36058.7891 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1343.5282 - mse: 18180158.0000 - val_loss: 78.6863 - val_mse: 33662.5391 - 682ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1325.5636 - mse: 16450878.0000 - val_loss: 75.2770 - val_mse: 30903.4180 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1279.3539 - mse: 15450536.0000 - val_loss: 73.0564 - val_mse: 29155.4746 - 674ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1199.1122 - mse: 13275265.0000 - val_loss: 69.2148 - val_mse: 26261.5859 - 675ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1291.3641 - mse: 17070328.0000 - val_loss: 67.3430 - val_mse: 24908.4141 - 691ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1251.0922 - mse: 16595031.0000 - val_loss: 63.5264 - val_mse: 22301.7988 - 674ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1216.4344 - mse: 15084384.0000 - val_loss: 60.7439 - val_mse: 20504.1543 - 678ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1311.9379 - mse: 17964046.0000 - val_loss: 59.8122 - val_mse: 19994.4668 - 704ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1182.0647 - mse: 13323556.0000 - val_loss: 55.3615 - val_mse: 17314.5742 - 714ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1197.7976 - mse: 14065676.0000 - val_loss: 54.1209 - val_mse: 16727.4961 - 694ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1188.0411 - mse: 13333053.0000 - val_loss: 53.1768 - val_mse: 16297.8213 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1245.3700 - mse: 15214490.0000 - val_loss: 54.7143 - val_mse: 17308.2285 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1207.2743 - mse: 14959165.0000 - val_loss: 54.3186 - val_mse: 17166.8438 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1181.4163 - mse: 14293029.0000 - val_loss: 52.2134 - val_mse: 15976.5928 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1184.3862 - mse: 14859681.0000 - val_loss: 49.5819 - val_mse: 14527.5811 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1235.9465 - mse: 17237818.0000 - val_loss: 50.6326 - val_mse: 15126.8018 - 658ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1143.9005 - mse: 12438669.0000 - val_loss: 49.0126 - val_mse: 14220.1328 - 647ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1145.1401 - mse: 14134878.0000 - val_loss: 50.1441 - val_mse: 14718.1797 - 648ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1112.7402 - mse: 11273491.0000 - val_loss: 47.4243 - val_mse: 13230.2344 - 643ms/epoch - 4ms/step\n",
            "143/143 - 1s - loss: 1105.6285 - mse: 12847862.0000 - val_loss: 49.3233 - val_mse: 14166.2188 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1075.5536 - mse: 10863895.0000 - val_loss: 48.5299 - val_mse: 13756.3271 - 662ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1098.4758 - mse: 10981303.0000 - val_loss: 45.2214 - val_mse: 12084.2861 - 657ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1130.0889 - mse: 11821648.0000 - val_loss: 45.8645 - val_mse: 12463.8125 - 652ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1104.0834 - mse: 12574325.0000 - val_loss: 44.3675 - val_mse: 11782.2275 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1051.0824 - mse: 9911634.0000 - val_loss: 46.2583 - val_mse: 12955.1670 - 689ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1063.1646 - mse: 11076524.0000 - val_loss: 44.0382 - val_mse: 11880.7324 - 675ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1120.2067 - mse: 14381902.0000 - val_loss: 41.7991 - val_mse: 10817.7861 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1091.2971 - mse: 12086867.0000 - val_loss: 42.3313 - val_mse: 11198.0508 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1081.8292 - mse: 13139385.0000 - val_loss: 42.6262 - val_mse: 11407.8232 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1089.7375 - mse: 12477813.0000 - val_loss: 41.2891 - val_mse: 10779.5537 - 664ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1099.0295 - mse: 12074012.0000 - val_loss: 42.0657 - val_mse: 11240.0547 - 673ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1028.7322 - mse: 10712490.0000 - val_loss: 44.1609 - val_mse: 12495.2744 - 675ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1073.6284 - mse: 11730849.0000 - val_loss: 44.8956 - val_mse: 12974.2559 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 995.0056 - mse: 8830261.0000 - val_loss: 48.2480 - val_mse: 14556.0098 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1058.3867 - mse: 12038999.0000 - val_loss: 45.7165 - val_mse: 13108.6875 - 665ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1012.8377 - mse: 9811647.0000 - val_loss: 44.2682 - val_mse: 12120.5361 - 675ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 994.2676 - mse: 9199471.0000 - val_loss: 43.0098 - val_mse: 11239.1562 - 670ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1008.3943 - mse: 9559665.0000 - val_loss: 41.3023 - val_mse: 9648.9697 - 671ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 991.1057 - mse: 10076774.0000 - val_loss: 38.0135 - val_mse: 7830.7324 - 681ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1026.7472 - mse: 10275869.0000 - val_loss: 32.6645 - val_mse: 5344.0947 - 678ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 986.8320 - mse: 10283789.0000 - val_loss: 27.5800 - val_mse: 3561.0291 - 681ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 984.1577 - mse: 9270878.0000 - val_loss: 22.6037 - val_mse: 2243.8884 - 710ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1032.0824 - mse: 11391132.0000 - val_loss: 15.0622 - val_mse: 857.3041 - 713ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 976.5128 - mse: 8857120.0000 - val_loss: 10.2851 - val_mse: 379.4947 - 704ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 993.6577 - mse: 9688634.0000 - val_loss: 6.4943 - val_mse: 155.6669 - 674ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1005.0576 - mse: 10208736.0000 - val_loss: 4.3931 - val_mse: 97.3772 - 1s/epoch - 8ms/step\n",
            "143/143 - 1s - loss: 976.0169 - mse: 9115799.0000 - val_loss: 3.6449 - val_mse: 67.0952 - 692ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 988.7170 - mse: 9199588.0000 - val_loss: 1.7624 - val_mse: 15.1813 - 699ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1013.0068 - mse: 10849353.0000 - val_loss: 0.6915 - val_mse: 2.5272 - 689ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 986.1001 - mse: 9731430.0000 - val_loss: 0.2887 - val_mse: 0.7029 - 680ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 945.7463 - mse: 8827886.0000 - val_loss: 0.9522 - val_mse: 9.1219 - 694ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 975.0515 - mse: 9684637.0000 - val_loss: 1.3310 - val_mse: 12.9394 - 687ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 942.5270 - mse: 9314167.0000 - val_loss: 1.8184 - val_mse: 23.5753 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 956.0417 - mse: 8468642.0000 - val_loss: 0.9628 - val_mse: 4.6732 - 700ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 967.4523 - mse: 9255914.0000 - val_loss: 2.4746 - val_mse: 48.2504 - 691ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1002.3257 - mse: 12314936.0000 - val_loss: 4.3713 - val_mse: 152.4245 - 692ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 992.1818 - mse: 9954285.0000 - val_loss: 7.2341 - val_mse: 413.9757 - 719ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 919.9920 - mse: 7705442.5000 - val_loss: 8.5405 - val_mse: 565.8801 - 725ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 924.1375 - mse: 7725852.5000 - val_loss: 9.9871 - val_mse: 744.9240 - 717ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 943.4382 - mse: 8178103.0000 - val_loss: 10.5161 - val_mse: 784.1147 - 714ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 938.6322 - mse: 8656803.0000 - val_loss: 10.8748 - val_mse: 799.6284 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 1004.0200 - mse: 12444959.0000 - val_loss: 12.0359 - val_mse: 979.8660 - 704ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 919.9822 - mse: 9426905.0000 - val_loss: 12.0742 - val_mse: 997.3201 - 681ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 969.8497 - mse: 9245674.0000 - val_loss: 12.8583 - val_mse: 1140.4950 - 685ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 915.7607 - mse: 8126068.0000 - val_loss: 13.6046 - val_mse: 1283.9563 - 677ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 882.8512 - mse: 6901231.0000 - val_loss: 13.9356 - val_mse: 1330.2999 - 672ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 906.3303 - mse: 8293464.5000 - val_loss: 14.3687 - val_mse: 1404.4080 - 682ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 952.6650 - mse: 10590459.0000 - val_loss: 14.9985 - val_mse: 1541.3884 - 676ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 940.5018 - mse: 8904337.0000 - val_loss: 15.7860 - val_mse: 1718.3356 - 686ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 931.3437 - mse: 9698236.0000 - val_loss: 15.6040 - val_mse: 1699.2195 - 645ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 936.4424 - mse: 8931891.0000 - val_loss: 15.0404 - val_mse: 1582.7406 - 667ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 935.6237 - mse: 8670960.0000 - val_loss: 14.6029 - val_mse: 1481.5686 - 663ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 936.4478 - mse: 9011540.0000 - val_loss: 12.8777 - val_mse: 1146.7999 - 659ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 925.3270 - mse: 8671657.0000 - val_loss: 12.2993 - val_mse: 1049.0004 - 696ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 914.4048 - mse: 8708694.0000 - val_loss: 10.8918 - val_mse: 838.4152 - 678ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 890.5601 - mse: 7694969.5000 - val_loss: 10.0484 - val_mse: 724.8649 - 701ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 904.3140 - mse: 8211762.0000 - val_loss: 11.2254 - val_mse: 881.9305 - 663ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 904.2458 - mse: 8403462.0000 - val_loss: 12.0846 - val_mse: 1006.2441 - 656ms/epoch - 5ms/step\n",
            "143/143 - 1s - loss: 850.1466 - mse: 6464490.0000 - val_loss: 11.8458 - val_mse: 970.7266 - 663ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 184 ended. Search finished for the next optimal point.\n",
            "Time taken: 84.6609\n",
            "Function value obtained: 970.7266\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 185 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [119, 125]\n",
            "Learning Rate: 1.352427088583964e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.46805244743181923\n",
            "Batch Size: 60\n",
            "----------------------------------------\n",
            "140/140 - 3s - loss: 1929.5166 - mse: 37059516.0000 - val_loss: 358.3801 - val_mse: 648049.6875 - 3s/epoch - 21ms/step\n",
            "140/140 - 1s - loss: 1976.9677 - mse: 41730540.0000 - val_loss: 311.8560 - val_mse: 490838.4375 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1888.3346 - mse: 34905864.0000 - val_loss: 271.1842 - val_mse: 371170.1562 - 636ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1795.7056 - mse: 33115380.0000 - val_loss: 235.3412 - val_mse: 280000.1562 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1740.7960 - mse: 30623906.0000 - val_loss: 204.4989 - val_mse: 211562.3906 - 616ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1766.4281 - mse: 30356226.0000 - val_loss: 168.8356 - val_mse: 143944.8125 - 620ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1652.1432 - mse: 24453490.0000 - val_loss: 140.5735 - val_mse: 99915.1875 - 636ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1651.6301 - mse: 27608410.0000 - val_loss: 117.0192 - val_mse: 69386.9141 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1633.7705 - mse: 26701258.0000 - val_loss: 97.3248 - val_mse: 48077.7422 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1731.0101 - mse: 30334642.0000 - val_loss: 77.1698 - val_mse: 30263.2617 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1685.3030 - mse: 30873090.0000 - val_loss: 64.1832 - val_mse: 21023.9434 - 630ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1627.6281 - mse: 28200076.0000 - val_loss: 46.0026 - val_mse: 10884.1689 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1525.5925 - mse: 21718920.0000 - val_loss: 31.9719 - val_mse: 5276.4521 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1647.9393 - mse: 26227850.0000 - val_loss: 16.9357 - val_mse: 1488.7419 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1592.8220 - mse: 25117220.0000 - val_loss: 6.1848 - val_mse: 203.0145 - 620ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1534.3134 - mse: 22335158.0000 - val_loss: 3.3153 - val_mse: 63.5211 - 618ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1532.1124 - mse: 21641526.0000 - val_loss: 9.0661 - val_mse: 420.7270 - 607ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1490.4344 - mse: 22642470.0000 - val_loss: 14.0450 - val_mse: 1008.5255 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1509.0968 - mse: 24583322.0000 - val_loss: 19.9151 - val_mse: 2158.0854 - 658ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1481.3904 - mse: 20994096.0000 - val_loss: 26.6326 - val_mse: 3548.3210 - 653ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1474.6287 - mse: 21749288.0000 - val_loss: 28.9703 - val_mse: 4128.8174 - 646ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1439.7362 - mse: 19119676.0000 - val_loss: 29.9116 - val_mse: 4281.2441 - 614ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1441.1649 - mse: 18766030.0000 - val_loss: 27.5453 - val_mse: 3455.2690 - 640ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1434.4790 - mse: 19319284.0000 - val_loss: 26.0540 - val_mse: 3121.3894 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1412.5901 - mse: 18672284.0000 - val_loss: 24.6550 - val_mse: 2869.5959 - 618ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1431.9579 - mse: 18686660.0000 - val_loss: 24.2546 - val_mse: 2744.3892 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1486.4480 - mse: 21717622.0000 - val_loss: 24.1083 - val_mse: 2827.5603 - 618ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1399.3813 - mse: 17555886.0000 - val_loss: 24.2895 - val_mse: 3022.1091 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1405.6307 - mse: 18596608.0000 - val_loss: 23.7420 - val_mse: 2830.8860 - 630ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1396.5999 - mse: 19766016.0000 - val_loss: 23.1722 - val_mse: 2639.4001 - 615ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1405.3704 - mse: 17641262.0000 - val_loss: 24.2966 - val_mse: 3069.0439 - 622ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1434.8743 - mse: 20257992.0000 - val_loss: 27.0638 - val_mse: 3824.1116 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1426.6383 - mse: 21162570.0000 - val_loss: 26.5637 - val_mse: 3430.6641 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1366.9580 - mse: 16071406.0000 - val_loss: 24.2111 - val_mse: 2568.2922 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1419.8148 - mse: 20533160.0000 - val_loss: 18.8994 - val_mse: 1246.3728 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1335.5537 - mse: 16161328.0000 - val_loss: 14.3992 - val_mse: 616.0452 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1353.6770 - mse: 18335190.0000 - val_loss: 10.2449 - val_mse: 288.2441 - 636ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1356.2128 - mse: 17151012.0000 - val_loss: 9.8215 - val_mse: 382.5841 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1346.0068 - mse: 17277172.0000 - val_loss: 11.5769 - val_mse: 806.8871 - 663ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1395.3307 - mse: 19649040.0000 - val_loss: 16.3617 - val_mse: 2022.6082 - 638ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1333.1781 - mse: 17571792.0000 - val_loss: 19.0487 - val_mse: 2724.2773 - 658ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1302.6788 - mse: 17325588.0000 - val_loss: 21.3969 - val_mse: 3306.6682 - 660ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1336.8894 - mse: 17756258.0000 - val_loss: 26.5978 - val_mse: 4735.1050 - 683ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1331.0765 - mse: 18739164.0000 - val_loss: 29.9461 - val_mse: 5832.0098 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1314.3472 - mse: 16717492.0000 - val_loss: 31.9645 - val_mse: 6536.4775 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1344.3804 - mse: 18439654.0000 - val_loss: 36.0839 - val_mse: 8152.2744 - 653ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1292.0859 - mse: 15992167.0000 - val_loss: 39.6784 - val_mse: 9613.6484 - 649ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1343.6608 - mse: 17348928.0000 - val_loss: 41.1928 - val_mse: 10230.0938 - 642ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1297.5989 - mse: 18994496.0000 - val_loss: 42.3468 - val_mse: 10740.1953 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1337.0586 - mse: 18508534.0000 - val_loss: 44.6874 - val_mse: 12005.4639 - 664ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1274.9094 - mse: 15349709.0000 - val_loss: 47.2334 - val_mse: 13328.3076 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1275.8152 - mse: 16051202.0000 - val_loss: 49.6514 - val_mse: 14660.8701 - 660ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1278.2701 - mse: 15529092.0000 - val_loss: 50.8932 - val_mse: 15347.8379 - 692ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1254.0898 - mse: 15887284.0000 - val_loss: 50.4127 - val_mse: 15065.2949 - 677ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1255.4515 - mse: 14193964.0000 - val_loss: 52.7989 - val_mse: 16460.4180 - 683ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1267.7500 - mse: 15424878.0000 - val_loss: 54.2170 - val_mse: 17288.1777 - 693ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1245.5344 - mse: 15402991.0000 - val_loss: 56.0976 - val_mse: 18460.5605 - 654ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1279.4738 - mse: 16193619.0000 - val_loss: 58.2635 - val_mse: 19857.8613 - 654ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1306.8373 - mse: 18236178.0000 - val_loss: 58.4419 - val_mse: 19958.5977 - 665ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1208.3477 - mse: 14361929.0000 - val_loss: 59.8523 - val_mse: 20877.8828 - 666ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1323.1152 - mse: 20025548.0000 - val_loss: 59.3615 - val_mse: 20540.5176 - 677ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1250.0597 - mse: 14856852.0000 - val_loss: 61.3959 - val_mse: 21872.9570 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1275.7799 - mse: 16276593.0000 - val_loss: 61.6087 - val_mse: 21972.5352 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1200.7371 - mse: 13917725.0000 - val_loss: 62.0408 - val_mse: 22192.0020 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1230.8953 - mse: 13948563.0000 - val_loss: 61.8765 - val_mse: 22083.7812 - 642ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1216.7616 - mse: 14449429.0000 - val_loss: 60.7559 - val_mse: 21295.8496 - 636ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1221.6543 - mse: 14546391.0000 - val_loss: 62.2937 - val_mse: 22306.0469 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1165.7922 - mse: 14359322.0000 - val_loss: 63.3090 - val_mse: 22983.5391 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1190.3528 - mse: 13889364.0000 - val_loss: 64.4504 - val_mse: 23756.6504 - 642ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1258.0359 - mse: 16059376.0000 - val_loss: 65.5085 - val_mse: 24428.3711 - 660ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1211.4612 - mse: 13688878.0000 - val_loss: 64.7457 - val_mse: 23846.2148 - 668ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1246.3705 - mse: 15634488.0000 - val_loss: 66.4813 - val_mse: 24993.5527 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1290.0338 - mse: 18384520.0000 - val_loss: 66.4502 - val_mse: 24954.8438 - 662ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1182.1445 - mse: 12268814.0000 - val_loss: 66.2746 - val_mse: 24765.1602 - 661ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1217.7606 - mse: 14438572.0000 - val_loss: 65.4809 - val_mse: 24190.9609 - 639ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1162.2306 - mse: 13079627.0000 - val_loss: 67.0366 - val_mse: 25263.4277 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1148.8755 - mse: 14170534.0000 - val_loss: 66.5921 - val_mse: 24900.1934 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1100.1615 - mse: 11671478.0000 - val_loss: 66.9647 - val_mse: 25226.4316 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1164.6982 - mse: 14030257.0000 - val_loss: 67.9212 - val_mse: 25852.1680 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1150.0894 - mse: 11557751.0000 - val_loss: 69.2729 - val_mse: 26832.8340 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1190.2551 - mse: 12618984.0000 - val_loss: 69.4735 - val_mse: 26898.3945 - 622ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1153.3627 - mse: 13791067.0000 - val_loss: 69.2128 - val_mse: 26702.5176 - 623ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1153.8950 - mse: 13111712.0000 - val_loss: 69.5197 - val_mse: 26887.8125 - 622ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1139.5863 - mse: 11896992.0000 - val_loss: 69.3211 - val_mse: 26712.5527 - 616ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1165.7649 - mse: 14429439.0000 - val_loss: 67.9678 - val_mse: 25725.3027 - 633ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1176.4365 - mse: 15579883.0000 - val_loss: 68.1717 - val_mse: 25872.6934 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1080.4233 - mse: 11551764.0000 - val_loss: 68.2489 - val_mse: 25925.4395 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1165.9133 - mse: 14111419.0000 - val_loss: 66.1994 - val_mse: 24394.8809 - 657ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1151.8606 - mse: 13346339.0000 - val_loss: 67.5871 - val_mse: 25456.4375 - 696ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1075.3740 - mse: 10722117.0000 - val_loss: 67.7799 - val_mse: 25674.1914 - 688ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1080.4476 - mse: 11699130.0000 - val_loss: 68.7916 - val_mse: 26409.1543 - 712ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1140.8590 - mse: 13712971.0000 - val_loss: 68.4789 - val_mse: 26171.4121 - 670ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1118.0792 - mse: 12575679.0000 - val_loss: 68.5086 - val_mse: 26201.3594 - 661ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1076.3491 - mse: 10625379.0000 - val_loss: 66.4295 - val_mse: 24669.7871 - 665ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1092.6042 - mse: 11625368.0000 - val_loss: 66.3217 - val_mse: 24558.0117 - 654ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1091.5233 - mse: 12093393.0000 - val_loss: 65.8517 - val_mse: 24177.8867 - 649ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1129.5959 - mse: 14419192.0000 - val_loss: 64.9328 - val_mse: 23505.1406 - 669ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1097.3534 - mse: 12002088.0000 - val_loss: 64.8876 - val_mse: 23434.6074 - 653ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1077.9385 - mse: 11573124.0000 - val_loss: 65.2362 - val_mse: 23649.6543 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1086.2863 - mse: 10566061.0000 - val_loss: 65.8920 - val_mse: 24055.4355 - 671ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 185 ended. Search finished for the next optimal point.\n",
            "Time taken: 80.3286\n",
            "Function value obtained: 24055.4355\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 186 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [51, 85]\n",
            "Learning Rate: 3.732285331391495e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.07652388767262898\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 262.2480 - mse: 757614.5000 - val_loss: 33.6925 - val_mse: 5474.2778 - 3s/epoch - 83ms/step\n",
            "33/33 - 0s - loss: 210.6092 - mse: 489999.6250 - val_loss: 1.9317 - val_mse: 22.2383 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 183.9538 - mse: 366108.0312 - val_loss: 2.9082 - val_mse: 31.7868 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 180.5112 - mse: 383446.3438 - val_loss: 1.7163 - val_mse: 21.3891 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 168.0458 - mse: 314066.8750 - val_loss: 5.0594 - val_mse: 247.1994 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 159.0846 - mse: 296147.0312 - val_loss: 1.9555 - val_mse: 19.5731 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 155.9342 - mse: 270466.2188 - val_loss: 8.1772 - val_mse: 410.8962 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 161.1737 - mse: 328591.1250 - val_loss: 1.3121 - val_mse: 15.3942 - 228ms/epoch - 7ms/step\n",
            "33/33 - 1s - loss: 153.7191 - mse: 279213.4375 - val_loss: 2.3256 - val_mse: 28.5864 - 787ms/epoch - 24ms/step\n",
            "33/33 - 0s - loss: 153.5227 - mse: 281508.3438 - val_loss: 2.2342 - val_mse: 44.1097 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 142.6009 - mse: 207110.9844 - val_loss: 4.6690 - val_mse: 139.7225 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 140.5180 - mse: 238215.6250 - val_loss: 2.1629 - val_mse: 39.8693 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 141.7828 - mse: 210596.7969 - val_loss: 1.5923 - val_mse: 16.7083 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 134.7485 - mse: 206414.8125 - val_loss: 0.4879 - val_mse: 1.6344 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 132.2890 - mse: 167804.2500 - val_loss: 2.4896 - val_mse: 44.1459 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 130.2201 - mse: 199561.1094 - val_loss: 0.6359 - val_mse: 2.1116 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 130.0935 - mse: 185239.2031 - val_loss: 0.2620 - val_mse: 0.5804 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 126.7301 - mse: 193122.6406 - val_loss: 5.2130 - val_mse: 191.6665 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 120.5950 - mse: 185935.8594 - val_loss: 4.4010 - val_mse: 161.9054 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 122.0319 - mse: 172429.9531 - val_loss: 0.7041 - val_mse: 2.2935 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 118.9446 - mse: 174659.6250 - val_loss: 0.8098 - val_mse: 8.7215 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 116.3194 - mse: 140897.0625 - val_loss: 0.4166 - val_mse: 1.2861 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 107.7539 - mse: 120952.3828 - val_loss: 1.4168 - val_mse: 14.5770 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 110.7241 - mse: 132229.7812 - val_loss: 0.3151 - val_mse: 0.9571 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 108.0286 - mse: 128263.3281 - val_loss: 1.8038 - val_mse: 32.0114 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 104.4653 - mse: 122302.8906 - val_loss: 0.5438 - val_mse: 1.7954 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 99.4152 - mse: 112758.2344 - val_loss: 0.5668 - val_mse: 2.1044 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 96.5278 - mse: 97937.1562 - val_loss: 1.2632 - val_mse: 20.9184 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 96.9544 - mse: 96171.7344 - val_loss: 2.9176 - val_mse: 67.0606 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 96.5100 - mse: 102256.2734 - val_loss: 1.7237 - val_mse: 22.9290 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 97.7813 - mse: 106134.4141 - val_loss: 2.0350 - val_mse: 36.5374 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 93.8117 - mse: 95509.9375 - val_loss: 0.9694 - val_mse: 5.3629 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 89.3109 - mse: 79387.8750 - val_loss: 3.2278 - val_mse: 93.6346 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 89.4421 - mse: 87378.3906 - val_loss: 0.5725 - val_mse: 1.8163 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 94.6774 - mse: 121962.8359 - val_loss: 0.4251 - val_mse: 1.5760 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 85.2269 - mse: 82805.8047 - val_loss: 0.1659 - val_mse: 0.3707 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 81.6755 - mse: 73734.1484 - val_loss: 2.3043 - val_mse: 46.9929 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 84.3023 - mse: 78892.2656 - val_loss: 0.8030 - val_mse: 7.7290 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 77.7526 - mse: 60729.7188 - val_loss: 0.6116 - val_mse: 3.4183 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 83.4327 - mse: 80311.7812 - val_loss: 1.0747 - val_mse: 10.2089 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 79.5936 - mse: 78955.9141 - val_loss: 0.2081 - val_mse: 0.4694 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 77.1328 - mse: 78973.1094 - val_loss: 0.2018 - val_mse: 0.4267 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 77.0524 - mse: 85067.9453 - val_loss: 0.4161 - val_mse: 1.0978 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 74.3284 - mse: 61536.7812 - val_loss: 0.1624 - val_mse: 0.5927 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 73.7532 - mse: 61516.2617 - val_loss: 2.8290 - val_mse: 56.0737 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 73.5143 - mse: 56368.0781 - val_loss: 0.9206 - val_mse: 8.4315 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 70.0879 - mse: 55245.7617 - val_loss: 0.2730 - val_mse: 0.9251 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 70.0612 - mse: 64047.0586 - val_loss: 0.6071 - val_mse: 2.6354 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 66.1723 - mse: 51756.8281 - val_loss: 0.7747 - val_mse: 4.5275 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 67.2749 - mse: 48979.5430 - val_loss: 0.3806 - val_mse: 1.0955 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 66.3484 - mse: 69226.1094 - val_loss: 0.8976 - val_mse: 8.0852 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 63.1797 - mse: 44973.5430 - val_loss: 0.2525 - val_mse: 0.7391 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 61.2409 - mse: 35715.2109 - val_loss: 0.5553 - val_mse: 2.5851 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 62.6033 - mse: 51325.6914 - val_loss: 1.2846 - val_mse: 14.0358 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 62.9019 - mse: 46895.6055 - val_loss: 0.8032 - val_mse: 6.8603 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 61.6427 - mse: 44429.5625 - val_loss: 1.3026 - val_mse: 13.4960 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 56.7372 - mse: 36956.3789 - val_loss: 0.4224 - val_mse: 2.1220 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 57.7592 - mse: 40047.4180 - val_loss: 0.9506 - val_mse: 8.6858 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 58.1706 - mse: 44908.0508 - val_loss: 0.4411 - val_mse: 1.3980 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 55.7484 - mse: 35396.5820 - val_loss: 0.1588 - val_mse: 0.4188 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 52.8293 - mse: 30363.5547 - val_loss: 0.4184 - val_mse: 1.5534 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 54.3852 - mse: 37479.4023 - val_loss: 0.3666 - val_mse: 1.6917 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 54.5985 - mse: 36888.5430 - val_loss: 0.0985 - val_mse: 0.1997 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 50.6119 - mse: 28492.7207 - val_loss: 0.3736 - val_mse: 1.7759 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 50.7414 - mse: 30190.5312 - val_loss: 0.6888 - val_mse: 4.8500 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 49.2922 - mse: 25211.9043 - val_loss: 1.3037 - val_mse: 14.7672 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 50.4151 - mse: 34053.7617 - val_loss: 0.2678 - val_mse: 0.8472 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 46.4130 - mse: 22025.8066 - val_loss: 0.2641 - val_mse: 1.1693 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 48.9622 - mse: 27140.4902 - val_loss: 0.3652 - val_mse: 1.5055 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 46.5377 - mse: 23869.0488 - val_loss: 0.2922 - val_mse: 1.2101 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 47.7596 - mse: 27530.7012 - val_loss: 0.2242 - val_mse: 0.8203 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 46.9511 - mse: 24523.4785 - val_loss: 0.6130 - val_mse: 4.3876 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 43.0201 - mse: 21707.6641 - val_loss: 0.2485 - val_mse: 0.9127 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 42.6719 - mse: 17721.0000 - val_loss: 0.0962 - val_mse: 0.2007 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 44.7664 - mse: 23298.2734 - val_loss: 0.5466 - val_mse: 3.0672 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 41.5785 - mse: 19672.6992 - val_loss: 0.3165 - val_mse: 1.0794 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 42.3094 - mse: 20289.2500 - val_loss: 0.1142 - val_mse: 0.2741 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 39.9852 - mse: 17702.6992 - val_loss: 1.0385 - val_mse: 8.9225 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 40.9545 - mse: 19899.8223 - val_loss: 0.1775 - val_mse: 0.5037 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 40.3692 - mse: 16461.7051 - val_loss: 0.3525 - val_mse: 1.8389 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 36.8451 - mse: 15041.4707 - val_loss: 0.3497 - val_mse: 1.6310 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 40.1543 - mse: 17964.9980 - val_loss: 0.5692 - val_mse: 3.3444 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 38.3168 - mse: 16412.6777 - val_loss: 0.2171 - val_mse: 0.5394 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 38.3961 - mse: 19704.7188 - val_loss: 0.1073 - val_mse: 0.2233 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 37.1268 - mse: 15892.3711 - val_loss: 0.1987 - val_mse: 0.5490 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 35.4223 - mse: 14009.5996 - val_loss: 0.0594 - val_mse: 0.1299 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 35.8442 - mse: 18833.0137 - val_loss: 0.3770 - val_mse: 1.6754 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 36.6021 - mse: 15560.2080 - val_loss: 0.2853 - val_mse: 1.0653 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 34.6272 - mse: 13614.8408 - val_loss: 0.0879 - val_mse: 0.1817 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 33.7046 - mse: 11798.6758 - val_loss: 0.0453 - val_mse: 0.0907 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 32.8806 - mse: 12787.2891 - val_loss: 0.3172 - val_mse: 1.1133 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 33.5384 - mse: 12563.5371 - val_loss: 0.9199 - val_mse: 9.5959 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 32.0602 - mse: 11361.2822 - val_loss: 0.2337 - val_mse: 0.7570 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 31.4943 - mse: 12261.5332 - val_loss: 0.0609 - val_mse: 0.1239 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 31.4936 - mse: 11326.3955 - val_loss: 0.0783 - val_mse: 0.1724 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 31.4480 - mse: 11698.5996 - val_loss: 0.0636 - val_mse: 0.1272 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 30.5259 - mse: 10153.0205 - val_loss: 0.1296 - val_mse: 0.3730 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 30.8473 - mse: 10371.5586 - val_loss: 0.0737 - val_mse: 0.1487 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 29.5849 - mse: 9884.4375 - val_loss: 0.0480 - val_mse: 0.0961 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 30.3362 - mse: 10059.2695 - val_loss: 0.2622 - val_mse: 0.7513 - 224ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 186 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.8677\n",
            "Function value obtained: 0.7513\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 187 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [77, 96]\n",
            "Learning Rate: 0.022761920197865413\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.37719742669387957\n",
            "Batch Size: 192\n",
            "----------------------------------------\n",
            "44/44 - 3s - loss: 1319.3101 - mse: 106156056.0000 - val_loss: 0.0153 - val_mse: 0.0305 - 3s/epoch - 63ms/step\n",
            "44/44 - 0s - loss: 0.8791 - mse: 139.8201 - val_loss: 0.0086 - val_mse: 0.0171 - 274ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.3981 - mse: 113.1220 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.2129 - mse: 15.3462 - val_loss: 0.0085 - val_mse: 0.0169 - 274ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.1822 - mse: 6.3294 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.1072 - mse: 3.5695 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0891 - mse: 2.4844 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.1037 - mse: 3.8571 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0572 - mse: 0.6681 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0650 - mse: 0.9430 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0327 - mse: 0.2731 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0516 - mse: 0.7571 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0439 - mse: 0.7576 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0464 - mse: 0.7415 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0424 - mse: 0.4419 - val_loss: 0.0084 - val_mse: 0.0168 - 261ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0307 - mse: 0.3132 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0368 - mse: 0.4506 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0293 - mse: 0.2683 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0362 - mse: 1.2651 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0249 - mse: 0.1445 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 7ms/step\n",
            "44/44 - 0s - loss: 0.0283 - mse: 0.3708 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0317 - mse: 0.2366 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0251 - mse: 0.2088 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0359 - mse: 0.5016 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0342 - mse: 0.4738 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0263 - mse: 0.2161 - val_loss: 0.0084 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0410 - mse: 1.2508 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0211 - mse: 0.1173 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0281 - mse: 0.2413 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0236 - mse: 0.2972 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0141 - mse: 0.0717 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0174 - mse: 0.0837 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0154 - mse: 0.0644 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0203 - mse: 0.1601 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0236 - mse: 0.4078 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0329 - mse: 1.7197 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0242 - mse: 0.3067 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0182 - mse: 0.1373 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0172 - mse: 0.2437 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0165 - mse: 0.0937 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0110 - mse: 0.0253 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0191 - mse: 0.1898 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0182 - mse: 0.2022 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0183 - mse: 0.1191 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0116 - mse: 0.0348 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0144 - mse: 0.0532 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0167 - mse: 0.1071 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0205 - mse: 0.1649 - val_loss: 0.0085 - val_mse: 0.0169 - 277ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0100 - mse: 0.0226 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0142 - mse: 0.0766 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0116 - mse: 0.0328 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0278 - mse: 1.7520 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0114 - mse: 0.0508 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0112 - mse: 0.0437 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0113 - mse: 0.0294 - val_loss: 0.0084 - val_mse: 0.0168 - 285ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0113 - mse: 0.0309 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0143 - mse: 0.1570 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0108 - mse: 0.0266 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0115 - mse: 0.0370 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0114 - mse: 0.0286 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0094 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0121 - mse: 0.0471 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0157 - mse: 0.1069 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0091 - mse: 0.0194 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0114 - mse: 0.0519 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0097 - mse: 0.0234 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0153 - mse: 0.0829 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0118 - mse: 0.0560 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0094 - mse: 0.0204 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0195 - mse: 0.9095 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0143 - mse: 0.2139 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0189 - mse: 0.4675 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0120 - mse: 0.0499 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0105 - mse: 0.0280 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0128 - mse: 0.1637 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0105 - mse: 0.0347 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0091 - mse: 0.0200 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0108 - mse: 0.0288 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0127 - mse: 0.0539 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0148 - mse: 0.1032 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0091 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0090 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0095 - mse: 0.0199 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0096 - mse: 0.0215 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0120 - mse: 0.0821 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0099 - mse: 0.0226 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0091 - mse: 0.0188 - val_loss: 0.0086 - val_mse: 0.0171 - 258ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0094 - mse: 0.0202 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0090 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0169 - 278ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0099 - mse: 0.0235 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "44/44 - 1s - loss: 0.0092 - mse: 0.0193 - val_loss: 0.0084 - val_mse: 0.0167 - 785ms/epoch - 18ms/step\n",
            "44/44 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 7ms/step\n",
            "44/44 - 0s - loss: 0.0097 - mse: 0.0206 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 7ms/step\n",
            "44/44 - 0s - loss: 0.0101 - mse: 0.0324 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0112 - mse: 0.0433 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 269ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0098 - mse: 0.0253 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "44/44 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0170 - 281ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01049495]\n",
            "\n",
            "Iteration No: 187 ended. Search finished for the next optimal point.\n",
            "Time taken: 44.1288\n",
            "Function value obtained: 0.0170\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 188 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [59, 77]\n",
            "Learning Rate: 6.786250161147246e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4357427664243042\n",
            "Batch Size: 60\n",
            "----------------------------------------\n",
            "140/140 - 3s - loss: 2783.6990 - mse: 70784248.0000 - val_loss: 81.7294 - val_mse: 34330.0391 - 3s/epoch - 22ms/step\n",
            "140/140 - 1s - loss: 1810.2010 - mse: 37089932.0000 - val_loss: 22.4072 - val_mse: 3141.4316 - 671ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1536.3568 - mse: 22223456.0000 - val_loss: 20.8929 - val_mse: 2747.7141 - 651ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1324.5254 - mse: 18198392.0000 - val_loss: 28.0954 - val_mse: 4216.7554 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1175.0474 - mse: 13033502.0000 - val_loss: 9.0712 - val_mse: 436.8940 - 634ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1008.2886 - mse: 9068280.0000 - val_loss: 7.4678 - val_mse: 363.9094 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 949.9638 - mse: 8633139.0000 - val_loss: 4.5345 - val_mse: 92.7275 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 878.9385 - mse: 7837587.0000 - val_loss: 4.1975 - val_mse: 134.1248 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 789.6930 - mse: 6911922.5000 - val_loss: 17.7568 - val_mse: 1815.1210 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 727.4987 - mse: 5632075.0000 - val_loss: 24.3537 - val_mse: 3359.7185 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 627.8968 - mse: 3934331.7500 - val_loss: 25.8531 - val_mse: 3714.8152 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 585.1614 - mse: 3245557.2500 - val_loss: 19.0743 - val_mse: 2100.0061 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 522.7166 - mse: 3117339.2500 - val_loss: 34.9926 - val_mse: 6715.0337 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 476.7703 - mse: 2171670.2500 - val_loss: 29.9053 - val_mse: 4974.0913 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 441.7334 - mse: 2168966.0000 - val_loss: 18.3636 - val_mse: 1931.8081 - 651ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 381.4435 - mse: 1227700.3750 - val_loss: 14.8968 - val_mse: 1299.1531 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 355.5822 - mse: 1219986.5000 - val_loss: 12.9274 - val_mse: 1042.2791 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 354.2357 - mse: 1474948.7500 - val_loss: 14.3600 - val_mse: 1219.7048 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 316.6039 - mse: 1043908.3750 - val_loss: 7.3432 - val_mse: 330.5313 - 666ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 284.9992 - mse: 872811.2500 - val_loss: 9.9134 - val_mse: 582.9615 - 666ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 257.3580 - mse: 630371.6250 - val_loss: 14.0885 - val_mse: 1148.5000 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 241.5750 - mse: 568377.1875 - val_loss: 12.6392 - val_mse: 930.9264 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 235.1931 - mse: 550995.0000 - val_loss: 12.0013 - val_mse: 843.7633 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 208.9926 - mse: 430345.7500 - val_loss: 12.1808 - val_mse: 857.7781 - 638ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 189.6658 - mse: 360536.2188 - val_loss: 7.8859 - val_mse: 388.8766 - 630ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 178.2453 - mse: 308064.7188 - val_loss: 11.0900 - val_mse: 729.1244 - 644ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 165.4034 - mse: 278814.6562 - val_loss: 8.7844 - val_mse: 467.9062 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 164.3081 - mse: 298871.0938 - val_loss: 9.6018 - val_mse: 547.3140 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 146.6392 - mse: 207391.0469 - val_loss: 10.8741 - val_mse: 697.2880 - 649ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 136.3955 - mse: 199561.2812 - val_loss: 10.5772 - val_mse: 664.6187 - 652ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 118.8566 - mse: 148874.9062 - val_loss: 9.9807 - val_mse: 599.7175 - 640ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 109.2952 - mse: 115018.7812 - val_loss: 6.1200 - val_mse: 239.6243 - 647ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 111.0003 - mse: 156457.8281 - val_loss: 3.2752 - val_mse: 76.6216 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 100.6747 - mse: 112820.0547 - val_loss: 3.4922 - val_mse: 85.2121 - 647ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 93.9040 - mse: 87268.7734 - val_loss: 2.9592 - val_mse: 62.2986 - 685ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 87.7400 - mse: 102182.2656 - val_loss: 3.0044 - val_mse: 63.5104 - 669ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 79.1302 - mse: 63348.4062 - val_loss: 2.8819 - val_mse: 58.3364 - 669ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 71.5032 - mse: 50879.9023 - val_loss: 2.0638 - val_mse: 33.1958 - 674ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 71.2964 - mse: 53553.2930 - val_loss: 1.1314 - val_mse: 11.5073 - 647ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 63.3898 - mse: 44845.6250 - val_loss: 1.0602 - val_mse: 10.0077 - 635ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 60.0063 - mse: 40993.7031 - val_loss: 0.8714 - val_mse: 7.2314 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 57.0781 - mse: 40360.7344 - val_loss: 0.4776 - val_mse: 2.4012 - 633ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 51.2099 - mse: 27918.6934 - val_loss: 0.5985 - val_mse: 3.6849 - 625ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 46.3449 - mse: 26843.5352 - val_loss: 0.7516 - val_mse: 5.5148 - 615ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 46.4810 - mse: 25849.0625 - val_loss: 0.4123 - val_mse: 1.9498 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 40.9456 - mse: 21420.1680 - val_loss: 0.1673 - val_mse: 0.3803 - 639ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 38.2186 - mse: 16905.6641 - val_loss: 0.1223 - val_mse: 0.2446 - 650ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 34.4526 - mse: 14445.7686 - val_loss: 0.1206 - val_mse: 0.2412 - 619ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 33.5946 - mse: 13258.3135 - val_loss: 0.1124 - val_mse: 0.2254 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 30.4779 - mse: 11201.6885 - val_loss: 0.1086 - val_mse: 0.2177 - 611ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 27.2290 - mse: 8231.7080 - val_loss: 0.1308 - val_mse: 0.2768 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 25.6739 - mse: 8022.5796 - val_loss: 0.1168 - val_mse: 0.2378 - 635ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 23.7585 - mse: 7255.1362 - val_loss: 0.1169 - val_mse: 0.2400 - 642ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 22.6439 - mse: 7483.5986 - val_loss: 0.1113 - val_mse: 0.2266 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 20.7809 - mse: 6157.3037 - val_loss: 0.1497 - val_mse: 0.3513 - 655ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 19.3141 - mse: 4817.0483 - val_loss: 0.1165 - val_mse: 0.2445 - 641ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 17.3478 - mse: 3502.7109 - val_loss: 0.1022 - val_mse: 0.2070 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 15.7770 - mse: 3954.3462 - val_loss: 0.0902 - val_mse: 0.1804 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 14.6880 - mse: 2775.2253 - val_loss: 0.0901 - val_mse: 0.1804 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 14.3459 - mse: 3020.4932 - val_loss: 0.0848 - val_mse: 0.1695 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 12.5238 - mse: 2316.9685 - val_loss: 0.0811 - val_mse: 0.1622 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 12.1481 - mse: 3185.0215 - val_loss: 0.0785 - val_mse: 0.1569 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 11.2274 - mse: 1695.7562 - val_loss: 0.0764 - val_mse: 0.1528 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 9.8868 - mse: 1419.8580 - val_loss: 0.0743 - val_mse: 0.1486 - 613ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 9.6020 - mse: 1463.9401 - val_loss: 0.0722 - val_mse: 0.1444 - 616ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 8.6170 - mse: 1172.3776 - val_loss: 0.0707 - val_mse: 0.1414 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 7.9373 - mse: 1104.6051 - val_loss: 0.0687 - val_mse: 0.1374 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 7.7461 - mse: 1094.9711 - val_loss: 0.0657 - val_mse: 0.1313 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 6.9011 - mse: 1267.7798 - val_loss: 0.0625 - val_mse: 0.1250 - 630ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 6.1759 - mse: 623.1735 - val_loss: 0.0587 - val_mse: 0.1173 - 630ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 5.4487 - mse: 639.5893 - val_loss: 0.0553 - val_mse: 0.1105 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 5.4467 - mse: 666.9516 - val_loss: 0.0521 - val_mse: 0.1043 - 643ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 4.6451 - mse: 431.5398 - val_loss: 0.0488 - val_mse: 0.0977 - 656ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 4.6781 - mse: 518.2289 - val_loss: 0.0457 - val_mse: 0.0913 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 4.2418 - mse: 386.1339 - val_loss: 0.0431 - val_mse: 0.0862 - 633ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 3.6140 - mse: 298.9972 - val_loss: 0.0403 - val_mse: 0.0805 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 3.6016 - mse: 311.3685 - val_loss: 0.0379 - val_mse: 0.0757 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 3.0645 - mse: 206.9045 - val_loss: 0.0354 - val_mse: 0.0707 - 624ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2.9321 - mse: 264.2103 - val_loss: 0.0328 - val_mse: 0.0655 - 631ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2.6892 - mse: 182.6784 - val_loss: 0.0303 - val_mse: 0.0606 - 639ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2.7394 - mse: 225.6923 - val_loss: 0.0284 - val_mse: 0.0568 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2.3993 - mse: 242.2804 - val_loss: 0.0265 - val_mse: 0.0529 - 626ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 2.1371 - mse: 174.1302 - val_loss: 0.0248 - val_mse: 0.0496 - 634ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 2.0857 - mse: 167.9172 - val_loss: 0.0227 - val_mse: 0.0455 - 637ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.7020 - mse: 80.9432 - val_loss: 0.0212 - val_mse: 0.0424 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 1.6539 - mse: 92.4121 - val_loss: 0.0197 - val_mse: 0.0395 - 645ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.5647 - mse: 96.8975 - val_loss: 0.0186 - val_mse: 0.0371 - 638ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.5266 - mse: 123.5235 - val_loss: 0.0175 - val_mse: 0.0351 - 666ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.2339 - mse: 78.2669 - val_loss: 0.0164 - val_mse: 0.0328 - 667ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.2480 - mse: 64.3965 - val_loss: 0.0154 - val_mse: 0.0309 - 665ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 1.0968 - mse: 50.7121 - val_loss: 0.0145 - val_mse: 0.0290 - 669ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 0.9344 - mse: 35.1650 - val_loss: 0.0137 - val_mse: 0.0273 - 620ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.9350 - mse: 39.9209 - val_loss: 0.0129 - val_mse: 0.0258 - 621ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.8088 - mse: 28.9898 - val_loss: 0.0120 - val_mse: 0.0241 - 629ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.9236 - mse: 58.8930 - val_loss: 0.0116 - val_mse: 0.0231 - 617ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.7379 - mse: 40.6372 - val_loss: 0.0109 - val_mse: 0.0218 - 632ms/epoch - 5ms/step\n",
            "140/140 - 1s - loss: 0.7047 - mse: 29.4334 - val_loss: 0.0104 - val_mse: 0.0208 - 628ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.5657 - mse: 16.5945 - val_loss: 0.0099 - val_mse: 0.0199 - 622ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.6648 - mse: 29.0167 - val_loss: 0.0096 - val_mse: 0.0192 - 627ms/epoch - 4ms/step\n",
            "140/140 - 1s - loss: 0.6061 - mse: 26.4275 - val_loss: 0.0093 - val_mse: 0.0187 - 637ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 188 ended. Search finished for the next optimal point.\n",
            "Time taken: 79.7184\n",
            "Function value obtained: 0.0187\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 189 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [55, 53]\n",
            "Learning Rate: 4.257373813635006e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.12527591162898205\n",
            "Batch Size: 254\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 1859.2057 - mse: 23222792.0000 - val_loss: 1515.9580 - val_mse: 11440935.0000 - 3s/epoch - 76ms/step\n",
            "34/34 - 0s - loss: 1789.5629 - mse: 22721718.0000 - val_loss: 1403.6359 - val_mse: 9797301.0000 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1714.9871 - mse: 22704078.0000 - val_loss: 1293.6575 - val_mse: 8312855.5000 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1587.8201 - mse: 18333124.0000 - val_loss: 1194.1450 - val_mse: 7076352.5000 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1536.5582 - mse: 17478700.0000 - val_loss: 1097.3936 - val_mse: 5966073.0000 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1454.6067 - mse: 16592528.0000 - val_loss: 1006.5847 - val_mse: 5011056.0000 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1403.4326 - mse: 15651759.0000 - val_loss: 914.2249 - val_mse: 4126393.2500 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1314.9541 - mse: 12131485.0000 - val_loss: 838.8403 - val_mse: 3470939.2500 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1286.3468 - mse: 12962525.0000 - val_loss: 771.1053 - val_mse: 2926049.7500 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1201.8160 - mse: 12007275.0000 - val_loss: 706.3536 - val_mse: 2448654.2500 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1178.9781 - mse: 11572919.0000 - val_loss: 637.7920 - val_mse: 1989039.3750 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1094.3738 - mse: 9206861.0000 - val_loss: 572.8378 - val_mse: 1597819.0000 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1020.9429 - mse: 8524659.0000 - val_loss: 512.0820 - val_mse: 1271017.1250 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1017.2220 - mse: 8509324.0000 - val_loss: 454.4836 - val_mse: 995684.3750 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 979.3112 - mse: 7990335.0000 - val_loss: 397.4178 - val_mse: 756112.6250 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 937.2563 - mse: 7478529.5000 - val_loss: 349.3310 - val_mse: 579866.1250 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 928.1901 - mse: 7517793.5000 - val_loss: 299.3934 - val_mse: 422685.2188 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 870.3260 - mse: 6189807.0000 - val_loss: 256.8100 - val_mse: 309413.5938 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 844.4936 - mse: 6201290.0000 - val_loss: 213.8351 - val_mse: 211844.9531 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 807.3564 - mse: 5491669.0000 - val_loss: 177.9665 - val_mse: 146910.7188 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 804.9444 - mse: 5859140.5000 - val_loss: 143.2556 - val_mse: 94173.5781 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 795.5817 - mse: 5736494.5000 - val_loss: 113.7243 - val_mse: 58102.9805 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 786.0880 - mse: 5900254.5000 - val_loss: 91.6611 - val_mse: 36772.0039 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 726.4428 - mse: 4516197.5000 - val_loss: 71.5041 - val_mse: 22400.8770 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 745.6869 - mse: 5097569.0000 - val_loss: 53.4284 - val_mse: 12904.1387 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 709.2333 - mse: 4486369.5000 - val_loss: 37.8837 - val_mse: 6586.2090 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 715.3708 - mse: 4544713.0000 - val_loss: 24.4340 - val_mse: 2720.8398 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 664.2175 - mse: 3822228.5000 - val_loss: 12.1935 - val_mse: 657.5776 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 636.7636 - mse: 3254629.0000 - val_loss: 2.9417 - val_mse: 30.3065 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 667.0620 - mse: 3968398.0000 - val_loss: 5.8642 - val_mse: 343.9985 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 649.9027 - mse: 3932706.2500 - val_loss: 15.0344 - val_mse: 1636.8350 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 648.8665 - mse: 4236386.0000 - val_loss: 24.7157 - val_mse: 3937.6191 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 644.1428 - mse: 3969452.7500 - val_loss: 34.8379 - val_mse: 7226.2231 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 618.4794 - mse: 3479768.5000 - val_loss: 41.9116 - val_mse: 10154.5342 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 594.0390 - mse: 3032184.5000 - val_loss: 49.5855 - val_mse: 13987.8936 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 606.9050 - mse: 3184277.5000 - val_loss: 57.6672 - val_mse: 18753.2988 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 599.5942 - mse: 3613690.7500 - val_loss: 62.9619 - val_mse: 22252.3418 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 602.2716 - mse: 3452022.2500 - val_loss: 71.1441 - val_mse: 28270.7715 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 586.1793 - mse: 3187460.5000 - val_loss: 75.2300 - val_mse: 31449.5840 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 571.7546 - mse: 2991390.2500 - val_loss: 79.1262 - val_mse: 34591.3945 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 566.7333 - mse: 3136348.2500 - val_loss: 83.2882 - val_mse: 38134.4492 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 547.9691 - mse: 2985447.2500 - val_loss: 88.8115 - val_mse: 43154.7422 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 529.1736 - mse: 2442329.7500 - val_loss: 92.7806 - val_mse: 46960.2188 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 533.4431 - mse: 2744150.0000 - val_loss: 94.3312 - val_mse: 48478.3945 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 529.2509 - mse: 2639266.5000 - val_loss: 93.7612 - val_mse: 47831.1406 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 509.9732 - mse: 2208026.0000 - val_loss: 92.4122 - val_mse: 46441.1836 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 547.5165 - mse: 2746692.2500 - val_loss: 91.9265 - val_mse: 45909.8164 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 519.6987 - mse: 2718794.7500 - val_loss: 93.6856 - val_mse: 47595.7266 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 517.3628 - mse: 2570063.0000 - val_loss: 95.5490 - val_mse: 49375.8555 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 517.8373 - mse: 2692163.0000 - val_loss: 95.8369 - val_mse: 49639.9258 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 506.2376 - mse: 2461699.2500 - val_loss: 94.4761 - val_mse: 48220.0898 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 499.5021 - mse: 2401866.0000 - val_loss: 93.6330 - val_mse: 47351.1328 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 486.0801 - mse: 2353987.0000 - val_loss: 90.9491 - val_mse: 44657.9336 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 478.9182 - mse: 1969467.8750 - val_loss: 90.2821 - val_mse: 44030.9297 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 488.8917 - mse: 2218881.7500 - val_loss: 90.3824 - val_mse: 44064.8438 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 453.8070 - mse: 1937839.7500 - val_loss: 89.1546 - val_mse: 42813.7734 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 486.0380 - mse: 2295376.7500 - val_loss: 88.3811 - val_mse: 41923.3086 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 470.1924 - mse: 2045635.6250 - val_loss: 87.0465 - val_mse: 40591.7656 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 463.6751 - mse: 2438306.2500 - val_loss: 84.8629 - val_mse: 38501.8281 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 435.9539 - mse: 1773712.1250 - val_loss: 82.3958 - val_mse: 36399.3125 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 429.6095 - mse: 1681129.2500 - val_loss: 80.8337 - val_mse: 35023.0430 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 447.2018 - mse: 2155362.7500 - val_loss: 77.3000 - val_mse: 31993.4902 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 446.2582 - mse: 1971906.3750 - val_loss: 75.6128 - val_mse: 30558.3125 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 442.2460 - mse: 1951458.1250 - val_loss: 75.5673 - val_mse: 30452.8848 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 421.8994 - mse: 1961000.7500 - val_loss: 72.0153 - val_mse: 27503.0078 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 427.7497 - mse: 1745324.2500 - val_loss: 70.0234 - val_mse: 26068.7285 - 256ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 426.9268 - mse: 1770542.2500 - val_loss: 70.2159 - val_mse: 26167.9062 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 407.1213 - mse: 1447272.2500 - val_loss: 66.8444 - val_mse: 23668.6914 - 261ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 429.3892 - mse: 2079953.5000 - val_loss: 65.2479 - val_mse: 22418.3730 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 401.6428 - mse: 1588113.8750 - val_loss: 62.9268 - val_mse: 20642.4238 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 407.6464 - mse: 1565439.5000 - val_loss: 60.8030 - val_mse: 19047.4336 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 393.0746 - mse: 1540353.2500 - val_loss: 58.5289 - val_mse: 17509.9160 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 386.5214 - mse: 1414587.8750 - val_loss: 57.1640 - val_mse: 16759.4102 - 251ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 403.9645 - mse: 1544226.8750 - val_loss: 55.2868 - val_mse: 15571.3047 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 388.8279 - mse: 1469851.2500 - val_loss: 53.5947 - val_mse: 14431.8320 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 381.1548 - mse: 1354839.1250 - val_loss: 53.2749 - val_mse: 14337.5195 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 400.5612 - mse: 1570751.7500 - val_loss: 51.5243 - val_mse: 13088.5645 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 386.1818 - mse: 1550323.8750 - val_loss: 49.7953 - val_mse: 12138.2100 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 373.2242 - mse: 1337501.0000 - val_loss: 48.8648 - val_mse: 11694.6035 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 386.3191 - mse: 1461072.5000 - val_loss: 46.8896 - val_mse: 10512.4043 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 377.8377 - mse: 1629390.8750 - val_loss: 45.4026 - val_mse: 9782.8408 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 366.2028 - mse: 1280114.0000 - val_loss: 43.3189 - val_mse: 8731.8408 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 361.2239 - mse: 1199770.7500 - val_loss: 42.0859 - val_mse: 8099.0303 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 377.2904 - mse: 1385739.8750 - val_loss: 40.6213 - val_mse: 7451.1411 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 362.3713 - mse: 1286697.7500 - val_loss: 40.0342 - val_mse: 7222.7295 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 351.7162 - mse: 1100081.5000 - val_loss: 39.1504 - val_mse: 6891.2295 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 363.6154 - mse: 1336832.8750 - val_loss: 38.8385 - val_mse: 6767.8682 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 349.1180 - mse: 1123155.7500 - val_loss: 38.0828 - val_mse: 6508.8018 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 362.8009 - mse: 1339260.6250 - val_loss: 37.5248 - val_mse: 6429.4058 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 365.4102 - mse: 1403286.6250 - val_loss: 36.5351 - val_mse: 6417.8086 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 346.8643 - mse: 1234358.0000 - val_loss: 36.1836 - val_mse: 6436.9209 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 354.7409 - mse: 1210446.3750 - val_loss: 35.9198 - val_mse: 6392.8818 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 343.2616 - mse: 1010786.7500 - val_loss: 35.7688 - val_mse: 6500.1030 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 347.1944 - mse: 1282543.6250 - val_loss: 34.7737 - val_mse: 6225.4912 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 350.5268 - mse: 1232336.2500 - val_loss: 33.5937 - val_mse: 5990.2163 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 342.7047 - mse: 1095254.0000 - val_loss: 33.0211 - val_mse: 5773.9282 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 342.1330 - mse: 1230787.0000 - val_loss: 32.0336 - val_mse: 5490.6743 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 342.2105 - mse: 1216815.8750 - val_loss: 29.8143 - val_mse: 5036.6646 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 348.7589 - mse: 1200948.2500 - val_loss: 27.7354 - val_mse: 4542.0581 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 352.3468 - mse: 1440852.1250 - val_loss: 22.9725 - val_mse: 3422.9187 - 224ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 189 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.8553\n",
            "Function value obtained: 3422.9187\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 190 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [98, 109]\n",
            "Learning Rate: 9.78433540497177e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4317001864934862\n",
            "Batch Size: 64\n",
            "----------------------------------------\n",
            "132/132 - 3s - loss: 1809.8960 - mse: 31951562.0000 - val_loss: 192.2486 - val_mse: 183666.3125 - 3s/epoch - 22ms/step\n",
            "132/132 - 1s - loss: 1600.2798 - mse: 22697898.0000 - val_loss: 87.4925 - val_mse: 38548.5039 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1566.4908 - mse: 24581862.0000 - val_loss: 50.4220 - val_mse: 12126.0371 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1527.2275 - mse: 23404094.0000 - val_loss: 30.3329 - val_mse: 4239.0737 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1441.8770 - mse: 20768138.0000 - val_loss: 76.7906 - val_mse: 31551.0117 - 608ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1391.0687 - mse: 18690728.0000 - val_loss: 127.4664 - val_mse: 80134.2109 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1309.9716 - mse: 15501995.0000 - val_loss: 146.9588 - val_mse: 105083.9844 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1327.2462 - mse: 17303830.0000 - val_loss: 141.2297 - val_mse: 97526.5781 - 618ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1332.0491 - mse: 17783432.0000 - val_loss: 149.8447 - val_mse: 109038.6094 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1202.8464 - mse: 14155452.0000 - val_loss: 145.5053 - val_mse: 102733.6484 - 623ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1139.3112 - mse: 11255042.0000 - val_loss: 117.5046 - val_mse: 65074.9180 - 625ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1201.7317 - mse: 14632579.0000 - val_loss: 91.7578 - val_mse: 40522.8750 - 634ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1157.4956 - mse: 13914317.0000 - val_loss: 85.0109 - val_mse: 35065.1484 - 644ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1128.8774 - mse: 12489835.0000 - val_loss: 88.7137 - val_mse: 37840.4688 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1097.4286 - mse: 10972385.0000 - val_loss: 79.0159 - val_mse: 30030.7246 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1123.0686 - mse: 12933307.0000 - val_loss: 87.5895 - val_mse: 37320.1641 - 619ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1065.8568 - mse: 10138120.0000 - val_loss: 86.8291 - val_mse: 36779.2266 - 614ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1010.0817 - mse: 9967459.0000 - val_loss: 79.4204 - val_mse: 30588.7520 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 997.1940 - mse: 10129729.0000 - val_loss: 80.2513 - val_mse: 31497.7715 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 964.9592 - mse: 7632836.0000 - val_loss: 66.7095 - val_mse: 21595.0039 - 602ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1046.8450 - mse: 12184331.0000 - val_loss: 65.1685 - val_mse: 20600.8574 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 965.8436 - mse: 9310812.0000 - val_loss: 72.3661 - val_mse: 24951.6797 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 930.9816 - mse: 8432985.0000 - val_loss: 71.4298 - val_mse: 24459.6094 - 617ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 930.6075 - mse: 9402521.0000 - val_loss: 67.1937 - val_mse: 21693.5918 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 917.2649 - mse: 8303295.5000 - val_loss: 59.5815 - val_mse: 17092.3164 - 591ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 939.1563 - mse: 10309851.0000 - val_loss: 56.5590 - val_mse: 15385.7197 - 597ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 862.9288 - mse: 7039053.0000 - val_loss: 55.8427 - val_mse: 15068.0684 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 887.3653 - mse: 7699183.5000 - val_loss: 50.2407 - val_mse: 12040.8652 - 615ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 846.8796 - mse: 7524722.5000 - val_loss: 48.1726 - val_mse: 11075.1895 - 636ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 800.3090 - mse: 6197108.0000 - val_loss: 43.8707 - val_mse: 9133.8975 - 630ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 787.5436 - mse: 7188626.5000 - val_loss: 33.0859 - val_mse: 5130.4121 - 636ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 774.3681 - mse: 6016143.0000 - val_loss: 30.7635 - val_mse: 4458.8833 - 618ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 783.1600 - mse: 5774641.5000 - val_loss: 25.6277 - val_mse: 3002.7590 - 626ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 742.3967 - mse: 4854462.5000 - val_loss: 18.8363 - val_mse: 1577.5048 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 716.9008 - mse: 4547969.0000 - val_loss: 10.5617 - val_mse: 460.0373 - 611ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 728.0015 - mse: 4909455.0000 - val_loss: 7.7111 - val_mse: 224.5309 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 728.3337 - mse: 5320024.5000 - val_loss: 11.0161 - val_mse: 518.6837 - 629ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 732.7589 - mse: 5407000.0000 - val_loss: 9.3562 - val_mse: 344.6361 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 679.3397 - mse: 4988391.5000 - val_loss: 8.5353 - val_mse: 283.4325 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 706.6138 - mse: 5101574.0000 - val_loss: 7.4495 - val_mse: 226.9669 - 610ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 642.8423 - mse: 3799673.2500 - val_loss: 1.8293 - val_mse: 22.8245 - 585ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 623.5914 - mse: 3731834.5000 - val_loss: 1.6067 - val_mse: 17.3918 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 627.6805 - mse: 3948514.7500 - val_loss: 1.3962 - val_mse: 12.1455 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 616.3850 - mse: 3581854.5000 - val_loss: 6.4637 - val_mse: 296.6271 - 599ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 600.5164 - mse: 3542108.5000 - val_loss: 2.2939 - val_mse: 38.3102 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 600.9506 - mse: 3850353.7500 - val_loss: 0.8164 - val_mse: 4.1156 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 589.6435 - mse: 3466820.7500 - val_loss: 3.5006 - val_mse: 80.6996 - 631ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 557.9107 - mse: 2934525.7500 - val_loss: 1.4146 - val_mse: 12.4642 - 621ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 563.3362 - mse: 3747651.5000 - val_loss: 3.8151 - val_mse: 80.2324 - 621ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 571.9960 - mse: 3600989.7500 - val_loss: 6.7326 - val_mse: 238.2958 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 556.3320 - mse: 3360496.7500 - val_loss: 4.5771 - val_mse: 111.1369 - 585ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 533.6962 - mse: 2922625.2500 - val_loss: 7.5917 - val_mse: 315.0253 - 612ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 514.3192 - mse: 2610523.5000 - val_loss: 12.3431 - val_mse: 827.3734 - 612ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 509.9266 - mse: 2674881.0000 - val_loss: 17.2307 - val_mse: 1700.1934 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 508.5436 - mse: 2715505.7500 - val_loss: 17.7420 - val_mse: 1838.6436 - 596ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 474.0519 - mse: 2261139.0000 - val_loss: 23.5693 - val_mse: 3088.4846 - 583ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 498.8633 - mse: 2734160.0000 - val_loss: 21.1349 - val_mse: 2613.5979 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 453.5732 - mse: 1941686.5000 - val_loss: 21.9805 - val_mse: 2813.0254 - 599ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 457.3040 - mse: 2031330.2500 - val_loss: 20.6137 - val_mse: 2498.9099 - 597ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 450.3791 - mse: 2132106.0000 - val_loss: 20.4889 - val_mse: 2464.2764 - 602ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 446.5682 - mse: 2058571.3750 - val_loss: 23.6066 - val_mse: 3141.7974 - 597ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 445.2505 - mse: 2019255.0000 - val_loss: 22.4263 - val_mse: 2823.9736 - 594ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 438.7797 - mse: 1800593.1250 - val_loss: 21.5984 - val_mse: 2699.7786 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 423.6466 - mse: 1861487.8750 - val_loss: 15.1325 - val_mse: 1464.9669 - 615ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 411.9877 - mse: 1665959.2500 - val_loss: 8.0715 - val_mse: 506.7741 - 620ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 405.6002 - mse: 1643727.0000 - val_loss: 11.7711 - val_mse: 996.7791 - 630ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 402.3299 - mse: 1748460.8750 - val_loss: 5.1234 - val_mse: 224.4346 - 628ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 397.2130 - mse: 1649326.1250 - val_loss: 17.8319 - val_mse: 1993.6023 - 635ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 373.2057 - mse: 1413471.3750 - val_loss: 18.0994 - val_mse: 2062.5310 - 591ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 364.9498 - mse: 1287578.8750 - val_loss: 16.7807 - val_mse: 1772.6455 - 596ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 342.5568 - mse: 1059262.2500 - val_loss: 18.5288 - val_mse: 2024.9626 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 377.7802 - mse: 1450476.3750 - val_loss: 19.1170 - val_mse: 2132.4526 - 599ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 350.7076 - mse: 1249608.8750 - val_loss: 17.7719 - val_mse: 1929.5293 - 592ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 331.4485 - mse: 1024006.9375 - val_loss: 13.2644 - val_mse: 1201.6212 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 342.6273 - mse: 1210653.8750 - val_loss: 6.5155 - val_mse: 351.1398 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 319.9713 - mse: 899740.6250 - val_loss: 2.3889 - val_mse: 60.5232 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 313.9957 - mse: 903321.3750 - val_loss: 5.3869 - val_mse: 126.7750 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 312.7708 - mse: 1015595.0000 - val_loss: 6.4698 - val_mse: 192.4870 - 599ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 304.2371 - mse: 794828.0625 - val_loss: 6.5585 - val_mse: 221.8983 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 293.0405 - mse: 853523.0625 - val_loss: 7.3033 - val_mse: 291.4723 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 310.6397 - mse: 1057984.7500 - val_loss: 1.9664 - val_mse: 23.5313 - 619ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 280.3228 - mse: 689162.6875 - val_loss: 0.8767 - val_mse: 6.3983 - 595ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 314.5203 - mse: 1144393.2500 - val_loss: 3.7876 - val_mse: 91.9219 - 608ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 288.7672 - mse: 908220.4375 - val_loss: 7.0382 - val_mse: 291.9856 - 648ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 271.8382 - mse: 701646.4375 - val_loss: 11.5604 - val_mse: 739.7753 - 626ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 277.3751 - mse: 770057.5000 - val_loss: 13.9655 - val_mse: 1064.9669 - 646ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 269.9039 - mse: 705671.5000 - val_loss: 12.4560 - val_mse: 856.3039 - 632ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 264.6342 - mse: 685920.0625 - val_loss: 14.5511 - val_mse: 1149.9045 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 258.1747 - mse: 646471.2500 - val_loss: 14.4820 - val_mse: 1133.2833 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 258.2131 - mse: 733580.6875 - val_loss: 6.8007 - val_mse: 276.5186 - 612ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 240.0204 - mse: 538916.2500 - val_loss: 11.3832 - val_mse: 704.3305 - 614ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 242.7797 - mse: 654453.2500 - val_loss: 11.0632 - val_mse: 669.9775 - 624ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 246.7589 - mse: 702093.4375 - val_loss: 10.7486 - val_mse: 632.2769 - 618ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 236.0262 - mse: 535822.8125 - val_loss: 15.9929 - val_mse: 1343.5614 - 618ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 227.1135 - mse: 528628.2500 - val_loss: 14.0515 - val_mse: 1005.4745 - 634ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 230.1201 - mse: 533100.3750 - val_loss: 14.2200 - val_mse: 1033.3394 - 624ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 224.0873 - mse: 457522.2188 - val_loss: 15.1859 - val_mse: 1190.9536 - 639ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 222.2023 - mse: 493847.2500 - val_loss: 15.6685 - val_mse: 1265.3317 - 640ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 215.5901 - mse: 453479.7500 - val_loss: 13.9775 - val_mse: 1017.3099 - 635ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 206.5034 - mse: 455085.3438 - val_loss: 14.7941 - val_mse: 1121.5436 - 623ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 190 ended. Search finished for the next optimal point.\n",
            "Time taken: 77.7187\n",
            "Function value obtained: 1121.5436\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 191 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [98, 115]\n",
            "Learning Rate: 8.539635665161339e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.444855568952041\n",
            "Batch Size: 57\n",
            "----------------------------------------\n",
            "148/148 - 3s - loss: 1106.9858 - mse: 13302847.0000 - val_loss: 2.8047 - val_mse: 66.9488 - 3s/epoch - 21ms/step\n",
            "148/148 - 1s - loss: 866.8153 - mse: 6517376.0000 - val_loss: 66.4210 - val_mse: 23796.0430 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 724.6938 - mse: 5122379.5000 - val_loss: 20.4743 - val_mse: 2285.2266 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 624.0884 - mse: 3904153.5000 - val_loss: 39.3360 - val_mse: 8331.6680 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 531.6335 - mse: 2694101.5000 - val_loss: 42.4439 - val_mse: 9272.9873 - 693ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 425.8028 - mse: 1867114.7500 - val_loss: 25.6273 - val_mse: 3536.1436 - 696ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 384.6343 - mse: 1473752.3750 - val_loss: 13.9471 - val_mse: 1067.6830 - 737ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 333.3431 - mse: 1252959.0000 - val_loss: 8.4688 - val_mse: 403.1283 - 704ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 278.9897 - mse: 748513.3125 - val_loss: 6.2248 - val_mse: 212.1726 - 719ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 255.7546 - mse: 588812.9375 - val_loss: 6.3778 - val_mse: 251.7973 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 225.8700 - mse: 465756.9062 - val_loss: 6.3823 - val_mse: 243.5191 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 193.0309 - mse: 374458.9375 - val_loss: 6.6232 - val_mse: 283.0036 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 171.2353 - mse: 283206.5000 - val_loss: 4.7415 - val_mse: 154.7444 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 157.0015 - mse: 235989.7969 - val_loss: 4.8707 - val_mse: 156.9603 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 145.3206 - mse: 205728.0781 - val_loss: 3.6015 - val_mse: 86.1507 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 125.1254 - mse: 183895.7500 - val_loss: 1.9030 - val_mse: 27.3161 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 115.4865 - mse: 137519.2969 - val_loss: 2.0935 - val_mse: 32.2080 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 105.4819 - mse: 112046.1172 - val_loss: 2.2863 - val_mse: 36.5485 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 91.9223 - mse: 78215.1719 - val_loss: 1.5345 - val_mse: 16.8974 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 83.9919 - mse: 81981.2812 - val_loss: 2.0483 - val_mse: 30.2700 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 76.7717 - mse: 64009.0547 - val_loss: 1.5226 - val_mse: 21.3732 - 666ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 67.4605 - mse: 51120.0312 - val_loss: 1.9291 - val_mse: 30.6571 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 63.0432 - mse: 47959.4805 - val_loss: 1.3482 - val_mse: 15.8884 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 57.6440 - mse: 35757.3047 - val_loss: 1.3117 - val_mse: 14.4242 - 712ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 50.3159 - mse: 24909.6504 - val_loss: 1.3280 - val_mse: 14.8342 - 722ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 47.7805 - mse: 23539.0059 - val_loss: 0.6313 - val_mse: 3.9227 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 43.4350 - mse: 21420.7363 - val_loss: 0.4995 - val_mse: 2.5668 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 39.4428 - mse: 16059.6748 - val_loss: 0.6951 - val_mse: 4.6803 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 35.2827 - mse: 13076.3330 - val_loss: 0.7004 - val_mse: 4.7461 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 30.7007 - mse: 9646.7617 - val_loss: 0.5017 - val_mse: 2.6086 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 28.6383 - mse: 8466.2441 - val_loss: 0.5790 - val_mse: 3.3614 - 666ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 26.7998 - mse: 7319.6421 - val_loss: 0.3946 - val_mse: 1.7056 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 24.4085 - mse: 6512.2944 - val_loss: 0.1716 - val_mse: 0.4105 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 22.0397 - mse: 6020.1528 - val_loss: 0.2142 - val_mse: 0.5970 - 656ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 20.2579 - mse: 5102.5122 - val_loss: 0.1613 - val_mse: 0.3776 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 17.8713 - mse: 4240.6582 - val_loss: 0.1058 - val_mse: 0.2130 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 17.5354 - mse: 4870.6377 - val_loss: 0.1094 - val_mse: 0.2236 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 15.6890 - mse: 3382.0151 - val_loss: 0.0912 - val_mse: 0.1824 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 13.9351 - mse: 2774.0049 - val_loss: 0.0978 - val_mse: 0.1965 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 12.8656 - mse: 2421.6228 - val_loss: 0.0916 - val_mse: 0.1835 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 10.6120 - mse: 1383.9558 - val_loss: 0.0840 - val_mse: 0.1681 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 9.6793 - mse: 1374.7467 - val_loss: 0.0800 - val_mse: 0.1600 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 9.4531 - mse: 1536.1865 - val_loss: 0.0747 - val_mse: 0.1494 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 8.3479 - mse: 1198.5178 - val_loss: 0.0724 - val_mse: 0.1447 - 666ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 7.5641 - mse: 915.3538 - val_loss: 0.0726 - val_mse: 0.1452 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 6.6208 - mse: 717.0056 - val_loss: 0.0668 - val_mse: 0.1336 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 5.8969 - mse: 534.7545 - val_loss: 0.0617 - val_mse: 0.1235 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 5.7034 - mse: 598.3741 - val_loss: 0.0570 - val_mse: 0.1139 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 4.7532 - mse: 359.4873 - val_loss: 0.0494 - val_mse: 0.0989 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 4.6158 - mse: 491.7271 - val_loss: 0.0436 - val_mse: 0.0872 - 640ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 4.0042 - mse: 272.7055 - val_loss: 0.0408 - val_mse: 0.0815 - 641ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 3.4806 - mse: 265.4340 - val_loss: 0.0376 - val_mse: 0.0753 - 646ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 3.2979 - mse: 215.5760 - val_loss: 0.0328 - val_mse: 0.0656 - 634ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2.7806 - mse: 165.2496 - val_loss: 0.0253 - val_mse: 0.0506 - 646ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2.5134 - mse: 134.5171 - val_loss: 0.0252 - val_mse: 0.0505 - 645ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2.5044 - mse: 163.1927 - val_loss: 0.0207 - val_mse: 0.0413 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 2.2861 - mse: 177.1233 - val_loss: 0.0188 - val_mse: 0.0375 - 685ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.9567 - mse: 95.5327 - val_loss: 0.0150 - val_mse: 0.0301 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.7599 - mse: 83.2295 - val_loss: 0.0151 - val_mse: 0.0303 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.5339 - mse: 80.5327 - val_loss: 0.0104 - val_mse: 0.0207 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.4685 - mse: 68.4058 - val_loss: 0.0093 - val_mse: 0.0187 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.3903 - mse: 85.8649 - val_loss: 0.0092 - val_mse: 0.0184 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1.3262 - mse: 63.7277 - val_loss: 0.0075 - val_mse: 0.0150 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1.2490 - mse: 94.4719 - val_loss: 0.0063 - val_mse: 0.0125 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.9562 - mse: 38.8993 - val_loss: 0.0057 - val_mse: 0.0114 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 1.0022 - mse: 74.9864 - val_loss: 0.0054 - val_mse: 0.0107 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.8356 - mse: 32.2976 - val_loss: 0.0046 - val_mse: 0.0092 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.7408 - mse: 30.3632 - val_loss: 0.0044 - val_mse: 0.0089 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.6657 - mse: 22.6835 - val_loss: 0.0046 - val_mse: 0.0093 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.6365 - mse: 23.4855 - val_loss: 0.0043 - val_mse: 0.0086 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.5617 - mse: 30.5090 - val_loss: 0.0042 - val_mse: 0.0083 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.5067 - mse: 21.8490 - val_loss: 0.0045 - val_mse: 0.0089 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.4643 - mse: 14.0075 - val_loss: 0.0041 - val_mse: 0.0082 - 653ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.4280 - mse: 13.1763 - val_loss: 0.0043 - val_mse: 0.0087 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.3971 - mse: 13.9273 - val_loss: 0.0041 - val_mse: 0.0082 - 692ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.3535 - mse: 6.6645 - val_loss: 0.0045 - val_mse: 0.0090 - 687ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.2999 - mse: 5.3991 - val_loss: 0.0047 - val_mse: 0.0095 - 682ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.2496 - mse: 4.1950 - val_loss: 0.0050 - val_mse: 0.0099 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2750 - mse: 8.4030 - val_loss: 0.0046 - val_mse: 0.0092 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2318 - mse: 3.9701 - val_loss: 0.0050 - val_mse: 0.0101 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2897 - mse: 12.6257 - val_loss: 0.0068 - val_mse: 0.0137 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.2143 - mse: 4.4686 - val_loss: 0.0045 - val_mse: 0.0091 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1807 - mse: 3.1138 - val_loss: 0.0047 - val_mse: 0.0094 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.2091 - mse: 5.6156 - val_loss: 0.0049 - val_mse: 0.0099 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1860 - mse: 3.2528 - val_loss: 0.0044 - val_mse: 0.0088 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.1893 - mse: 5.3960 - val_loss: 0.0049 - val_mse: 0.0099 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1542 - mse: 2.9654 - val_loss: 0.0077 - val_mse: 0.0153 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1381 - mse: 4.1295 - val_loss: 0.0052 - val_mse: 0.0103 - 654ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1312 - mse: 3.0138 - val_loss: 0.0081 - val_mse: 0.0163 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.1034 - mse: 1.6236 - val_loss: 0.0050 - val_mse: 0.0100 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.1095 - mse: 1.9116 - val_loss: 0.0058 - val_mse: 0.0116 - 692ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.0962 - mse: 2.1319 - val_loss: 0.0053 - val_mse: 0.0107 - 690ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.1191 - mse: 3.6946 - val_loss: 0.0057 - val_mse: 0.0114 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.1054 - mse: 4.4755 - val_loss: 0.0049 - val_mse: 0.0097 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.0763 - mse: 1.0598 - val_loss: 0.0048 - val_mse: 0.0097 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0605 - mse: 0.6375 - val_loss: 0.0053 - val_mse: 0.0107 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0692 - mse: 0.7634 - val_loss: 0.0053 - val_mse: 0.0107 - 673ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 0.0637 - mse: 0.6689 - val_loss: 0.0054 - val_mse: 0.0109 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0745 - mse: 1.9555 - val_loss: 0.0055 - val_mse: 0.0110 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 0.0547 - mse: 1.0893 - val_loss: 0.0061 - val_mse: 0.0121 - 668ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 191 ended. Search finished for the next optimal point.\n",
            "Time taken: 83.9467\n",
            "Function value obtained: 0.0121\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 192 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [47, 84]\n",
            "Learning Rate: 1.127353312352036e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.152676931561796\n",
            "Batch Size: 254\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 2770.7732 - mse: 48006588.0000 - val_loss: 2161.3213 - val_mse: 23682014.0000 - 3s/epoch - 76ms/step\n",
            "34/34 - 0s - loss: 2559.8259 - mse: 43736620.0000 - val_loss: 1921.5535 - val_mse: 18717692.0000 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 2274.0535 - mse: 35877432.0000 - val_loss: 1710.6188 - val_mse: 14822605.0000 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1977.0128 - mse: 28042670.0000 - val_loss: 1517.2610 - val_mse: 11644201.0000 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1778.2986 - mse: 21978094.0000 - val_loss: 1332.9562 - val_mse: 8948452.0000 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1558.0267 - mse: 18245036.0000 - val_loss: 1164.1871 - val_mse: 6845467.0000 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1437.4720 - mse: 15215632.0000 - val_loss: 1029.8052 - val_mse: 5372747.0000 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1285.1904 - mse: 13921994.0000 - val_loss: 907.5222 - val_mse: 4163522.0000 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 1140.9816 - mse: 11876578.0000 - val_loss: 800.2966 - val_mse: 3234924.0000 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 1006.8403 - mse: 7901378.5000 - val_loss: 706.1046 - val_mse: 2520493.0000 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 934.3133 - mse: 7456110.5000 - val_loss: 628.1782 - val_mse: 1996024.7500 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 866.3761 - mse: 6218300.5000 - val_loss: 556.3966 - val_mse: 1572095.7500 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 801.4877 - mse: 6439493.5000 - val_loss: 499.1425 - val_mse: 1263689.3750 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 728.7556 - mse: 5044612.0000 - val_loss: 453.8053 - val_mse: 1050661.8750 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 654.8958 - mse: 3740143.2500 - val_loss: 411.6197 - val_mse: 854388.7500 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 628.3983 - mse: 3503898.5000 - val_loss: 358.6527 - val_mse: 643072.7500 - 217ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 596.3701 - mse: 3071024.0000 - val_loss: 301.8949 - val_mse: 450059.0625 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 549.2139 - mse: 2630127.7500 - val_loss: 240.3934 - val_mse: 280870.3125 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 528.9171 - mse: 2507957.0000 - val_loss: 174.9245 - val_mse: 145988.4531 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 536.8774 - mse: 2687127.5000 - val_loss: 118.6045 - val_mse: 66442.3828 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 519.1847 - mse: 2894379.2500 - val_loss: 79.2837 - val_mse: 27575.7949 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 509.8852 - mse: 2483597.5000 - val_loss: 37.2115 - val_mse: 4707.8320 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 490.5411 - mse: 2206325.0000 - val_loss: 13.5411 - val_mse: 553.7402 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 471.6826 - mse: 1938254.6250 - val_loss: 4.5466 - val_mse: 152.2868 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 465.3329 - mse: 2012548.2500 - val_loss: 17.2230 - val_mse: 1993.4261 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 474.0686 - mse: 2134199.0000 - val_loss: 27.0205 - val_mse: 4772.6934 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 445.1419 - mse: 1634888.5000 - val_loss: 33.3354 - val_mse: 7002.8389 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 452.1395 - mse: 1825616.3750 - val_loss: 42.3474 - val_mse: 10532.3613 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 433.2020 - mse: 1667935.2500 - val_loss: 48.3783 - val_mse: 13358.3330 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 442.7312 - mse: 1814735.3750 - val_loss: 52.2138 - val_mse: 15323.5986 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 421.2035 - mse: 1640834.2500 - val_loss: 53.0761 - val_mse: 15776.8662 - 216ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 429.4248 - mse: 1702891.3750 - val_loss: 56.1963 - val_mse: 17587.3457 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 441.1941 - mse: 1938202.7500 - val_loss: 54.5841 - val_mse: 16284.3311 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 435.2982 - mse: 1804273.7500 - val_loss: 56.3872 - val_mse: 17318.9258 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 424.7551 - mse: 1643502.6250 - val_loss: 60.5652 - val_mse: 19888.1465 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 412.1740 - mse: 1600163.6250 - val_loss: 59.8114 - val_mse: 19445.3359 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 405.1245 - mse: 1722202.3750 - val_loss: 58.6138 - val_mse: 18664.6836 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 401.1867 - mse: 1571158.5000 - val_loss: 57.2215 - val_mse: 17801.7422 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 395.9058 - mse: 1506387.6250 - val_loss: 53.9740 - val_mse: 15859.9902 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 416.2713 - mse: 1873718.0000 - val_loss: 53.4781 - val_mse: 15580.3613 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 399.7116 - mse: 1575080.0000 - val_loss: 53.8338 - val_mse: 15853.8291 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 381.4625 - mse: 1430943.7500 - val_loss: 53.7629 - val_mse: 15800.7900 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 383.8607 - mse: 1375220.8750 - val_loss: 51.5146 - val_mse: 14538.3223 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 389.8871 - mse: 1520040.0000 - val_loss: 54.3214 - val_mse: 16165.3467 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 382.4845 - mse: 1412449.2500 - val_loss: 53.8077 - val_mse: 15906.8906 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 374.5331 - mse: 1441459.7500 - val_loss: 50.1837 - val_mse: 14026.9404 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 380.4528 - mse: 1501262.7500 - val_loss: 47.6557 - val_mse: 12667.5059 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 372.2309 - mse: 1367599.2500 - val_loss: 46.0656 - val_mse: 11881.0674 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 361.4320 - mse: 1323496.2500 - val_loss: 44.4798 - val_mse: 11080.1846 - 214ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 360.4108 - mse: 1233918.8750 - val_loss: 40.6241 - val_mse: 9134.4775 - 217ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 349.9075 - mse: 1310165.6250 - val_loss: 37.8667 - val_mse: 7913.5259 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 372.7159 - mse: 1368507.8750 - val_loss: 35.9762 - val_mse: 7372.2119 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 346.6016 - mse: 1149178.6250 - val_loss: 35.6357 - val_mse: 7260.6230 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 352.5042 - mse: 1330751.1250 - val_loss: 34.3215 - val_mse: 6965.9976 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 354.9760 - mse: 1271911.5000 - val_loss: 34.0635 - val_mse: 6786.7100 - 214ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 337.6915 - mse: 1145909.6250 - val_loss: 32.7005 - val_mse: 6226.0410 - 217ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 341.0882 - mse: 1107783.5000 - val_loss: 30.6164 - val_mse: 5490.8496 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 324.5238 - mse: 935430.9375 - val_loss: 27.6266 - val_mse: 4517.1582 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 333.1983 - mse: 1051885.8750 - val_loss: 25.3266 - val_mse: 3831.7334 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 342.0650 - mse: 1129913.6250 - val_loss: 25.1880 - val_mse: 3778.9817 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 318.3237 - mse: 918516.6250 - val_loss: 22.9407 - val_mse: 3170.1523 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 329.5126 - mse: 1084729.7500 - val_loss: 24.3115 - val_mse: 3525.8933 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 320.6411 - mse: 916880.0625 - val_loss: 24.3159 - val_mse: 3544.7925 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 315.1849 - mse: 924193.5625 - val_loss: 22.5648 - val_mse: 3108.1970 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 325.7361 - mse: 1030883.4375 - val_loss: 21.2153 - val_mse: 2767.0654 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 310.8569 - mse: 880070.5000 - val_loss: 20.2850 - val_mse: 2646.9878 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 310.8418 - mse: 877260.0625 - val_loss: 16.4812 - val_mse: 1993.7609 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 314.1071 - mse: 1011484.0625 - val_loss: 9.1374 - val_mse: 669.5394 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 307.9559 - mse: 950175.1250 - val_loss: 8.0536 - val_mse: 529.4876 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 314.9697 - mse: 1045132.2500 - val_loss: 12.3463 - val_mse: 1187.6783 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 300.2076 - mse: 816723.0000 - val_loss: 11.3052 - val_mse: 1014.5300 - 220ms/epoch - 6ms/step\n",
            "34/34 - 1s - loss: 304.7965 - mse: 868189.1250 - val_loss: 7.4824 - val_mse: 462.2058 - 723ms/epoch - 21ms/step\n",
            "34/34 - 0s - loss: 309.0838 - mse: 863641.2500 - val_loss: 4.9587 - val_mse: 193.6212 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 293.4442 - mse: 843859.3125 - val_loss: 4.7883 - val_mse: 180.0769 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 296.7445 - mse: 915219.1250 - val_loss: 8.8091 - val_mse: 645.2946 - 256ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 298.0204 - mse: 802853.5625 - val_loss: 6.6713 - val_mse: 376.7465 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 300.4366 - mse: 855670.6875 - val_loss: 6.5874 - val_mse: 368.1173 - 255ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 292.4501 - mse: 754793.5625 - val_loss: 5.7645 - val_mse: 276.1742 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 296.4821 - mse: 794210.3125 - val_loss: 7.0966 - val_mse: 423.6128 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 297.6571 - mse: 1078032.3750 - val_loss: 8.8291 - val_mse: 641.5198 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 286.4728 - mse: 812573.1875 - val_loss: 8.5930 - val_mse: 608.1230 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 302.2366 - mse: 930254.0000 - val_loss: 5.2313 - val_mse: 216.5702 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 296.0325 - mse: 912909.3125 - val_loss: 4.8862 - val_mse: 185.2864 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 291.4651 - mse: 889122.3125 - val_loss: 2.7639 - val_mse: 26.9798 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 287.9586 - mse: 824040.3750 - val_loss: 4.4618 - val_mse: 152.4888 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 289.0089 - mse: 878931.6250 - val_loss: 3.1899 - val_mse: 58.4988 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 292.1801 - mse: 929408.5625 - val_loss: 3.0366 - val_mse: 47.1145 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 273.6982 - mse: 680307.7500 - val_loss: 3.6593 - val_mse: 90.7887 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 275.5183 - mse: 726514.1875 - val_loss: 3.8019 - val_mse: 99.3224 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 271.8569 - mse: 634305.6250 - val_loss: 3.3767 - val_mse: 70.9779 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 273.6096 - mse: 795511.2500 - val_loss: 4.0841 - val_mse: 119.6981 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 286.9146 - mse: 918650.5000 - val_loss: 5.7949 - val_mse: 267.4791 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 267.9451 - mse: 701685.3750 - val_loss: 6.9270 - val_mse: 390.2614 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 271.5501 - mse: 749899.8750 - val_loss: 9.0797 - val_mse: 611.5549 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 271.0303 - mse: 713014.1250 - val_loss: 8.1678 - val_mse: 449.1914 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 269.5117 - mse: 716785.5625 - val_loss: 8.8509 - val_mse: 518.3609 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 261.5587 - mse: 692757.4375 - val_loss: 9.0156 - val_mse: 536.5488 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 267.2447 - mse: 719392.8750 - val_loss: 6.1960 - val_mse: 302.6061 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 265.1779 - mse: 714589.4375 - val_loss: 7.4454 - val_mse: 390.5207 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 270.1984 - mse: 704290.8750 - val_loss: 8.5658 - val_mse: 506.1342 - 227ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 192 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.0667\n",
            "Function value obtained: 506.1342\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 193 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [64, 39]\n",
            "Learning Rate: 1.8223038915183926e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.24173387146567482\n",
            "Batch Size: 179\n",
            "----------------------------------------\n",
            "47/47 - 3s - loss: 1144.1327 - mse: 13314487.0000 - val_loss: 322.5272 - val_mse: 487731.0625 - 3s/epoch - 55ms/step\n",
            "47/47 - 0s - loss: 978.5570 - mse: 9847633.0000 - val_loss: 182.2485 - val_mse: 156230.7500 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 845.8076 - mse: 7260657.0000 - val_loss: 82.4305 - val_mse: 30487.0742 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 802.3714 - mse: 7080687.0000 - val_loss: 23.6751 - val_mse: 1957.6847 - 263ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 761.3978 - mse: 6139520.0000 - val_loss: 8.8729 - val_mse: 547.1679 - 267ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 696.9748 - mse: 6047953.0000 - val_loss: 16.3558 - val_mse: 1676.3236 - 269ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 669.2723 - mse: 5268582.5000 - val_loss: 23.1249 - val_mse: 3158.2229 - 262ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 614.8632 - mse: 3901245.7500 - val_loss: 31.3019 - val_mse: 5605.3838 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 595.9050 - mse: 3558504.5000 - val_loss: 38.8213 - val_mse: 8377.6387 - 266ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 583.4946 - mse: 3610026.2500 - val_loss: 41.8167 - val_mse: 9600.8037 - 264ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 572.0831 - mse: 4288928.5000 - val_loss: 44.2577 - val_mse: 10670.7832 - 273ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 558.9339 - mse: 3433855.5000 - val_loss: 44.1024 - val_mse: 10573.9697 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 552.1500 - mse: 3674818.0000 - val_loss: 42.7886 - val_mse: 9953.2432 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 491.8794 - mse: 2211264.7500 - val_loss: 37.6138 - val_mse: 7760.1436 - 273ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 489.1241 - mse: 2401143.2500 - val_loss: 37.6582 - val_mse: 7761.4600 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 489.4093 - mse: 2487606.2500 - val_loss: 31.6884 - val_mse: 5568.2769 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 459.7616 - mse: 1967529.0000 - val_loss: 29.0909 - val_mse: 4724.1411 - 271ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 493.8160 - mse: 2664137.0000 - val_loss: 28.1547 - val_mse: 4435.3057 - 263ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 467.2375 - mse: 2251300.0000 - val_loss: 26.8916 - val_mse: 4059.0334 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 469.0696 - mse: 2272766.2500 - val_loss: 21.7943 - val_mse: 2722.6975 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 421.9912 - mse: 1593252.7500 - val_loss: 20.3422 - val_mse: 2400.6377 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 443.4273 - mse: 2198587.5000 - val_loss: 16.3169 - val_mse: 1599.6320 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 432.5589 - mse: 1864760.6250 - val_loss: 10.5742 - val_mse: 732.8423 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 408.9423 - mse: 1726671.8750 - val_loss: 2.5915 - val_mse: 55.2577 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 410.7258 - mse: 1779307.3750 - val_loss: 5.4479 - val_mse: 219.5251 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 401.2854 - mse: 1653488.5000 - val_loss: 7.7681 - val_mse: 404.0979 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 388.6235 - mse: 1626647.6250 - val_loss: 5.1234 - val_mse: 190.2915 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 376.9799 - mse: 1375570.2500 - val_loss: 4.8682 - val_mse: 179.1610 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 387.1939 - mse: 1638832.2500 - val_loss: 1.1200 - val_mse: 8.9129 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 363.4093 - mse: 1537523.0000 - val_loss: 3.1718 - val_mse: 34.4387 - 294ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 350.3708 - mse: 1339082.3750 - val_loss: 4.8043 - val_mse: 89.5385 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 350.4026 - mse: 1256994.6250 - val_loss: 6.6140 - val_mse: 180.7051 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 325.0696 - mse: 1021109.6875 - val_loss: 11.2540 - val_mse: 565.2745 - 267ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 326.7955 - mse: 1107702.8750 - val_loss: 12.6397 - val_mse: 723.2048 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 303.0992 - mse: 829804.3750 - val_loss: 11.1603 - val_mse: 558.5287 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 314.6924 - mse: 934550.8125 - val_loss: 14.6299 - val_mse: 985.5536 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 304.0943 - mse: 923624.1250 - val_loss: 18.6591 - val_mse: 1634.6754 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 296.2203 - mse: 824078.8125 - val_loss: 19.8799 - val_mse: 1864.6931 - 271ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 284.7906 - mse: 767473.1875 - val_loss: 21.2837 - val_mse: 2146.7593 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 294.5536 - mse: 1041451.1875 - val_loss: 24.6585 - val_mse: 2909.6758 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 279.1557 - mse: 804409.0625 - val_loss: 25.9292 - val_mse: 3229.3096 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 285.8135 - mse: 888418.1875 - val_loss: 25.5121 - val_mse: 3126.5259 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 267.4579 - mse: 692672.7500 - val_loss: 27.4300 - val_mse: 3630.6533 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 265.4937 - mse: 733356.9375 - val_loss: 29.6750 - val_mse: 4261.4155 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 250.4237 - mse: 686156.5625 - val_loss: 31.4544 - val_mse: 4810.3955 - 264ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 262.4230 - mse: 771529.8750 - val_loss: 34.6382 - val_mse: 5889.9165 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 232.8856 - mse: 687266.4375 - val_loss: 35.3430 - val_mse: 6152.4468 - 266ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 246.4366 - mse: 633071.2500 - val_loss: 34.5252 - val_mse: 5838.2544 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 235.9472 - mse: 583067.1875 - val_loss: 36.6232 - val_mse: 6490.0972 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 222.2340 - mse: 490301.5625 - val_loss: 36.7144 - val_mse: 6548.0825 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 225.4589 - mse: 553989.2500 - val_loss: 35.1453 - val_mse: 5964.0146 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 218.3669 - mse: 512397.6250 - val_loss: 33.2329 - val_mse: 5326.6523 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 210.0951 - mse: 447169.3125 - val_loss: 32.4991 - val_mse: 5117.6445 - 264ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 210.9102 - mse: 525655.1875 - val_loss: 30.7352 - val_mse: 4676.4897 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 204.2211 - mse: 407828.6562 - val_loss: 28.6198 - val_mse: 4051.5266 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 198.4263 - mse: 392040.4688 - val_loss: 26.8719 - val_mse: 3569.1440 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 203.3343 - mse: 476348.1250 - val_loss: 25.5424 - val_mse: 3246.4788 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 199.6517 - mse: 446555.5000 - val_loss: 24.7935 - val_mse: 3074.4526 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 196.7574 - mse: 410972.0625 - val_loss: 24.0508 - val_mse: 2915.4150 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 177.9399 - mse: 293103.1250 - val_loss: 23.1494 - val_mse: 2690.0862 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 182.8707 - mse: 387005.5000 - val_loss: 20.9745 - val_mse: 2201.1194 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 175.4562 - mse: 365361.6875 - val_loss: 19.6925 - val_mse: 1938.1899 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 175.4496 - mse: 365043.5312 - val_loss: 17.8148 - val_mse: 1584.3689 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 162.9643 - mse: 264778.0938 - val_loss: 18.2519 - val_mse: 1660.4352 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 167.8541 - mse: 335094.8125 - val_loss: 17.5351 - val_mse: 1532.8939 - 286ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 160.2858 - mse: 347675.0625 - val_loss: 17.0474 - val_mse: 1446.0192 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 157.5513 - mse: 368744.4062 - val_loss: 16.5911 - val_mse: 1368.3539 - 288ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 149.4787 - mse: 242035.1875 - val_loss: 16.2220 - val_mse: 1306.7333 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 154.1200 - mse: 307572.4375 - val_loss: 15.7812 - val_mse: 1237.6368 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 142.4978 - mse: 255881.3281 - val_loss: 15.6489 - val_mse: 1217.7244 - 281ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 146.3913 - mse: 270441.3750 - val_loss: 15.2892 - val_mse: 1162.0836 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 142.5276 - mse: 271823.9375 - val_loss: 14.9167 - val_mse: 1106.4794 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 134.9078 - mse: 196818.1406 - val_loss: 14.3709 - val_mse: 1025.4321 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 129.7005 - mse: 191383.8750 - val_loss: 13.7724 - val_mse: 940.0521 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 130.2335 - mse: 196875.8594 - val_loss: 12.9915 - val_mse: 835.1478 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 122.7450 - mse: 194520.3438 - val_loss: 12.8659 - val_mse: 817.3345 - 270ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 124.4905 - mse: 192937.0312 - val_loss: 13.0914 - val_mse: 847.2506 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 121.9838 - mse: 209115.7812 - val_loss: 13.0817 - val_mse: 846.2275 - 269ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 122.6082 - mse: 206162.0938 - val_loss: 12.2092 - val_mse: 736.2029 - 266ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 120.9005 - mse: 258224.4062 - val_loss: 12.3069 - val_mse: 748.5943 - 263ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 110.5871 - mse: 138896.1406 - val_loss: 12.5965 - val_mse: 783.9586 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 109.1573 - mse: 166534.8594 - val_loss: 12.3743 - val_mse: 756.5560 - 266ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 99.4282 - mse: 110179.5625 - val_loss: 11.6748 - val_mse: 674.4142 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 96.4586 - mse: 110580.5078 - val_loss: 11.2177 - val_mse: 621.0958 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 102.0403 - mse: 137524.5000 - val_loss: 11.2517 - val_mse: 621.1522 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 100.7329 - mse: 152273.1562 - val_loss: 11.3975 - val_mse: 635.3173 - 261ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 89.4342 - mse: 79876.3047 - val_loss: 11.4109 - val_mse: 640.1435 - 267ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 88.6338 - mse: 125498.0625 - val_loss: 11.1099 - val_mse: 612.2943 - 269ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 90.6523 - mse: 102888.2344 - val_loss: 10.9415 - val_mse: 603.1700 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 89.3344 - mse: 104802.2422 - val_loss: 10.3141 - val_mse: 537.4274 - 264ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 84.9742 - mse: 84879.5859 - val_loss: 9.8667 - val_mse: 491.5252 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 86.9244 - mse: 105282.5859 - val_loss: 9.2973 - val_mse: 436.2335 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 87.0185 - mse: 107162.3828 - val_loss: 8.9390 - val_mse: 403.2670 - 271ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 85.3984 - mse: 116855.6797 - val_loss: 8.4515 - val_mse: 360.3115 - 267ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 76.6260 - mse: 88034.1641 - val_loss: 7.9054 - val_mse: 315.2599 - 271ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 77.2105 - mse: 88983.9375 - val_loss: 7.5916 - val_mse: 290.7235 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 75.4898 - mse: 90572.2109 - val_loss: 7.3148 - val_mse: 269.8461 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 74.0518 - mse: 72906.5469 - val_loss: 6.9205 - val_mse: 241.2720 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 68.8610 - mse: 68725.0547 - val_loss: 6.5618 - val_mse: 216.5095 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 72.0986 - mse: 141414.5312 - val_loss: 6.2853 - val_mse: 198.3555 - 281ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 193 ended. Search finished for the next optimal point.\n",
            "Time taken: 43.3149\n",
            "Function value obtained: 198.3555\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 194 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [75]\n",
            "Learning Rate: 7.92977790903431e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.47903988751144655\n",
            "Batch Size: 65\n",
            "----------------------------------------\n",
            "130/130 - 2s - loss: 4436.0488 - mse: 163734016.0000 - val_loss: 335.7487 - val_mse: 575651.4375 - 2s/epoch - 17ms/step\n",
            "130/130 - 1s - loss: 4393.5874 - mse: 186524176.0000 - val_loss: 299.0158 - val_mse: 456726.2188 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 4201.9932 - mse: 143677504.0000 - val_loss: 228.2345 - val_mse: 266543.0938 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3978.4194 - mse: 132835248.0000 - val_loss: 172.0218 - val_mse: 151696.7969 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 4020.1096 - mse: 139356976.0000 - val_loss: 136.5332 - val_mse: 95693.5078 - 518ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3800.3772 - mse: 123014840.0000 - val_loss: 118.5728 - val_mse: 72212.1797 - 511ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3737.5830 - mse: 122613008.0000 - val_loss: 101.3671 - val_mse: 52840.2305 - 532ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3573.7383 - mse: 100977016.0000 - val_loss: 61.9007 - val_mse: 19881.9277 - 534ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3474.2190 - mse: 107670200.0000 - val_loss: 65.6064 - val_mse: 22280.5605 - 553ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3209.2524 - mse: 89206872.0000 - val_loss: 59.9718 - val_mse: 18659.0195 - 535ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3246.1846 - mse: 89808592.0000 - val_loss: 30.8893 - val_mse: 5072.7964 - 548ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3275.5862 - mse: 95345280.0000 - val_loss: 19.8180 - val_mse: 2160.4619 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3025.1670 - mse: 81666360.0000 - val_loss: 11.1889 - val_mse: 689.1601 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 3076.9905 - mse: 99278240.0000 - val_loss: 6.8449 - val_mse: 251.9597 - 525ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2933.0649 - mse: 78492400.0000 - val_loss: 23.1351 - val_mse: 2783.5105 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2739.2092 - mse: 70079288.0000 - val_loss: 37.4877 - val_mse: 7230.9033 - 523ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2669.4275 - mse: 64345452.0000 - val_loss: 47.8945 - val_mse: 11759.4180 - 535ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2711.7439 - mse: 69375896.0000 - val_loss: 52.0805 - val_mse: 13894.2949 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2569.1570 - mse: 59077200.0000 - val_loss: 61.3818 - val_mse: 19267.8164 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2485.4294 - mse: 52233044.0000 - val_loss: 66.8766 - val_mse: 22852.5508 - 532ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2437.7173 - mse: 58042688.0000 - val_loss: 73.0560 - val_mse: 27239.7988 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2335.6038 - mse: 48558944.0000 - val_loss: 74.2891 - val_mse: 28137.7754 - 524ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2410.4800 - mse: 56936868.0000 - val_loss: 87.4557 - val_mse: 38989.6914 - 522ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2195.5840 - mse: 44423296.0000 - val_loss: 93.0271 - val_mse: 44135.3320 - 532ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2217.1890 - mse: 48221828.0000 - val_loss: 100.1882 - val_mse: 51250.3828 - 513ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2139.6746 - mse: 45797496.0000 - val_loss: 98.9496 - val_mse: 50204.3516 - 520ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2124.2473 - mse: 42264804.0000 - val_loss: 101.6742 - val_mse: 53459.1172 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 2055.0149 - mse: 41328336.0000 - val_loss: 97.6792 - val_mse: 49796.7617 - 545ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1947.3973 - mse: 32874662.0000 - val_loss: 92.5830 - val_mse: 44866.3125 - 548ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1932.7422 - mse: 34361932.0000 - val_loss: 84.0977 - val_mse: 37167.4219 - 533ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1893.4849 - mse: 33974436.0000 - val_loss: 82.9805 - val_mse: 36257.0742 - 531ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1996.3390 - mse: 40648584.0000 - val_loss: 83.9878 - val_mse: 37235.9219 - 543ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1924.0889 - mse: 36455048.0000 - val_loss: 78.2227 - val_mse: 32610.5098 - 512ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1851.1788 - mse: 32224314.0000 - val_loss: 73.2937 - val_mse: 29023.1094 - 523ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1771.5739 - mse: 30131298.0000 - val_loss: 66.9651 - val_mse: 24431.7617 - 518ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1761.4592 - mse: 29890286.0000 - val_loss: 58.6516 - val_mse: 19228.1523 - 531ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1674.4796 - mse: 28494788.0000 - val_loss: 45.3151 - val_mse: 12188.8877 - 529ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1662.0242 - mse: 25647258.0000 - val_loss: 44.4125 - val_mse: 11774.8779 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1714.4840 - mse: 28246920.0000 - val_loss: 42.4673 - val_mse: 10846.5186 - 523ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1630.7308 - mse: 23903724.0000 - val_loss: 33.5636 - val_mse: 6987.8086 - 516ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1628.2275 - mse: 24676044.0000 - val_loss: 21.2905 - val_mse: 2996.1987 - 509ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1618.1157 - mse: 24074574.0000 - val_loss: 13.2286 - val_mse: 1225.8124 - 524ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1608.5614 - mse: 26077800.0000 - val_loss: 4.9825 - val_mse: 156.9401 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1570.7278 - mse: 22359724.0000 - val_loss: 3.5889 - val_mse: 35.2306 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1599.7766 - mse: 23213544.0000 - val_loss: 5.5985 - val_mse: 85.6569 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1589.0839 - mse: 25711336.0000 - val_loss: 8.2951 - val_mse: 211.5099 - 529ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1519.3568 - mse: 22170640.0000 - val_loss: 7.3679 - val_mse: 158.8870 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1603.7875 - mse: 28865578.0000 - val_loss: 15.5771 - val_mse: 952.8854 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1498.6996 - mse: 22265734.0000 - val_loss: 16.6222 - val_mse: 1138.8430 - 552ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1467.7645 - mse: 19400322.0000 - val_loss: 21.7554 - val_mse: 2153.1736 - 550ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1511.8087 - mse: 24243000.0000 - val_loss: 24.8304 - val_mse: 2990.8342 - 541ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1482.8250 - mse: 23277904.0000 - val_loss: 24.2377 - val_mse: 2868.5530 - 1s/epoch - 8ms/step\n",
            "130/130 - 1s - loss: 1461.2246 - mse: 20987888.0000 - val_loss: 24.9808 - val_mse: 3351.0415 - 532ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1460.2714 - mse: 19607972.0000 - val_loss: 23.1676 - val_mse: 3089.6726 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1468.7634 - mse: 20542218.0000 - val_loss: 21.1748 - val_mse: 2649.5906 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1439.1301 - mse: 19986948.0000 - val_loss: 16.7282 - val_mse: 1653.5778 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1375.9384 - mse: 16596641.0000 - val_loss: 16.2005 - val_mse: 1541.7435 - 514ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1383.0402 - mse: 18425864.0000 - val_loss: 13.1751 - val_mse: 1131.8147 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1385.5510 - mse: 17168210.0000 - val_loss: 10.6635 - val_mse: 794.8675 - 534ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1418.5304 - mse: 20238812.0000 - val_loss: 6.2126 - val_mse: 340.8672 - 522ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1360.7700 - mse: 16380734.0000 - val_loss: 2.0945 - val_mse: 30.0354 - 517ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1375.6217 - mse: 18977178.0000 - val_loss: 2.2629 - val_mse: 40.3743 - 524ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1375.6655 - mse: 18301002.0000 - val_loss: 2.0704 - val_mse: 34.3554 - 549ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1364.6287 - mse: 17151588.0000 - val_loss: 1.6555 - val_mse: 12.3146 - 540ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1324.4119 - mse: 15890160.0000 - val_loss: 1.4619 - val_mse: 15.3233 - 527ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1286.5651 - mse: 14389752.0000 - val_loss: 1.5407 - val_mse: 23.4170 - 534ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1324.8634 - mse: 15935867.0000 - val_loss: 1.1519 - val_mse: 7.5681 - 532ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1329.0911 - mse: 16539355.0000 - val_loss: 1.1243 - val_mse: 7.4480 - 535ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1313.6763 - mse: 16123387.0000 - val_loss: 2.6113 - val_mse: 49.1786 - 546ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1267.8976 - mse: 15934534.0000 - val_loss: 2.5211 - val_mse: 50.9121 - 540ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1305.0902 - mse: 15842904.0000 - val_loss: 1.8814 - val_mse: 35.3036 - 550ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1275.6176 - mse: 15268040.0000 - val_loss: 1.7061 - val_mse: 37.6069 - 553ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1314.7766 - mse: 15560999.0000 - val_loss: 2.3719 - val_mse: 72.2234 - 525ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1245.2406 - mse: 14974171.0000 - val_loss: 1.3326 - val_mse: 28.9770 - 530ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1199.7085 - mse: 12457523.0000 - val_loss: 1.5184 - val_mse: 33.1973 - 513ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1210.4973 - mse: 14013577.0000 - val_loss: 0.8629 - val_mse: 7.3677 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1207.4445 - mse: 12946674.0000 - val_loss: 1.2431 - val_mse: 15.3479 - 523ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1185.0577 - mse: 12054727.0000 - val_loss: 0.8824 - val_mse: 10.2288 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1272.0111 - mse: 16627918.0000 - val_loss: 0.5406 - val_mse: 1.7193 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1253.6456 - mse: 16171632.0000 - val_loss: 0.4995 - val_mse: 1.6975 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1174.9167 - mse: 12657177.0000 - val_loss: 0.7225 - val_mse: 3.6353 - 536ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1164.0281 - mse: 11826180.0000 - val_loss: 0.9272 - val_mse: 3.3997 - 528ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1163.3324 - mse: 13443729.0000 - val_loss: 1.0413 - val_mse: 4.0763 - 537ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1168.8368 - mse: 14023826.0000 - val_loss: 0.8482 - val_mse: 3.0480 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1226.4812 - mse: 15877240.0000 - val_loss: 0.7730 - val_mse: 2.7329 - 537ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1188.7546 - mse: 13987113.0000 - val_loss: 0.7316 - val_mse: 2.4694 - 533ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1178.2512 - mse: 14845793.0000 - val_loss: 1.1147 - val_mse: 5.3567 - 526ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1161.4409 - mse: 12913738.0000 - val_loss: 0.7465 - val_mse: 2.5792 - 530ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1143.5760 - mse: 11576956.0000 - val_loss: 1.0705 - val_mse: 5.0886 - 541ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1119.3474 - mse: 11918881.0000 - val_loss: 0.8522 - val_mse: 3.4741 - 546ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1172.6512 - mse: 12307462.0000 - val_loss: 1.2800 - val_mse: 10.4944 - 554ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1129.3461 - mse: 12431176.0000 - val_loss: 1.0145 - val_mse: 5.3290 - 553ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1119.1117 - mse: 12129315.0000 - val_loss: 1.1726 - val_mse: 5.0874 - 551ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1064.4076 - mse: 9670287.0000 - val_loss: 1.2642 - val_mse: 5.6123 - 516ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1092.4137 - mse: 10459411.0000 - val_loss: 2.0486 - val_mse: 13.6052 - 522ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1127.7203 - mse: 11659232.0000 - val_loss: 2.0241 - val_mse: 12.7140 - 534ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1059.6302 - mse: 9334016.0000 - val_loss: 2.0140 - val_mse: 12.2253 - 531ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1091.0040 - mse: 12050252.0000 - val_loss: 3.1710 - val_mse: 33.5995 - 530ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1037.0063 - mse: 10003639.0000 - val_loss: 5.1225 - val_mse: 122.8867 - 521ms/epoch - 4ms/step\n",
            "130/130 - 1s - loss: 1112.4539 - mse: 11861588.0000 - val_loss: 4.2095 - val_mse: 71.1223 - 523ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 194 ended. Search finished for the next optimal point.\n",
            "Time taken: 68.6031\n",
            "Function value obtained: 71.1223\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 195 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [93, 95]\n",
            "Learning Rate: 3.04435690428204e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4714785175020273\n",
            "Batch Size: 64\n",
            "----------------------------------------\n",
            "132/132 - 3s - loss: 2507.2849 - mse: 60446524.0000 - val_loss: 9.2599 - val_mse: 336.8179 - 3s/epoch - 23ms/step\n",
            "132/132 - 1s - loss: 2413.9641 - mse: 52270824.0000 - val_loss: 14.1662 - val_mse: 874.7122 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2430.9353 - mse: 57095060.0000 - val_loss: 24.5470 - val_mse: 2838.9363 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2273.3059 - mse: 48519720.0000 - val_loss: 35.9862 - val_mse: 6262.5122 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2406.6213 - mse: 62710620.0000 - val_loss: 36.2312 - val_mse: 6396.1665 - 594ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 2321.9304 - mse: 56712580.0000 - val_loss: 43.6687 - val_mse: 9465.8740 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2142.1211 - mse: 42337912.0000 - val_loss: 58.7154 - val_mse: 17281.2734 - 598ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2259.6125 - mse: 50351540.0000 - val_loss: 59.4426 - val_mse: 17721.6621 - 596ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2112.8660 - mse: 44340012.0000 - val_loss: 87.3570 - val_mse: 38458.8945 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2078.8398 - mse: 43474152.0000 - val_loss: 98.7322 - val_mse: 49315.9336 - 595ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2071.5293 - mse: 43003016.0000 - val_loss: 107.5358 - val_mse: 59148.7891 - 591ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1954.4243 - mse: 35353440.0000 - val_loss: 102.5874 - val_mse: 53970.9531 - 599ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2041.2484 - mse: 37646252.0000 - val_loss: 99.6489 - val_mse: 51510.8125 - 590ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1981.8788 - mse: 37481672.0000 - val_loss: 92.4183 - val_mse: 44448.4688 - 593ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1948.2581 - mse: 41775460.0000 - val_loss: 79.7631 - val_mse: 33173.8125 - 617ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 2035.7090 - mse: 45065408.0000 - val_loss: 70.3909 - val_mse: 25822.1387 - 622ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1983.0724 - mse: 45861052.0000 - val_loss: 64.9025 - val_mse: 21677.9922 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1917.0206 - mse: 38375384.0000 - val_loss: 66.9160 - val_mse: 23050.4062 - 625ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1856.1401 - mse: 31622636.0000 - val_loss: 68.7251 - val_mse: 24452.0957 - 629ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1784.6371 - mse: 28511868.0000 - val_loss: 66.8425 - val_mse: 23136.0898 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1769.8937 - mse: 27271694.0000 - val_loss: 65.5791 - val_mse: 22283.7070 - 610ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1803.0348 - mse: 33724068.0000 - val_loss: 67.4684 - val_mse: 23620.2207 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1851.4927 - mse: 35078124.0000 - val_loss: 69.0779 - val_mse: 24702.9707 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1796.1451 - mse: 32447384.0000 - val_loss: 72.8006 - val_mse: 27408.7422 - 612ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1816.6007 - mse: 33156226.0000 - val_loss: 72.2460 - val_mse: 27001.0215 - 597ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1758.1658 - mse: 29163838.0000 - val_loss: 69.4389 - val_mse: 24992.5938 - 592ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1677.1771 - mse: 27664478.0000 - val_loss: 66.7292 - val_mse: 23182.5996 - 596ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1735.0077 - mse: 35836696.0000 - val_loss: 68.8448 - val_mse: 24615.8242 - 602ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1760.3044 - mse: 31262404.0000 - val_loss: 70.2916 - val_mse: 25557.3164 - 591ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1750.7212 - mse: 31001416.0000 - val_loss: 69.7407 - val_mse: 24978.4570 - 590ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1743.1405 - mse: 32611254.0000 - val_loss: 70.0215 - val_mse: 25265.7539 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1663.5542 - mse: 27420172.0000 - val_loss: 69.2297 - val_mse: 24820.0039 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1645.7100 - mse: 25197032.0000 - val_loss: 66.1774 - val_mse: 22782.3848 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1627.8958 - mse: 24100178.0000 - val_loss: 68.4073 - val_mse: 24383.2324 - 635ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1650.1132 - mse: 29979150.0000 - val_loss: 69.5715 - val_mse: 25277.1230 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1600.6794 - mse: 26117278.0000 - val_loss: 66.8494 - val_mse: 23355.6855 - 630ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1635.6343 - mse: 32310404.0000 - val_loss: 65.8900 - val_mse: 22682.9746 - 628ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1684.0477 - mse: 32975460.0000 - val_loss: 65.2454 - val_mse: 22247.8984 - 598ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1535.9827 - mse: 22291188.0000 - val_loss: 64.6626 - val_mse: 21882.1914 - 598ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1579.5793 - mse: 25692466.0000 - val_loss: 61.8111 - val_mse: 20031.6055 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1533.6368 - mse: 23977858.0000 - val_loss: 60.4647 - val_mse: 19174.0586 - 610ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1566.0398 - mse: 25853842.0000 - val_loss: 56.2227 - val_mse: 16541.4473 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1595.6532 - mse: 33948460.0000 - val_loss: 51.7640 - val_mse: 14078.3545 - 604ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1570.5928 - mse: 29625472.0000 - val_loss: 50.1641 - val_mse: 13272.7021 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1538.0951 - mse: 23164260.0000 - val_loss: 48.0568 - val_mse: 12258.4375 - 640ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1497.9935 - mse: 23394542.0000 - val_loss: 43.7410 - val_mse: 10194.1729 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1539.8391 - mse: 24054314.0000 - val_loss: 41.7208 - val_mse: 9307.9023 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1543.4906 - mse: 26115152.0000 - val_loss: 43.1962 - val_mse: 9878.7588 - 615ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1497.7278 - mse: 23085046.0000 - val_loss: 43.6486 - val_mse: 10099.5127 - 592ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1483.2592 - mse: 22464940.0000 - val_loss: 41.9665 - val_mse: 9350.8545 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1454.5924 - mse: 19423576.0000 - val_loss: 40.6115 - val_mse: 8783.5566 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1439.0764 - mse: 21387674.0000 - val_loss: 39.3855 - val_mse: 8355.2744 - 625ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1457.6974 - mse: 19788758.0000 - val_loss: 40.3127 - val_mse: 8768.6797 - 623ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1407.6234 - mse: 19991702.0000 - val_loss: 39.2756 - val_mse: 8358.3906 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1436.6737 - mse: 20962844.0000 - val_loss: 37.4084 - val_mse: 7605.2480 - 635ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1404.7145 - mse: 18810150.0000 - val_loss: 35.9155 - val_mse: 7021.1294 - 613ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1416.7009 - mse: 23044094.0000 - val_loss: 38.5774 - val_mse: 8072.1733 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1411.0767 - mse: 19671802.0000 - val_loss: 36.9716 - val_mse: 7411.9780 - 593ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1397.8859 - mse: 19284874.0000 - val_loss: 38.5364 - val_mse: 8018.8345 - 607ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1433.2712 - mse: 23006422.0000 - val_loss: 38.3803 - val_mse: 7971.4941 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1357.4061 - mse: 17226170.0000 - val_loss: 38.7244 - val_mse: 8054.7988 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1323.3413 - mse: 17691474.0000 - val_loss: 37.4007 - val_mse: 7560.0991 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1359.9277 - mse: 17625574.0000 - val_loss: 35.8395 - val_mse: 6923.2637 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1362.5773 - mse: 18268770.0000 - val_loss: 35.5044 - val_mse: 6805.4678 - 598ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1308.9591 - mse: 16625593.0000 - val_loss: 34.8793 - val_mse: 6611.1582 - 585ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1327.9615 - mse: 17573278.0000 - val_loss: 35.5740 - val_mse: 6840.5654 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1342.9031 - mse: 18606932.0000 - val_loss: 35.8299 - val_mse: 6934.6870 - 587ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1298.2609 - mse: 17600554.0000 - val_loss: 34.1287 - val_mse: 6285.3252 - 594ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1292.5656 - mse: 16744813.0000 - val_loss: 35.0611 - val_mse: 6590.4932 - 590ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1275.3237 - mse: 15980694.0000 - val_loss: 33.8962 - val_mse: 6167.3154 - 588ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1255.1067 - mse: 14973863.0000 - val_loss: 35.7828 - val_mse: 6857.5874 - 634ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1301.6666 - mse: 16584014.0000 - val_loss: 33.7769 - val_mse: 6190.6006 - 619ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1175.7048 - mse: 12675595.0000 - val_loss: 34.7379 - val_mse: 6470.5933 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1194.7858 - mse: 12375410.0000 - val_loss: 34.5579 - val_mse: 6443.5405 - 611ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1196.0632 - mse: 15306674.0000 - val_loss: 34.1925 - val_mse: 6304.9097 - 597ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1233.8170 - mse: 14881680.0000 - val_loss: 33.9406 - val_mse: 6268.0732 - 593ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1204.7010 - mse: 14979797.0000 - val_loss: 34.9002 - val_mse: 6599.9141 - 596ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1219.8545 - mse: 15364807.0000 - val_loss: 35.1607 - val_mse: 6698.6787 - 590ms/epoch - 4ms/step\n",
            "132/132 - 1s - loss: 1174.3210 - mse: 13206120.0000 - val_loss: 35.1176 - val_mse: 6614.5996 - 600ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1193.7017 - mse: 15919488.0000 - val_loss: 33.6945 - val_mse: 6079.8403 - 603ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1208.6311 - mse: 13910668.0000 - val_loss: 33.0549 - val_mse: 5961.9907 - 594ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1169.3884 - mse: 14571672.0000 - val_loss: 32.0266 - val_mse: 5581.7905 - 617ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1170.2250 - mse: 14720871.0000 - val_loss: 31.6796 - val_mse: 5471.0063 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1145.2588 - mse: 15339863.0000 - val_loss: 32.2691 - val_mse: 5638.4360 - 615ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1105.3331 - mse: 11372601.0000 - val_loss: 31.0990 - val_mse: 5194.8345 - 616ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1138.1238 - mse: 13383867.0000 - val_loss: 31.6127 - val_mse: 5350.1528 - 617ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1154.7446 - mse: 14622450.0000 - val_loss: 33.1535 - val_mse: 5870.9077 - 620ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1098.7781 - mse: 11601523.0000 - val_loss: 33.0448 - val_mse: 5816.0811 - 632ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1089.7578 - mse: 11080834.0000 - val_loss: 31.5346 - val_mse: 5301.4653 - 639ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1093.3624 - mse: 12207823.0000 - val_loss: 32.0169 - val_mse: 5460.6514 - 645ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1076.6017 - mse: 11096297.0000 - val_loss: 31.8323 - val_mse: 5398.0864 - 642ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1078.3265 - mse: 11434474.0000 - val_loss: 32.2448 - val_mse: 5530.1924 - 649ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1024.1381 - mse: 8645699.0000 - val_loss: 30.6553 - val_mse: 5012.5317 - 605ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1079.3556 - mse: 12088056.0000 - val_loss: 32.0301 - val_mse: 5468.1675 - 609ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1094.8610 - mse: 12962880.0000 - val_loss: 32.2523 - val_mse: 5530.4922 - 606ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1055.0128 - mse: 11616282.0000 - val_loss: 32.8472 - val_mse: 5724.9834 - 632ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1062.9894 - mse: 12717532.0000 - val_loss: 32.3637 - val_mse: 5550.2036 - 601ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1082.8721 - mse: 12818067.0000 - val_loss: 29.9365 - val_mse: 4751.7695 - 622ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 1059.4274 - mse: 11660892.0000 - val_loss: 29.2080 - val_mse: 4521.0366 - 612ms/epoch - 5ms/step\n",
            "132/132 - 1s - loss: 997.6265 - mse: 10175721.0000 - val_loss: 27.7648 - val_mse: 4093.1143 - 617ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 195 ended. Search finished for the next optimal point.\n",
            "Time taken: 77.0099\n",
            "Function value obtained: 4093.1143\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 196 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [37, 106]\n",
            "Learning Rate: 0.08759852500147265\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.12211642022745181\n",
            "Batch Size: 255\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 7332.1797 - mse: 4060602112.0000 - val_loss: 0.0237 - val_mse: 0.0473 - 3s/epoch - 78ms/step\n",
            "33/33 - 0s - loss: 5.2192 - mse: 2676.8142 - val_loss: 0.0132 - val_mse: 0.0264 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0126 - mse: 0.0252 - val_loss: 0.0084 - val_mse: 0.0169 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0171 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 219ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.00901753]\n",
            "\n",
            "Iteration No: 196 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.5314\n",
            "Function value obtained: 0.0169\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 197 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [121, 33]\n",
            "Learning Rate: 6.90345473374492e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45581766646804583\n",
            "Batch Size: 56\n",
            "----------------------------------------\n",
            "150/150 - 3s - loss: 3077.6394 - mse: 91667976.0000 - val_loss: 741.1583 - val_mse: 2740645.5000 - 3s/epoch - 20ms/step\n",
            "150/150 - 1s - loss: 2838.7734 - mse: 88564192.0000 - val_loss: 608.2627 - val_mse: 1844006.3750 - 666ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 2660.9185 - mse: 68495152.0000 - val_loss: 534.5939 - val_mse: 1424664.2500 - 672ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 2538.2136 - mse: 64835872.0000 - val_loss: 454.2126 - val_mse: 1027474.0625 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 2389.8792 - mse: 65904352.0000 - val_loss: 371.3438 - val_mse: 686018.3125 - 675ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 2203.2827 - mse: 48486752.0000 - val_loss: 316.8047 - val_mse: 498943.8125 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 2245.8362 - mse: 52711460.0000 - val_loss: 258.7419 - val_mse: 332535.4688 - 664ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1969.0889 - mse: 35913128.0000 - val_loss: 211.7324 - val_mse: 222385.4219 - 691ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1976.8838 - mse: 39558304.0000 - val_loss: 163.6995 - val_mse: 132645.5312 - 672ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1886.2042 - mse: 36944320.0000 - val_loss: 135.6711 - val_mse: 90502.8672 - 692ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1793.5848 - mse: 32219718.0000 - val_loss: 107.3569 - val_mse: 55749.7148 - 679ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1702.0155 - mse: 28438716.0000 - val_loss: 80.0274 - val_mse: 30487.8691 - 679ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1691.8848 - mse: 26553990.0000 - val_loss: 60.3052 - val_mse: 16964.4453 - 690ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1607.3124 - mse: 26229500.0000 - val_loss: 39.0420 - val_mse: 6780.9336 - 656ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1554.2156 - mse: 22907054.0000 - val_loss: 29.9694 - val_mse: 3862.5920 - 656ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1490.0725 - mse: 22004350.0000 - val_loss: 11.9623 - val_mse: 516.9258 - 656ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1438.5276 - mse: 19461806.0000 - val_loss: 3.2958 - val_mse: 81.4301 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1342.7383 - mse: 20929926.0000 - val_loss: 9.2512 - val_mse: 616.4140 - 655ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1387.3340 - mse: 18268176.0000 - val_loss: 20.7345 - val_mse: 2755.7458 - 667ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1290.8485 - mse: 14508230.0000 - val_loss: 30.7817 - val_mse: 5641.7739 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1281.7719 - mse: 15738984.0000 - val_loss: 30.2734 - val_mse: 4650.3726 - 654ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1261.3400 - mse: 16325219.0000 - val_loss: 24.3199 - val_mse: 2873.2319 - 657ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1204.1378 - mse: 12963463.0000 - val_loss: 21.3361 - val_mse: 2192.7261 - 653ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1210.0559 - mse: 14743316.0000 - val_loss: 20.5922 - val_mse: 1935.0754 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1127.2986 - mse: 12023399.0000 - val_loss: 17.2931 - val_mse: 1329.7765 - 663ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1141.8473 - mse: 13771648.0000 - val_loss: 12.5069 - val_mse: 667.3116 - 667ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 1051.8510 - mse: 11574352.0000 - val_loss: 10.1181 - val_mse: 511.2758 - 701ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1077.8624 - mse: 12915747.0000 - val_loss: 7.2081 - val_mse: 261.0125 - 693ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1032.5952 - mse: 11710376.0000 - val_loss: 5.7601 - val_mse: 184.7500 - 699ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 1011.2697 - mse: 10273479.0000 - val_loss: 4.9832 - val_mse: 146.8993 - 697ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 939.6320 - mse: 8686900.0000 - val_loss: 4.2993 - val_mse: 101.7950 - 663ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 953.4592 - mse: 8819067.0000 - val_loss: 3.9034 - val_mse: 76.7285 - 668ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 969.1904 - mse: 10173016.0000 - val_loss: 3.0211 - val_mse: 74.8710 - 682ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 861.8459 - mse: 7396402.5000 - val_loss: 5.5170 - val_mse: 338.5874 - 673ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 875.4657 - mse: 8202858.0000 - val_loss: 9.1520 - val_mse: 744.7599 - 681ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 816.5046 - mse: 6234314.5000 - val_loss: 8.6786 - val_mse: 654.2023 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 843.2698 - mse: 7641227.0000 - val_loss: 9.8900 - val_mse: 924.2886 - 684ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 797.0344 - mse: 7121007.5000 - val_loss: 7.0346 - val_mse: 474.4282 - 685ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 786.0892 - mse: 7096293.0000 - val_loss: 6.6864 - val_mse: 423.3858 - 692ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 783.9332 - mse: 6978261.0000 - val_loss: 6.5856 - val_mse: 415.6038 - 675ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 802.2100 - mse: 7494221.0000 - val_loss: 4.1080 - val_mse: 169.5794 - 690ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 729.1702 - mse: 5646814.5000 - val_loss: 4.8332 - val_mse: 220.9353 - 677ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 694.4449 - mse: 5229994.0000 - val_loss: 3.2852 - val_mse: 90.7639 - 684ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 699.9790 - mse: 5149438.0000 - val_loss: 5.2262 - val_mse: 125.8933 - 697ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 639.9570 - mse: 3928733.7500 - val_loss: 6.6563 - val_mse: 274.7120 - 697ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 673.0218 - mse: 4856928.0000 - val_loss: 5.1781 - val_mse: 136.8262 - 696ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 657.8052 - mse: 3942932.5000 - val_loss: 5.8623 - val_mse: 221.3381 - 673ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 645.4528 - mse: 4672685.0000 - val_loss: 6.0272 - val_mse: 223.8695 - 686ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 646.0894 - mse: 4929591.0000 - val_loss: 6.2723 - val_mse: 213.0344 - 692ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 592.7899 - mse: 3967089.2500 - val_loss: 6.3866 - val_mse: 227.9198 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 588.7733 - mse: 3817503.0000 - val_loss: 5.4702 - val_mse: 172.6647 - 666ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 566.1262 - mse: 3314012.0000 - val_loss: 4.9591 - val_mse: 129.8033 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 540.2767 - mse: 2839965.5000 - val_loss: 4.7049 - val_mse: 114.6159 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 540.9583 - mse: 3100809.0000 - val_loss: 4.7298 - val_mse: 106.5414 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 518.3004 - mse: 2708044.0000 - val_loss: 3.6851 - val_mse: 70.8163 - 665ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 484.5636 - mse: 2502978.5000 - val_loss: 3.2069 - val_mse: 58.8443 - 661ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 500.8304 - mse: 2660105.5000 - val_loss: 1.8220 - val_mse: 20.1666 - 667ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 458.1529 - mse: 2043103.2500 - val_loss: 0.7221 - val_mse: 5.0444 - 678ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 466.2178 - mse: 2399651.7500 - val_loss: 0.5949 - val_mse: 4.0484 - 667ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 443.9112 - mse: 2093051.8750 - val_loss: 0.8354 - val_mse: 6.2580 - 668ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 433.7030 - mse: 2156352.7500 - val_loss: 0.7858 - val_mse: 4.5553 - 694ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 440.6194 - mse: 2171597.5000 - val_loss: 0.7101 - val_mse: 1.8938 - 699ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 406.1839 - mse: 1662493.1250 - val_loss: 1.3520 - val_mse: 5.0079 - 704ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 403.6625 - mse: 1902804.2500 - val_loss: 1.2028 - val_mse: 3.8807 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 380.6591 - mse: 1676034.0000 - val_loss: 1.4902 - val_mse: 6.7756 - 661ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 383.5698 - mse: 1782557.5000 - val_loss: 2.3412 - val_mse: 21.3087 - 674ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 381.2036 - mse: 1944533.7500 - val_loss: 2.9587 - val_mse: 42.7956 - 664ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 370.1165 - mse: 1596912.8750 - val_loss: 2.9107 - val_mse: 42.8830 - 668ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 331.0340 - mse: 1012005.6250 - val_loss: 2.7849 - val_mse: 38.7969 - 673ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 326.9264 - mse: 1086839.7500 - val_loss: 2.3461 - val_mse: 27.2159 - 680ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 330.0237 - mse: 1105613.0000 - val_loss: 2.1547 - val_mse: 22.6411 - 670ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 320.9784 - mse: 1083594.3750 - val_loss: 1.8602 - val_mse: 16.4444 - 686ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 318.2010 - mse: 1363955.7500 - val_loss: 1.6859 - val_mse: 13.1004 - 682ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 317.7253 - mse: 1173720.6250 - val_loss: 1.5910 - val_mse: 11.2674 - 680ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 292.6084 - mse: 942544.3750 - val_loss: 1.5575 - val_mse: 10.4546 - 694ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 292.5142 - mse: 1072452.7500 - val_loss: 1.5544 - val_mse: 10.4057 - 670ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 278.0007 - mse: 938842.1875 - val_loss: 1.4884 - val_mse: 9.5606 - 708ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 280.7932 - mse: 1030976.4375 - val_loss: 1.5029 - val_mse: 9.6481 - 716ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 276.7044 - mse: 1090893.7500 - val_loss: 1.5314 - val_mse: 10.2070 - 696ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 257.3163 - mse: 808380.1250 - val_loss: 1.5612 - val_mse: 10.7581 - 706ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 253.4935 - mse: 750572.0000 - val_loss: 1.5254 - val_mse: 10.3302 - 664ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 233.8510 - mse: 537168.3750 - val_loss: 1.4863 - val_mse: 9.7553 - 682ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 230.1625 - mse: 643529.3750 - val_loss: 1.4287 - val_mse: 8.8605 - 672ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 233.0211 - mse: 775798.1250 - val_loss: 1.3908 - val_mse: 8.4267 - 668ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 216.2496 - mse: 600653.9375 - val_loss: 1.3919 - val_mse: 8.4237 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 208.9181 - mse: 453635.9062 - val_loss: 1.3598 - val_mse: 8.0052 - 669ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 201.8450 - mse: 474601.7812 - val_loss: 1.3078 - val_mse: 7.4677 - 671ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 205.5865 - mse: 484994.6875 - val_loss: 1.2848 - val_mse: 7.1844 - 677ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 201.8905 - mse: 476988.4062 - val_loss: 1.2593 - val_mse: 6.8902 - 684ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 182.2773 - mse: 399928.0000 - val_loss: 1.2097 - val_mse: 6.3605 - 675ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 192.5310 - mse: 546279.5625 - val_loss: 1.1078 - val_mse: 5.3290 - 673ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 190.7530 - mse: 466429.7188 - val_loss: 1.0825 - val_mse: 5.1443 - 674ms/epoch - 4ms/step\n",
            "150/150 - 1s - loss: 173.1537 - mse: 358080.1875 - val_loss: 1.0339 - val_mse: 4.8150 - 677ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 165.9442 - mse: 346888.4062 - val_loss: 0.9944 - val_mse: 4.5746 - 729ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 156.7804 - mse: 303807.9688 - val_loss: 0.9361 - val_mse: 4.0253 - 710ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 155.0968 - mse: 263886.7188 - val_loss: 0.8386 - val_mse: 3.2563 - 714ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 149.9045 - mse: 297481.2812 - val_loss: 0.7856 - val_mse: 2.8156 - 687ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 147.4820 - mse: 280482.2812 - val_loss: 0.7072 - val_mse: 2.2268 - 677ms/epoch - 5ms/step\n",
            "150/150 - 1s - loss: 140.0503 - mse: 247410.9688 - val_loss: 0.6690 - val_mse: 1.9732 - 1s/epoch - 8ms/step\n",
            "150/150 - 1s - loss: 136.3227 - mse: 235338.5938 - val_loss: 0.6229 - val_mse: 1.7199 - 693ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 197 ended. Search finished for the next optimal point.\n",
            "Time taken: 84.6960\n",
            "Function value obtained: 1.7199\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 198 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [42, 45]\n",
            "Learning Rate: 0.06460764358363459\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.00015746490200657662\n",
            "Batch Size: 243\n",
            "----------------------------------------\n",
            "35/35 - 3s - loss: 1702.8448 - mse: 147141504.0000 - val_loss: 20.4233 - val_mse: 2311.7773 - 3s/epoch - 80ms/step\n",
            "35/35 - 0s - loss: 4.4745 - mse: 353.8245 - val_loss: 0.0999 - val_mse: 0.2083 - 237ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0248 - mse: 0.0503 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 242ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0118 - mse: 0.1033 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0101 - mse: 0.0323 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0099 - mse: 0.0326 - val_loss: 0.0084 - val_mse: 0.0168 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0093 - mse: 0.0218 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0103 - mse: 0.0431 - val_loss: 0.0084 - val_mse: 0.0169 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 231ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0090 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0091 - mse: 0.0198 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0091 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0090 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0168 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 220ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 237ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 243ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 240ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0090 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 232ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 232ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 232ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 237ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 231ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0089 - val_mse: 0.0177 - 237ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 250ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 245ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 227ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0089 - val_mse: 0.0178 - 224ms/epoch - 6ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 241ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 233ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "35/35 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 198 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.9864\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 199 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [122, 55]\n",
            "Learning Rate: 1.4146873569675611e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45909741470483645\n",
            "Batch Size: 57\n",
            "----------------------------------------\n",
            "148/148 - 3s - loss: 1498.8403 - mse: 20409930.0000 - val_loss: 38.0780 - val_mse: 7465.9634 - 3s/epoch - 21ms/step\n",
            "148/148 - 1s - loss: 1302.2162 - mse: 16473152.0000 - val_loss: 23.0373 - val_mse: 3226.2605 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1200.4232 - mse: 14246043.0000 - val_loss: 36.3065 - val_mse: 7817.9829 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1119.5007 - mse: 11994538.0000 - val_loss: 34.7059 - val_mse: 7085.3179 - 685ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 1052.1108 - mse: 11236545.0000 - val_loss: 41.2649 - val_mse: 8406.6523 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 958.8265 - mse: 9281652.0000 - val_loss: 57.6896 - val_mse: 16662.9785 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 914.8660 - mse: 8758874.0000 - val_loss: 63.3735 - val_mse: 22639.9355 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 847.5604 - mse: 7224528.0000 - val_loss: 57.8567 - val_mse: 18815.0469 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 826.6815 - mse: 7798689.0000 - val_loss: 57.5136 - val_mse: 18254.3730 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 749.3992 - mse: 6121543.5000 - val_loss: 56.8827 - val_mse: 18339.2949 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 725.8431 - mse: 4891525.5000 - val_loss: 51.9422 - val_mse: 15040.4062 - 654ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 703.1182 - mse: 5249376.5000 - val_loss: 52.6223 - val_mse: 15526.0283 - 688ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 650.7355 - mse: 3698796.7500 - val_loss: 53.4974 - val_mse: 15987.7031 - 701ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 663.2317 - mse: 4714219.0000 - val_loss: 54.3362 - val_mse: 15975.6260 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 626.2302 - mse: 3942976.5000 - val_loss: 52.9155 - val_mse: 15031.4932 - 707ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 622.7020 - mse: 4135551.5000 - val_loss: 53.9736 - val_mse: 15576.1221 - 657ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 584.0388 - mse: 3604246.5000 - val_loss: 49.4115 - val_mse: 13133.1592 - 650ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 567.3407 - mse: 3152930.0000 - val_loss: 44.5907 - val_mse: 10648.7031 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 543.4611 - mse: 3396827.2500 - val_loss: 41.8995 - val_mse: 9407.9316 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 500.7940 - mse: 2790633.7500 - val_loss: 44.0516 - val_mse: 10487.5840 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 512.6894 - mse: 3178822.2500 - val_loss: 40.3350 - val_mse: 9076.7471 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 485.4599 - mse: 2310099.5000 - val_loss: 33.8802 - val_mse: 6514.2373 - 656ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 459.7134 - mse: 2137102.0000 - val_loss: 29.0362 - val_mse: 4868.3818 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 455.7704 - mse: 2445015.7500 - val_loss: 22.7628 - val_mse: 3074.0408 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 421.3342 - mse: 1706492.8750 - val_loss: 20.6433 - val_mse: 2551.3350 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 401.9432 - mse: 1532870.8750 - val_loss: 16.1562 - val_mse: 1610.8011 - 666ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 385.5562 - mse: 1530683.7500 - val_loss: 16.6172 - val_mse: 1696.1483 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 370.9538 - mse: 1496804.6250 - val_loss: 15.1055 - val_mse: 1427.7955 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 352.7456 - mse: 1189988.6250 - val_loss: 14.0681 - val_mse: 1250.4657 - 691ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 349.1490 - mse: 1138672.7500 - val_loss: 13.2421 - val_mse: 1126.2803 - 697ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 334.3135 - mse: 1172579.7500 - val_loss: 11.3351 - val_mse: 835.3642 - 687ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 318.5640 - mse: 980631.8750 - val_loss: 11.6145 - val_mse: 874.3377 - 683ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 313.4337 - mse: 1096855.6250 - val_loss: 9.6266 - val_mse: 611.4683 - 649ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 305.2814 - mse: 945935.9375 - val_loss: 7.8675 - val_mse: 410.7874 - 660ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 281.7131 - mse: 790938.3750 - val_loss: 7.5215 - val_mse: 364.0502 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 289.7811 - mse: 1152506.3750 - val_loss: 8.2622 - val_mse: 423.8983 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 264.2308 - mse: 733784.3125 - val_loss: 7.2528 - val_mse: 331.1209 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 274.7524 - mse: 787459.3750 - val_loss: 6.3906 - val_mse: 260.7645 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 247.7274 - mse: 644092.2500 - val_loss: 5.7978 - val_mse: 213.9371 - 679ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 241.0074 - mse: 661230.8125 - val_loss: 6.3944 - val_mse: 255.9274 - 671ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 240.1996 - mse: 619416.3750 - val_loss: 6.3127 - val_mse: 249.6193 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 226.9335 - mse: 601766.6250 - val_loss: 6.5833 - val_mse: 268.6784 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 214.6508 - mse: 432351.1250 - val_loss: 6.2896 - val_mse: 246.9659 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 213.2097 - mse: 476503.5938 - val_loss: 6.4796 - val_mse: 261.7861 - 676ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 201.4105 - mse: 462543.0000 - val_loss: 6.9690 - val_mse: 299.1997 - 682ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 195.3960 - mse: 425514.3438 - val_loss: 6.7094 - val_mse: 277.4898 - 717ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 190.4017 - mse: 419327.7812 - val_loss: 6.3855 - val_mse: 252.4232 - 716ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 181.7301 - mse: 378930.7188 - val_loss: 5.9046 - val_mse: 217.7992 - 704ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 173.2182 - mse: 367136.7188 - val_loss: 5.3150 - val_mse: 179.3515 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 167.2145 - mse: 281717.2188 - val_loss: 4.8387 - val_mse: 151.1538 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 156.0079 - mse: 260914.2031 - val_loss: 4.0255 - val_mse: 109.5980 - 682ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 151.2835 - mse: 234870.3125 - val_loss: 3.5178 - val_mse: 86.1606 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 150.9244 - mse: 229050.0938 - val_loss: 3.1556 - val_mse: 69.5552 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 145.9348 - mse: 257609.6250 - val_loss: 2.0714 - val_mse: 31.9278 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 133.3436 - mse: 185410.7969 - val_loss: 1.2249 - val_mse: 12.4425 - 672ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 137.4171 - mse: 233509.0000 - val_loss: 1.0260 - val_mse: 8.9245 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 120.7874 - mse: 157359.4062 - val_loss: 0.6868 - val_mse: 4.1630 - 680ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 125.8171 - mse: 218595.1094 - val_loss: 0.5902 - val_mse: 3.1461 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 121.5492 - mse: 153263.8594 - val_loss: 0.6987 - val_mse: 4.4792 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 117.4052 - mse: 160100.3438 - val_loss: 0.8259 - val_mse: 6.0252 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 105.9958 - mse: 119952.9375 - val_loss: 1.2649 - val_mse: 13.3271 - 674ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 104.0117 - mse: 126839.4062 - val_loss: 1.3768 - val_mse: 15.4852 - 700ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 97.5214 - mse: 94056.8906 - val_loss: 1.1477 - val_mse: 11.1208 - 706ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 97.0321 - mse: 101687.6250 - val_loss: 1.4213 - val_mse: 16.9676 - 705ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 96.0764 - mse: 107168.5391 - val_loss: 1.2947 - val_mse: 13.9803 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 93.3183 - mse: 120150.1016 - val_loss: 1.1695 - val_mse: 11.3827 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 86.0947 - mse: 95213.2656 - val_loss: 0.9298 - val_mse: 7.4189 - 668ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 83.0178 - mse: 87204.1484 - val_loss: 0.8457 - val_mse: 6.2052 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 77.4267 - mse: 59734.4453 - val_loss: 0.7260 - val_mse: 4.6944 - 644ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 76.9657 - mse: 75725.7188 - val_loss: 0.6816 - val_mse: 4.1330 - 646ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 68.7152 - mse: 52483.3984 - val_loss: 0.7504 - val_mse: 4.9594 - 646ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 69.4215 - mse: 68742.9297 - val_loss: 0.7529 - val_mse: 4.9864 - 661ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 69.8575 - mse: 66055.3047 - val_loss: 0.7172 - val_mse: 4.5356 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 66.8702 - mse: 62850.6562 - val_loss: 0.7967 - val_mse: 5.5622 - 655ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 63.6904 - mse: 58642.4375 - val_loss: 0.7146 - val_mse: 4.5303 - 667ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 63.4596 - mse: 90684.2422 - val_loss: 0.6167 - val_mse: 3.4113 - 659ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 57.0826 - mse: 37845.9531 - val_loss: 0.5461 - val_mse: 2.6927 - 653ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 57.8034 - mse: 50103.9258 - val_loss: 0.4898 - val_mse: 2.1535 - 684ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 54.2542 - mse: 40594.2031 - val_loss: 0.4791 - val_mse: 2.0566 - 709ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 54.5022 - mse: 41737.3320 - val_loss: 0.4029 - val_mse: 1.4657 - 695ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 50.6472 - mse: 32733.1875 - val_loss: 0.3366 - val_mse: 1.0197 - 711ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 43.8925 - mse: 23332.0098 - val_loss: 0.2812 - val_mse: 0.7119 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 48.4955 - mse: 43402.4531 - val_loss: 0.2365 - val_mse: 0.5126 - 665ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 42.0638 - mse: 22941.8086 - val_loss: 0.2145 - val_mse: 0.4341 - 677ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 41.1396 - mse: 23289.8711 - val_loss: 0.2120 - val_mse: 0.4239 - 670ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 38.5719 - mse: 18693.6816 - val_loss: 0.2203 - val_mse: 0.4406 - 664ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 36.7881 - mse: 17129.5840 - val_loss: 0.2316 - val_mse: 0.4632 - 681ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 35.1344 - mse: 16819.1973 - val_loss: 0.2299 - val_mse: 0.4599 - 666ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 36.5039 - mse: 22668.3164 - val_loss: 0.2285 - val_mse: 0.4569 - 658ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 33.1462 - mse: 14961.5283 - val_loss: 0.2270 - val_mse: 0.4540 - 649ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 32.3105 - mse: 23902.5762 - val_loss: 0.2255 - val_mse: 0.4509 - 663ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 31.3430 - mse: 16390.5586 - val_loss: 0.2240 - val_mse: 0.4480 - 675ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 29.0011 - mse: 13037.9414 - val_loss: 0.2225 - val_mse: 0.4450 - 662ms/epoch - 4ms/step\n",
            "148/148 - 1s - loss: 28.6509 - mse: 12859.4678 - val_loss: 0.2211 - val_mse: 0.4421 - 678ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 26.8219 - mse: 11619.2617 - val_loss: 0.2197 - val_mse: 0.4393 - 692ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 24.8099 - mse: 9499.4287 - val_loss: 0.2182 - val_mse: 0.4364 - 686ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 24.8678 - mse: 13577.3887 - val_loss: 0.2168 - val_mse: 0.4335 - 691ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 23.7365 - mse: 9339.3604 - val_loss: 0.2152 - val_mse: 0.4305 - 689ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 23.6609 - mse: 11076.1895 - val_loss: 0.2136 - val_mse: 0.4272 - 669ms/epoch - 5ms/step\n",
            "148/148 - 1s - loss: 21.4772 - mse: 7613.6689 - val_loss: 0.2121 - val_mse: 0.4241 - 665ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 199 ended. Search finished for the next optimal point.\n",
            "Time taken: 84.6292\n",
            "Function value obtained: 0.4241\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 200 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [32, 57]\n",
            "Learning Rate: 6.773799439718363e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.12690134717666923\n",
            "Batch Size: 238\n",
            "----------------------------------------\n",
            "36/36 - 3s - loss: 1547.6036 - mse: 18631230.0000 - val_loss: 78.0548 - val_mse: 26394.8906 - 3s/epoch - 71ms/step\n",
            "36/36 - 0s - loss: 1216.1418 - mse: 12114587.0000 - val_loss: 222.4380 - val_mse: 266874.2812 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 1079.3607 - mse: 10678910.0000 - val_loss: 183.6553 - val_mse: 182887.9531 - 226ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 904.7760 - mse: 6378187.5000 - val_loss: 197.1025 - val_mse: 208162.7500 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 774.9715 - mse: 4965978.0000 - val_loss: 148.0871 - val_mse: 118079.9609 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 681.0947 - mse: 4079523.5000 - val_loss: 125.0615 - val_mse: 83719.7109 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 561.9281 - mse: 2724232.2500 - val_loss: 89.2667 - val_mse: 43383.6602 - 245ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 452.3318 - mse: 1657701.2500 - val_loss: 76.3914 - val_mse: 31754.4551 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 374.8551 - mse: 1157361.3750 - val_loss: 65.0234 - val_mse: 23002.0039 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 314.6903 - mse: 886312.1250 - val_loss: 49.9820 - val_mse: 13684.7334 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 264.5399 - mse: 621211.1875 - val_loss: 38.8852 - val_mse: 8287.3623 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 223.6695 - mse: 466662.4062 - val_loss: 27.0524 - val_mse: 4082.7319 - 225ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 205.6470 - mse: 415327.2188 - val_loss: 13.2790 - val_mse: 1114.0514 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 198.5033 - mse: 440869.6250 - val_loss: 2.2150 - val_mse: 22.9746 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 177.4241 - mse: 327866.0625 - val_loss: 2.4988 - val_mse: 21.7619 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 182.4173 - mse: 370808.6562 - val_loss: 2.5001 - val_mse: 36.3920 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 163.9228 - mse: 251422.4062 - val_loss: 2.3071 - val_mse: 39.0406 - 238ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 164.5840 - mse: 263904.5312 - val_loss: 1.8288 - val_mse: 31.5739 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 166.8994 - mse: 317946.4375 - val_loss: 1.8839 - val_mse: 46.8789 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 153.8647 - mse: 232794.6406 - val_loss: 4.4540 - val_mse: 154.5616 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 149.4613 - mse: 223020.8125 - val_loss: 2.9994 - val_mse: 135.8229 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 151.3322 - mse: 238091.3125 - val_loss: 5.2793 - val_mse: 161.3682 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 147.5907 - mse: 232649.7031 - val_loss: 4.5657 - val_mse: 96.3568 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 146.0853 - mse: 233095.5938 - val_loss: 5.2596 - val_mse: 159.5922 - 225ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 140.9222 - mse: 240645.2969 - val_loss: 6.4741 - val_mse: 316.6198 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 142.2614 - mse: 252570.3438 - val_loss: 6.7048 - val_mse: 261.0704 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 130.0839 - mse: 189814.3594 - val_loss: 4.5972 - val_mse: 82.9643 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 125.7205 - mse: 166746.4062 - val_loss: 3.1701 - val_mse: 80.8741 - 223ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 126.1875 - mse: 164024.3281 - val_loss: 6.1962 - val_mse: 258.4821 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 126.6145 - mse: 174767.4062 - val_loss: 6.6425 - val_mse: 326.0474 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 120.9545 - mse: 140856.5781 - val_loss: 5.0137 - val_mse: 124.2251 - 238ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 118.6889 - mse: 145351.7812 - val_loss: 4.2748 - val_mse: 73.9345 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 114.6510 - mse: 130078.3281 - val_loss: 4.7009 - val_mse: 91.8922 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 114.3046 - mse: 153593.6562 - val_loss: 2.7067 - val_mse: 31.3500 - 221ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 109.8613 - mse: 134931.6719 - val_loss: 2.5858 - val_mse: 34.3552 - 227ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 109.6831 - mse: 137188.6875 - val_loss: 5.0810 - val_mse: 104.4708 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 105.7036 - mse: 122633.1094 - val_loss: 2.2094 - val_mse: 28.2777 - 224ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 98.6811 - mse: 105548.3125 - val_loss: 3.6002 - val_mse: 55.8112 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 100.2195 - mse: 104549.7891 - val_loss: 4.0830 - val_mse: 73.0536 - 234ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 102.7359 - mse: 137646.9531 - val_loss: 5.5882 - val_mse: 202.3218 - 243ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 99.8715 - mse: 101016.9922 - val_loss: 3.5828 - val_mse: 54.0682 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 90.2111 - mse: 90276.1016 - val_loss: 2.2712 - val_mse: 21.4183 - 245ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 88.7591 - mse: 74093.7344 - val_loss: 1.9564 - val_mse: 17.4394 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 87.6127 - mse: 84907.3125 - val_loss: 4.2345 - val_mse: 185.5300 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 89.2990 - mse: 87563.6875 - val_loss: 1.7713 - val_mse: 13.1107 - 241ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 85.5049 - mse: 82607.0469 - val_loss: 1.7157 - val_mse: 13.8362 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 84.3695 - mse: 81207.5859 - val_loss: 1.8474 - val_mse: 13.6392 - 241ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 82.7412 - mse: 71153.6406 - val_loss: 2.7380 - val_mse: 29.1523 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 85.1467 - mse: 85095.0625 - val_loss: 2.1785 - val_mse: 19.8277 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 83.5563 - mse: 81271.6875 - val_loss: 2.0774 - val_mse: 17.7662 - 224ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 81.0914 - mse: 84116.7891 - val_loss: 2.5195 - val_mse: 63.4323 - 228ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 76.2623 - mse: 67106.5547 - val_loss: 1.7357 - val_mse: 27.8042 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 74.3858 - mse: 64572.5859 - val_loss: 3.0230 - val_mse: 66.3720 - 227ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 77.1824 - mse: 69389.0156 - val_loss: 1.7573 - val_mse: 29.5157 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 73.5091 - mse: 54908.6602 - val_loss: 1.5539 - val_mse: 13.5420 - 234ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 69.6424 - mse: 54617.5586 - val_loss: 1.5411 - val_mse: 18.2462 - 228ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 70.7831 - mse: 58001.7109 - val_loss: 1.2278 - val_mse: 12.6848 - 223ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 65.3157 - mse: 43435.1445 - val_loss: 1.7355 - val_mse: 35.1662 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 67.7063 - mse: 44637.0625 - val_loss: 1.8176 - val_mse: 13.6704 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 68.3155 - mse: 62140.0508 - val_loss: 1.1894 - val_mse: 13.6835 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 66.0638 - mse: 49559.5469 - val_loss: 1.3744 - val_mse: 16.1626 - 243ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 62.8625 - mse: 43233.3398 - val_loss: 0.9585 - val_mse: 4.4879 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 62.5356 - mse: 41108.2031 - val_loss: 1.1384 - val_mse: 12.0971 - 233ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 59.0252 - mse: 43984.7461 - val_loss: 1.1081 - val_mse: 12.3660 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 62.4469 - mse: 46870.3711 - val_loss: 0.6511 - val_mse: 3.2507 - 234ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 59.1372 - mse: 35968.8945 - val_loss: 0.9267 - val_mse: 10.6935 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 55.3065 - mse: 32537.2637 - val_loss: 0.7856 - val_mse: 6.2879 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 55.5980 - mse: 32681.9297 - val_loss: 0.6385 - val_mse: 3.5574 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 54.7171 - mse: 34183.3125 - val_loss: 1.2539 - val_mse: 8.4870 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 52.4626 - mse: 32689.4062 - val_loss: 0.6825 - val_mse: 2.8822 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 54.6663 - mse: 36773.5898 - val_loss: 0.2172 - val_mse: 0.5537 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 51.1021 - mse: 25612.2305 - val_loss: 0.3167 - val_mse: 0.9442 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 50.8334 - mse: 28378.8164 - val_loss: 1.3435 - val_mse: 9.3949 - 234ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 48.2266 - mse: 27351.9277 - val_loss: 0.7155 - val_mse: 7.3047 - 244ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 48.9986 - mse: 27426.8809 - val_loss: 0.8425 - val_mse: 7.0744 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 49.2730 - mse: 28764.7266 - val_loss: 0.5482 - val_mse: 2.8299 - 232ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 45.7466 - mse: 23280.2773 - val_loss: 0.6762 - val_mse: 3.2979 - 249ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 47.1061 - mse: 26779.8730 - val_loss: 0.8375 - val_mse: 4.2943 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 44.6343 - mse: 22430.6133 - val_loss: 0.9844 - val_mse: 7.6275 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 43.7776 - mse: 25967.1738 - val_loss: 0.2735 - val_mse: 0.6801 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 42.4950 - mse: 20085.5469 - val_loss: 0.6819 - val_mse: 4.0652 - 243ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 43.6634 - mse: 20702.1836 - val_loss: 0.2109 - val_mse: 0.5169 - 239ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 42.0880 - mse: 18214.9609 - val_loss: 0.7550 - val_mse: 5.1563 - 244ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 40.7947 - mse: 18505.9414 - val_loss: 0.4574 - val_mse: 1.9575 - 241ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 39.8431 - mse: 18920.6992 - val_loss: 0.3968 - val_mse: 2.7647 - 241ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 38.1748 - mse: 16337.7773 - val_loss: 0.3684 - val_mse: 2.7446 - 245ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 37.7799 - mse: 15752.1855 - val_loss: 0.3485 - val_mse: 1.7658 - 240ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 35.3791 - mse: 15519.8350 - val_loss: 0.3824 - val_mse: 1.6883 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 37.3562 - mse: 16743.8613 - val_loss: 0.2894 - val_mse: 0.9369 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 36.3467 - mse: 16490.7773 - val_loss: 0.4159 - val_mse: 1.6063 - 230ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 35.8610 - mse: 15649.1582 - val_loss: 0.3332 - val_mse: 1.3019 - 229ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 35.6308 - mse: 14880.5488 - val_loss: 0.5425 - val_mse: 5.0055 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 32.6469 - mse: 11876.6191 - val_loss: 1.3744 - val_mse: 21.8276 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 34.3574 - mse: 15236.4697 - val_loss: 1.6390 - val_mse: 28.1677 - 235ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 32.8050 - mse: 12805.5566 - val_loss: 0.2321 - val_mse: 0.7062 - 236ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 32.3918 - mse: 11506.6162 - val_loss: 0.8221 - val_mse: 11.2184 - 237ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 30.3823 - mse: 9314.3291 - val_loss: 1.6912 - val_mse: 25.7314 - 238ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 30.6380 - mse: 11869.9619 - val_loss: 1.2574 - val_mse: 20.6371 - 242ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 29.8590 - mse: 10373.0889 - val_loss: 1.3544 - val_mse: 22.4732 - 231ms/epoch - 6ms/step\n",
            "36/36 - 0s - loss: 28.9937 - mse: 9955.9121 - val_loss: 1.0741 - val_mse: 13.7181 - 235ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 200 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.2437\n",
            "Function value obtained: 13.7181\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 201 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [36, 64]\n",
            "Learning Rate: 2.105660651799237e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0835234819997385\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 3555.1240 - mse: 87802408.0000 - val_loss: 3161.9163 - val_mse: 50810604.0000 - 3s/epoch - 80ms/step\n",
            "33/33 - 0s - loss: 3503.0215 - mse: 83801744.0000 - val_loss: 3061.5613 - val_mse: 47637040.0000 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3365.6772 - mse: 76843536.0000 - val_loss: 2960.6367 - val_mse: 44547772.0000 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3352.5759 - mse: 84259800.0000 - val_loss: 2863.8062 - val_mse: 41686252.0000 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3259.5195 - mse: 72154552.0000 - val_loss: 2766.1218 - val_mse: 38900148.0000 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3133.5471 - mse: 68380168.0000 - val_loss: 2668.6409 - val_mse: 36214776.0000 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3067.6965 - mse: 66683808.0000 - val_loss: 2570.8494 - val_mse: 33603560.0000 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 3035.8477 - mse: 71734832.0000 - val_loss: 2479.3545 - val_mse: 31255074.0000 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2982.9985 - mse: 63212420.0000 - val_loss: 2386.8391 - val_mse: 28968294.0000 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2989.2844 - mse: 68017480.0000 - val_loss: 2290.1011 - val_mse: 26670314.0000 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2808.3943 - mse: 56164332.0000 - val_loss: 2197.4727 - val_mse: 24559454.0000 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2795.1616 - mse: 57377332.0000 - val_loss: 2107.8149 - val_mse: 22601032.0000 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2815.3064 - mse: 57638064.0000 - val_loss: 2016.3427 - val_mse: 20684696.0000 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2588.1863 - mse: 48651764.0000 - val_loss: 1928.7981 - val_mse: 18928444.0000 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2692.4651 - mse: 56654996.0000 - val_loss: 1840.8101 - val_mse: 17242992.0000 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2612.4553 - mse: 50607424.0000 - val_loss: 1756.3319 - val_mse: 15698499.0000 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2525.7053 - mse: 47695988.0000 - val_loss: 1673.8082 - val_mse: 14259178.0000 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2484.7625 - mse: 46365476.0000 - val_loss: 1590.1624 - val_mse: 12872368.0000 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2436.9368 - mse: 44678612.0000 - val_loss: 1510.9117 - val_mse: 11623199.0000 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2462.2141 - mse: 45935524.0000 - val_loss: 1430.0304 - val_mse: 10413942.0000 - 256ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2359.0105 - mse: 44618856.0000 - val_loss: 1350.9570 - val_mse: 9295813.0000 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2399.5815 - mse: 48718856.0000 - val_loss: 1276.1812 - val_mse: 8296416.0000 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2395.2878 - mse: 45211452.0000 - val_loss: 1205.7998 - val_mse: 7405850.5000 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2249.1672 - mse: 38479080.0000 - val_loss: 1143.3422 - val_mse: 6661848.5000 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2261.8384 - mse: 41331000.0000 - val_loss: 1080.1079 - val_mse: 5947095.5000 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2244.2134 - mse: 38769968.0000 - val_loss: 1024.7051 - val_mse: 5353973.0000 - 254ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2190.1829 - mse: 37566488.0000 - val_loss: 964.4303 - val_mse: 4744028.5000 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2198.5872 - mse: 38562492.0000 - val_loss: 907.6879 - val_mse: 4203352.5000 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2120.9370 - mse: 34088792.0000 - val_loss: 849.0776 - val_mse: 3678500.2500 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2162.8196 - mse: 37380304.0000 - val_loss: 795.6674 - val_mse: 3231149.5000 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2138.6328 - mse: 37006712.0000 - val_loss: 754.0258 - val_mse: 2903361.0000 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2104.2280 - mse: 33148152.0000 - val_loss: 708.3702 - val_mse: 2563539.7500 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 2107.6548 - mse: 35855268.0000 - val_loss: 663.5778 - val_mse: 2250631.7500 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2048.7488 - mse: 32406336.0000 - val_loss: 621.0590 - val_mse: 1972429.3750 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2040.8816 - mse: 35260784.0000 - val_loss: 586.1603 - val_mse: 1757793.8750 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 2002.2579 - mse: 31076696.0000 - val_loss: 547.5026 - val_mse: 1534469.3750 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1969.0217 - mse: 30853116.0000 - val_loss: 515.0223 - val_mse: 1358546.1250 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1986.8815 - mse: 30481870.0000 - val_loss: 480.9535 - val_mse: 1185544.6250 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1983.2540 - mse: 31221124.0000 - val_loss: 456.2119 - val_mse: 1067280.8750 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1857.2917 - mse: 24739376.0000 - val_loss: 421.6760 - val_mse: 912601.5625 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1935.6191 - mse: 31130374.0000 - val_loss: 390.8289 - val_mse: 784661.6875 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1939.9269 - mse: 30720634.0000 - val_loss: 359.7151 - val_mse: 665405.1250 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1938.6649 - mse: 32460192.0000 - val_loss: 339.7026 - val_mse: 593877.2500 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1831.6104 - mse: 25134550.0000 - val_loss: 324.2554 - val_mse: 541439.8125 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1853.4685 - mse: 27558022.0000 - val_loss: 296.7349 - val_mse: 454044.8125 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1900.5756 - mse: 29219584.0000 - val_loss: 272.1474 - val_mse: 382463.6875 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1825.7678 - mse: 24726528.0000 - val_loss: 247.6049 - val_mse: 317123.0000 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1827.6715 - mse: 28366808.0000 - val_loss: 236.9846 - val_mse: 290721.9688 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1897.1464 - mse: 29303424.0000 - val_loss: 224.1364 - val_mse: 260318.5312 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1800.2808 - mse: 26384162.0000 - val_loss: 209.0080 - val_mse: 226666.9062 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1842.2579 - mse: 26738616.0000 - val_loss: 190.4598 - val_mse: 188588.1406 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1767.3973 - mse: 24994904.0000 - val_loss: 180.2233 - val_mse: 169054.0469 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1801.4098 - mse: 26104634.0000 - val_loss: 165.5166 - val_mse: 142854.9375 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1796.2826 - mse: 25496080.0000 - val_loss: 148.8768 - val_mse: 115854.4922 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1800.1083 - mse: 26957072.0000 - val_loss: 140.9065 - val_mse: 103884.7656 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1802.0529 - mse: 29084130.0000 - val_loss: 138.0015 - val_mse: 99637.6484 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1750.3680 - mse: 24219262.0000 - val_loss: 123.7205 - val_mse: 80306.9453 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1778.1736 - mse: 25698944.0000 - val_loss: 120.8933 - val_mse: 76717.1250 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1747.9694 - mse: 25949024.0000 - val_loss: 117.6986 - val_mse: 72757.2891 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1685.5653 - mse: 23720292.0000 - val_loss: 102.8770 - val_mse: 55785.8438 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 1677.1722 - mse: 21573414.0000 - val_loss: 94.6167 - val_mse: 47291.1328 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1664.8033 - mse: 21167992.0000 - val_loss: 87.0661 - val_mse: 40136.7227 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1681.0815 - mse: 23791284.0000 - val_loss: 80.8197 - val_mse: 34657.4297 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1642.2384 - mse: 20021186.0000 - val_loss: 70.7854 - val_mse: 26686.9902 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1686.7556 - mse: 23931020.0000 - val_loss: 59.5540 - val_mse: 18969.1602 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1657.3347 - mse: 25092786.0000 - val_loss: 56.9423 - val_mse: 17353.3789 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1547.4989 - mse: 19089066.0000 - val_loss: 56.2180 - val_mse: 16915.0547 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1606.8484 - mse: 22174622.0000 - val_loss: 55.6305 - val_mse: 16562.5293 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1587.4788 - mse: 20964838.0000 - val_loss: 53.0352 - val_mse: 15062.4814 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1584.1770 - mse: 19887684.0000 - val_loss: 48.5651 - val_mse: 12640.3555 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1600.6934 - mse: 22323272.0000 - val_loss: 49.5415 - val_mse: 13150.2783 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1581.0887 - mse: 21304664.0000 - val_loss: 43.2417 - val_mse: 10021.4043 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1580.8092 - mse: 20759326.0000 - val_loss: 32.4807 - val_mse: 5610.5562 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1608.4839 - mse: 20557750.0000 - val_loss: 28.4538 - val_mse: 4267.3462 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1531.0840 - mse: 19231812.0000 - val_loss: 23.4181 - val_mse: 2825.6636 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1532.9976 - mse: 18711292.0000 - val_loss: 18.8606 - val_mse: 1763.3396 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1565.4657 - mse: 21955590.0000 - val_loss: 18.4907 - val_mse: 1687.6445 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1553.4491 - mse: 20216384.0000 - val_loss: 17.9984 - val_mse: 1588.7802 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1542.9174 - mse: 21167072.0000 - val_loss: 14.1368 - val_mse: 909.0076 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1525.7352 - mse: 20237152.0000 - val_loss: 16.4002 - val_mse: 1286.7457 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1512.2330 - mse: 19460366.0000 - val_loss: 12.1791 - val_mse: 630.0577 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1437.6171 - mse: 16660817.0000 - val_loss: 13.0501 - val_mse: 748.1188 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1511.9578 - mse: 21150110.0000 - val_loss: 19.1515 - val_mse: 1816.7686 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1477.3169 - mse: 17915988.0000 - val_loss: 17.3194 - val_mse: 1450.3505 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1431.1761 - mse: 17683070.0000 - val_loss: 13.5853 - val_mse: 823.0814 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1395.7489 - mse: 15379650.0000 - val_loss: 14.7228 - val_mse: 997.3250 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1414.4520 - mse: 16522950.0000 - val_loss: 12.3133 - val_mse: 646.0220 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1381.3771 - mse: 15630542.0000 - val_loss: 8.4525 - val_mse: 206.9382 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1368.2645 - mse: 14193399.0000 - val_loss: 18.9926 - val_mse: 1708.4268 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1357.0801 - mse: 14926670.0000 - val_loss: 17.0225 - val_mse: 1346.8977 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1421.7505 - mse: 17312050.0000 - val_loss: 13.2953 - val_mse: 762.9948 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1356.9174 - mse: 16717344.0000 - val_loss: 16.0254 - val_mse: 1176.9082 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1381.0461 - mse: 16426486.0000 - val_loss: 21.7982 - val_mse: 2271.2783 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1344.0496 - mse: 15167208.0000 - val_loss: 17.5167 - val_mse: 1422.4073 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1323.7959 - mse: 14508480.0000 - val_loss: 16.2673 - val_mse: 1206.1488 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1294.9291 - mse: 14960626.0000 - val_loss: 14.0767 - val_mse: 864.3858 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1308.7954 - mse: 14523991.0000 - val_loss: 16.0365 - val_mse: 1150.8409 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1268.1938 - mse: 13493128.0000 - val_loss: 18.7979 - val_mse: 1598.1974 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1280.9552 - mse: 14508229.0000 - val_loss: 27.6386 - val_mse: 3501.3364 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 1228.6221 - mse: 12564339.0000 - val_loss: 27.9356 - val_mse: 3519.5066 - 221ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 201 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.6722\n",
            "Function value obtained: 3519.5066\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 202 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [88]\n",
            "Learning Rate: 0.00020382302755427324\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4967163295215611\n",
            "Batch Size: 42\n",
            "----------------------------------------\n",
            "200/200 - 2s - loss: 1536.9550 - mse: 23567700.0000 - val_loss: 41.2591 - val_mse: 8516.5322 - 2s/epoch - 12ms/step\n",
            "200/200 - 1s - loss: 1202.7798 - mse: 15048010.0000 - val_loss: 47.1760 - val_mse: 13255.8545 - 736ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 974.2296 - mse: 9336259.0000 - val_loss: 37.8196 - val_mse: 6474.8398 - 749ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 791.1799 - mse: 6004736.0000 - val_loss: 29.2201 - val_mse: 3580.2727 - 747ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 634.0603 - mse: 4133644.5000 - val_loss: 25.2445 - val_mse: 2565.7598 - 757ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 544.2647 - mse: 3166534.0000 - val_loss: 3.3440 - val_mse: 28.9538 - 737ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 419.5482 - mse: 1742865.3750 - val_loss: 27.6325 - val_mse: 3771.1946 - 745ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 359.6291 - mse: 1486692.7500 - val_loss: 9.2473 - val_mse: 522.7817 - 748ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 280.9959 - mse: 840055.4375 - val_loss: 18.3932 - val_mse: 2075.1489 - 753ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 226.1517 - mse: 491627.5625 - val_loss: 21.7793 - val_mse: 2860.9634 - 775ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 178.9797 - mse: 344559.0625 - val_loss: 1.1606 - val_mse: 7.5607 - 765ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 144.2833 - mse: 237684.6719 - val_loss: 10.1654 - val_mse: 639.2881 - 779ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 109.7431 - mse: 129342.8125 - val_loss: 10.1983 - val_mse: 607.2405 - 760ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 80.3632 - mse: 64040.7188 - val_loss: 4.4391 - val_mse: 117.3009 - 752ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 58.8513 - mse: 47830.8477 - val_loss: 6.8813 - val_mse: 276.1218 - 760ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 36.2753 - mse: 16085.1846 - val_loss: 0.5456 - val_mse: 2.1665 - 783ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 21.8255 - mse: 6631.8774 - val_loss: 1.3052 - val_mse: 14.2072 - 786ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 12.5770 - mse: 8299.1562 - val_loss: 0.6403 - val_mse: 4.0049 - 752ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 6.7315 - mse: 1889.4854 - val_loss: 0.4602 - val_mse: 2.2884 - 757ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 3.9382 - mse: 950.0191 - val_loss: 1.5353 - val_mse: 19.3225 - 756ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 2.9952 - mse: 201.4706 - val_loss: 2.1819 - val_mse: 35.6310 - 745ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.7760 - mse: 109.7570 - val_loss: 0.5362 - val_mse: 2.0515 - 759ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.5515 - mse: 101.7999 - val_loss: 0.4689 - val_mse: 2.4634 - 754ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.4271 - mse: 264.0815 - val_loss: 0.8918 - val_mse: 7.3326 - 764ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.6788 - mse: 228.9598 - val_loss: 1.1603 - val_mse: 8.9139 - 775ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.2122 - mse: 112.5698 - val_loss: 0.1002 - val_mse: 0.2104 - 794ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.3336 - mse: 95.7558 - val_loss: 0.8587 - val_mse: 5.4620 - 782ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.4448 - mse: 239.3745 - val_loss: 1.4649 - val_mse: 17.0117 - 767ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 1.3010 - mse: 722.8737 - val_loss: 0.8867 - val_mse: 7.1786 - 767ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.8371 - mse: 12.0022 - val_loss: 1.0183 - val_mse: 7.7414 - 761ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.7529 - mse: 59.2430 - val_loss: 0.1190 - val_mse: 0.2901 - 772ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.8696 - mse: 84.8519 - val_loss: 0.0307 - val_mse: 0.0615 - 756ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.8386 - mse: 10.6749 - val_loss: 0.2158 - val_mse: 0.6763 - 754ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.7441 - mse: 77.1181 - val_loss: 0.9391 - val_mse: 7.1043 - 753ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.6894 - mse: 18.5166 - val_loss: 0.1704 - val_mse: 0.5044 - 758ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.6874 - mse: 27.7116 - val_loss: 0.5357 - val_mse: 2.8569 - 757ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.6035 - mse: 9.7419 - val_loss: 0.2324 - val_mse: 0.8240 - 789ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.6154 - mse: 6.4131 - val_loss: 0.2524 - val_mse: 0.9254 - 762ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4201 - mse: 3.5658 - val_loss: 0.0809 - val_mse: 0.1910 - 886ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4653 - mse: 16.2286 - val_loss: 0.0550 - val_mse: 0.1202 - 820ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.5239 - mse: 30.2181 - val_loss: 0.0252 - val_mse: 0.0505 - 811ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4010 - mse: 3.8674 - val_loss: 0.1777 - val_mse: 0.5382 - 817ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4100 - mse: 19.6608 - val_loss: 0.1899 - val_mse: 0.6358 - 783ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4366 - mse: 6.5225 - val_loss: 0.1151 - val_mse: 0.2977 - 771ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.4038 - mse: 6.8946 - val_loss: 0.0709 - val_mse: 0.1782 - 775ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.2818 - mse: 2.4243 - val_loss: 0.0049 - val_mse: 0.0098 - 784ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.3170 - mse: 2.2701 - val_loss: 0.0235 - val_mse: 0.0491 - 790ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.2903 - mse: 11.7427 - val_loss: 0.1286 - val_mse: 0.3851 - 780ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.2956 - mse: 5.3668 - val_loss: 0.1418 - val_mse: 0.4414 - 798ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1897 - mse: 1.3150 - val_loss: 0.0046 - val_mse: 0.0091 - 781ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1604 - mse: 1.2751 - val_loss: 0.0090 - val_mse: 0.0181 - 777ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1264 - mse: 0.7999 - val_loss: 0.0848 - val_mse: 0.2276 - 770ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1913 - mse: 5.4396 - val_loss: 0.0057 - val_mse: 0.0115 - 772ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1288 - mse: 4.4199 - val_loss: 0.0153 - val_mse: 0.0310 - 778ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1277 - mse: 7.6815 - val_loss: 0.0359 - val_mse: 0.0729 - 800ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.1019 - mse: 0.3964 - val_loss: 0.0423 - val_mse: 0.0979 - 782ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0855 - mse: 0.4402 - val_loss: 0.0334 - val_mse: 0.0676 - 784ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0572 - mse: 0.1713 - val_loss: 0.0059 - val_mse: 0.0118 - 754ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0943 - mse: 1.3669 - val_loss: 0.0058 - val_mse: 0.0115 - 766ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0724 - mse: 0.8371 - val_loss: 0.0051 - val_mse: 0.0102 - 765ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0267 - mse: 0.0649 - val_loss: 0.0108 - val_mse: 0.0217 - 781ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0344 - mse: 0.3395 - val_loss: 0.0107 - val_mse: 0.0215 - 775ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0341 - mse: 0.0972 - val_loss: 0.0048 - val_mse: 0.0097 - 769ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0208 - mse: 0.4438 - val_loss: 0.0050 - val_mse: 0.0100 - 802ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0286 - mse: 2.3095 - val_loss: 0.0087 - val_mse: 0.0175 - 793ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0098 - mse: 0.0204 - val_loss: 0.0042 - val_mse: 0.0084 - 796ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0130 - mse: 0.0535 - val_loss: 0.0047 - val_mse: 0.0094 - 799ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0407 - mse: 6.6814 - val_loss: 0.0091 - val_mse: 0.0182 - 791ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0071 - mse: 0.0143 - val_loss: 0.0044 - val_mse: 0.0087 - 812ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0095 - mse: 0.0516 - val_loss: 0.0045 - val_mse: 0.0091 - 809ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0281 - mse: 3.6132 - val_loss: 0.0042 - val_mse: 0.0084 - 820ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0062 - mse: 0.0126 - val_loss: 0.0046 - val_mse: 0.0092 - 828ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0042 - val_mse: 0.0085 - 797ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0062 - mse: 0.0125 - val_loss: 0.0059 - val_mse: 0.0117 - 786ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0046 - val_mse: 0.0093 - 784ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0137 - mse: 0.4058 - val_loss: 0.0048 - val_mse: 0.0097 - 778ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0043 - val_mse: 0.0085 - 777ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0066 - mse: 0.0231 - val_loss: 0.0043 - val_mse: 0.0086 - 798ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0052 - mse: 0.0105 - val_loss: 0.0043 - val_mse: 0.0086 - 787ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0053 - val_mse: 0.0106 - 778ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0053 - mse: 0.0105 - val_loss: 0.0045 - val_mse: 0.0091 - 759ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0052 - val_mse: 0.0103 - 756ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0054 - mse: 0.0107 - val_loss: 0.0043 - val_mse: 0.0086 - 757ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0050 - val_mse: 0.0100 - 794ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0043 - val_mse: 0.0086 - 803ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0042 - val_mse: 0.0085 - 791ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0059 - mse: 0.0124 - val_loss: 0.0043 - val_mse: 0.0086 - 759ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0058 - mse: 0.0119 - val_loss: 0.0044 - val_mse: 0.0088 - 746ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0043 - val_mse: 0.0085 - 745ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0065 - mse: 0.0197 - val_loss: 0.0044 - val_mse: 0.0089 - 758ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0052 - val_mse: 0.0104 - 745ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0048 - val_mse: 0.0095 - 746ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0060 - mse: 0.0120 - val_loss: 0.0048 - val_mse: 0.0096 - 760ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0044 - val_mse: 0.0088 - 741ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086 - 742ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0052 - val_mse: 0.0103 - 758ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0045 - val_mse: 0.0090 - 748ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0060 - mse: 0.0119 - val_loss: 0.0051 - val_mse: 0.0103 - 746ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0045 - val_mse: 0.0090 - 792ms/epoch - 4ms/step\n",
            "200/200 - 1s - loss: 0.0151 - mse: 0.7368 - val_loss: 0.0049 - val_mse: 0.0098 - 784ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 202 ended. Search finished for the next optimal point.\n",
            "Time taken: 93.8809\n",
            "Function value obtained: 0.0098\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 203 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 26285.4277 - mse: 50664886272.0000 - val_loss: 0.0085 - val_mse: 0.0171 - 3s/epoch - 87ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0085 - val_mse: 0.0170 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0088 - val_mse: 0.0176 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0171 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0173 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 208ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 209ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0090 - val_mse: 0.0180 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0088 - val_mse: 0.0177 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0175 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0175 - 208ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0087 - val_mse: 0.0175 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 208ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0103 - val_mse: 0.0206 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0171 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0171 - 210ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0177 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0085 - val_mse: 0.0170 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0175 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0089 - val_mse: 0.0177 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0088 - val_mse: 0.0176 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 221ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.011102]\n",
            "\n",
            "Iteration No: 203 ended. Search finished for the next optimal point.\n",
            "Time taken: 39.1691\n",
            "Function value obtained: 0.0169\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 204 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [61, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 108\n",
            "----------------------------------------\n",
            "78/78 - 3s - loss: 7683.1807 - mse: 8775974912.0000 - val_loss: 0.0113 - val_mse: 0.0226 - 3s/epoch - 34ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0086 - val_mse: 0.0172 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0176 - 408ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 400ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 407ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 403ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0093 - val_mse: 0.0185 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0087 - val_mse: 0.0175 - 376ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0086 - val_mse: 0.0171 - 384ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0089 - val_mse: 0.0177 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0089 - val_mse: 0.0178 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 377ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0169 - 389ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 386ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 391ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 390ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0101 - val_mse: 0.0201 - 388ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0098 - mse: 0.0197 - val_loss: 0.0086 - val_mse: 0.0172 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0088 - val_mse: 0.0176 - 385ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0104 - mse: 0.0208 - val_loss: 0.0087 - val_mse: 0.0173 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0091 - val_mse: 0.0183 - 374ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0097 - mse: 0.0194 - val_loss: 0.0102 - val_mse: 0.0205 - 375ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0087 - val_mse: 0.0174 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0095 - mse: 0.0191 - val_loss: 0.0085 - val_mse: 0.0171 - 386ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 377ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0113 - mse: 0.0226 - val_loss: 0.0084 - val_mse: 0.0168 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0138 - val_mse: 0.0277 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0203 - val_loss: 0.0085 - val_mse: 0.0170 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0114 - val_mse: 0.0227 - 390ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0098 - mse: 0.0195 - val_loss: 0.0087 - val_mse: 0.0173 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0103 - mse: 0.0206 - val_loss: 0.0099 - val_mse: 0.0198 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0094 - val_mse: 0.0188 - 373ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0099 - mse: 0.0198 - val_loss: 0.0084 - val_mse: 0.0168 - 376ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 379ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0204 - val_loss: 0.0105 - val_mse: 0.0210 - 386ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 374ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0103 - mse: 0.0206 - val_loss: 0.0088 - val_mse: 0.0177 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0086 - val_mse: 0.0172 - 377ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0106 - mse: 0.0212 - val_loss: 0.0085 - val_mse: 0.0170 - 378ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0100 - val_mse: 0.0201 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0097 - mse: 0.0193 - val_loss: 0.0084 - val_mse: 0.0167 - 372ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0107 - mse: 0.0213 - val_loss: 0.0133 - val_mse: 0.0267 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0095 - mse: 0.0190 - val_loss: 0.0112 - val_mse: 0.0225 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0193 - val_loss: 0.0084 - val_mse: 0.0169 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0095 - val_mse: 0.0191 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0099 - mse: 0.0198 - val_loss: 0.0084 - val_mse: 0.0167 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0097 - mse: 0.0193 - val_loss: 0.0086 - val_mse: 0.0171 - 378ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0107 - mse: 0.0215 - val_loss: 0.0084 - val_mse: 0.0169 - 384ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0090 - val_mse: 0.0180 - 378ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0203 - val_loss: 0.0141 - val_mse: 0.0281 - 373ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0113 - mse: 0.0225 - val_loss: 0.0088 - val_mse: 0.0176 - 375ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0087 - val_mse: 0.0173 - 376ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0100 - mse: 0.0201 - val_loss: 0.0120 - val_mse: 0.0240 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0167 - 386ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0099 - mse: 0.0198 - val_loss: 0.0099 - val_mse: 0.0199 - 392ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0102 - val_mse: 0.0203 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0112 - mse: 0.0225 - val_loss: 0.0094 - val_mse: 0.0187 - 393ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0090 - val_mse: 0.0179 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0098 - mse: 0.0196 - val_loss: 0.0099 - val_mse: 0.0199 - 382ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0097 - mse: 0.0193 - val_loss: 0.0093 - val_mse: 0.0186 - 377ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0098 - mse: 0.0196 - val_loss: 0.0102 - val_mse: 0.0203 - 373ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0100 - mse: 0.0199 - val_loss: 0.0096 - val_mse: 0.0191 - 369ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0086 - val_mse: 0.0172 - 368ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0204 - val_loss: 0.0112 - val_mse: 0.0223 - 376ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0100 - mse: 0.0199 - val_loss: 0.0084 - val_mse: 0.0167 - 379ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0099 - mse: 0.0198 - val_loss: 0.0089 - val_mse: 0.0178 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0099 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167 - 391ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0168 - 378ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0168 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0089 - val_mse: 0.0178 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0095 - val_mse: 0.0190 - 372ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0098 - mse: 0.0195 - val_loss: 0.0086 - val_mse: 0.0171 - 366ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0089 - val_mse: 0.0178 - 375ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0087 - val_mse: 0.0175 - 368ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0095 - mse: 0.0190 - val_loss: 0.0085 - val_mse: 0.0170 - 386ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0193 - val_loss: 0.0086 - val_mse: 0.0171 - 374ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0169 - 384ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0168 - 388ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0111 - mse: 0.0222 - val_loss: 0.0088 - val_mse: 0.0176 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0168 - val_mse: 0.0335 - 405ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0104 - mse: 0.0208 - val_loss: 0.0084 - val_mse: 0.0169 - 397ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0106 - mse: 0.0212 - val_loss: 0.0107 - val_mse: 0.0214 - 399ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0101 - mse: 0.0202 - val_loss: 0.0091 - val_mse: 0.0181 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0101 - mse: 0.0202 - val_loss: 0.0109 - val_mse: 0.0219 - 404ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0103 - mse: 0.0206 - val_loss: 0.0086 - val_mse: 0.0173 - 401ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0204 - val_loss: 0.0118 - val_mse: 0.0237 - 380ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0140 - val_mse: 0.0279 - 384ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0107 - mse: 0.0215 - val_loss: 0.0107 - val_mse: 0.0214 - 396ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0089 - val_mse: 0.0178 - 387ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0096 - mse: 0.0191 - val_loss: 0.0086 - val_mse: 0.0172 - 381ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0097 - mse: 0.0195 - val_loss: 0.0110 - val_mse: 0.0221 - 374ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0102 - mse: 0.0203 - val_loss: 0.0098 - val_mse: 0.0195 - 365ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0090 - val_mse: 0.0179 - 383ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0168 - 372ms/epoch - 5ms/step\n",
            "78/78 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0109 - val_mse: 0.0218 - 386ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.01236459]\n",
            "\n",
            "Iteration No: 204 ended. Search finished for the next optimal point.\n",
            "Time taken: 55.6627\n",
            "Function value obtained: 0.0218\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 205 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [86, 110]\n",
            "Learning Rate: 0.022767518189592814\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.12745781643447995\n",
            "Batch Size: 252\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 2743.1970 - mse: 418856544.0000 - val_loss: 0.4566 - val_mse: 1.9632 - 3s/epoch - 96ms/step\n",
            "34/34 - 0s - loss: 1.6194 - mse: 77.4185 - val_loss: 0.0421 - val_mse: 0.0842 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.4303 - mse: 9.1468 - val_loss: 0.0086 - val_mse: 0.0171 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.3154 - mse: 4.8832 - val_loss: 0.0090 - val_mse: 0.0180 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.2151 - mse: 4.7928 - val_loss: 0.0077 - val_mse: 0.0154 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.1620 - mse: 3.0154 - val_loss: 0.0081 - val_mse: 0.0161 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.1413 - mse: 6.9656 - val_loss: 0.0074 - val_mse: 0.0148 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0853 - mse: 1.0450 - val_loss: 0.0065 - val_mse: 0.0130 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0679 - mse: 1.3218 - val_loss: 0.0071 - val_mse: 0.0141 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0461 - mse: 0.3774 - val_loss: 0.0068 - val_mse: 0.0136 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0316 - mse: 0.1304 - val_loss: 0.0061 - val_mse: 0.0122 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0431 - mse: 0.8415 - val_loss: 0.0060 - val_mse: 0.0119 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0343 - mse: 0.2170 - val_loss: 0.0063 - val_mse: 0.0127 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0277 - mse: 0.1988 - val_loss: 0.0054 - val_mse: 0.0108 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0248 - mse: 0.1346 - val_loss: 0.0053 - val_mse: 0.0106 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0238 - mse: 0.2506 - val_loss: 0.0057 - val_mse: 0.0114 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0170 - mse: 0.0655 - val_loss: 0.0058 - val_mse: 0.0117 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0217 - mse: 0.2271 - val_loss: 0.0053 - val_mse: 0.0105 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0135 - mse: 0.0429 - val_loss: 0.0055 - val_mse: 0.0110 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0133 - mse: 0.0669 - val_loss: 0.0056 - val_mse: 0.0113 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0141 - mse: 0.0482 - val_loss: 0.0052 - val_mse: 0.0104 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0137 - mse: 0.0873 - val_loss: 0.0054 - val_mse: 0.0108 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0227 - mse: 0.3168 - val_loss: 0.0051 - val_mse: 0.0101 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0213 - mse: 0.6077 - val_loss: 0.0063 - val_mse: 0.0125 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0151 - mse: 0.1168 - val_loss: 0.0050 - val_mse: 0.0101 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0110 - mse: 0.0328 - val_loss: 0.0057 - val_mse: 0.0113 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0148 - mse: 0.1161 - val_loss: 0.0055 - val_mse: 0.0110 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0098 - mse: 0.0522 - val_loss: 0.0058 - val_mse: 0.0116 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0097 - mse: 0.0392 - val_loss: 0.0059 - val_mse: 0.0119 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0109 - mse: 0.0391 - val_loss: 0.0058 - val_mse: 0.0116 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0102 - mse: 0.0293 - val_loss: 0.0050 - val_mse: 0.0101 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0092 - mse: 0.0262 - val_loss: 0.0056 - val_mse: 0.0111 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0108 - mse: 0.0531 - val_loss: 0.0047 - val_mse: 0.0095 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0097 - mse: 0.0596 - val_loss: 0.0059 - val_mse: 0.0117 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0147 - val_loss: 0.0053 - val_mse: 0.0105 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0095 - mse: 0.0681 - val_loss: 0.0048 - val_mse: 0.0097 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0095 - mse: 0.0300 - val_loss: 0.0071 - val_mse: 0.0141 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0131 - mse: 0.0715 - val_loss: 0.0059 - val_mse: 0.0117 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0106 - mse: 0.0373 - val_loss: 0.0049 - val_mse: 0.0099 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0107 - mse: 0.0458 - val_loss: 0.0058 - val_mse: 0.0116 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0099 - mse: 0.0493 - val_loss: 0.0053 - val_mse: 0.0107 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0096 - mse: 0.0368 - val_loss: 0.0047 - val_mse: 0.0093 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0092 - mse: 0.0390 - val_loss: 0.0048 - val_mse: 0.0096 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0104 - mse: 0.0338 - val_loss: 0.0066 - val_mse: 0.0132 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0080 - mse: 0.0180 - val_loss: 0.0059 - val_mse: 0.0118 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0125 - mse: 0.1905 - val_loss: 0.0045 - val_mse: 0.0090 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0105 - mse: 0.0328 - val_loss: 0.0049 - val_mse: 0.0099 - 218ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0077 - mse: 0.0179 - val_loss: 0.0050 - val_mse: 0.0100 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0102 - mse: 0.0659 - val_loss: 0.0051 - val_mse: 0.0101 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0071 - mse: 0.0159 - val_loss: 0.0053 - val_mse: 0.0107 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0085 - mse: 0.0324 - val_loss: 0.0053 - val_mse: 0.0107 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0080 - mse: 0.0185 - val_loss: 0.0062 - val_mse: 0.0125 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0076 - mse: 0.0162 - val_loss: 0.0046 - val_mse: 0.0092 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0084 - mse: 0.0245 - val_loss: 0.0048 - val_mse: 0.0095 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0085 - mse: 0.0256 - val_loss: 0.0070 - val_mse: 0.0140 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0101 - mse: 0.0912 - val_loss: 0.0052 - val_mse: 0.0104 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0072 - mse: 0.0149 - val_loss: 0.0058 - val_mse: 0.0117 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0047 - val_mse: 0.0094 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0083 - mse: 0.0193 - val_loss: 0.0050 - val_mse: 0.0099 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0143 - val_loss: 0.0054 - val_mse: 0.0108 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0051 - val_mse: 0.0102 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0082 - mse: 0.0242 - val_loss: 0.0045 - val_mse: 0.0089 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0064 - mse: 0.0133 - val_loss: 0.0048 - val_mse: 0.0095 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0064 - mse: 0.0127 - val_loss: 0.0049 - val_mse: 0.0097 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0139 - val_loss: 0.0047 - val_mse: 0.0094 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0077 - mse: 0.0211 - val_loss: 0.0057 - val_mse: 0.0115 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0085 - mse: 0.0236 - val_loss: 0.0046 - val_mse: 0.0092 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0059 - val_mse: 0.0118 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0063 - mse: 0.0126 - val_loss: 0.0051 - val_mse: 0.0102 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0064 - mse: 0.0131 - val_loss: 0.0045 - val_mse: 0.0089 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0050 - val_mse: 0.0100 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0092 - mse: 0.0528 - val_loss: 0.0044 - val_mse: 0.0087 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0046 - val_mse: 0.0091 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0049 - val_mse: 0.0099 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0153 - val_loss: 0.0047 - val_mse: 0.0094 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0047 - val_mse: 0.0094 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0087 - mse: 0.0308 - val_loss: 0.0047 - val_mse: 0.0094 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0084 - mse: 0.0469 - val_loss: 0.0055 - val_mse: 0.0109 - 268ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0045 - val_mse: 0.0090 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0077 - mse: 0.0187 - val_loss: 0.0044 - val_mse: 0.0088 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0076 - mse: 0.0153 - val_loss: 0.0073 - val_mse: 0.0145 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0045 - val_mse: 0.0090 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0074 - mse: 0.0166 - val_loss: 0.0063 - val_mse: 0.0126 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0138 - val_loss: 0.0054 - val_mse: 0.0107 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0123 - val_loss: 0.0050 - val_mse: 0.0100 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0073 - mse: 0.0145 - val_loss: 0.0046 - val_mse: 0.0092 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0068 - mse: 0.0138 - val_loss: 0.0052 - val_mse: 0.0104 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0076 - mse: 0.0206 - val_loss: 0.0045 - val_mse: 0.0091 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0069 - mse: 0.0161 - val_loss: 0.0055 - val_mse: 0.0111 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0070 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0144 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0078 - mse: 0.0197 - val_loss: 0.0047 - val_mse: 0.0095 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0064 - mse: 0.0128 - val_loss: 0.0053 - val_mse: 0.0105 - 217ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0045 - val_mse: 0.0090 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0075 - mse: 0.0154 - val_loss: 0.0046 - val_mse: 0.0091 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0059 - val_mse: 0.0118 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0080 - mse: 0.0180 - val_loss: 0.0049 - val_mse: 0.0097 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0083 - mse: 0.0241 - val_loss: 0.0076 - val_mse: 0.0152 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0074 - mse: 0.0148 - val_loss: 0.0064 - val_mse: 0.0127 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0067 - mse: 0.0137 - val_loss: 0.0049 - val_mse: 0.0098 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 0.0066 - mse: 0.0133 - val_loss: 0.0053 - val_mse: 0.0105 - 232ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.03637804]\n",
            "\n",
            "Iteration No: 205 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.8880\n",
            "Function value obtained: 0.0105\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 206 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [95, 127]\n",
            "Learning Rate: 0.0371128854473941\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4293359834009208\n",
            "Batch Size: 61\n",
            "----------------------------------------\n",
            "138/138 - 3s - loss: 896.3918 - mse: 232410688.0000 - val_loss: 0.0086 - val_mse: 0.0173 - 3s/epoch - 22ms/step\n",
            "138/138 - 1s - loss: 0.1517 - mse: 8.5858 - val_loss: 0.0085 - val_mse: 0.0169 - 637ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0114 - mse: 0.0311 - val_loss: 0.0084 - val_mse: 0.0169 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 628ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 635ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 666ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 663ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 677ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 675ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 635ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 632ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 631ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 627ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0173 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 657ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 651ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 645ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 643ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 639ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0088 - val_mse: 0.0175 - 651ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 647ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0173 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 667ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0091 - val_mse: 0.0181 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 658ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 649ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 655ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 643ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 644ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 664ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0169 - 664ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 663ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 645ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 649ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 644ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 628ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 658ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 654ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 639ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0093 - val_mse: 0.0185 - 649ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 655ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 660ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 669ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 688ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 704ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 690ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 1s/epoch - 9ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 679ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 682ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 675ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 687ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 662ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 674ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 677ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0172 - 666ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 681ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 689ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 670ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 684ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 685ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178 - 688ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 685ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 639ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 643ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 653ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 648ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 663ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 659ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 643ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 648ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 648ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 654ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 676ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 687ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 655ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 645ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 654ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.01084179]\n",
            "\n",
            "Iteration No: 206 ended. Search finished for the next optimal point.\n",
            "Time taken: 84.8532\n",
            "Function value obtained: 0.0173\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 207 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [94, 48]\n",
            "Learning Rate: 0.0046193229558895\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.36645442076976836\n",
            "Batch Size: 190\n",
            "----------------------------------------\n",
            "45/45 - 3s - loss: 357.5364 - mse: 3151074.0000 - val_loss: 0.4742 - val_mse: 1.0830 - 3s/epoch - 60ms/step\n",
            "45/45 - 0s - loss: 7.1112 - mse: 1383.9451 - val_loss: 0.1268 - val_mse: 0.2535 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 2.5886 - mse: 641.1860 - val_loss: 0.0474 - val_mse: 0.0948 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 1.5197 - mse: 224.7982 - val_loss: 0.0179 - val_mse: 0.0357 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.9487 - mse: 123.2294 - val_loss: 0.0091 - val_mse: 0.0181 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.7030 - mse: 175.4262 - val_loss: 0.0064 - val_mse: 0.0128 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.4755 - mse: 53.1371 - val_loss: 0.0090 - val_mse: 0.0179 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.4593 - mse: 91.1151 - val_loss: 0.0088 - val_mse: 0.0176 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.4227 - mse: 54.7148 - val_loss: 0.0085 - val_mse: 0.0169 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.3192 - mse: 25.4127 - val_loss: 0.0085 - val_mse: 0.0170 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.4408 - mse: 100.1373 - val_loss: 0.0085 - val_mse: 0.0170 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1951 - mse: 9.9253 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.2569 - mse: 47.2561 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1993 - mse: 54.0704 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.2397 - mse: 32.3151 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1335 - mse: 7.8497 - val_loss: 0.0087 - val_mse: 0.0174 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1138 - mse: 7.8444 - val_loss: 0.0084 - val_mse: 0.0169 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1389 - mse: 19.1618 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1222 - mse: 11.1566 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0958 - mse: 15.7505 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0457 - mse: 1.5293 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0845 - mse: 6.1556 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0772 - mse: 3.4099 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0387 - mse: 1.3499 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0274 - mse: 0.5042 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0252 - mse: 0.2538 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0463 - mse: 1.6603 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0698 - mse: 5.3873 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1032 - mse: 13.1738 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0398 - mse: 1.1648 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0886 - mse: 11.5622 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0305 - mse: 0.6620 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0487 - mse: 6.3251 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0556 - mse: 10.6661 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0961 - mse: 46.5054 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0321 - mse: 0.9815 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0229 - mse: 0.4057 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0144 - mse: 0.0592 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0162 - mse: 0.1154 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0252 - mse: 0.4530 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0227 - mse: 0.5802 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0420 - mse: 4.8118 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0127 - mse: 0.0534 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0188 - mse: 0.4011 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0171 - mse: 0.1422 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0450 - mse: 10.2030 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0328 - mse: 4.3415 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0181 - mse: 0.1321 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0371 - mse: 4.7114 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0211 - mse: 0.4995 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0343 - mse: 1.5274 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0183 - mse: 0.2011 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0096 - mse: 0.0215 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0179 - mse: 0.3152 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0128 - mse: 0.0554 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0095 - mse: 0.0224 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0140 - mse: 0.1768 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0130 - mse: 0.0426 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0146 - mse: 0.1483 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0132 - mse: 0.1098 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0148 - mse: 0.0515 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0225 - mse: 0.3423 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.2819 - mse: 613.2823 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0327 - mse: 2.1748 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0395 - mse: 2.7316 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0256 - mse: 1.0169 - val_loss: 0.0084 - val_mse: 0.0167 - 298ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0119 - mse: 0.0632 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0091 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0514 - mse: 14.2026 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0100 - mse: 0.0241 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0121 - mse: 0.1058 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0108 - mse: 0.0405 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0962 - mse: 45.4399 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0090 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0097 - mse: 0.0218 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0099 - mse: 0.0269 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0110 - mse: 0.0463 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0156 - mse: 0.1937 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0091 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0111 - mse: 0.0418 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0135 - mse: 0.1859 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0112 - mse: 0.0394 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0110 - mse: 0.0295 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0098 - mse: 0.0233 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0093 - mse: 0.0200 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0092 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0110 - mse: 0.0508 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0099 - mse: 0.0272 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0151 - mse: 0.3545 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0091 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0092 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0114 - mse: 0.0406 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0110 - mse: 0.0372 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0105 - mse: 0.0306 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0092 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.00895438]\n",
            "\n",
            "Iteration No: 207 ended. Search finished for the next optimal point.\n",
            "Time taken: 46.7144\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 208 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [69, 128]\n",
            "Learning Rate: 0.00015924766729917488\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.05964999912282128\n",
            "Batch Size: 79\n",
            "----------------------------------------\n",
            "107/107 - 3s - loss: 108.7086 - mse: 126893.3828 - val_loss: 1.6885 - val_mse: 19.9885 - 3s/epoch - 28ms/step\n",
            "107/107 - 1s - loss: 65.0945 - mse: 46638.2031 - val_loss: 5.0558 - val_mse: 140.3226 - 502ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 57.9790 - mse: 39092.6289 - val_loss: 1.4473 - val_mse: 20.7089 - 531ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 50.5309 - mse: 29390.9570 - val_loss: 3.1992 - val_mse: 50.7448 - 536ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 42.4557 - mse: 19680.8809 - val_loss: 2.9706 - val_mse: 47.2393 - 533ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 37.3815 - mse: 17427.0957 - val_loss: 1.2017 - val_mse: 8.8650 - 522ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 32.3127 - mse: 11418.0078 - val_loss: 0.1847 - val_mse: 0.3802 - 512ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 29.9492 - mse: 10308.3691 - val_loss: 1.9586 - val_mse: 17.3747 - 515ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 26.0180 - mse: 8960.1133 - val_loss: 0.2597 - val_mse: 0.9194 - 501ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 23.0113 - mse: 6350.5098 - val_loss: 0.6096 - val_mse: 2.4657 - 505ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 20.6489 - mse: 5232.4990 - val_loss: 0.0880 - val_mse: 0.1905 - 506ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 18.9232 - mse: 4452.8320 - val_loss: 0.5227 - val_mse: 2.5810 - 509ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 17.5732 - mse: 3790.1716 - val_loss: 0.5189 - val_mse: 2.3259 - 516ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 14.5361 - mse: 2395.7046 - val_loss: 1.5004 - val_mse: 13.5318 - 503ms/epoch - 5ms/step\n",
            "107/107 - 0s - loss: 13.5200 - mse: 2365.1353 - val_loss: 0.3898 - val_mse: 1.9684 - 499ms/epoch - 5ms/step\n",
            "107/107 - 0s - loss: 12.5392 - mse: 1799.2612 - val_loss: 0.8049 - val_mse: 4.9415 - 499ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 11.3725 - mse: 1570.7179 - val_loss: 0.6193 - val_mse: 3.2683 - 504ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 10.9167 - mse: 1589.9042 - val_loss: 0.1196 - val_mse: 0.2540 - 508ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 9.5690 - mse: 1141.3906 - val_loss: 0.0824 - val_mse: 0.1931 - 502ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 8.8146 - mse: 983.5304 - val_loss: 0.1642 - val_mse: 0.4578 - 511ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 8.0816 - mse: 746.7538 - val_loss: 0.0413 - val_mse: 0.0842 - 510ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 7.5887 - mse: 686.5950 - val_loss: 0.7793 - val_mse: 6.6741 - 527ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 6.8651 - mse: 639.8416 - val_loss: 0.0444 - val_mse: 0.0890 - 513ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 6.7359 - mse: 544.9601 - val_loss: 0.3002 - val_mse: 1.0415 - 539ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 5.9573 - mse: 466.7200 - val_loss: 0.0900 - val_mse: 0.2246 - 550ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 5.4613 - mse: 479.5661 - val_loss: 0.0152 - val_mse: 0.0303 - 539ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 5.0817 - mse: 318.3514 - val_loss: 0.7803 - val_mse: 5.6853 - 531ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 4.7542 - mse: 282.7445 - val_loss: 0.1025 - val_mse: 0.3538 - 534ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 4.4886 - mse: 298.6041 - val_loss: 0.2580 - val_mse: 1.0114 - 508ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 4.0784 - mse: 216.9669 - val_loss: 0.6692 - val_mse: 4.6752 - 511ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 3.9872 - mse: 214.7391 - val_loss: 0.0200 - val_mse: 0.0401 - 504ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 3.8652 - mse: 230.7134 - val_loss: 0.3496 - val_mse: 1.7474 - 527ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 3.4994 - mse: 174.7557 - val_loss: 0.0257 - val_mse: 0.0514 - 538ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.9562 - mse: 133.3390 - val_loss: 0.0412 - val_mse: 0.0908 - 536ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.8410 - mse: 121.0343 - val_loss: 0.0383 - val_mse: 0.0776 - 537ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.7393 - mse: 127.7311 - val_loss: 0.0624 - val_mse: 0.1466 - 543ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.3063 - mse: 86.9537 - val_loss: 0.8136 - val_mse: 6.0087 - 556ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.3287 - mse: 85.3354 - val_loss: 0.0356 - val_mse: 0.0714 - 551ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.2769 - mse: 94.1390 - val_loss: 0.1770 - val_mse: 0.6342 - 563ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 2.1613 - mse: 74.7056 - val_loss: 0.1888 - val_mse: 0.5727 - 560ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.9125 - mse: 73.2674 - val_loss: 0.0286 - val_mse: 0.0575 - 564ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.7179 - mse: 51.5611 - val_loss: 0.0549 - val_mse: 0.1122 - 556ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.5864 - mse: 44.9388 - val_loss: 0.0246 - val_mse: 0.0492 - 574ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.4740 - mse: 38.5747 - val_loss: 0.0111 - val_mse: 0.0223 - 579ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.3485 - mse: 48.3195 - val_loss: 0.0240 - val_mse: 0.0481 - 591ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 1.3444 - mse: 37.6107 - val_loss: 0.1451 - val_mse: 0.4154 - 595ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 1.1404 - mse: 31.2218 - val_loss: 0.0282 - val_mse: 0.0563 - 566ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.1204 - mse: 30.3191 - val_loss: 0.0562 - val_mse: 0.1248 - 540ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 1.0234 - mse: 36.4301 - val_loss: 0.0300 - val_mse: 0.0600 - 521ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.9122 - mse: 23.2984 - val_loss: 0.0530 - val_mse: 0.1060 - 540ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.8614 - mse: 34.2182 - val_loss: 0.0218 - val_mse: 0.0436 - 532ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.6820 - mse: 12.6935 - val_loss: 0.0119 - val_mse: 0.0237 - 516ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.6219 - mse: 12.7353 - val_loss: 0.0202 - val_mse: 0.0403 - 530ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.5220 - mse: 11.1159 - val_loss: 0.0232 - val_mse: 0.0464 - 526ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.5497 - mse: 11.3099 - val_loss: 0.0241 - val_mse: 0.0481 - 540ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.3854 - mse: 5.1981 - val_loss: 0.0247 - val_mse: 0.0494 - 545ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.4133 - mse: 8.3998 - val_loss: 0.0250 - val_mse: 0.0499 - 531ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.3132 - mse: 5.6197 - val_loss: 0.0159 - val_mse: 0.0318 - 542ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.2534 - mse: 3.6254 - val_loss: 0.0177 - val_mse: 0.0354 - 538ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.2746 - mse: 5.4434 - val_loss: 0.0152 - val_mse: 0.0303 - 520ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.2092 - mse: 3.5218 - val_loss: 0.0126 - val_mse: 0.0252 - 511ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.2117 - mse: 4.4424 - val_loss: 0.0113 - val_mse: 0.0225 - 519ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.1559 - mse: 2.4419 - val_loss: 0.0111 - val_mse: 0.0223 - 526ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.1322 - mse: 1.3579 - val_loss: 0.0106 - val_mse: 0.0212 - 563ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.1074 - mse: 0.9673 - val_loss: 0.0101 - val_mse: 0.0201 - 552ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.1136 - mse: 2.5889 - val_loss: 0.0092 - val_mse: 0.0184 - 550ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0868 - mse: 0.8370 - val_loss: 0.0086 - val_mse: 0.0172 - 559ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0861 - mse: 0.9538 - val_loss: 0.0076 - val_mse: 0.0152 - 529ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0808 - mse: 1.1396 - val_loss: 0.0081 - val_mse: 0.0161 - 529ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0715 - mse: 1.0293 - val_loss: 0.0071 - val_mse: 0.0142 - 530ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0477 - mse: 0.4986 - val_loss: 0.0067 - val_mse: 0.0134 - 521ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0646 - mse: 1.5500 - val_loss: 0.0064 - val_mse: 0.0127 - 528ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0708 - mse: 1.1149 - val_loss: 0.0072 - val_mse: 0.0143 - 505ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0398 - mse: 0.2929 - val_loss: 0.0063 - val_mse: 0.0126 - 514ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0312 - mse: 0.2223 - val_loss: 0.0068 - val_mse: 0.0137 - 501ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0342 - mse: 0.4051 - val_loss: 0.0087 - val_mse: 0.0174 - 515ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0267 - mse: 0.1510 - val_loss: 0.0058 - val_mse: 0.0117 - 516ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0321 - mse: 0.4432 - val_loss: 0.0059 - val_mse: 0.0118 - 505ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0392 - mse: 0.6266 - val_loss: 0.0063 - val_mse: 0.0127 - 526ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0317 - mse: 0.3009 - val_loss: 0.0069 - val_mse: 0.0138 - 531ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0381 - mse: 0.6332 - val_loss: 0.0057 - val_mse: 0.0114 - 527ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0348 - mse: 0.4153 - val_loss: 0.0064 - val_mse: 0.0129 - 511ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0164 - mse: 0.0844 - val_loss: 0.0063 - val_mse: 0.0127 - 507ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0194 - mse: 0.1936 - val_loss: 0.0060 - val_mse: 0.0120 - 518ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0241 - mse: 0.2533 - val_loss: 0.0068 - val_mse: 0.0137 - 522ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0218 - mse: 0.2001 - val_loss: 0.0047 - val_mse: 0.0095 - 518ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0204 - mse: 0.4824 - val_loss: 0.0058 - val_mse: 0.0116 - 519ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0296 - mse: 0.5137 - val_loss: 0.0063 - val_mse: 0.0127 - 541ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0127 - mse: 0.0529 - val_loss: 0.0050 - val_mse: 0.0100 - 506ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0122 - mse: 0.0415 - val_loss: 0.0066 - val_mse: 0.0133 - 507ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0157 - mse: 0.1180 - val_loss: 0.0060 - val_mse: 0.0120 - 508ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0201 - mse: 0.3240 - val_loss: 0.0065 - val_mse: 0.0130 - 509ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0117 - mse: 0.0469 - val_loss: 0.0064 - val_mse: 0.0128 - 510ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0085 - mse: 0.0197 - val_loss: 0.0045 - val_mse: 0.0090 - 508ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0174 - mse: 0.1939 - val_loss: 0.0054 - val_mse: 0.0109 - 509ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0094 - mse: 0.0420 - val_loss: 0.0047 - val_mse: 0.0094 - 514ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0133 - mse: 0.0829 - val_loss: 0.0053 - val_mse: 0.0105 - 505ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0094 - mse: 0.0269 - val_loss: 0.0055 - val_mse: 0.0110 - 513ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0085 - mse: 0.0239 - val_loss: 0.0076 - val_mse: 0.0152 - 515ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 0.0114 - mse: 0.0707 - val_loss: 0.0055 - val_mse: 0.0110 - 514ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 208 ended. Search finished for the next optimal point.\n",
            "Time taken: 71.3105\n",
            "Function value obtained: 0.0110\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 209 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [58, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3213089738872857\n",
            "Batch Size: 144\n",
            "----------------------------------------\n",
            "59/59 - 3s - loss: 3222.0952 - mse: 3583461120.0000 - val_loss: 0.0089 - val_mse: 0.0179 - 3s/epoch - 46ms/step\n",
            "59/59 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 325ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 324ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 312ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 327ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 330ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 330ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 333ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 327ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 331ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0174 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 330ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 321ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0173 - 323ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172 - 324ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0171 - 312ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 324ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 313ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 316ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 316ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0088 - val_mse: 0.0175 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0171 - 314ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 327ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 333ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 329ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 329ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0091 - val_mse: 0.0183 - 329ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 332ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 335ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 330ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 312ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0089 - val_mse: 0.0177 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 325ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0171 - 323ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 329ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 323ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172 - 321ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 314ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 323ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0091 - val_mse: 0.0181 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 316ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 328ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0093 - val_mse: 0.0187 - 320ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0176 - 314ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 321ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0090 - val_mse: 0.0181 - 312ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 324ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0090 - val_mse: 0.0181 - 331ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 329ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 328ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 325ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0096 - val_mse: 0.0191 - 336ms/epoch - 6ms/step\n",
            "59/59 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0089 - val_mse: 0.0178 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0170 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 323ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 321ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169 - 315ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 319ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0095 - val_mse: 0.0189 - 317ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 324ms/epoch - 5ms/step\n",
            "59/59 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 320ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.01109136]\n",
            "\n",
            "Iteration No: 209 ended. Search finished for the next optimal point.\n",
            "Time taken: 49.7057\n",
            "Function value obtained: 0.0174\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 210 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 - 3s - loss: 41446.9727 - mse: 169967075328.0000 - val_loss: 0.0084 - val_mse: 0.0167 - 3s/epoch - 93ms/step\n",
            "33/33 - 0s - loss: 0.0097 - mse: 0.0195 - val_loss: 0.0086 - val_mse: 0.0172 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0174 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0175 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0173 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0107 - val_mse: 0.0215 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0088 - val_mse: 0.0177 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0102 - val_mse: 0.0204 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0086 - val_mse: 0.0171 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0091 - val_mse: 0.0182 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0092 - val_mse: 0.0184 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0086 - val_mse: 0.0172 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0099 - val_mse: 0.0198 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0171 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0091 - val_mse: 0.0182 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0173 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0177 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0096 - val_mse: 0.0193 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0091 - val_mse: 0.0183 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0090 - val_mse: 0.0180 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0178 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0172 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0175 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0091 - val_mse: 0.0182 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0088 - val_mse: 0.0175 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0088 - val_mse: 0.0175 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0088 - val_mse: 0.0176 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0102 - val_mse: 0.0205 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0089 - val_mse: 0.0178 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0175 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0090 - val_mse: 0.0180 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0090 - val_mse: 0.0179 - 214ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01095016]\n",
            "\n",
            "Iteration No: 210 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.4762\n",
            "Function value obtained: 0.0179\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 211 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [121]\n",
            "Learning Rate: 0.00016758992079697954\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3765155020031479\n",
            "Batch Size: 74\n",
            "----------------------------------------\n",
            "114/114 - 2s - loss: 1085.4965 - mse: 12999006.0000 - val_loss: 63.9150 - val_mse: 23000.5449 - 2s/epoch - 19ms/step\n",
            "114/114 - 0s - loss: 746.2109 - mse: 5181149.5000 - val_loss: 8.8185 - val_mse: 433.8751 - 483ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 622.6035 - mse: 4151392.0000 - val_loss: 4.1579 - val_mse: 92.4259 - 485ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 573.2385 - mse: 3034881.5000 - val_loss: 4.4151 - val_mse: 193.3151 - 480ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 504.8128 - mse: 2547424.0000 - val_loss: 5.9908 - val_mse: 275.1866 - 482ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 467.4023 - mse: 1995385.0000 - val_loss: 6.0321 - val_mse: 343.5232 - 480ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 426.8820 - mse: 1790221.3750 - val_loss: 7.4152 - val_mse: 320.0592 - 473ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 394.1151 - mse: 1495110.0000 - val_loss: 1.7808 - val_mse: 33.2687 - 467ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 373.1831 - mse: 1467451.0000 - val_loss: 14.9634 - val_mse: 1182.2115 - 462ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 334.1924 - mse: 1060878.8750 - val_loss: 3.1237 - val_mse: 41.3081 - 469ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 278.9978 - mse: 759803.0000 - val_loss: 10.9786 - val_mse: 436.3272 - 488ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 264.3399 - mse: 708775.0000 - val_loss: 9.9302 - val_mse: 636.6700 - 496ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 244.2474 - mse: 577306.2500 - val_loss: 5.9134 - val_mse: 93.2737 - 506ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 220.8016 - mse: 457592.6875 - val_loss: 7.4705 - val_mse: 361.2100 - 485ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 202.9340 - mse: 408334.4375 - val_loss: 14.3928 - val_mse: 917.1492 - 496ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 188.6772 - mse: 398787.7188 - val_loss: 0.9028 - val_mse: 2.5883 - 471ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 165.5518 - mse: 286980.0312 - val_loss: 5.3530 - val_mse: 196.2762 - 475ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 150.3964 - mse: 262808.5000 - val_loss: 3.0776 - val_mse: 81.1884 - 468ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 133.4894 - mse: 177821.2344 - val_loss: 1.3206 - val_mse: 5.0816 - 464ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 118.6170 - mse: 144961.8125 - val_loss: 1.3245 - val_mse: 9.3120 - 472ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 106.6068 - mse: 114265.1016 - val_loss: 3.0063 - val_mse: 43.3416 - 471ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 96.2440 - mse: 82297.3516 - val_loss: 3.1878 - val_mse: 94.5233 - 464ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 85.2040 - mse: 73001.5938 - val_loss: 9.2622 - val_mse: 481.4531 - 462ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 74.6986 - mse: 56655.4492 - val_loss: 7.9637 - val_mse: 383.1296 - 475ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 67.8771 - mse: 50032.6836 - val_loss: 2.6440 - val_mse: 57.5773 - 482ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 57.2194 - mse: 31063.4648 - val_loss: 4.2971 - val_mse: 130.5776 - 490ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 49.4281 - mse: 25882.0605 - val_loss: 7.8248 - val_mse: 365.7196 - 484ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 41.8086 - mse: 17848.2930 - val_loss: 7.6615 - val_mse: 301.9356 - 481ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 36.5528 - mse: 15503.7119 - val_loss: 1.0543 - val_mse: 10.4425 - 480ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 31.9350 - mse: 12302.6191 - val_loss: 1.5428 - val_mse: 14.8377 - 480ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 24.4148 - mse: 6701.0020 - val_loss: 0.9650 - val_mse: 7.5549 - 469ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 19.0253 - mse: 3879.9070 - val_loss: 0.8730 - val_mse: 6.9248 - 473ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 14.6201 - mse: 2507.0217 - val_loss: 0.1486 - val_mse: 0.3109 - 492ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 11.4345 - mse: 2199.5515 - val_loss: 0.8039 - val_mse: 3.2522 - 503ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 7.4264 - mse: 702.8564 - val_loss: 2.1338 - val_mse: 33.4583 - 499ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 5.6579 - mse: 1307.0682 - val_loss: 1.0881 - val_mse: 9.7490 - 503ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 3.4476 - mse: 277.0236 - val_loss: 1.0138 - val_mse: 6.6675 - 494ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 2.2880 - mse: 160.3448 - val_loss: 1.5052 - val_mse: 17.9785 - 500ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 1.8749 - mse: 120.4438 - val_loss: 0.4294 - val_mse: 1.4465 - 488ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 1.3417 - mse: 51.1976 - val_loss: 0.5940 - val_mse: 3.6239 - 481ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.9617 - mse: 53.3376 - val_loss: 0.3326 - val_mse: 0.9749 - 483ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.9056 - mse: 50.7753 - val_loss: 0.0707 - val_mse: 0.1414 - 496ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.9394 - mse: 49.5782 - val_loss: 0.9701 - val_mse: 6.2764 - 488ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.7855 - mse: 28.1719 - val_loss: 0.1124 - val_mse: 0.2688 - 479ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.9097 - mse: 127.6597 - val_loss: 0.0853 - val_mse: 0.1872 - 471ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.5958 - mse: 16.4961 - val_loss: 0.3613 - val_mse: 1.6191 - 478ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.5021 - mse: 5.3352 - val_loss: 0.1130 - val_mse: 0.2420 - 479ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.5573 - mse: 19.2159 - val_loss: 0.3434 - val_mse: 1.5040 - 469ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4718 - mse: 39.0187 - val_loss: 0.0362 - val_mse: 0.0724 - 470ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4368 - mse: 4.4351 - val_loss: 0.0394 - val_mse: 0.0789 - 473ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4506 - mse: 15.6805 - val_loss: 0.2138 - val_mse: 0.7236 - 477ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4587 - mse: 7.5224 - val_loss: 0.0796 - val_mse: 0.1679 - 470ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3211 - mse: 9.2358 - val_loss: 0.0566 - val_mse: 0.1200 - 475ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.5010 - mse: 4.5774 - val_loss: 0.0416 - val_mse: 0.0833 - 478ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3771 - mse: 10.7453 - val_loss: 0.3790 - val_mse: 1.4933 - 474ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4177 - mse: 3.0774 - val_loss: 1.0188 - val_mse: 8.8465 - 491ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4090 - mse: 15.8127 - val_loss: 0.5301 - val_mse: 2.5953 - 486ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4173 - mse: 7.7509 - val_loss: 0.0391 - val_mse: 0.0790 - 489ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3026 - mse: 5.0703 - val_loss: 0.0630 - val_mse: 0.1351 - 495ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.2617 - mse: 5.0848 - val_loss: 0.0356 - val_mse: 0.0722 - 505ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3847 - mse: 6.5459 - val_loss: 0.6358 - val_mse: 3.9697 - 482ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3507 - mse: 8.2131 - val_loss: 0.1147 - val_mse: 0.3026 - 468ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2963 - mse: 4.3625 - val_loss: 0.1249 - val_mse: 0.3310 - 479ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3870 - mse: 14.5981 - val_loss: 0.4541 - val_mse: 2.2645 - 472ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.4516 - mse: 20.1021 - val_loss: 0.2349 - val_mse: 0.8283 - 478ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3143 - mse: 1.8450 - val_loss: 0.0352 - val_mse: 0.0727 - 468ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2526 - mse: 2.6654 - val_loss: 0.4952 - val_mse: 2.5924 - 468ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3642 - mse: 2.7298 - val_loss: 0.3857 - val_mse: 1.7126 - 464ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2624 - mse: 1.3619 - val_loss: 0.0378 - val_mse: 0.0780 - 470ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2211 - mse: 2.6722 - val_loss: 0.5006 - val_mse: 2.6392 - 462ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2648 - mse: 3.1269 - val_loss: 0.4092 - val_mse: 1.9081 - 470ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.3606 - mse: 10.8613 - val_loss: 0.5297 - val_mse: 2.8148 - 479ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1827 - mse: 1.2162 - val_loss: 0.3743 - val_mse: 1.6480 - 469ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2031 - mse: 2.0161 - val_loss: 0.1256 - val_mse: 0.3344 - 480ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2680 - mse: 1.5521 - val_loss: 0.1827 - val_mse: 0.5659 - 471ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1437 - mse: 1.0006 - val_loss: 0.0223 - val_mse: 0.0454 - 478ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2794 - mse: 2.7623 - val_loss: 0.3125 - val_mse: 1.2412 - 468ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1677 - mse: 0.7021 - val_loss: 0.0056 - val_mse: 0.0113 - 476ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2133 - mse: 1.8963 - val_loss: 0.0252 - val_mse: 0.0524 - 499ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1345 - mse: 0.6002 - val_loss: 0.0056 - val_mse: 0.0111 - 491ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1867 - mse: 4.5232 - val_loss: 0.0980 - val_mse: 0.2423 - 485ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1594 - mse: 0.6482 - val_loss: 0.2506 - val_mse: 0.8892 - 485ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1703 - mse: 0.9900 - val_loss: 0.0047 - val_mse: 0.0095 - 487ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2101 - mse: 1.2268 - val_loss: 0.0668 - val_mse: 0.1650 - 466ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1701 - mse: 0.8065 - val_loss: 0.2196 - val_mse: 0.7201 - 476ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1508 - mse: 1.4661 - val_loss: 0.0125 - val_mse: 0.0251 - 482ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1665 - mse: 1.5272 - val_loss: 0.0861 - val_mse: 0.2020 - 481ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.1477 - mse: 1.5793 - val_loss: 0.2230 - val_mse: 0.7328 - 503ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.2429 - mse: 7.4217 - val_loss: 0.0071 - val_mse: 0.0141 - 495ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.1317 - mse: 0.9643 - val_loss: 0.0405 - val_mse: 0.0833 - 521ms/epoch - 5ms/step\n",
            "114/114 - 1s - loss: 0.1206 - mse: 0.4799 - val_loss: 0.0318 - val_mse: 0.0696 - 518ms/epoch - 5ms/step\n",
            "114/114 - 1s - loss: 0.0992 - mse: 1.1950 - val_loss: 0.0170 - val_mse: 0.0348 - 508ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.1181 - mse: 0.4357 - val_loss: 0.0054 - val_mse: 0.0108 - 510ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.0508 - mse: 0.2605 - val_loss: 0.0038 - val_mse: 0.0077 - 497ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.0746 - mse: 0.5330 - val_loss: 0.0478 - val_mse: 0.1004 - 513ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.1379 - mse: 0.8481 - val_loss: 0.0114 - val_mse: 0.0228 - 498ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.0696 - mse: 0.3199 - val_loss: 0.1549 - val_mse: 0.4355 - 493ms/epoch - 4ms/step\n",
            "114/114 - 0s - loss: 0.0691 - mse: 0.2010 - val_loss: 0.2160 - val_mse: 0.7007 - 497ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.0805 - mse: 1.2927 - val_loss: 0.0178 - val_mse: 0.0357 - 508ms/epoch - 4ms/step\n",
            "114/114 - 1s - loss: 0.0822 - mse: 0.3958 - val_loss: 0.0400 - val_mse: 0.0911 - 513ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 211 ended. Search finished for the next optimal point.\n",
            "Time taken: 66.1190\n",
            "Function value obtained: 0.0911\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 212 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [32, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 6529.2046 - mse: 2522054912.0000 - val_loss: 0.0085 - val_mse: 0.0170 - 3s/epoch - 76ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0171 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0098 - val_mse: 0.0196 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0169 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0087 - val_mse: 0.0175 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0090 - val_mse: 0.0181 - 212ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0086 - val_mse: 0.0172 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0171 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0098 - mse: 0.0196 - val_loss: 0.0086 - val_mse: 0.0171 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0100 - val_mse: 0.0201 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0169 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 213ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0169 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0093 - val_mse: 0.0186 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0086 - val_mse: 0.0171 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0095 - val_mse: 0.0189 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0086 - val_mse: 0.0172 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0087 - val_mse: 0.0173 - 211ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0105 - val_mse: 0.0210 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0088 - val_mse: 0.0177 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0108 - val_mse: 0.0216 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0095 - val_mse: 0.0191 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0091 - val_mse: 0.0183 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0176 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0169 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0168 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0091 - val_mse: 0.0183 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0087 - val_mse: 0.0175 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0169 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0126 - val_mse: 0.0253 - 214ms/epoch - 6ms/step\n",
            "33/33 - 0s - loss: 0.0098 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167 - 215ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0108 - val_mse: 0.0215 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0109 - mse: 0.0218 - val_loss: 0.0123 - val_mse: 0.0246 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0105 - val_mse: 0.0211 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0089 - val_mse: 0.0178 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0086 - val_mse: 0.0172 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0089 - val_mse: 0.0178 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0100 - mse: 0.0201 - val_loss: 0.0099 - val_mse: 0.0198 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0099 - mse: 0.0199 - val_loss: 0.0086 - val_mse: 0.0172 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0102 - val_mse: 0.0204 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0085 - val_mse: 0.0170 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0171 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0169 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0085 - val_mse: 0.0171 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0096 - val_mse: 0.0192 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0088 - val_mse: 0.0176 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0095 - mse: 0.0190 - val_loss: 0.0084 - val_mse: 0.0168 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0091 - val_mse: 0.0183 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0093 - val_mse: 0.0186 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0085 - val_mse: 0.0170 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0126 - val_mse: 0.0252 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0097 - mse: 0.0193 - val_loss: 0.0086 - val_mse: 0.0172 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0092 - val_mse: 0.0185 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0095 - val_mse: 0.0191 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0175 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0099 - val_mse: 0.0199 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0093 - val_mse: 0.0185 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0087 - val_mse: 0.0175 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0102 - mse: 0.0204 - val_loss: 0.0120 - val_mse: 0.0241 - 224ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.01217541]\n",
            "\n",
            "Iteration No: 212 ended. Search finished for the next optimal point.\n",
            "Time taken: 40.0403\n",
            "Function value obtained: 0.0241\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 213 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [124, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 18759.9023 - mse: 27227019264.0000 - val_loss: 0.2593 - val_mse: 0.5186 - 3s/epoch - 76ms/step\n",
            "33/33 - 0s - loss: 0.0495 - mse: 0.0991 - val_loss: 0.0123 - val_mse: 0.0246 - 221ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0096 - mse: 0.0193 - val_loss: 0.0085 - val_mse: 0.0170 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0090 - val_mse: 0.0180 - 224ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0171 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 223ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 219ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 218ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0175 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 217ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0088 - val_mse: 0.0176 - 216ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0175 - 220ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0169 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0090 - val_mse: 0.0181 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0099 - mse: 0.0199 - val_loss: 0.0095 - val_mse: 0.0191 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0169 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0085 - val_mse: 0.0169 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0169 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0173 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0094 - val_mse: 0.0188 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0095 - val_mse: 0.0190 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0095 - mse: 0.0190 - val_loss: 0.0086 - val_mse: 0.0172 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0088 - val_mse: 0.0175 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 254ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0168 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0178 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0100 - val_mse: 0.0201 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0086 - val_mse: 0.0173 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0108 - val_mse: 0.0215 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0094 - val_mse: 0.0189 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0170 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0171 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0176 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 228ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0094 - val_mse: 0.0187 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0170 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0091 - val_mse: 0.0182 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0123 - mse: 0.0247 - val_loss: 0.0092 - val_mse: 0.0184 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0109 - mse: 0.0217 - val_loss: 0.0093 - val_mse: 0.0186 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0173 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0179 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0171 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0169 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0178 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0170 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0086 - val_mse: 0.0171 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0173 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0169 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0171 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0177 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0088 - val_mse: 0.0176 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0179 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0088 - val_mse: 0.0175 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 233ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.01799268]\n",
            "\n",
            "Iteration No: 213 ended. Search finished for the next optimal point.\n",
            "Time taken: 42.7749\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 214 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [99, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 159\n",
            "----------------------------------------\n",
            "53/53 - 3s - loss: 10306.2910 - mse: 18217793536.0000 - val_loss: 0.0104 - val_mse: 0.0208 - 3s/epoch - 52ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0167 - 303ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0093 - val_mse: 0.0185 - 306ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0172 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 300ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0087 - val_mse: 0.0175 - 302ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0179 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 301ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 307ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0173 - 299ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0088 - val_mse: 0.0175 - 298ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0092 - val_mse: 0.0184 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0169 - 296ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0089 - val_mse: 0.0179 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 294ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0085 - val_mse: 0.0170 - 312ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0171 - 309ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 305ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 312ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0091 - val_mse: 0.0182 - 311ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0086 - val_mse: 0.0171 - 315ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 296ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 308ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0086 - val_mse: 0.0171 - 302ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0088 - val_mse: 0.0175 - 295ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0101 - val_mse: 0.0202 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0094 - val_mse: 0.0187 - 289ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 291ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0100 - val_mse: 0.0200 - 295ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0095 - val_mse: 0.0190 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0095 - val_mse: 0.0190 - 291ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 286ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0086 - val_mse: 0.0172 - 285ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0098 - mse: 0.0196 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0169 - 287ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0174 - 293ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0093 - val_mse: 0.0187 - 288ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0169 - 286ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0089 - val_mse: 0.0178 - 294ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0170 - 298ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0101 - mse: 0.0202 - val_loss: 0.0099 - val_mse: 0.0199 - 284ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0086 - val_mse: 0.0171 - 307ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0095 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 302ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0091 - val_mse: 0.0182 - 301ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 300ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0087 - val_mse: 0.0175 - 306ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0089 - val_mse: 0.0178 - 311ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0085 - val_mse: 0.0169 - 315ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0091 - val_mse: 0.0181 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0086 - val_mse: 0.0172 - 300ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0086 - val_mse: 0.0172 - 300ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0101 - val_mse: 0.0202 - 292ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0101 - mse: 0.0203 - val_loss: 0.0091 - val_mse: 0.0182 - 285ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0088 - val_mse: 0.0175 - 283ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0091 - val_mse: 0.0181 - 288ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0088 - val_mse: 0.0177 - 296ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0105 - val_mse: 0.0209 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0095 - mse: 0.0191 - val_loss: 0.0091 - val_mse: 0.0182 - 292ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0086 - val_mse: 0.0171 - 291ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0097 - mse: 0.0194 - val_loss: 0.0085 - val_mse: 0.0170 - 287ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0087 - val_mse: 0.0174 - 281ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0095 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0085 - val_mse: 0.0171 - 291ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0085 - val_mse: 0.0171 - 288ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0087 - val_mse: 0.0174 - 285ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0086 - val_mse: 0.0171 - 281ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0094 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0169 - 300ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 297ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0093 - val_mse: 0.0186 - 293ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 292ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0094 - val_mse: 0.0188 - 299ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0095 - val_mse: 0.0191 - 298ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0090 - val_mse: 0.0181 - 295ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0085 - val_mse: 0.0171 - 292ms/epoch - 6ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 5ms/step\n",
            "53/53 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0087 - val_mse: 0.0175 - 288ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [0.01092302]\n",
            "\n",
            "Iteration No: 214 ended. Search finished for the next optimal point.\n",
            "Time taken: 47.9492\n",
            "Function value obtained: 0.0175\n",
            "Current minimum: 0.0053\n",
            "Iteration No: 215 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 128]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 271ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 279ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 251ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 247ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 252ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0173 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 257ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 251ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0087 - val_mse: 0.0173 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 268ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0170 - 264ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 263ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 261ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 272ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0089 - val_mse: 0.0178 - 251ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0092 - val_mse: 0.0183 - 258ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 255ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 251ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 262ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 254ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175 - 253ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 256ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0085 - val_mse: 0.0169 - 259ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 266ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 252ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 256ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0084 - val_mse: 0.0168 - 261ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0172 - 260ms/epoch - 6ms/step\n",
            "43/43 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 257ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01084486]\n",
            "\n",
            "Iteration No: 359 ended. Search finished for the next optimal point.\n",
            "Time taken: 56.4784\n",
            "Function value obtained: 0.0168\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 360 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [87, 88]\n",
            "Learning Rate: 0.01448341790542799\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.02450920243011703\n",
            "Batch Size: 181\n",
            "----------------------------------------\n",
            "47/47 - 3s - loss: 1011.0635 - mse: 64089244.0000 - val_loss: 0.2886 - val_mse: 0.8388 - 3s/epoch - 57ms/step\n",
            "47/47 - 0s - loss: 5.6164 - mse: 710.5858 - val_loss: 1.2146 - val_mse: 11.8458 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 2.6577 - mse: 225.9677 - val_loss: 0.7314 - val_mse: 4.9870 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 1.4079 - mse: 30.7187 - val_loss: 0.4249 - val_mse: 2.2798 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.8488 - mse: 60.8843 - val_loss: 0.0085 - val_mse: 0.0171 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.2848 - mse: 7.1459 - val_loss: 0.0060 - val_mse: 0.0120 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0963 - mse: 0.8951 - val_loss: 0.0287 - val_mse: 0.0577 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0723 - mse: 2.7455 - val_loss: 0.0065 - val_mse: 0.0130 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0239 - mse: 0.4154 - val_loss: 0.0067 - val_mse: 0.0134 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0203 - mse: 0.1255 - val_loss: 0.0045 - val_mse: 0.0089 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0089 - mse: 0.0211 - val_loss: 0.0113 - val_mse: 0.0227 - 268ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0165 - mse: 0.0975 - val_loss: 0.0079 - val_mse: 0.0158 - 269ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0202 - mse: 0.7310 - val_loss: 0.0060 - val_mse: 0.0120 - 275ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0159 - mse: 0.1057 - val_loss: 0.0066 - val_mse: 0.0132 - 272ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0142 - mse: 0.1713 - val_loss: 0.0044 - val_mse: 0.0088 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0109 - mse: 0.1110 - val_loss: 0.0042 - val_mse: 0.0085 - 277ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0095 - mse: 0.0407 - val_loss: 0.0047 - val_mse: 0.0093 - 271ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0076 - mse: 0.0194 - val_loss: 0.0090 - val_mse: 0.0181 - 279ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0092 - mse: 0.0459 - val_loss: 0.0049 - val_mse: 0.0098 - 286ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0061 - mse: 0.0124 - val_loss: 0.0043 - val_mse: 0.0086 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0239 - mse: 1.3465 - val_loss: 0.0053 - val_mse: 0.0105 - 276ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0212 - val_loss: 0.0044 - val_mse: 0.0088 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0150 - val_loss: 0.0053 - val_mse: 0.0105 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0327 - val_loss: 0.0045 - val_mse: 0.0089 - 274ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0154 - val_loss: 0.0051 - val_mse: 0.0101 - 292ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0053 - mse: 0.0107 - val_loss: 0.0053 - val_mse: 0.0107 - 265ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0079 - mse: 0.0281 - val_loss: 0.0047 - val_mse: 0.0094 - 270ms/epoch - 6ms/step\n",
            "47/47 - 1s - loss: 0.0108 - mse: 0.2735 - val_loss: 0.0043 - val_mse: 0.0085 - 815ms/epoch - 17ms/step\n",
            "47/47 - 0s - loss: 0.0076 - mse: 0.0263 - val_loss: 0.0044 - val_mse: 0.0089 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0160 - val_loss: 0.0045 - val_mse: 0.0090 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0056 - mse: 0.0113 - val_loss: 0.0044 - val_mse: 0.0088 - 299ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0077 - mse: 0.0554 - val_loss: 0.0043 - val_mse: 0.0086 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0082 - mse: 0.0373 - val_loss: 0.0043 - val_mse: 0.0085 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0091 - mse: 0.0563 - val_loss: 0.0043 - val_mse: 0.0086 - 299ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0085 - 300ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0051 - mse: 0.0103 - val_loss: 0.0042 - val_mse: 0.0085 - 303ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0083 - mse: 0.0734 - val_loss: 0.0045 - val_mse: 0.0090 - 312ms/epoch - 7ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0133 - val_loss: 0.0057 - val_mse: 0.0114 - 299ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0056 - mse: 0.0114 - val_loss: 0.0043 - val_mse: 0.0086 - 310ms/epoch - 7ms/step\n",
            "47/47 - 0s - loss: 0.0130 - mse: 0.2653 - val_loss: 0.0043 - val_mse: 0.0087 - 303ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0059 - mse: 0.0119 - val_loss: 0.0053 - val_mse: 0.0106 - 297ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0043 - val_mse: 0.0086 - 305ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0046 - val_mse: 0.0092 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0045 - val_mse: 0.0090 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0056 - mse: 0.0112 - val_loss: 0.0062 - val_mse: 0.0125 - 278ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0063 - mse: 0.0125 - val_loss: 0.0044 - val_mse: 0.0088 - 281ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0166 - val_loss: 0.0073 - val_mse: 0.0147 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0054 - mse: 0.0108 - val_loss: 0.0045 - val_mse: 0.0089 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0268 - mse: 0.8851 - val_loss: 0.0043 - val_mse: 0.0086 - 282ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0076 - mse: 0.0283 - val_loss: 0.0044 - val_mse: 0.0087 - 296ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0082 - mse: 0.0351 - val_loss: 0.0051 - val_mse: 0.0102 - 296ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0057 - mse: 0.0114 - val_loss: 0.0054 - val_mse: 0.0109 - 298ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0081 - mse: 0.0638 - val_loss: 0.0045 - val_mse: 0.0090 - 302ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0070 - mse: 0.0142 - val_loss: 0.0063 - val_mse: 0.0126 - 293ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0075 - mse: 0.0258 - val_loss: 0.0042 - val_mse: 0.0085 - 291ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0134 - val_loss: 0.0049 - val_mse: 0.0099 - 301ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0055 - mse: 0.0110 - val_loss: 0.0044 - val_mse: 0.0087 - 313ms/epoch - 7ms/step\n",
            "47/47 - 0s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0046 - val_mse: 0.0092 - 289ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0221 - val_loss: 0.0076 - val_mse: 0.0152 - 296ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0132 - val_loss: 0.0044 - val_mse: 0.0088 - 292ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0043 - val_mse: 0.0086 - 288ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0133 - val_loss: 0.0074 - val_mse: 0.0147 - 290ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0138 - val_loss: 0.0043 - val_mse: 0.0086 - 289ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0080 - mse: 0.0325 - val_loss: 0.0043 - val_mse: 0.0086 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0067 - mse: 0.0136 - val_loss: 0.0045 - val_mse: 0.0090 - 293ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0045 - val_mse: 0.0090 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0068 - mse: 0.0136 - val_loss: 0.0051 - val_mse: 0.0102 - 286ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0129 - val_loss: 0.0044 - val_mse: 0.0089 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0059 - val_mse: 0.0117 - 291ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0149 - val_loss: 0.0057 - val_mse: 0.0114 - 292ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0074 - mse: 0.0273 - val_loss: 0.0045 - val_mse: 0.0090 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0043 - val_mse: 0.0085 - 281ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0064 - mse: 0.0130 - val_loss: 0.0044 - val_mse: 0.0087 - 288ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0075 - val_mse: 0.0151 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0066 - mse: 0.0131 - val_loss: 0.0059 - val_mse: 0.0118 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0054 - val_mse: 0.0109 - 290ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0047 - val_mse: 0.0094 - 281ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0059 - mse: 0.0118 - val_loss: 0.0054 - val_mse: 0.0108 - 286ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0065 - mse: 0.0131 - val_loss: 0.0043 - val_mse: 0.0086 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0043 - val_mse: 0.0086 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0056 - mse: 0.0111 - val_loss: 0.0053 - val_mse: 0.0107 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0057 - val_mse: 0.0114 - 297ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0072 - mse: 0.0184 - val_loss: 0.0043 - val_mse: 0.0085 - 310ms/epoch - 7ms/step\n",
            "47/47 - 0s - loss: 0.0085 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0173 - 301ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0130 - mse: 0.1805 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0088 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0254 - mse: 2.3441 - val_loss: 0.0084 - val_mse: 0.0167 - 299ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0094 - mse: 0.0229 - val_loss: 0.0084 - val_mse: 0.0167 - 295ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0090 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0087 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0167 - 291ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0079 - mse: 0.0157 - val_loss: 0.0043 - val_mse: 0.0086 - 280ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0098 - mse: 0.0211 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0094 - mse: 0.0201 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "47/47 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.4409843]\n",
            "\n",
            "Iteration No: 360 ended. Search finished for the next optimal point.\n",
            "Time taken: 60.3330\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 361 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [81, 100]\n",
            "Learning Rate: 0.06611544214924799\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3739856722587713\n",
            "Batch Size: 187\n",
            "----------------------------------------\n",
            "45/45 - 3s - loss: 3118.9355 - mse: 1930369152.0000 - val_loss: 0.0085 - val_mse: 0.0170 - 3s/epoch - 63ms/step\n",
            "45/45 - 0s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0088 - val_mse: 0.0175 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0171 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 259ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 260ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0178 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 261ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0089 - val_mse: 0.0178 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 274ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01085494]\n",
            "\n",
            "Iteration No: 361 ended. Search finished for the next optimal point.\n",
            "Time taken: 60.4222\n",
            "Function value obtained: 0.0169\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 362 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [78, 107]\n",
            "Learning Rate: 0.0014342071106835292\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3326762885294097\n",
            "Batch Size: 184\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 393.7055 - mse: 2017081.0000 - val_loss: 4.4609 - val_mse: 146.1941 - 3s/epoch - 58ms/step\n",
            "46/46 - 0s - loss: 111.6607 - mse: 117464.3047 - val_loss: 0.5609 - val_mse: 2.6050 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 52.9270 - mse: 27900.5801 - val_loss: 3.0362 - val_mse: 67.4299 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 28.6564 - mse: 10132.7578 - val_loss: 2.1445 - val_mse: 36.0341 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 17.1921 - mse: 3601.1030 - val_loss: 0.1696 - val_mse: 0.4101 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 11.3622 - mse: 1850.3196 - val_loss: 0.0683 - val_mse: 0.1366 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 7.0179 - mse: 782.1698 - val_loss: 0.0454 - val_mse: 0.0908 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 4.4814 - mse: 403.1426 - val_loss: 0.0191 - val_mse: 0.0383 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.0193 - mse: 187.3103 - val_loss: 0.0097 - val_mse: 0.0194 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.2668 - mse: 138.5588 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.7811 - mse: 117.9097 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.2856 - mse: 73.1491 - val_loss: 0.0084 - val_mse: 0.0167 - 313ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.8784 - mse: 32.5516 - val_loss: 0.0084 - val_mse: 0.0168 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.7727 - mse: 36.3821 - val_loss: 0.0084 - val_mse: 0.0169 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.7371 - mse: 64.4149 - val_loss: 0.0084 - val_mse: 0.0169 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.5396 - mse: 29.4751 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4368 - mse: 12.9892 - val_loss: 0.0084 - val_mse: 0.0169 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.3769 - mse: 12.1428 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3752 - mse: 21.5214 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3282 - mse: 11.3689 - val_loss: 0.0084 - val_mse: 0.0169 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2700 - mse: 11.0677 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2654 - mse: 8.5549 - val_loss: 0.0084 - val_mse: 0.0169 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2650 - mse: 11.3962 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2546 - mse: 11.5371 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1821 - mse: 4.4834 - val_loss: 0.0084 - val_mse: 0.0168 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.2389 - mse: 13.5449 - val_loss: 0.0085 - val_mse: 0.0169 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2076 - mse: 7.5288 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1784 - mse: 6.4611 - val_loss: 0.0084 - val_mse: 0.0167 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1445 - mse: 4.0388 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1345 - mse: 3.0204 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1146 - mse: 2.4265 - val_loss: 0.0084 - val_mse: 0.0168 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1219 - mse: 3.3006 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1325 - mse: 3.7766 - val_loss: 0.0084 - val_mse: 0.0168 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0980 - mse: 1.5555 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0971 - mse: 2.3482 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1025 - mse: 2.1953 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0839 - mse: 1.7740 - val_loss: 0.0084 - val_mse: 0.0168 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0745 - mse: 1.4971 - val_loss: 0.0084 - val_mse: 0.0168 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1187 - mse: 8.3486 - val_loss: 0.0084 - val_mse: 0.0168 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0949 - mse: 3.5852 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0751 - mse: 1.3857 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0794 - mse: 1.6414 - val_loss: 0.0084 - val_mse: 0.0169 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0737 - mse: 1.8152 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0534 - mse: 0.6685 - val_loss: 0.0084 - val_mse: 0.0168 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0628 - mse: 0.8800 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0614 - mse: 0.7761 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0606 - mse: 1.0224 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0623 - mse: 0.9508 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0586 - mse: 1.3671 - val_loss: 0.0084 - val_mse: 0.0169 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0718 - mse: 2.3901 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0624 - mse: 1.6662 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0607 - mse: 2.3551 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0477 - mse: 2.0801 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0400 - mse: 1.0415 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0341 - mse: 0.2825 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0360 - mse: 0.4545 - val_loss: 0.0084 - val_mse: 0.0169 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0470 - mse: 0.6627 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0463 - mse: 0.8941 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0249 - mse: 0.3336 - val_loss: 0.0084 - val_mse: 0.0169 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0327 - mse: 0.2778 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0338 - mse: 0.3593 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0404 - mse: 0.4630 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0494 - mse: 1.5237 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0382 - mse: 0.4851 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0311 - mse: 0.2730 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0321 - mse: 0.2987 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0327 - mse: 0.4399 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0324 - mse: 0.2597 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0349 - mse: 0.7600 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0283 - mse: 0.2945 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0346 - mse: 0.3777 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0238 - mse: 0.2387 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0240 - mse: 0.3881 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0210 - mse: 0.1088 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0339 - mse: 0.6698 - val_loss: 0.0084 - val_mse: 0.0167 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0260 - mse: 0.3266 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0213 - mse: 0.2895 - val_loss: 0.0084 - val_mse: 0.0168 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0304 - mse: 0.6717 - val_loss: 0.0084 - val_mse: 0.0168 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0217 - mse: 0.1890 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0217 - mse: 0.1677 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0147 - mse: 0.1329 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0203 - mse: 0.1754 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0184 - mse: 0.1693 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0187 - mse: 0.1549 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0184 - mse: 0.1481 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0208 - mse: 0.1292 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0364 - mse: 1.5069 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0242 - mse: 0.4070 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0204 - mse: 0.2085 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0207 - mse: 0.1509 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0267 - mse: 1.3283 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0193 - mse: 0.1658 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0137 - mse: 0.0527 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0176 - mse: 0.0977 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0156 - mse: 0.1198 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0153 - mse: 0.0707 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0142 - mse: 0.0468 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0118 - mse: 0.0425 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0295 - mse: 2.1318 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0161 - mse: 0.1022 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 362 ended. Search finished for the next optimal point.\n",
            "Time taken: 61.2555\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 363 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [88, 95]\n",
            "Learning Rate: 0.0006135765711235397\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.40878510693245484\n",
            "Batch Size: 61\n",
            "----------------------------------------\n",
            "138/138 - 3s - loss: 779.6657 - mse: 6576106.0000 - val_loss: 26.2111 - val_mse: 4262.7285 - 3s/epoch - 23ms/step\n",
            "138/138 - 1s - loss: 281.7363 - mse: 819792.6250 - val_loss: 3.4624 - val_mse: 86.1760 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 142.6259 - mse: 190469.6094 - val_loss: 3.0345 - val_mse: 65.3217 - 635ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 82.4137 - mse: 84872.8203 - val_loss: 0.2102 - val_mse: 0.4442 - 671ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 49.3018 - mse: 27208.2559 - val_loss: 1.0949 - val_mse: 10.8892 - 658ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 32.0062 - mse: 12316.7568 - val_loss: 0.4261 - val_mse: 2.1155 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 20.4098 - mse: 4881.9453 - val_loss: 0.0823 - val_mse: 0.1647 - 658ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 14.4481 - mse: 3636.9060 - val_loss: 0.0396 - val_mse: 0.0793 - 657ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 9.9936 - mse: 2125.9666 - val_loss: 0.0188 - val_mse: 0.0376 - 684ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 6.0921 - mse: 960.1342 - val_loss: 0.0109 - val_mse: 0.0217 - 683ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 4.2691 - mse: 492.3491 - val_loss: 0.0087 - val_mse: 0.0174 - 654ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 3.3036 - mse: 596.5910 - val_loss: 0.0084 - val_mse: 0.0167 - 677ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 2.2896 - mse: 220.8243 - val_loss: 0.0084 - val_mse: 0.0167 - 644ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 1.7363 - mse: 142.5713 - val_loss: 0.0084 - val_mse: 0.0167 - 659ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 1.2664 - mse: 86.2113 - val_loss: 0.0084 - val_mse: 0.0167 - 649ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 1.3046 - mse: 157.8702 - val_loss: 0.0084 - val_mse: 0.0168 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.9076 - mse: 80.6000 - val_loss: 0.0084 - val_mse: 0.0168 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 1.0406 - mse: 140.6282 - val_loss: 0.0084 - val_mse: 0.0167 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.7483 - mse: 85.9307 - val_loss: 0.0084 - val_mse: 0.0168 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.7162 - mse: 45.0741 - val_loss: 0.0084 - val_mse: 0.0168 - 636ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.5995 - mse: 56.9725 - val_loss: 0.0085 - val_mse: 0.0169 - 638ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.5036 - mse: 59.3223 - val_loss: 0.0084 - val_mse: 0.0168 - 631ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.4552 - mse: 60.9832 - val_loss: 0.0084 - val_mse: 0.0168 - 642ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.4632 - mse: 45.7538 - val_loss: 0.0084 - val_mse: 0.0167 - 639ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.2859 - mse: 16.8989 - val_loss: 0.0084 - val_mse: 0.0168 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.4047 - mse: 52.8299 - val_loss: 0.0084 - val_mse: 0.0168 - 651ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.2933 - mse: 27.7301 - val_loss: 0.0084 - val_mse: 0.0168 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.2053 - mse: 10.3475 - val_loss: 0.0084 - val_mse: 0.0169 - 656ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.2305 - mse: 12.8969 - val_loss: 0.0084 - val_mse: 0.0168 - 644ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1958 - mse: 9.9087 - val_loss: 0.0085 - val_mse: 0.0169 - 644ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1744 - mse: 9.9315 - val_loss: 0.0084 - val_mse: 0.0169 - 622ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1693 - mse: 14.0268 - val_loss: 0.0085 - val_mse: 0.0170 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1626 - mse: 9.5957 - val_loss: 0.0085 - val_mse: 0.0169 - 619ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.1158 - mse: 3.3607 - val_loss: 0.0085 - val_mse: 0.0170 - 640ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1291 - mse: 7.2115 - val_loss: 0.0085 - val_mse: 0.0169 - 635ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1227 - mse: 7.0982 - val_loss: 0.0084 - val_mse: 0.0169 - 627ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0830 - mse: 2.9231 - val_loss: 0.0084 - val_mse: 0.0169 - 620ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.1447 - mse: 40.3091 - val_loss: 0.0084 - val_mse: 0.0168 - 630ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0755 - mse: 2.7925 - val_loss: 0.0086 - val_mse: 0.0171 - 629ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1185 - mse: 13.3819 - val_loss: 0.0084 - val_mse: 0.0169 - 626ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0599 - mse: 0.8458 - val_loss: 0.0084 - val_mse: 0.0168 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.1785 - mse: 59.6637 - val_loss: 0.0084 - val_mse: 0.0168 - 632ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0483 - mse: 1.9989 - val_loss: 0.0084 - val_mse: 0.0168 - 634ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0565 - mse: 2.1702 - val_loss: 0.0085 - val_mse: 0.0169 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0340 - mse: 0.3214 - val_loss: 0.0084 - val_mse: 0.0168 - 656ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0645 - mse: 1.9716 - val_loss: 0.0084 - val_mse: 0.0168 - 679ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0573 - mse: 1.6805 - val_loss: 0.0084 - val_mse: 0.0168 - 661ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0400 - mse: 1.1396 - val_loss: 0.0084 - val_mse: 0.0169 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0294 - mse: 0.4769 - val_loss: 0.0084 - val_mse: 0.0168 - 630ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0412 - mse: 2.0603 - val_loss: 0.0084 - val_mse: 0.0168 - 634ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0583 - mse: 5.7928 - val_loss: 0.0084 - val_mse: 0.0168 - 627ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0408 - mse: 2.0224 - val_loss: 0.0084 - val_mse: 0.0169 - 635ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0220 - mse: 0.2860 - val_loss: 0.0084 - val_mse: 0.0168 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0228 - mse: 0.2516 - val_loss: 0.0084 - val_mse: 0.0168 - 616ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0247 - mse: 0.2674 - val_loss: 0.0084 - val_mse: 0.0168 - 619ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0315 - mse: 1.1666 - val_loss: 0.0084 - val_mse: 0.0168 - 618ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0358 - mse: 0.5940 - val_loss: 0.0084 - val_mse: 0.0168 - 618ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0180 - mse: 0.1190 - val_loss: 0.0084 - val_mse: 0.0168 - 629ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0222 - mse: 0.2365 - val_loss: 0.0084 - val_mse: 0.0168 - 622ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0191 - mse: 0.1472 - val_loss: 0.0084 - val_mse: 0.0168 - 633ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0344 - mse: 2.1144 - val_loss: 0.0084 - val_mse: 0.0167 - 628ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0206 - mse: 0.2461 - val_loss: 0.0084 - val_mse: 0.0168 - 650ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0203 - mse: 0.2107 - val_loss: 0.0084 - val_mse: 0.0168 - 648ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0487 - mse: 6.2360 - val_loss: 0.0084 - val_mse: 0.0168 - 637ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0254 - mse: 0.6822 - val_loss: 0.0084 - val_mse: 0.0167 - 652ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0623 - mse: 15.6481 - val_loss: 0.0084 - val_mse: 0.0168 - 618ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0248 - mse: 0.4680 - val_loss: 0.0084 - val_mse: 0.0168 - 607ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0170 - mse: 0.1444 - val_loss: 0.0084 - val_mse: 0.0168 - 626ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0199 - mse: 0.5084 - val_loss: 0.0084 - val_mse: 0.0168 - 630ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0109 - mse: 0.0257 - val_loss: 0.0084 - val_mse: 0.0168 - 629ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0146 - mse: 0.0646 - val_loss: 0.0084 - val_mse: 0.0167 - 636ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0141 - mse: 0.1089 - val_loss: 0.0084 - val_mse: 0.0168 - 634ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0119 - mse: 0.0337 - val_loss: 0.0084 - val_mse: 0.0168 - 636ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0149 - mse: 0.1635 - val_loss: 0.0084 - val_mse: 0.0168 - 649ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0206 - mse: 0.3785 - val_loss: 0.0084 - val_mse: 0.0167 - 639ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0179 - mse: 0.3517 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0098 - mse: 0.0201 - val_loss: 0.0084 - val_mse: 0.0167 - 645ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0116 - mse: 0.0824 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0150 - mse: 0.0821 - val_loss: 0.0084 - val_mse: 0.0167 - 641ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0250 - mse: 1.5337 - val_loss: 0.0084 - val_mse: 0.0167 - 664ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0105 - mse: 0.0264 - val_loss: 0.0084 - val_mse: 0.0167 - 651ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0094 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 646ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0149 - mse: 0.1179 - val_loss: 0.0084 - val_mse: 0.0168 - 643ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0179 - mse: 0.7005 - val_loss: 0.0084 - val_mse: 0.0167 - 623ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0295 - mse: 1.8940 - val_loss: 0.0084 - val_mse: 0.0167 - 615ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0107 - mse: 0.0336 - val_loss: 0.0084 - val_mse: 0.0168 - 624ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0126 - mse: 0.0730 - val_loss: 0.0084 - val_mse: 0.0167 - 622ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0147 - mse: 0.2996 - val_loss: 0.0084 - val_mse: 0.0168 - 621ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0169 - mse: 0.2630 - val_loss: 0.0084 - val_mse: 0.0168 - 610ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0093 - mse: 0.0201 - val_loss: 0.0084 - val_mse: 0.0168 - 612ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0094 - mse: 0.0206 - val_loss: 0.0084 - val_mse: 0.0167 - 604ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0123 - mse: 0.0847 - val_loss: 0.0084 - val_mse: 0.0167 - 606ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0100 - mse: 0.0243 - val_loss: 0.0084 - val_mse: 0.0167 - 613ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0090 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 615ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0100 - mse: 0.0220 - val_loss: 0.0084 - val_mse: 0.0167 - 619ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0092 - mse: 0.0208 - val_loss: 0.0084 - val_mse: 0.0167 - 625ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 615ms/epoch - 4ms/step\n",
            "138/138 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 637ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0514 - mse: 14.9468 - val_loss: 0.0084 - val_mse: 0.0167 - 659ms/epoch - 5ms/step\n",
            "138/138 - 1s - loss: 0.0107 - mse: 0.0353 - val_loss: 0.0084 - val_mse: 0.0168 - 646ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 363 ended. Search finished for the next optimal point.\n",
            "Time taken: 94.2358\n",
            "Function value obtained: 0.0168\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 364 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [81, 100]\n",
            "Learning Rate: 0.03769396531271143\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3732248203995753\n",
            "Batch Size: 187\n",
            "----------------------------------------\n",
            "45/45 - 3s - loss: 1545.4430 - mse: 327974912.0000 - val_loss: 0.0119 - val_mse: 0.0237 - 3s/epoch - 75ms/step\n",
            "45/45 - 0s - loss: 0.3974 - mse: 10.2057 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.1608 - mse: 4.5232 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0669 - mse: 0.4358 - val_loss: 0.0085 - val_mse: 0.0169 - 293ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0729 - mse: 0.6601 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0528 - mse: 0.3173 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0497 - mse: 0.8325 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0307 - mse: 0.1453 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0207 - mse: 0.0777 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0245 - mse: 0.2712 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0178 - mse: 0.0822 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0159 - mse: 0.0511 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0140 - mse: 0.0380 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0169 - mse: 0.0598 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0140 - mse: 0.0669 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0152 - mse: 0.0688 - val_loss: 0.0084 - val_mse: 0.0169 - 289ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0113 - mse: 0.0259 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0122 - mse: 0.0369 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0106 - mse: 0.0249 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0105 - mse: 0.0323 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0105 - mse: 0.0254 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0096 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0169 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0094 - mse: 0.0195 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0093 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0091 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0095 - mse: 0.0202 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0092 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0092 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0095 - mse: 0.0203 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0169 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0123 - mse: 0.0328 - val_loss: 0.0087 - val_mse: 0.0173 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0202 - mse: 0.1587 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0099 - mse: 0.0208 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0091 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0090 - mse: 0.0199 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0171 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0169 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0170 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0163 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0087 - val_mse: 0.0174 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0163 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0085 - val_mse: 0.0169 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0162 - val_loss: 0.0086 - val_mse: 0.0172 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0162 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0085 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0162 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0168 - val_loss: 0.0085 - val_mse: 0.0169 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0165 - val_loss: 0.0085 - val_mse: 0.0170 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0086 - val_mse: 0.0172 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0163 - val_loss: 0.0084 - val_mse: 0.0169 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0163 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0163 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0164 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0087 - val_mse: 0.0173 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0162 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0083 - mse: 0.0167 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0163 - val_loss: 0.0086 - val_mse: 0.0172 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0082 - mse: 0.0165 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0081 - mse: 0.0162 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01070629]\n",
            "\n",
            "Iteration No: 364 ended. Search finished for the next optimal point.\n",
            "Time taken: 60.1719\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 365 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [73, 105]\n",
            "Learning Rate: 0.07195207006972422\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3378796366134692\n",
            "Batch Size: 186\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 3311.2964 - mse: 952940224.0000 - val_loss: 0.0090 - val_mse: 0.0180 - 3s/epoch - 59ms/step\n",
            "46/46 - 0s - loss: 0.0112 - mse: 0.0225 - val_loss: 0.0086 - val_mse: 0.0172 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0088 - val_mse: 0.0176 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0090 - val_mse: 0.0179 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0095 - val_mse: 0.0190 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 313ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.01079683]\n",
            "\n",
            "Iteration No: 365 ended. Search finished for the next optimal point.\n",
            "Time taken: 61.5523\n",
            "Function value obtained: 0.0169\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 366 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [75, 107]\n",
            "Learning Rate: 0.0004471634320706066\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.32390660684683703\n",
            "Batch Size: 184\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 814.0259 - mse: 6814797.5000 - val_loss: 25.0462 - val_mse: 3331.6138 - 3s/epoch - 64ms/step\n",
            "46/46 - 0s - loss: 449.9506 - mse: 1898164.6250 - val_loss: 8.6802 - val_mse: 435.2247 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 289.4209 - mse: 840147.1875 - val_loss: 5.2665 - val_mse: 70.7895 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 208.8642 - mse: 401548.7188 - val_loss: 0.8451 - val_mse: 4.8208 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 166.6568 - mse: 265832.7188 - val_loss: 4.6745 - val_mse: 70.8797 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 127.2971 - mse: 165370.0781 - val_loss: 5.5774 - val_mse: 151.8568 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 98.7751 - mse: 101623.7500 - val_loss: 9.7190 - val_mse: 579.8281 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 81.7597 - mse: 78221.1719 - val_loss: 3.7093 - val_mse: 98.4485 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 61.2131 - mse: 39192.7812 - val_loss: 2.7693 - val_mse: 55.7577 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 51.5615 - mse: 29328.2383 - val_loss: 0.6215 - val_mse: 4.4292 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 43.8171 - mse: 19782.6719 - val_loss: 0.2229 - val_mse: 0.4489 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 34.8691 - mse: 12329.8447 - val_loss: 0.4726 - val_mse: 2.6450 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 29.0966 - mse: 9160.3652 - val_loss: 0.2225 - val_mse: 0.5996 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 23.7716 - mse: 6565.8340 - val_loss: 0.1296 - val_mse: 0.2593 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 20.4631 - mse: 5033.1035 - val_loss: 0.1365 - val_mse: 0.2955 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 17.5760 - mse: 4306.5366 - val_loss: 0.0864 - val_mse: 0.1727 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 14.6054 - mse: 3267.5789 - val_loss: 0.0863 - val_mse: 0.1727 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 12.2797 - mse: 2350.4043 - val_loss: 0.0758 - val_mse: 0.1516 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 9.9566 - mse: 1705.2886 - val_loss: 0.0683 - val_mse: 0.1367 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 8.5657 - mse: 1488.4188 - val_loss: 0.0616 - val_mse: 0.1233 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 7.4943 - mse: 1250.5961 - val_loss: 0.0443 - val_mse: 0.0885 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 6.1742 - mse: 858.2976 - val_loss: 0.0345 - val_mse: 0.0690 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 6.0907 - mse: 1095.6169 - val_loss: 0.0172 - val_mse: 0.0345 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 4.0563 - mse: 455.7600 - val_loss: 0.0123 - val_mse: 0.0246 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 4.4622 - mse: 508.0325 - val_loss: 0.0100 - val_mse: 0.0200 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.9259 - mse: 545.3341 - val_loss: 0.0088 - val_mse: 0.0177 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.1944 - mse: 408.7501 - val_loss: 0.0085 - val_mse: 0.0170 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.3445 - mse: 449.7428 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.6698 - mse: 301.5316 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.3269 - mse: 257.4600 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.3236 - mse: 309.1662 - val_loss: 0.0084 - val_mse: 0.0168 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.0419 - mse: 199.2597 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.8478 - mse: 186.9814 - val_loss: 0.0084 - val_mse: 0.0169 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.6931 - mse: 142.9579 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.7528 - mse: 252.9863 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.5823 - mse: 232.1411 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.4580 - mse: 172.5221 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.1793 - mse: 147.2082 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.1709 - mse: 81.1321 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.0347 - mse: 86.2094 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.0820 - mse: 132.4899 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.8768 - mse: 60.8669 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.9478 - mse: 85.4441 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.8226 - mse: 51.7038 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7162 - mse: 39.7987 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.6825 - mse: 34.6108 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7675 - mse: 46.5653 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5655 - mse: 29.9500 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.6817 - mse: 65.6363 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5860 - mse: 36.0151 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5831 - mse: 47.1051 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5694 - mse: 39.3473 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5170 - mse: 38.2687 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5390 - mse: 44.4463 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4240 - mse: 28.7904 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4982 - mse: 54.5679 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4260 - mse: 24.5461 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3115 - mse: 14.4159 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4249 - mse: 46.4300 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4638 - mse: 43.0751 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3785 - mse: 22.5277 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3456 - mse: 36.4341 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3231 - mse: 18.5745 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2934 - mse: 11.7781 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2733 - mse: 10.0981 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3034 - mse: 17.0342 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3149 - mse: 22.0865 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3226 - mse: 37.7368 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2628 - mse: 11.6652 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3172 - mse: 19.0423 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2525 - mse: 10.5163 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2708 - mse: 43.3591 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2625 - mse: 20.5111 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1850 - mse: 11.4092 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2340 - mse: 20.4685 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1909 - mse: 6.2721 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1798 - mse: 7.8349 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1712 - mse: 5.7595 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2534 - mse: 19.4672 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1686 - mse: 7.2294 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2132 - mse: 14.0785 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1724 - mse: 12.1898 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1757 - mse: 9.2713 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2391 - mse: 25.6605 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1421 - mse: 6.0995 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1392 - mse: 3.0549 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1176 - mse: 4.1842 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1897 - mse: 12.6557 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1752 - mse: 12.8152 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1294 - mse: 8.3675 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0928 - mse: 3.3829 - val_loss: 0.0084 - val_mse: 0.0168 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1076 - mse: 6.5833 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1136 - mse: 3.3318 - val_loss: 0.0084 - val_mse: 0.0168 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1406 - mse: 15.0156 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0918 - mse: 2.6641 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0958 - mse: 6.2649 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1356 - mse: 11.1118 - val_loss: 0.0084 - val_mse: 0.0168 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0955 - mse: 3.2879 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0911 - mse: 2.8001 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1077 - mse: 21.3152 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 366 ended. Search finished for the next optimal point.\n",
            "Time taken: 58.7041\n",
            "Function value obtained: 0.0168\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 367 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [81, 99]\n",
            "Learning Rate: 0.09459324334779771\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.37444060177838373\n",
            "Batch Size: 188\n",
            "----------------------------------------\n",
            "45/45 - 3s - loss: 12523.9277 - mse: 21510381568.0000 - val_loss: 0.0094 - val_mse: 0.0188 - 3s/epoch - 58ms/step\n",
            "45/45 - 0s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0174 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0169 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 283ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0093 - val_mse: 0.0187 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 273ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 265ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 268ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0173 - 272ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0086 - val_mse: 0.0172 - 278ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 260ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 6ms/step\n",
            "45/45 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 834ms/epoch - 19ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 285ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0175 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 284ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 294ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0087 - val_mse: 0.0174 - 305ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 304ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 300ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 308ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 300ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0169 - 311ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 296ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 299ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 299ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 316ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 310ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0173 - 298ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 298ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 306ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 297ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 304ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 306ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0089 - val_mse: 0.0179 - 294ms/epoch - 7ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0093 - val_mse: 0.0186 - 291ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "45/45 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 278ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.01086431]\n",
            "\n",
            "Iteration No: 367 ended. Search finished for the next optimal point.\n",
            "Time taken: 62.1186\n",
            "Function value obtained: 0.0168\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 368 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [106, 107]\n",
            "Learning Rate: 0.0010404343261794194\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4583289809615259\n",
            "Batch Size: 62\n",
            "----------------------------------------\n",
            "136/136 - 3s - loss: 550.4554 - mse: 3907195.2500 - val_loss: 4.2105 - val_mse: 84.1155 - 3s/epoch - 24ms/step\n",
            "136/136 - 1s - loss: 117.4416 - mse: 173234.8594 - val_loss: 0.3958 - val_mse: 1.4351 - 672ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 48.5735 - mse: 30826.9121 - val_loss: 0.1597 - val_mse: 0.3193 - 650ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 22.0469 - mse: 7376.9297 - val_loss: 0.0849 - val_mse: 0.1698 - 668ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 11.3520 - mse: 2665.2134 - val_loss: 0.0223 - val_mse: 0.0447 - 712ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 7.0080 - mse: 1740.0266 - val_loss: 0.0100 - val_mse: 0.0200 - 711ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 4.3839 - mse: 592.9172 - val_loss: 0.0084 - val_mse: 0.0168 - 702ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 3.0453 - mse: 415.3742 - val_loss: 0.0084 - val_mse: 0.0167 - 687ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1.8638 - mse: 155.6043 - val_loss: 0.0084 - val_mse: 0.0167 - 678ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1.6859 - mse: 260.7393 - val_loss: 0.0084 - val_mse: 0.0167 - 687ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 1.3176 - mse: 232.4162 - val_loss: 0.0084 - val_mse: 0.0167 - 707ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.9115 - mse: 80.2591 - val_loss: 0.0084 - val_mse: 0.0167 - 682ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.8038 - mse: 125.1292 - val_loss: 0.0084 - val_mse: 0.0167 - 700ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.5843 - mse: 35.4161 - val_loss: 0.0084 - val_mse: 0.0167 - 711ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.5223 - mse: 31.0538 - val_loss: 0.0084 - val_mse: 0.0167 - 684ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.5100 - mse: 68.2140 - val_loss: 0.0084 - val_mse: 0.0167 - 670ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.3383 - mse: 23.0482 - val_loss: 0.0084 - val_mse: 0.0168 - 653ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.4169 - mse: 51.9308 - val_loss: 0.0085 - val_mse: 0.0169 - 675ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.3133 - mse: 21.8303 - val_loss: 0.0084 - val_mse: 0.0168 - 674ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.2437 - mse: 12.3877 - val_loss: 0.0085 - val_mse: 0.0169 - 684ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1922 - mse: 7.5285 - val_loss: 0.0084 - val_mse: 0.0168 - 701ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.2967 - mse: 68.8339 - val_loss: 0.0084 - val_mse: 0.0167 - 697ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1138 - mse: 3.5571 - val_loss: 0.0084 - val_mse: 0.0168 - 701ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1745 - mse: 8.2120 - val_loss: 0.0084 - val_mse: 0.0167 - 698ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.2014 - mse: 14.3862 - val_loss: 0.0084 - val_mse: 0.0168 - 662ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0880 - mse: 2.4033 - val_loss: 0.0084 - val_mse: 0.0167 - 719ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1607 - mse: 11.7891 - val_loss: 0.0084 - val_mse: 0.0168 - 694ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1150 - mse: 4.4136 - val_loss: 0.0084 - val_mse: 0.0168 - 685ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1404 - mse: 13.3544 - val_loss: 0.0084 - val_mse: 0.0168 - 672ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0983 - mse: 3.3054 - val_loss: 0.0084 - val_mse: 0.0169 - 685ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0613 - mse: 1.4547 - val_loss: 0.0084 - val_mse: 0.0168 - 693ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0695 - mse: 2.4516 - val_loss: 0.0084 - val_mse: 0.0168 - 689ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0724 - mse: 3.3255 - val_loss: 0.0084 - val_mse: 0.0168 - 705ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0699 - mse: 2.6350 - val_loss: 0.0084 - val_mse: 0.0169 - 701ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.1201 - mse: 18.9075 - val_loss: 0.0084 - val_mse: 0.0168 - 695ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0940 - mse: 5.2171 - val_loss: 0.0084 - val_mse: 0.0168 - 676ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0244 - mse: 0.1867 - val_loss: 0.0084 - val_mse: 0.0168 - 687ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0373 - mse: 0.6609 - val_loss: 0.0084 - val_mse: 0.0167 - 715ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0162 - mse: 0.0714 - val_loss: 0.0084 - val_mse: 0.0167 - 700ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0481 - mse: 3.3590 - val_loss: 0.0084 - val_mse: 0.0168 - 726ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0503 - mse: 2.4041 - val_loss: 0.0084 - val_mse: 0.0168 - 719ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0259 - mse: 0.2301 - val_loss: 0.0084 - val_mse: 0.0168 - 662ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0374 - mse: 1.2770 - val_loss: 0.0084 - val_mse: 0.0168 - 645ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0411 - mse: 1.2597 - val_loss: 0.0084 - val_mse: 0.0167 - 651ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0384 - mse: 3.5245 - val_loss: 0.0084 - val_mse: 0.0168 - 667ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0257 - mse: 0.2150 - val_loss: 0.0084 - val_mse: 0.0167 - 668ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0359 - mse: 0.4920 - val_loss: 0.0084 - val_mse: 0.0167 - 657ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0370 - mse: 1.5507 - val_loss: 0.0084 - val_mse: 0.0167 - 655ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0479 - mse: 5.4028 - val_loss: 0.0084 - val_mse: 0.0167 - 646ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0335 - mse: 0.9200 - val_loss: 0.0084 - val_mse: 0.0167 - 661ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0185 - mse: 0.1494 - val_loss: 0.0084 - val_mse: 0.0167 - 660ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0117 - mse: 0.0324 - val_loss: 0.0084 - val_mse: 0.0167 - 662ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0229 - mse: 0.3992 - val_loss: 0.0084 - val_mse: 0.0167 - 665ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0141 - mse: 0.0551 - val_loss: 0.0084 - val_mse: 0.0167 - 658ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0189 - mse: 0.2341 - val_loss: 0.0084 - val_mse: 0.0167 - 696ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0126 - mse: 0.0561 - val_loss: 0.0084 - val_mse: 0.0167 - 685ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0160 - mse: 0.1180 - val_loss: 0.0084 - val_mse: 0.0167 - 679ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0197 - mse: 0.3522 - val_loss: 0.0084 - val_mse: 0.0167 - 681ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0126 - mse: 0.0350 - val_loss: 0.0084 - val_mse: 0.0168 - 684ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0164 - mse: 0.1589 - val_loss: 0.0084 - val_mse: 0.0167 - 674ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0253 - mse: 1.3859 - val_loss: 0.0084 - val_mse: 0.0168 - 687ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0169 - mse: 0.2200 - val_loss: 0.0084 - val_mse: 0.0168 - 684ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0128 - mse: 0.0602 - val_loss: 0.0084 - val_mse: 0.0167 - 675ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0209 - mse: 0.4788 - val_loss: 0.0084 - val_mse: 0.0168 - 679ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0136 - mse: 0.1980 - val_loss: 0.0084 - val_mse: 0.0167 - 667ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0099 - mse: 0.0219 - val_loss: 0.0084 - val_mse: 0.0167 - 666ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0131 - mse: 0.0680 - val_loss: 0.0084 - val_mse: 0.0167 - 677ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0188 - mse: 0.2871 - val_loss: 0.0084 - val_mse: 0.0167 - 668ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 645ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 669ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0099 - mse: 0.0245 - val_loss: 0.0084 - val_mse: 0.0167 - 691ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0092 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 690ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0107 - mse: 0.0300 - val_loss: 0.0084 - val_mse: 0.0167 - 708ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0106 - mse: 0.0339 - val_loss: 0.0084 - val_mse: 0.0167 - 697ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0181 - mse: 0.3573 - val_loss: 0.0084 - val_mse: 0.0167 - 659ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0107 - mse: 0.0380 - val_loss: 0.0084 - val_mse: 0.0167 - 661ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0106 - mse: 0.0362 - val_loss: 0.0084 - val_mse: 0.0167 - 660ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0166 - mse: 0.2038 - val_loss: 0.0084 - val_mse: 0.0167 - 675ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0096 - mse: 0.0211 - val_loss: 0.0084 - val_mse: 0.0167 - 707ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0153 - mse: 0.2277 - val_loss: 0.0084 - val_mse: 0.0167 - 682ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0124 - mse: 0.0831 - val_loss: 0.0084 - val_mse: 0.0167 - 671ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0114 - mse: 0.0763 - val_loss: 0.0084 - val_mse: 0.0168 - 694ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 695ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0106 - mse: 0.0315 - val_loss: 0.0084 - val_mse: 0.0167 - 693ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 696ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 699ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0096 - mse: 0.0227 - val_loss: 0.0084 - val_mse: 0.0167 - 697ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0092 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 713ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 700ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0088 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 731ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 710ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0091 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 670ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 670ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 692ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0092 - mse: 0.0211 - val_loss: 0.0084 - val_mse: 0.0167 - 684ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 668ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 680ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0167 - mse: 0.3286 - val_loss: 0.0084 - val_mse: 0.0167 - 668ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0097 - mse: 0.0219 - val_loss: 0.0084 - val_mse: 0.0167 - 689ms/epoch - 5ms/step\n",
            "136/136 - 1s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 665ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.37419483]\n",
            "\n",
            "Iteration No: 368 ended. Search finished for the next optimal point.\n",
            "Time taken: 101.5218\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 369 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [79, 107]\n",
            "Learning Rate: 0.0051571395297743735\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.33246411314993035\n",
            "Batch Size: 184\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 225.3772 - mse: 1111999.7500 - val_loss: 0.3157 - val_mse: 0.7464 - 3s/epoch - 62ms/step\n",
            "46/46 - 0s - loss: 7.2570 - mse: 760.2909 - val_loss: 0.1207 - val_mse: 0.2414 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.2158 - mse: 152.4338 - val_loss: 0.0335 - val_mse: 0.0669 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.1416 - mse: 44.8008 - val_loss: 0.0043 - val_mse: 0.0086 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7600 - mse: 32.8435 - val_loss: 0.0098 - val_mse: 0.0197 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5164 - mse: 55.9347 - val_loss: 0.0061 - val_mse: 0.0122 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3848 - mse: 9.3777 - val_loss: 0.0066 - val_mse: 0.0133 - 301ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.2854 - mse: 5.6812 - val_loss: 0.0070 - val_mse: 0.0141 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2180 - mse: 4.7088 - val_loss: 0.0086 - val_mse: 0.0172 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1473 - mse: 2.5898 - val_loss: 0.0086 - val_mse: 0.0171 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1838 - mse: 10.0360 - val_loss: 0.0084 - val_mse: 0.0169 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1081 - mse: 1.4716 - val_loss: 0.0084 - val_mse: 0.0169 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0709 - mse: 0.8231 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0894 - mse: 1.6555 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0953 - mse: 3.1051 - val_loss: 0.0084 - val_mse: 0.0169 - 311ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0662 - mse: 0.8287 - val_loss: 0.0084 - val_mse: 0.0169 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0610 - mse: 1.4663 - val_loss: 0.0084 - val_mse: 0.0168 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0946 - mse: 11.5807 - val_loss: 0.0084 - val_mse: 0.0169 - 310ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0806 - mse: 5.6762 - val_loss: 0.0078 - val_mse: 0.0157 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0499 - mse: 0.8182 - val_loss: 0.0078 - val_mse: 0.0157 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0440 - mse: 1.0450 - val_loss: 0.0085 - val_mse: 0.0169 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0462 - mse: 0.6100 - val_loss: 0.0085 - val_mse: 0.0171 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0386 - mse: 0.4571 - val_loss: 0.0085 - val_mse: 0.0169 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0475 - mse: 3.6504 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0452 - mse: 0.7507 - val_loss: 0.0084 - val_mse: 0.0169 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0250 - mse: 0.1882 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0408 - mse: 1.5016 - val_loss: 0.0085 - val_mse: 0.0170 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0345 - mse: 0.5206 - val_loss: 0.0077 - val_mse: 0.0155 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0239 - mse: 0.1266 - val_loss: 0.0079 - val_mse: 0.0157 - 297ms/epoch - 6ms/step\n",
            "46/46 - 1s - loss: 0.0199 - mse: 0.1208 - val_loss: 0.0080 - val_mse: 0.0160 - 929ms/epoch - 20ms/step\n",
            "46/46 - 0s - loss: 0.0287 - mse: 1.0234 - val_loss: 0.0085 - val_mse: 0.0171 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0320 - mse: 0.3445 - val_loss: 0.0085 - val_mse: 0.0169 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0237 - mse: 0.1823 - val_loss: 0.0085 - val_mse: 0.0170 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0237 - mse: 0.3586 - val_loss: 0.0085 - val_mse: 0.0170 - 317ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0217 - mse: 0.1764 - val_loss: 0.0085 - val_mse: 0.0170 - 315ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0234 - mse: 0.4093 - val_loss: 0.0086 - val_mse: 0.0172 - 313ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0185 - mse: 0.1179 - val_loss: 0.0085 - val_mse: 0.0170 - 320ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0160 - mse: 0.1130 - val_loss: 0.0085 - val_mse: 0.0170 - 334ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0242 - mse: 0.4913 - val_loss: 0.0084 - val_mse: 0.0169 - 315ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0167 - mse: 0.0825 - val_loss: 0.0087 - val_mse: 0.0173 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0126 - mse: 0.0368 - val_loss: 0.0087 - val_mse: 0.0174 - 313ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0218 - mse: 0.1598 - val_loss: 0.0086 - val_mse: 0.0173 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0172 - mse: 0.1407 - val_loss: 0.0086 - val_mse: 0.0172 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0181 - mse: 0.2238 - val_loss: 0.0071 - val_mse: 0.0142 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0196 - mse: 0.2483 - val_loss: 0.0069 - val_mse: 0.0137 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0216 - mse: 0.3174 - val_loss: 0.0067 - val_mse: 0.0134 - 311ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0189 - mse: 0.1684 - val_loss: 0.0067 - val_mse: 0.0133 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0188 - mse: 0.1174 - val_loss: 0.0066 - val_mse: 0.0131 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0142 - mse: 0.0478 - val_loss: 0.0065 - val_mse: 0.0131 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0143 - mse: 0.1344 - val_loss: 0.0065 - val_mse: 0.0129 - 305ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0118 - mse: 0.0636 - val_loss: 0.0064 - val_mse: 0.0127 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0157 - mse: 0.2008 - val_loss: 0.0063 - val_mse: 0.0126 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0142 - mse: 0.0810 - val_loss: 0.0063 - val_mse: 0.0127 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0118 - mse: 0.0395 - val_loss: 0.0064 - val_mse: 0.0128 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0277 - mse: 2.5062 - val_loss: 0.0064 - val_mse: 0.0128 - 300ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0137 - mse: 0.0718 - val_loss: 0.0065 - val_mse: 0.0130 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0177 - mse: 0.2821 - val_loss: 0.0083 - val_mse: 0.0166 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0278 - mse: 1.5783 - val_loss: 0.0068 - val_mse: 0.0137 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0112 - mse: 0.0307 - val_loss: 0.0071 - val_mse: 0.0143 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0117 - mse: 0.0425 - val_loss: 0.0070 - val_mse: 0.0139 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0095 - mse: 0.0241 - val_loss: 0.0069 - val_mse: 0.0139 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0116 - mse: 0.0468 - val_loss: 0.0080 - val_mse: 0.0160 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0117 - mse: 0.0380 - val_loss: 0.0079 - val_mse: 0.0157 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0106 - mse: 0.0679 - val_loss: 0.0067 - val_mse: 0.0135 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0183 - mse: 0.5498 - val_loss: 0.0067 - val_mse: 0.0135 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0103 - mse: 0.0317 - val_loss: 0.0065 - val_mse: 0.0130 - 299ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0096 - mse: 0.0252 - val_loss: 0.0067 - val_mse: 0.0134 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0102 - mse: 0.0327 - val_loss: 0.0064 - val_mse: 0.0128 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0090 - mse: 0.0230 - val_loss: 0.0062 - val_mse: 0.0123 - 299ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0081 - mse: 0.0167 - val_loss: 0.0061 - val_mse: 0.0122 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0182 - mse: 0.7788 - val_loss: 0.0060 - val_mse: 0.0120 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0104 - mse: 0.0340 - val_loss: 0.0059 - val_mse: 0.0118 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0206 - val_loss: 0.0059 - val_mse: 0.0117 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0092 - mse: 0.0231 - val_loss: 0.0057 - val_mse: 0.0114 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0089 - mse: 0.0205 - val_loss: 0.0057 - val_mse: 0.0115 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0084 - mse: 0.0195 - val_loss: 0.0056 - val_mse: 0.0113 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0093 - mse: 0.0249 - val_loss: 0.0057 - val_mse: 0.0114 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0085 - mse: 0.0234 - val_loss: 0.0056 - val_mse: 0.0112 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0121 - mse: 0.0445 - val_loss: 0.0055 - val_mse: 0.0110 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0101 - mse: 0.0247 - val_loss: 0.0058 - val_mse: 0.0116 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0080 - mse: 0.0165 - val_loss: 0.0058 - val_mse: 0.0116 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0089 - mse: 0.0234 - val_loss: 0.0056 - val_mse: 0.0111 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0082 - mse: 0.0174 - val_loss: 0.0054 - val_mse: 0.0108 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0075 - mse: 0.0153 - val_loss: 0.0054 - val_mse: 0.0108 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0084 - mse: 0.0187 - val_loss: 0.0054 - val_mse: 0.0107 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0078 - mse: 0.0175 - val_loss: 0.0053 - val_mse: 0.0106 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0073 - mse: 0.0151 - val_loss: 0.0053 - val_mse: 0.0105 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0092 - mse: 0.0311 - val_loss: 0.0053 - val_mse: 0.0106 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0077 - mse: 0.0167 - val_loss: 0.0056 - val_mse: 0.0111 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0086 - mse: 0.0243 - val_loss: 0.0052 - val_mse: 0.0104 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0072 - mse: 0.0145 - val_loss: 0.0052 - val_mse: 0.0105 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0076 - mse: 0.0156 - val_loss: 0.0055 - val_mse: 0.0110 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0083 - mse: 0.0226 - val_loss: 0.0056 - val_mse: 0.0112 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0085 - mse: 0.0364 - val_loss: 0.0054 - val_mse: 0.0108 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0083 - mse: 0.0189 - val_loss: 0.0057 - val_mse: 0.0113 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0075 - mse: 0.0170 - val_loss: 0.0051 - val_mse: 0.0102 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0073 - mse: 0.0151 - val_loss: 0.0050 - val_mse: 0.0100 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0070 - mse: 0.0143 - val_loss: 0.0050 - val_mse: 0.0099 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0167 - mse: 0.3895 - val_loss: 0.0051 - val_mse: 0.0102 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0068 - mse: 0.0137 - val_loss: 0.0052 - val_mse: 0.0104 - 285ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.00031783]\n",
            "\n",
            "Iteration No: 369 ended. Search finished for the next optimal point.\n",
            "Time taken: 63.3606\n",
            "Function value obtained: 0.0104\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 370 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [81, 106]\n",
            "Learning Rate: 0.0011342369894229948\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.34165339308788073\n",
            "Batch Size: 185\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 597.6193 - mse: 3893428.2500 - val_loss: 35.1044 - val_mse: 6711.8223 - 3s/epoch - 59ms/step\n",
            "46/46 - 0s - loss: 189.5372 - mse: 363093.2812 - val_loss: 23.4159 - val_mse: 3020.7502 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 103.2804 - mse: 110345.3672 - val_loss: 5.1871 - val_mse: 134.5314 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 60.7329 - mse: 43727.2539 - val_loss: 0.8962 - val_mse: 3.8630 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 34.9902 - mse: 13694.6230 - val_loss: 0.1352 - val_mse: 0.2703 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 24.4248 - mse: 7291.7539 - val_loss: 0.1815 - val_mse: 0.4063 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 15.2585 - mse: 3252.2952 - val_loss: 0.1147 - val_mse: 0.2294 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 10.6457 - mse: 1899.5060 - val_loss: 0.0689 - val_mse: 0.1379 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 8.1553 - mse: 1462.2848 - val_loss: 0.0292 - val_mse: 0.0584 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 5.3702 - mse: 594.9494 - val_loss: 0.0122 - val_mse: 0.0244 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.7774 - mse: 386.1874 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.9721 - mse: 277.2303 - val_loss: 0.0089 - val_mse: 0.0178 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.7290 - mse: 401.6801 - val_loss: 0.0088 - val_mse: 0.0175 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 2.2586 - mse: 298.9381 - val_loss: 0.0086 - val_mse: 0.0171 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.8632 - mse: 142.7831 - val_loss: 0.0085 - val_mse: 0.0171 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.5029 - mse: 84.5454 - val_loss: 0.0084 - val_mse: 0.0169 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.4532 - mse: 219.1361 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.3609 - mse: 110.1388 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.2056 - mse: 113.6536 - val_loss: 0.0084 - val_mse: 0.0167 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.9267 - mse: 68.3603 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.7886 - mse: 42.9577 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7331 - mse: 33.1445 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7569 - mse: 78.3168 - val_loss: 0.0084 - val_mse: 0.0167 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.6274 - mse: 39.1887 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5488 - mse: 33.8194 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4473 - mse: 17.3540 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4573 - mse: 22.6933 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4568 - mse: 35.7490 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4786 - mse: 56.0843 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4224 - mse: 27.4356 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2912 - mse: 11.4836 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3726 - mse: 14.2424 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3000 - mse: 13.5604 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3184 - mse: 20.9486 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2241 - mse: 8.1143 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2381 - mse: 6.6230 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2134 - mse: 14.1898 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2539 - mse: 20.0220 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1381 - mse: 3.3568 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.2102 - mse: 7.5118 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1536 - mse: 5.4734 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1987 - mse: 8.4292 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1661 - mse: 6.9712 - val_loss: 0.0084 - val_mse: 0.0167 - 280ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1917 - mse: 13.3729 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1250 - mse: 4.6198 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1505 - mse: 6.8015 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1589 - mse: 19.5842 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1256 - mse: 4.6603 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1116 - mse: 5.8645 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1201 - mse: 5.6930 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1463 - mse: 10.1252 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1054 - mse: 8.1061 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1032 - mse: 3.2990 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0731 - mse: 1.3122 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1221 - mse: 6.6354 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1109 - mse: 20.5894 - val_loss: 0.0084 - val_mse: 0.0167 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1406 - mse: 14.6552 - val_loss: 0.0084 - val_mse: 0.0168 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0487 - mse: 0.9756 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1292 - mse: 36.8898 - val_loss: 0.0084 - val_mse: 0.0167 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.1455 - mse: 13.3022 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0803 - mse: 2.5889 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0474 - mse: 0.5143 - val_loss: 0.0084 - val_mse: 0.0167 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0943 - mse: 9.4129 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0743 - mse: 4.3910 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0567 - mse: 1.0504 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0429 - mse: 0.7440 - val_loss: 0.0084 - val_mse: 0.0167 - 278ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0670 - mse: 4.6981 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0681 - mse: 1.8481 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0503 - mse: 1.0587 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0399 - mse: 0.3381 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0487 - mse: 0.9602 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0443 - mse: 0.9982 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0516 - mse: 2.1343 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0495 - mse: 1.3340 - val_loss: 0.0084 - val_mse: 0.0167 - 281ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0407 - mse: 0.5846 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0769 - mse: 5.7716 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0328 - mse: 0.6329 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0368 - mse: 1.4614 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0328 - mse: 0.3909 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0233 - mse: 0.1715 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0300 - mse: 0.2463 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0301 - mse: 0.4744 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0861 - mse: 5.3066 - val_loss: 0.0084 - val_mse: 0.0167 - 293ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0222 - mse: 0.2207 - val_loss: 0.0084 - val_mse: 0.0167 - 284ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0415 - mse: 0.9641 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0247 - mse: 0.1372 - val_loss: 0.0084 - val_mse: 0.0167 - 288ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0430 - mse: 1.0710 - val_loss: 0.0084 - val_mse: 0.0167 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0173 - mse: 0.0876 - val_loss: 0.0084 - val_mse: 0.0167 - 303ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0409 - mse: 0.9568 - val_loss: 0.0084 - val_mse: 0.0168 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0259 - mse: 0.2487 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0218 - mse: 0.1720 - val_loss: 0.0084 - val_mse: 0.0167 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0173 - mse: 0.0654 - val_loss: 0.0084 - val_mse: 0.0167 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0291 - mse: 0.6850 - val_loss: 0.0084 - val_mse: 0.0167 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0333 - mse: 0.8587 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0594 - mse: 6.9062 - val_loss: 0.0084 - val_mse: 0.0167 - 282ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0148 - mse: 0.0434 - val_loss: 0.0084 - val_mse: 0.0167 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0388 - mse: 3.1911 - val_loss: 0.0084 - val_mse: 0.0167 - 299ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0328 - mse: 0.9593 - val_loss: 0.0084 - val_mse: 0.0167 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0242 - mse: 0.2504 - val_loss: 0.0084 - val_mse: 0.0167 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0178 - mse: 0.1124 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 370 ended. Search finished for the next optimal point.\n",
            "Time taken: 64.3636\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 371 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [32, 128, 48]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 1412.4528 - mse: 4390394880.0000 - val_loss: 0.0085 - val_mse: 0.0169 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0098 - mse: 0.0195 - val_loss: 0.0090 - val_mse: 0.0180 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0096 - mse: 0.0192 - val_loss: 0.0094 - val_mse: 0.0188 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0100 - mse: 0.0199 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0096 - mse: 0.0191 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0086 - val_mse: 0.0171 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0106 - val_mse: 0.0212 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0097 - val_mse: 0.0194 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0107 - val_mse: 0.0213 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0095 - val_mse: 0.0189 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0101 - val_mse: 0.0201 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0100 - val_mse: 0.0200 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0105 - val_mse: 0.0210 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0125 - val_mse: 0.0250 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0090 - val_mse: 0.0179 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0088 - val_mse: 0.0177 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0092 - val_mse: 0.0183 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0095 - val_mse: 0.0190 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0103 - val_mse: 0.0206 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0103 - val_mse: 0.0205 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0106 - val_mse: 0.0212 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0095 - val_mse: 0.0190 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0097 - val_mse: 0.0193 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0089 - val_mse: 0.0179 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0089 - val_mse: 0.0179 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0086 - val_mse: 0.0173 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0089 - val_mse: 0.0177 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0087 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0098 - val_mse: 0.0197 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0096 - val_mse: 0.0191 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0087 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0179 - val_loss: 0.0093 - val_mse: 0.0186 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0095 - mse: 0.0191 - val_loss: 0.0087 - val_mse: 0.0173 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0087 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0124 - val_mse: 0.0247 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0094 - val_mse: 0.0188 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0091 - val_mse: 0.0182 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0107 - val_mse: 0.0213 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0085 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0123 - val_mse: 0.0247 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0089 - val_mse: 0.0178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0088 - val_mse: 0.0176 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0089 - val_mse: 0.0178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0090 - val_mse: 0.0180 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0091 - val_mse: 0.0182 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0094 - mse: 0.0187 - val_loss: 0.0096 - val_mse: 0.0192 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0088 - val_mse: 0.0177 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0095 - mse: 0.0189 - val_loss: 0.0094 - val_mse: 0.0189 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0099 - val_mse: 0.0199 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0085 - val_mse: 0.0170 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0184 - val_loss: 0.0094 - val_mse: 0.0189 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0182 - val_loss: 0.0084 - val_mse: 0.0167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0085 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0186 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0183 - val_loss: 0.0084 - val_mse: 0.0168 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0087 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0086 - val_mse: 0.0172 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0096 - val_mse: 0.0192 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0093 - mse: 0.0185 - val_loss: 0.0088 - val_mse: 0.0175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0092 - mse: 0.0185 - val_loss: 0.0084 - val_mse: 0.0169 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [0.01105399]\n",
            "\n",
            "Iteration No: 371 ended. Search finished for the next optimal point.\n",
            "Time taken: 266.7340\n",
            "Function value obtained: 0.0169\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 372 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [119, 104]\n",
            "Learning Rate: 2.8341950380080272e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.44856748221459997\n",
            "Batch Size: 58\n",
            "----------------------------------------\n",
            "145/145 - 3s - loss: 1825.1261 - mse: 32179966.0000 - val_loss: 95.0167 - val_mse: 47681.6367 - 3s/epoch - 23ms/step\n",
            "145/145 - 1s - loss: 1446.8898 - mse: 20398924.0000 - val_loss: 18.5114 - val_mse: 2299.2886 - 690ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1240.7941 - mse: 14763726.0000 - val_loss: 20.7647 - val_mse: 2046.6781 - 695ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1174.9661 - mse: 13857158.0000 - val_loss: 81.5459 - val_mse: 34392.9531 - 685ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1069.6309 - mse: 10758528.0000 - val_loss: 74.6869 - val_mse: 28038.0898 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 969.0215 - mse: 8327975.5000 - val_loss: 52.3173 - val_mse: 13960.6670 - 673ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 929.0719 - mse: 8763930.0000 - val_loss: 68.0160 - val_mse: 23102.0234 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 894.4447 - mse: 8156783.5000 - val_loss: 42.0468 - val_mse: 8940.1348 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 795.7692 - mse: 5720180.5000 - val_loss: 27.4763 - val_mse: 3752.2771 - 653ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 754.0072 - mse: 6074987.5000 - val_loss: 26.7048 - val_mse: 3769.2185 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 698.8605 - mse: 4541183.0000 - val_loss: 35.0992 - val_mse: 6294.2319 - 646ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 645.9740 - mse: 3888801.0000 - val_loss: 36.2337 - val_mse: 6565.7812 - 654ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 628.3922 - mse: 3692069.0000 - val_loss: 35.1650 - val_mse: 6371.0503 - 682ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 589.1148 - mse: 3883669.5000 - val_loss: 41.6752 - val_mse: 9363.3145 - 681ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 549.9430 - mse: 2863869.5000 - val_loss: 37.6312 - val_mse: 7630.4209 - 666ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 505.7136 - mse: 2391069.0000 - val_loss: 17.5958 - val_mse: 2062.3594 - 673ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 498.1640 - mse: 2785285.0000 - val_loss: 1.6980 - val_mse: 13.9038 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 448.6580 - mse: 1874865.6250 - val_loss: 1.3520 - val_mse: 14.3396 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 435.1823 - mse: 2122581.2500 - val_loss: 0.2968 - val_mse: 0.6441 - 651ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 391.2269 - mse: 1491585.7500 - val_loss: 6.1956 - val_mse: 177.4444 - 657ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 370.6653 - mse: 1251489.5000 - val_loss: 2.3655 - val_mse: 21.0199 - 654ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 351.7745 - mse: 1176485.3750 - val_loss: 4.2073 - val_mse: 81.5391 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 331.9610 - mse: 1070160.6250 - val_loss: 3.0829 - val_mse: 49.5649 - 657ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 326.7643 - mse: 1079314.6250 - val_loss: 4.9834 - val_mse: 123.5625 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 296.0285 - mse: 869025.5625 - val_loss: 0.3806 - val_mse: 0.9689 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 282.3685 - mse: 731228.9375 - val_loss: 1.8252 - val_mse: 22.0283 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 260.1878 - mse: 635834.0625 - val_loss: 4.2776 - val_mse: 92.1757 - 688ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 246.0541 - mse: 545664.8125 - val_loss: 4.3329 - val_mse: 101.7314 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 243.9669 - mse: 634086.5000 - val_loss: 0.7330 - val_mse: 3.0432 - 670ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 225.5945 - mse: 473526.9062 - val_loss: 0.7227 - val_mse: 2.9479 - 696ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 208.9968 - mse: 423629.1562 - val_loss: 8.5060 - val_mse: 398.2991 - 693ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 198.2607 - mse: 382729.5000 - val_loss: 8.5364 - val_mse: 404.5980 - 690ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 190.3331 - mse: 429685.1562 - val_loss: 9.2087 - val_mse: 489.8272 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 172.0697 - mse: 272582.2188 - val_loss: 10.4863 - val_mse: 653.9113 - 653ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 165.2629 - mse: 272188.9062 - val_loss: 9.4412 - val_mse: 534.9525 - 661ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 152.0077 - mse: 223519.3438 - val_loss: 5.9246 - val_mse: 217.1322 - 668ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 146.2321 - mse: 205393.8906 - val_loss: 6.9838 - val_mse: 292.7320 - 664ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 135.3915 - mse: 184693.7656 - val_loss: 4.7823 - val_mse: 150.3142 - 641ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 138.7725 - mse: 202790.0156 - val_loss: 3.1178 - val_mse: 68.4447 - 645ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 130.3886 - mse: 175591.4375 - val_loss: 4.6172 - val_mse: 139.5117 - 643ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 120.7060 - mse: 144946.8281 - val_loss: 3.9883 - val_mse: 107.2440 - 656ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 110.1132 - mse: 117017.3359 - val_loss: 2.8760 - val_mse: 59.2235 - 646ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 105.2205 - mse: 126033.2031 - val_loss: 2.3858 - val_mse: 42.1054 - 642ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 101.2891 - mse: 106021.0469 - val_loss: 1.9749 - val_mse: 29.4798 - 645ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 91.6944 - mse: 81079.3047 - val_loss: 1.5974 - val_mse: 20.3581 - 649ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 91.0445 - mse: 86580.4531 - val_loss: 1.1316 - val_mse: 10.6253 - 656ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 81.0734 - mse: 62577.2812 - val_loss: 0.8794 - val_mse: 6.6234 - 673ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 78.6064 - mse: 64485.2656 - val_loss: 0.9530 - val_mse: 7.6835 - 682ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 70.8808 - mse: 47414.0273 - val_loss: 0.8067 - val_mse: 5.6467 - 683ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 72.7145 - mse: 65155.6367 - val_loss: 0.4709 - val_mse: 2.1076 - 718ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 68.7363 - mse: 60636.0781 - val_loss: 0.2024 - val_mse: 0.4375 - 665ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 64.6082 - mse: 50536.0156 - val_loss: 0.1917 - val_mse: 0.4036 - 659ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 60.4918 - mse: 38251.5898 - val_loss: 0.3598 - val_mse: 1.3353 - 663ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 54.9462 - mse: 28098.5312 - val_loss: 0.4759 - val_mse: 2.2493 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 52.5019 - mse: 30988.0762 - val_loss: 0.6553 - val_mse: 4.1192 - 652ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 50.3591 - mse: 27308.8848 - val_loss: 0.6592 - val_mse: 4.1098 - 655ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 45.8661 - mse: 23650.0820 - val_loss: 0.7599 - val_mse: 5.2244 - 651ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 45.7341 - mse: 27432.8418 - val_loss: 0.7098 - val_mse: 4.5841 - 650ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 41.1213 - mse: 18494.4668 - val_loss: 0.5401 - val_mse: 2.7440 - 638ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 39.1289 - mse: 18271.7676 - val_loss: 0.4589 - val_mse: 2.0011 - 639ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 39.1427 - mse: 20139.1367 - val_loss: 0.3542 - val_mse: 1.2137 - 633ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 35.1713 - mse: 13502.3438 - val_loss: 0.3192 - val_mse: 1.0275 - 642ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 32.6909 - mse: 12993.1348 - val_loss: 0.3013 - val_mse: 0.9098 - 1s/epoch - 8ms/step\n",
            "145/145 - 1s - loss: 31.2551 - mse: 11012.6963 - val_loss: 0.3253 - val_mse: 1.0532 - 705ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 28.9166 - mse: 10062.5615 - val_loss: 0.2655 - val_mse: 0.7150 - 694ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 26.4308 - mse: 8595.3750 - val_loss: 0.2366 - val_mse: 0.5835 - 714ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 26.7445 - mse: 8756.5703 - val_loss: 0.2240 - val_mse: 0.5353 - 693ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 24.3114 - mse: 7635.5503 - val_loss: 0.1974 - val_mse: 0.4349 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 22.0006 - mse: 6082.2754 - val_loss: 0.2038 - val_mse: 0.4567 - 682ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 21.2504 - mse: 5088.0210 - val_loss: 0.2069 - val_mse: 0.4718 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 20.1841 - mse: 5694.8120 - val_loss: 0.1895 - val_mse: 0.4105 - 674ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 18.9077 - mse: 4846.9663 - val_loss: 0.1724 - val_mse: 0.3548 - 683ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 18.0637 - mse: 4078.1033 - val_loss: 0.1661 - val_mse: 0.3381 - 670ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 16.6655 - mse: 3945.4993 - val_loss: 0.1577 - val_mse: 0.3163 - 685ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 15.2331 - mse: 2907.8953 - val_loss: 0.1545 - val_mse: 0.3096 - 688ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 14.4682 - mse: 3554.3230 - val_loss: 0.1518 - val_mse: 0.3039 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 13.4781 - mse: 2642.6267 - val_loss: 0.1483 - val_mse: 0.2967 - 682ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 12.9154 - mse: 3313.5713 - val_loss: 0.1466 - val_mse: 0.2932 - 680ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 11.9026 - mse: 2087.8628 - val_loss: 0.1457 - val_mse: 0.2915 - 686ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 10.8921 - mse: 2419.3469 - val_loss: 0.1439 - val_mse: 0.2878 - 716ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 10.4374 - mse: 1777.2859 - val_loss: 0.1415 - val_mse: 0.2830 - 703ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 9.9766 - mse: 3109.9492 - val_loss: 0.1380 - val_mse: 0.2760 - 712ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 8.8180 - mse: 1288.6183 - val_loss: 0.1335 - val_mse: 0.2670 - 683ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 8.5441 - mse: 1568.6119 - val_loss: 0.1293 - val_mse: 0.2586 - 678ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 7.4222 - mse: 972.9100 - val_loss: 0.1242 - val_mse: 0.2483 - 655ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 7.3914 - mse: 1064.7438 - val_loss: 0.1198 - val_mse: 0.2396 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 6.6586 - mse: 801.3898 - val_loss: 0.1143 - val_mse: 0.2287 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 6.4976 - mse: 933.8638 - val_loss: 0.1086 - val_mse: 0.2172 - 656ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 5.8506 - mse: 758.6996 - val_loss: 0.1033 - val_mse: 0.2065 - 657ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.9606 - mse: 488.3156 - val_loss: 0.0984 - val_mse: 0.1968 - 660ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.8433 - mse: 567.2324 - val_loss: 0.0932 - val_mse: 0.1864 - 659ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.5793 - mse: 439.7729 - val_loss: 0.0881 - val_mse: 0.1762 - 650ms/epoch - 4ms/step\n",
            "145/145 - 1s - loss: 4.7284 - mse: 685.2457 - val_loss: 0.0832 - val_mse: 0.1664 - 658ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.0029 - mse: 457.3147 - val_loss: 0.0787 - val_mse: 0.1574 - 654ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 4.0283 - mse: 440.6041 - val_loss: 0.0743 - val_mse: 0.1486 - 662ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 3.4404 - mse: 357.1221 - val_loss: 0.0698 - val_mse: 0.1395 - 670ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2.9969 - mse: 232.4471 - val_loss: 0.0654 - val_mse: 0.1307 - 687ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 3.0551 - mse: 409.9202 - val_loss: 0.0611 - val_mse: 0.1222 - 690ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2.8292 - mse: 400.5917 - val_loss: 0.0571 - val_mse: 0.1141 - 696ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 2.6565 - mse: 266.2406 - val_loss: 0.0530 - val_mse: 0.1061 - 695ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 372 ended. Search finished for the next optimal point.\n",
            "Time taken: 100.1410\n",
            "Function value obtained: 0.1061\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 373 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 128, 51]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 120189.6797 - mse: 2761782460416.0000 - val_loss: 0.0091 - val_mse: 0.0182 - 3s/epoch - 102ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0088 - val_mse: 0.0176 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 254ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0171 - 256ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0174 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0168 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 249ms/epoch - 8ms/step\n",
            "\n",
            "Predicted Performance: [0.01073371]\n",
            "\n",
            "Iteration No: 373 ended. Search finished for the next optimal point.\n",
            "Time taken: 58.3847\n",
            "Function value obtained: 0.0171\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 374 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [32, 32, 66]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 53.6132 - mse: 25221.2852 - val_loss: 0.5084 - val_mse: 1.2861 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 0.5249 - mse: 1.3231 - val_loss: 0.5004 - val_mse: 1.2469 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5285 - mse: 1.3987 - val_loss: 0.4987 - val_mse: 1.3212 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5139 - mse: 1.3474 - val_loss: 0.4826 - val_mse: 1.0984 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5098 - mse: 1.3655 - val_loss: 0.5101 - val_mse: 1.1087 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5014 - mse: 1.3234 - val_loss: 0.4626 - val_mse: 1.0984 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4817 - mse: 1.2073 - val_loss: 0.4959 - val_mse: 1.5747 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4702 - mse: 1.2110 - val_loss: 0.3813 - val_mse: 0.8383 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.3629 - mse: 0.8307 - val_loss: 0.5584 - val_mse: 1.2586 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3525 - mse: 0.8156 - val_loss: 0.3852 - val_mse: 0.7789 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3395 - mse: 0.7659 - val_loss: 0.3538 - val_mse: 0.7114 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3344 - mse: 0.7610 - val_loss: 0.3077 - val_mse: 0.6233 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3245 - mse: 0.7268 - val_loss: 0.2975 - val_mse: 0.6153 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3198 - mse: 0.7196 - val_loss: 0.3201 - val_mse: 0.6415 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3024 - mse: 0.6597 - val_loss: 0.2880 - val_mse: 0.6302 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3004 - mse: 0.6645 - val_loss: 0.2904 - val_mse: 0.6824 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2855 - mse: 0.6351 - val_loss: 0.2436 - val_mse: 0.5087 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2565 - mse: 0.5446 - val_loss: 0.2502 - val_mse: 0.5510 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2495 - mse: 0.5388 - val_loss: 0.2544 - val_mse: 0.5818 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2447 - mse: 0.5250 - val_loss: 0.2280 - val_mse: 0.4766 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2392 - mse: 0.5136 - val_loss: 0.2401 - val_mse: 0.5379 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2347 - mse: 0.5094 - val_loss: 0.2110 - val_mse: 0.4281 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2311 - mse: 0.4985 - val_loss: 0.2304 - val_mse: 0.4612 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2241 - mse: 0.4835 - val_loss: 0.1992 - val_mse: 0.3990 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2141 - mse: 0.4495 - val_loss: 0.1990 - val_mse: 0.3981 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.2198 - mse: 0.4767 - val_loss: 0.1898 - val_mse: 0.3798 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2063 - mse: 0.4392 - val_loss: 0.1882 - val_mse: 0.3766 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 0.2086 - mse: 0.4447 - val_loss: 0.1855 - val_mse: 0.3790 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1953 - mse: 0.4203 - val_loss: 0.1910 - val_mse: 0.4022 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.2056 - mse: 0.4426 - val_loss: 0.1702 - val_mse: 0.3413 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1779 - mse: 0.3657 - val_loss: 0.1759 - val_mse: 0.3520 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1807 - mse: 0.3795 - val_loss: 0.1628 - val_mse: 0.3257 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1780 - mse: 0.3680 - val_loss: 0.1595 - val_mse: 0.3208 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1820 - mse: 0.3896 - val_loss: 0.1869 - val_mse: 0.4111 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.1666 - mse: 0.3435 - val_loss: 0.1966 - val_mse: 0.4511 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1728 - mse: 0.3766 - val_loss: 0.1654 - val_mse: 0.3309 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1602 - mse: 0.3338 - val_loss: 0.1407 - val_mse: 0.2816 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.1494 - mse: 0.3044 - val_loss: 0.1694 - val_mse: 0.3655 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.1434 - mse: 0.2901 - val_loss: 0.1398 - val_mse: 0.2815 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.1512 - mse: 0.3154 - val_loss: 0.1525 - val_mse: 0.3052 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1617 - mse: 0.3495 - val_loss: 0.1285 - val_mse: 0.2574 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1497 - mse: 0.3144 - val_loss: 0.1243 - val_mse: 0.2488 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1314 - mse: 0.2676 - val_loss: 0.1255 - val_mse: 0.2512 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1395 - mse: 0.2907 - val_loss: 0.1167 - val_mse: 0.2336 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1291 - mse: 0.2663 - val_loss: 0.1200 - val_mse: 0.2410 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1345 - mse: 0.2796 - val_loss: 0.1247 - val_mse: 0.2527 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1366 - mse: 0.2937 - val_loss: 0.1219 - val_mse: 0.2438 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1209 - mse: 0.2524 - val_loss: 0.1044 - val_mse: 0.2089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1273 - mse: 0.2686 - val_loss: 0.1047 - val_mse: 0.2097 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1082 - mse: 0.2323 - val_loss: 0.0953 - val_mse: 0.1912 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0922 - mse: 0.1866 - val_loss: 0.0818 - val_mse: 0.1638 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0938 - mse: 0.1939 - val_loss: 0.1274 - val_mse: 0.2650 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0941 - mse: 0.1948 - val_loss: 0.0785 - val_mse: 0.1570 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0861 - mse: 0.1750 - val_loss: 0.0728 - val_mse: 0.1457 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0905 - mse: 0.1965 - val_loss: 0.1393 - val_mse: 0.3180 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0842 - mse: 0.1797 - val_loss: 0.0768 - val_mse: 0.1537 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0801 - mse: 0.1634 - val_loss: 0.0723 - val_mse: 0.1447 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0758 - mse: 0.1543 - val_loss: 0.0631 - val_mse: 0.1261 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0807 - mse: 0.1681 - val_loss: 0.0674 - val_mse: 0.1347 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0745 - mse: 0.1539 - val_loss: 0.0655 - val_mse: 0.1310 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0664 - mse: 0.1335 - val_loss: 0.0593 - val_mse: 0.1186 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0780 - mse: 0.1672 - val_loss: 0.0584 - val_mse: 0.1167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0746 - mse: 0.1584 - val_loss: 0.0545 - val_mse: 0.1089 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0620 - mse: 0.1256 - val_loss: 0.0538 - val_mse: 0.1075 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0626 - mse: 0.1290 - val_loss: 0.0565 - val_mse: 0.1131 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0667 - mse: 0.1420 - val_loss: 0.0481 - val_mse: 0.0962 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0594 - mse: 0.1236 - val_loss: 0.0523 - val_mse: 0.1045 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0706 - mse: 0.1555 - val_loss: 0.0425 - val_mse: 0.0849 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0574 - mse: 0.1199 - val_loss: 0.0404 - val_mse: 0.0807 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0560 - mse: 0.1197 - val_loss: 0.0491 - val_mse: 0.0983 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0598 - mse: 0.1284 - val_loss: 0.0373 - val_mse: 0.0745 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0476 - mse: 0.1029 - val_loss: 0.0554 - val_mse: 0.1125 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0645 - mse: 0.1433 - val_loss: 0.0396 - val_mse: 0.0792 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0556 - mse: 0.1226 - val_loss: 0.1138 - val_mse: 0.2743 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0522 - mse: 0.1195 - val_loss: 0.0311 - val_mse: 0.0623 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0563 - mse: 0.1295 - val_loss: 0.0631 - val_mse: 0.1292 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0612 - mse: 0.1520 - val_loss: 0.0550 - val_mse: 0.1116 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0352 - mse: 0.0708 - val_loss: 0.0283 - val_mse: 0.0567 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0519 - mse: 0.1184 - val_loss: 0.0267 - val_mse: 0.0534 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0414 - mse: 0.0860 - val_loss: 0.1095 - val_mse: 0.2548 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0434 - mse: 0.0915 - val_loss: 0.0672 - val_mse: 0.1416 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0495 - mse: 0.1077 - val_loss: 0.0297 - val_mse: 0.0594 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0556 - mse: 0.1372 - val_loss: 0.0244 - val_mse: 0.0488 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0489 - mse: 0.1077 - val_loss: 0.1140 - val_mse: 0.2876 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0373 - mse: 0.0772 - val_loss: 0.0248 - val_mse: 0.0497 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0394 - mse: 0.0855 - val_loss: 0.0254 - val_mse: 0.0508 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0540 - mse: 0.1187 - val_loss: 0.0242 - val_mse: 0.0484 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0390 - mse: 0.0839 - val_loss: 0.0223 - val_mse: 0.0447 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0470 - mse: 0.1153 - val_loss: 0.0848 - val_mse: 0.1883 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0506 - mse: 0.1167 - val_loss: 0.0243 - val_mse: 0.0487 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0480 - mse: 0.1106 - val_loss: 0.0218 - val_mse: 0.0436 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0515 - mse: 0.1226 - val_loss: 0.0267 - val_mse: 0.0536 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0377 - mse: 0.0792 - val_loss: 0.0325 - val_mse: 0.0650 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0371 - mse: 0.0800 - val_loss: 0.0837 - val_mse: 0.1850 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0423 - mse: 0.0998 - val_loss: 0.0245 - val_mse: 0.0491 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0406 - mse: 0.0901 - val_loss: 0.0299 - val_mse: 0.0598 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0429 - mse: 0.0962 - val_loss: 0.0590 - val_mse: 0.1332 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0383 - mse: 0.0846 - val_loss: 0.0622 - val_mse: 0.1313 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0332 - mse: 0.0713 - val_loss: 0.0249 - val_mse: 0.0498 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0468 - mse: 0.1061 - val_loss: 0.0240 - val_mse: 0.0481 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [1.65359807]\n",
            "\n",
            "Iteration No: 374 ended. Search finished for the next optimal point.\n",
            "Time taken: 265.0262\n",
            "Function value obtained: 0.0481\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 375 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 32, 128]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 186.5758 - mse: 178842.5469 - val_loss: 129.0201 - val_mse: 86009.9453 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 100.9750 - mse: 52581.4844 - val_loss: 70.1477 - val_mse: 25771.8496 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 56.3772 - mse: 16827.5977 - val_loss: 38.9011 - val_mse: 8144.5864 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 29.9038 - mse: 4838.3203 - val_loss: 18.7257 - val_mse: 1973.6384 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 5.9996 - mse: 476.3858 - val_loss: 0.2636 - val_mse: 0.5391 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2524 - mse: 0.5075 - val_loss: 0.2465 - val_mse: 0.4961 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2313 - mse: 0.4640 - val_loss: 0.2233 - val_mse: 0.4470 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2152 - mse: 0.4307 - val_loss: 0.2076 - val_mse: 0.4152 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2028 - mse: 0.4059 - val_loss: 0.1993 - val_mse: 0.3990 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1983 - mse: 0.3971 - val_loss: 0.1959 - val_mse: 0.3918 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1943 - mse: 0.3892 - val_loss: 0.1934 - val_mse: 0.3871 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1906 - mse: 0.3817 - val_loss: 0.1884 - val_mse: 0.3776 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1864 - mse: 0.3733 - val_loss: 0.1879 - val_mse: 0.3758 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1820 - mse: 0.3646 - val_loss: 0.1816 - val_mse: 0.3646 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1786 - mse: 0.3580 - val_loss: 0.1734 - val_mse: 0.3478 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1717 - mse: 0.3441 - val_loss: 0.1674 - val_mse: 0.3350 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1638 - mse: 0.3282 - val_loss: 0.1637 - val_mse: 0.3275 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1566 - mse: 0.3138 - val_loss: 0.1497 - val_mse: 0.2999 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1487 - mse: 0.2980 - val_loss: 0.1470 - val_mse: 0.2963 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1415 - mse: 0.2835 - val_loss: 0.1387 - val_mse: 0.2787 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1354 - mse: 0.2714 - val_loss: 0.1308 - val_mse: 0.2619 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1292 - mse: 0.2589 - val_loss: 0.1230 - val_mse: 0.2464 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1244 - mse: 0.2493 - val_loss: 0.1214 - val_mse: 0.2446 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1161 - mse: 0.2326 - val_loss: 0.1110 - val_mse: 0.2224 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1113 - mse: 0.2230 - val_loss: 0.1061 - val_mse: 0.2123 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.1051 - mse: 0.2103 - val_loss: 0.1011 - val_mse: 0.2028 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0995 - mse: 0.1995 - val_loss: 0.0957 - val_mse: 0.1917 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0937 - mse: 0.1876 - val_loss: 0.0889 - val_mse: 0.1781 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0878 - mse: 0.1759 - val_loss: 0.0837 - val_mse: 0.1675 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0827 - mse: 0.1655 - val_loss: 0.0849 - val_mse: 0.1698 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0777 - mse: 0.1554 - val_loss: 0.0735 - val_mse: 0.1470 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0727 - mse: 0.1455 - val_loss: 0.0700 - val_mse: 0.1400 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0678 - mse: 0.1356 - val_loss: 0.0659 - val_mse: 0.1318 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0642 - mse: 0.1285 - val_loss: 0.0783 - val_mse: 0.1565 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0601 - mse: 0.1203 - val_loss: 0.0588 - val_mse: 0.1176 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0560 - mse: 0.1120 - val_loss: 0.0534 - val_mse: 0.1069 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0543 - mse: 0.1086 - val_loss: 0.0506 - val_mse: 0.1012 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0509 - mse: 0.1018 - val_loss: 0.0486 - val_mse: 0.0973 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0491 - mse: 0.0983 - val_loss: 0.0475 - val_mse: 0.0951 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0475 - mse: 0.0950 - val_loss: 0.0452 - val_mse: 0.0904 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0459 - mse: 0.0917 - val_loss: 0.0468 - val_mse: 0.0935 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0446 - mse: 0.0892 - val_loss: 0.0437 - val_mse: 0.0873 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0429 - mse: 0.0859 - val_loss: 0.0428 - val_mse: 0.0855 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0420 - mse: 0.0839 - val_loss: 0.0403 - val_mse: 0.0805 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0411 - mse: 0.0821 - val_loss: 0.0382 - val_mse: 0.0763 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0390 - mse: 0.0780 - val_loss: 0.0396 - val_mse: 0.0791 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0379 - mse: 0.0758 - val_loss: 0.0352 - val_mse: 0.0705 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0363 - mse: 0.0725 - val_loss: 0.0346 - val_mse: 0.0691 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0353 - mse: 0.0706 - val_loss: 0.0331 - val_mse: 0.0662 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0346 - mse: 0.0693 - val_loss: 0.0344 - val_mse: 0.0687 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0335 - mse: 0.0670 - val_loss: 0.0317 - val_mse: 0.0635 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0319 - mse: 0.0637 - val_loss: 0.0298 - val_mse: 0.0595 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0310 - mse: 0.0620 - val_loss: 0.0289 - val_mse: 0.0578 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0298 - mse: 0.0597 - val_loss: 0.0278 - val_mse: 0.0555 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0286 - mse: 0.0572 - val_loss: 0.0292 - val_mse: 0.0584 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0271 - mse: 0.0542 - val_loss: 0.0261 - val_mse: 0.0521 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0267 - mse: 0.0535 - val_loss: 0.0254 - val_mse: 0.0507 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0260 - mse: 0.0520 - val_loss: 0.0289 - val_mse: 0.0577 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0250 - mse: 0.0499 - val_loss: 0.0241 - val_mse: 0.0482 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0240 - mse: 0.0480 - val_loss: 0.0228 - val_mse: 0.0456 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0238 - mse: 0.0476 - val_loss: 0.0236 - val_mse: 0.0473 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0226 - mse: 0.0451 - val_loss: 0.0225 - val_mse: 0.0450 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0224 - mse: 0.0448 - val_loss: 0.0209 - val_mse: 0.0418 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0218 - mse: 0.0435 - val_loss: 0.0202 - val_mse: 0.0404 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0212 - mse: 0.0424 - val_loss: 0.0199 - val_mse: 0.0397 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0209 - mse: 0.0418 - val_loss: 0.0194 - val_mse: 0.0387 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0198 - mse: 0.0396 - val_loss: 0.0189 - val_mse: 0.0379 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0194 - mse: 0.0387 - val_loss: 0.0187 - val_mse: 0.0374 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0198 - mse: 0.0397 - val_loss: 0.0193 - val_mse: 0.0386 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0185 - mse: 0.0371 - val_loss: 0.0173 - val_mse: 0.0347 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0179 - mse: 0.0358 - val_loss: 0.0173 - val_mse: 0.0346 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0175 - mse: 0.0349 - val_loss: 0.0203 - val_mse: 0.0406 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0168 - mse: 0.0336 - val_loss: 0.0161 - val_mse: 0.0322 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0170 - mse: 0.0340 - val_loss: 0.0155 - val_mse: 0.0309 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0158 - mse: 0.0316 - val_loss: 0.0149 - val_mse: 0.0298 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0168 - mse: 0.0337 - val_loss: 0.0146 - val_mse: 0.0292 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0152 - mse: 0.0305 - val_loss: 0.0144 - val_mse: 0.0288 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0146 - mse: 0.0293 - val_loss: 0.0162 - val_mse: 0.0324 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0142 - mse: 0.0284 - val_loss: 0.0133 - val_mse: 0.0267 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0139 - mse: 0.0277 - val_loss: 0.0136 - val_mse: 0.0272 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0138 - mse: 0.0277 - val_loss: 0.0126 - val_mse: 0.0251 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0134 - mse: 0.0268 - val_loss: 0.0129 - val_mse: 0.0258 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0126 - mse: 0.0252 - val_loss: 0.0121 - val_mse: 0.0242 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0126 - mse: 0.0251 - val_loss: 0.0118 - val_mse: 0.0236 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0126 - mse: 0.0252 - val_loss: 0.0117 - val_mse: 0.0233 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0116 - mse: 0.0232 - val_loss: 0.0112 - val_mse: 0.0223 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0115 - mse: 0.0230 - val_loss: 0.0116 - val_mse: 0.0231 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0111 - mse: 0.0221 - val_loss: 0.0103 - val_mse: 0.0206 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0106 - mse: 0.0213 - val_loss: 0.0100 - val_mse: 0.0201 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0107 - mse: 0.0215 - val_loss: 0.0134 - val_mse: 0.0269 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0100 - mse: 0.0200 - val_loss: 0.0139 - val_mse: 0.0279 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0121 - mse: 0.0249 - val_loss: 0.0094 - val_mse: 0.0187 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0095 - mse: 0.0191 - val_loss: 0.0099 - val_mse: 0.0198 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0097 - mse: 0.0194 - val_loss: 0.0091 - val_mse: 0.0181 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0171 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0129 - val_mse: 0.0259 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0100 - val_mse: 0.0201 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0083 - val_mse: 0.0165 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0082 - val_mse: 0.0164 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0074 - val_mse: 0.0147 - 2s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 375 ended. Search finished for the next optimal point.\n",
            "Time taken: 268.7396\n",
            "Function value obtained: 0.0147\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 376 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [60, 128, 73]\n",
            "Learning Rate: 1.9271838174386487e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.27623450021432555\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 6s - loss: 674.8420 - mse: 4367070.5000 - val_loss: 127.5809 - val_mse: 81068.2969 - 6s/epoch - 11ms/step\n",
            "525/525 - 2s - loss: 602.1574 - mse: 3500760.7500 - val_loss: 76.0180 - val_mse: 28479.0684 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 584.1696 - mse: 3377309.0000 - val_loss: 45.2082 - val_mse: 9788.6846 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 534.3760 - mse: 2699097.0000 - val_loss: 31.8615 - val_mse: 4708.1133 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 551.2275 - mse: 3196638.2500 - val_loss: 17.5099 - val_mse: 1348.0610 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 534.4269 - mse: 3103564.7500 - val_loss: 8.0097 - val_mse: 250.6042 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 482.5121 - mse: 2109798.7500 - val_loss: 2.5972 - val_mse: 19.2576 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 495.6988 - mse: 2710859.0000 - val_loss: 2.2703 - val_mse: 35.0320 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 489.0247 - mse: 2291614.7500 - val_loss: 4.8983 - val_mse: 164.6756 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 469.4897 - mse: 2410671.5000 - val_loss: 5.3143 - val_mse: 195.7739 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 471.8764 - mse: 2066100.3750 - val_loss: 3.5291 - val_mse: 91.5947 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 453.1309 - mse: 2441669.7500 - val_loss: 4.0727 - val_mse: 121.4726 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 438.0550 - mse: 1829442.8750 - val_loss: 5.4186 - val_mse: 215.7061 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 422.7353 - mse: 1638914.8750 - val_loss: 7.2992 - val_mse: 357.9740 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 414.6392 - mse: 1809065.7500 - val_loss: 6.8200 - val_mse: 311.8754 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 394.0877 - mse: 1430461.7500 - val_loss: 6.7214 - val_mse: 281.5022 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 411.3214 - mse: 1703466.1250 - val_loss: 3.5169 - val_mse: 51.7234 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 403.6334 - mse: 1598836.3750 - val_loss: 1.1425 - val_mse: 6.1682 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 387.8164 - mse: 1438261.5000 - val_loss: 1.3348 - val_mse: 10.8196 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 395.3209 - mse: 1672170.7500 - val_loss: 1.6794 - val_mse: 25.0257 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 381.5367 - mse: 1489985.7500 - val_loss: 1.5248 - val_mse: 20.2038 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 373.2959 - mse: 1238746.5000 - val_loss: 0.9901 - val_mse: 6.9202 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 358.5016 - mse: 1162714.8750 - val_loss: 1.1334 - val_mse: 8.8456 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 368.5965 - mse: 1410726.7500 - val_loss: 0.5651 - val_mse: 1.9844 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 345.6001 - mse: 1072031.8750 - val_loss: 3.2565 - val_mse: 90.7690 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 346.7913 - mse: 1172113.8750 - val_loss: 4.4552 - val_mse: 150.3406 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 341.1901 - mse: 1136456.8750 - val_loss: 5.2829 - val_mse: 218.2270 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 340.6503 - mse: 1092328.6250 - val_loss: 3.7229 - val_mse: 120.0367 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 341.7435 - mse: 1400809.5000 - val_loss: 1.8877 - val_mse: 32.6337 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 323.5538 - mse: 1103045.0000 - val_loss: 1.1287 - val_mse: 4.9327 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 320.3955 - mse: 1036831.0625 - val_loss: 0.8634 - val_mse: 3.2223 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 302.6424 - mse: 932066.3125 - val_loss: 1.1057 - val_mse: 9.8404 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 312.1985 - mse: 974470.1875 - val_loss: 1.7210 - val_mse: 20.9930 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 319.9617 - mse: 1151872.7500 - val_loss: 1.2122 - val_mse: 10.3312 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 301.7946 - mse: 956849.1250 - val_loss: 0.7287 - val_mse: 2.1075 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 298.5632 - mse: 931816.5000 - val_loss: 0.8745 - val_mse: 4.5179 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 295.5383 - mse: 867969.3750 - val_loss: 0.8696 - val_mse: 4.3868 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 280.6338 - mse: 714163.0625 - val_loss: 0.5510 - val_mse: 1.3191 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 273.6788 - mse: 705984.3750 - val_loss: 0.5885 - val_mse: 2.1946 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 271.3459 - mse: 665388.5000 - val_loss: 0.7492 - val_mse: 3.4805 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 266.4569 - mse: 640877.1250 - val_loss: 0.6570 - val_mse: 2.7041 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 255.7925 - mse: 618245.6875 - val_loss: 0.5892 - val_mse: 2.1763 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 256.0970 - mse: 644580.1875 - val_loss: 0.6077 - val_mse: 1.4880 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 255.8791 - mse: 670491.5000 - val_loss: 0.6904 - val_mse: 4.3521 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 252.0594 - mse: 678267.6875 - val_loss: 0.8211 - val_mse: 4.1601 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 256.3100 - mse: 692409.3750 - val_loss: 0.7303 - val_mse: 5.2928 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 245.0946 - mse: 581139.2500 - val_loss: 0.7725 - val_mse: 5.6704 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 237.2560 - mse: 572674.3125 - val_loss: 0.4933 - val_mse: 1.0801 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 228.7390 - mse: 466900.9688 - val_loss: 0.7055 - val_mse: 1.9876 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 225.5691 - mse: 498662.4375 - val_loss: 0.5883 - val_mse: 1.4032 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 223.4472 - mse: 499881.2500 - val_loss: 0.3873 - val_mse: 0.8061 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 226.7008 - mse: 541033.0000 - val_loss: 0.6919 - val_mse: 4.3261 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 215.6714 - mse: 435977.3125 - val_loss: 0.4681 - val_mse: 1.7864 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 216.7493 - mse: 428553.9688 - val_loss: 0.3055 - val_mse: 0.7170 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 209.8875 - mse: 420837.5938 - val_loss: 0.4133 - val_mse: 1.3971 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 206.5643 - mse: 408593.6875 - val_loss: 0.5637 - val_mse: 1.4047 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 203.6404 - mse: 365650.9375 - val_loss: 0.7649 - val_mse: 2.5370 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 200.0408 - mse: 390604.5938 - val_loss: 0.6083 - val_mse: 1.6324 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 201.7100 - mse: 403879.6562 - val_loss: 0.5499 - val_mse: 1.3311 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 186.4704 - mse: 307958.4375 - val_loss: 1.1120 - val_mse: 6.0367 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 199.0318 - mse: 401329.0938 - val_loss: 0.8751 - val_mse: 4.1553 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 191.1457 - mse: 344097.0625 - val_loss: 0.4380 - val_mse: 1.2417 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 192.6194 - mse: 364320.6562 - val_loss: 1.0064 - val_mse: 5.3064 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 174.9750 - mse: 310149.6562 - val_loss: 0.4333 - val_mse: 1.4672 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 186.0180 - mse: 339983.4062 - val_loss: 0.3247 - val_mse: 0.7489 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 179.1346 - mse: 310107.6875 - val_loss: 0.3558 - val_mse: 0.8714 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 183.7045 - mse: 380598.1875 - val_loss: 0.5880 - val_mse: 2.7069 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 175.9051 - mse: 304733.7812 - val_loss: 0.5976 - val_mse: 2.8273 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 169.3551 - mse: 277394.9375 - val_loss: 1.6518 - val_mse: 20.5315 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 174.7348 - mse: 302597.8125 - val_loss: 2.4832 - val_mse: 43.2573 - 3s/epoch - 6ms/step\n",
            "525/525 - 2s - loss: 161.0995 - mse: 249229.6406 - val_loss: 3.2809 - val_mse: 71.8412 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 155.8929 - mse: 223065.8281 - val_loss: 3.9215 - val_mse: 100.0097 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 162.2287 - mse: 274896.8438 - val_loss: 3.9844 - val_mse: 101.2838 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 157.4306 - mse: 236980.8438 - val_loss: 3.9319 - val_mse: 98.2596 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 160.9852 - mse: 270442.8750 - val_loss: 4.4652 - val_mse: 125.9116 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 154.7063 - mse: 241887.8281 - val_loss: 4.3555 - val_mse: 118.4288 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 149.9498 - mse: 221169.7500 - val_loss: 4.4578 - val_mse: 122.6069 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 144.6590 - mse: 249064.6094 - val_loss: 4.5642 - val_mse: 129.5121 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 149.6251 - mse: 247508.1094 - val_loss: 4.5053 - val_mse: 125.7201 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 146.4021 - mse: 210685.5469 - val_loss: 4.2703 - val_mse: 115.4763 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 144.5838 - mse: 211894.7812 - val_loss: 4.6479 - val_mse: 135.5054 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 146.1635 - mse: 208708.6719 - val_loss: 4.9999 - val_mse: 155.2964 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 138.0228 - mse: 194760.3906 - val_loss: 4.9861 - val_mse: 152.4468 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 139.6518 - mse: 209116.4844 - val_loss: 4.7157 - val_mse: 137.0025 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 138.2346 - mse: 202390.2969 - val_loss: 4.9390 - val_mse: 149.1855 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 141.0552 - mse: 220157.9688 - val_loss: 5.3620 - val_mse: 175.1083 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 126.2459 - mse: 153294.9688 - val_loss: 5.5597 - val_mse: 186.1225 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 126.9998 - mse: 173408.4219 - val_loss: 5.8730 - val_mse: 205.1464 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 130.5151 - mse: 172285.5781 - val_loss: 5.9381 - val_mse: 210.1079 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 126.0561 - mse: 162529.5156 - val_loss: 6.0158 - val_mse: 214.9617 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 124.4344 - mse: 174983.3438 - val_loss: 6.2138 - val_mse: 228.0507 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 122.1694 - mse: 155831.7500 - val_loss: 6.0422 - val_mse: 216.7932 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 121.3415 - mse: 154307.4219 - val_loss: 5.8421 - val_mse: 204.8874 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 117.0120 - mse: 126357.8594 - val_loss: 5.8296 - val_mse: 204.5031 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 110.6146 - mse: 116360.9531 - val_loss: 5.5779 - val_mse: 189.0091 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 117.5334 - mse: 178913.9219 - val_loss: 5.4478 - val_mse: 180.2281 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 113.5360 - mse: 125511.3047 - val_loss: 5.4604 - val_mse: 181.3718 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 107.9861 - mse: 110762.1406 - val_loss: 5.0778 - val_mse: 157.7876 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 111.8198 - mse: 143459.3281 - val_loss: 4.9914 - val_mse: 150.5754 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 109.9894 - mse: 123674.7891 - val_loss: 5.2906 - val_mse: 166.8273 - 2s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 376 ended. Search finished for the next optimal point.\n",
            "Time taken: 280.5013\n",
            "Function value obtained: 166.8273\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 377 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [32, 32, 85]\n",
            "Learning Rate: 0.0018857126665055195\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.30393312833494024\n",
            "Batch Size: 106\n",
            "----------------------------------------\n",
            "80/80 - 4s - loss: 320.5105 - mse: 1547976.8750 - val_loss: 0.5702 - val_mse: 2.2386 - 4s/epoch - 47ms/step\n",
            "80/80 - 0s - loss: 55.0905 - mse: 63864.9336 - val_loss: 0.5281 - val_mse: 2.7015 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 22.5781 - mse: 7430.7451 - val_loss: 0.0460 - val_mse: 0.0920 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 11.8305 - mse: 2067.8689 - val_loss: 0.0110 - val_mse: 0.0219 - 450ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 7.4891 - mse: 1372.9543 - val_loss: 0.0128 - val_mse: 0.0256 - 447ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 4.4093 - mse: 418.5975 - val_loss: 0.0090 - val_mse: 0.0180 - 459ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 3.2350 - mse: 306.2346 - val_loss: 0.0084 - val_mse: 0.0167 - 459ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 2.2506 - mse: 237.1275 - val_loss: 0.0085 - val_mse: 0.0170 - 463ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 1.7285 - mse: 268.5525 - val_loss: 0.0084 - val_mse: 0.0168 - 452ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 1.2336 - mse: 72.0971 - val_loss: 0.0085 - val_mse: 0.0169 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 1.1821 - mse: 75.8238 - val_loss: 0.0084 - val_mse: 0.0168 - 447ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.7669 - mse: 36.1067 - val_loss: 0.0084 - val_mse: 0.0169 - 461ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.7670 - mse: 55.7583 - val_loss: 0.0084 - val_mse: 0.0167 - 459ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.6717 - mse: 59.6800 - val_loss: 0.0084 - val_mse: 0.0167 - 449ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.4961 - mse: 31.0162 - val_loss: 0.0084 - val_mse: 0.0168 - 462ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.4969 - mse: 33.6166 - val_loss: 0.0084 - val_mse: 0.0167 - 467ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.4276 - mse: 17.1221 - val_loss: 0.0084 - val_mse: 0.0167 - 480ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.2625 - mse: 8.2836 - val_loss: 0.0084 - val_mse: 0.0168 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.2795 - mse: 19.2508 - val_loss: 0.0084 - val_mse: 0.0167 - 472ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.3000 - mse: 16.8622 - val_loss: 0.0084 - val_mse: 0.0167 - 475ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.2467 - mse: 8.9247 - val_loss: 0.0084 - val_mse: 0.0167 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.2808 - mse: 24.8299 - val_loss: 0.0084 - val_mse: 0.0167 - 462ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1604 - mse: 3.2196 - val_loss: 0.0084 - val_mse: 0.0167 - 470ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.2255 - mse: 11.8103 - val_loss: 0.0084 - val_mse: 0.0167 - 455ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1432 - mse: 4.7794 - val_loss: 0.0084 - val_mse: 0.0167 - 464ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1516 - mse: 5.3734 - val_loss: 0.0084 - val_mse: 0.0168 - 464ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1303 - mse: 8.6091 - val_loss: 0.0084 - val_mse: 0.0167 - 450ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1592 - mse: 4.9557 - val_loss: 0.0084 - val_mse: 0.0168 - 466ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0813 - mse: 1.2324 - val_loss: 0.0084 - val_mse: 0.0167 - 464ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0983 - mse: 3.2521 - val_loss: 0.0084 - val_mse: 0.0169 - 462ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1022 - mse: 3.5076 - val_loss: 0.0084 - val_mse: 0.0167 - 474ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0954 - mse: 3.1237 - val_loss: 0.0084 - val_mse: 0.0168 - 464ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0842 - mse: 2.5216 - val_loss: 0.0084 - val_mse: 0.0167 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.1026 - mse: 2.3426 - val_loss: 0.0084 - val_mse: 0.0167 - 450ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0598 - mse: 0.6197 - val_loss: 0.0084 - val_mse: 0.0168 - 446ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0661 - mse: 2.5364 - val_loss: 0.0084 - val_mse: 0.0167 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0803 - mse: 1.4909 - val_loss: 0.0084 - val_mse: 0.0167 - 449ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0687 - mse: 2.0979 - val_loss: 0.0084 - val_mse: 0.0167 - 442ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0984 - mse: 5.6060 - val_loss: 0.0084 - val_mse: 0.0168 - 465ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0401 - mse: 0.4563 - val_loss: 0.0084 - val_mse: 0.0167 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0631 - mse: 2.1539 - val_loss: 0.0084 - val_mse: 0.0167 - 457ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0337 - mse: 0.3911 - val_loss: 0.0084 - val_mse: 0.0167 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0581 - mse: 3.0036 - val_loss: 0.0084 - val_mse: 0.0167 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0431 - mse: 0.4656 - val_loss: 0.0084 - val_mse: 0.0167 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0293 - mse: 0.2377 - val_loss: 0.0084 - val_mse: 0.0167 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0409 - mse: 0.6172 - val_loss: 0.0084 - val_mse: 0.0167 - 452ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0503 - mse: 1.1069 - val_loss: 0.0084 - val_mse: 0.0167 - 443ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0404 - mse: 0.5955 - val_loss: 0.0084 - val_mse: 0.0168 - 441ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0372 - mse: 1.2457 - val_loss: 0.0084 - val_mse: 0.0167 - 444ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0437 - mse: 1.4176 - val_loss: 0.0084 - val_mse: 0.0167 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0304 - mse: 0.4437 - val_loss: 0.0084 - val_mse: 0.0167 - 451ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0311 - mse: 0.4099 - val_loss: 0.0084 - val_mse: 0.0167 - 452ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0573 - mse: 2.9894 - val_loss: 0.0084 - val_mse: 0.0168 - 444ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0249 - mse: 0.2343 - val_loss: 0.0084 - val_mse: 0.0167 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0190 - mse: 0.0915 - val_loss: 0.0084 - val_mse: 0.0167 - 444ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0194 - mse: 0.1230 - val_loss: 0.0084 - val_mse: 0.0167 - 448ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0439 - mse: 1.9835 - val_loss: 0.0084 - val_mse: 0.0167 - 439ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.0384 - mse: 1.9144 - val_loss: 0.0084 - val_mse: 0.0169 - 449ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0384 - mse: 2.0158 - val_loss: 0.0084 - val_mse: 0.0168 - 448ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0156 - mse: 0.0537 - val_loss: 0.0084 - val_mse: 0.0167 - 443ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0145 - mse: 0.0751 - val_loss: 0.0084 - val_mse: 0.0167 - 446ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0195 - mse: 0.2056 - val_loss: 0.0084 - val_mse: 0.0167 - 438ms/epoch - 5ms/step\n",
            "80/80 - 0s - loss: 0.0268 - mse: 0.6862 - val_loss: 0.0084 - val_mse: 0.0167 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0327 - mse: 3.5663 - val_loss: 0.0084 - val_mse: 0.0167 - 466ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0239 - mse: 0.2210 - val_loss: 0.0084 - val_mse: 0.0167 - 455ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0184 - mse: 0.1140 - val_loss: 0.0084 - val_mse: 0.0167 - 470ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0137 - mse: 0.0578 - val_loss: 0.0084 - val_mse: 0.0167 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0136 - mse: 0.0510 - val_loss: 0.0084 - val_mse: 0.0167 - 460ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0208 - mse: 0.2284 - val_loss: 0.0084 - val_mse: 0.0167 - 441ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0260 - mse: 0.4899 - val_loss: 0.0084 - val_mse: 0.0167 - 441ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0179 - mse: 0.4400 - val_loss: 0.0084 - val_mse: 0.0167 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0160 - mse: 0.0955 - val_loss: 0.0084 - val_mse: 0.0167 - 451ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0159 - mse: 0.1186 - val_loss: 0.0084 - val_mse: 0.0169 - 462ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0140 - mse: 0.0766 - val_loss: 0.0084 - val_mse: 0.0167 - 444ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0147 - mse: 0.0921 - val_loss: 0.0084 - val_mse: 0.0167 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0120 - mse: 0.0344 - val_loss: 0.0084 - val_mse: 0.0167 - 456ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0104 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0167 - 452ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0227 - mse: 1.1426 - val_loss: 0.0084 - val_mse: 0.0168 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0106 - mse: 0.0290 - val_loss: 0.0084 - val_mse: 0.0167 - 459ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0092 - mse: 0.0190 - val_loss: 0.0084 - val_mse: 0.0168 - 455ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0152 - mse: 0.0810 - val_loss: 0.0084 - val_mse: 0.0167 - 451ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0133 - mse: 0.0487 - val_loss: 0.0084 - val_mse: 0.0167 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0131 - mse: 0.0571 - val_loss: 0.0084 - val_mse: 0.0167 - 441ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0152 - mse: 0.0737 - val_loss: 0.0084 - val_mse: 0.0167 - 445ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0125 - mse: 0.0485 - val_loss: 0.0084 - val_mse: 0.0167 - 448ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0114 - mse: 0.0358 - val_loss: 0.0084 - val_mse: 0.0167 - 468ms/epoch - 6ms/step\n",
            "80/80 - 1s - loss: 0.0101 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0167 - 504ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0123 - mse: 0.0419 - val_loss: 0.0084 - val_mse: 0.0169 - 477ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0110 - mse: 0.0395 - val_loss: 0.0084 - val_mse: 0.0168 - 471ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0093 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 475ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0098 - mse: 0.0204 - val_loss: 0.0084 - val_mse: 0.0167 - 478ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0096 - mse: 0.0196 - val_loss: 0.0084 - val_mse: 0.0168 - 454ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0121 - mse: 0.0828 - val_loss: 0.0084 - val_mse: 0.0167 - 455ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0118 - mse: 0.0398 - val_loss: 0.0084 - val_mse: 0.0168 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0098 - mse: 0.0231 - val_loss: 0.0084 - val_mse: 0.0167 - 453ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0106 - mse: 0.0373 - val_loss: 0.0084 - val_mse: 0.0167 - 448ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0118 - mse: 0.0479 - val_loss: 0.0084 - val_mse: 0.0167 - 451ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0126 - mse: 0.0931 - val_loss: 0.0084 - val_mse: 0.0167 - 461ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 456ms/epoch - 6ms/step\n",
            "80/80 - 0s - loss: 0.0109 - mse: 0.0436 - val_loss: 0.0084 - val_mse: 0.0167 - 469ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [0.34142659]\n",
            "\n",
            "Iteration No: 377 ended. Search finished for the next optimal point.\n",
            "Time taken: 79.7705\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 378 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 128, 38]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 244.3166 - mse: 375069.0625 - val_loss: 27.6702 - val_mse: 3552.4680 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 1.5066 - mse: 80.5735 - val_loss: 0.1343 - val_mse: 0.3030 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1600 - mse: 0.4068 - val_loss: 0.0919 - val_mse: 0.1981 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1265 - mse: 0.2989 - val_loss: 0.1955 - val_mse: 0.5494 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1393 - mse: 0.3549 - val_loss: 0.0803 - val_mse: 0.1665 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1351 - mse: 0.3716 - val_loss: 0.0985 - val_mse: 0.2037 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1357 - mse: 0.3756 - val_loss: 0.1588 - val_mse: 0.3578 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1254 - mse: 0.3128 - val_loss: 0.1118 - val_mse: 0.2339 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1412 - mse: 0.3917 - val_loss: 0.1483 - val_mse: 0.3174 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1112 - mse: 0.2673 - val_loss: 0.0598 - val_mse: 0.1208 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1248 - mse: 0.3300 - val_loss: 0.1020 - val_mse: 0.2236 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1006 - mse: 0.2726 - val_loss: 0.0554 - val_mse: 0.1114 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0966 - mse: 0.2284 - val_loss: 0.0691 - val_mse: 0.1408 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0759 - mse: 0.1656 - val_loss: 0.1562 - val_mse: 0.4121 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1059 - mse: 0.2627 - val_loss: 0.0976 - val_mse: 0.2175 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1311 - mse: 0.3966 - val_loss: 0.0538 - val_mse: 0.1079 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0871 - mse: 0.2015 - val_loss: 0.0467 - val_mse: 0.0936 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1117 - mse: 0.3142 - val_loss: 0.0766 - val_mse: 0.1594 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0843 - mse: 0.1973 - val_loss: 0.0472 - val_mse: 0.0946 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1147 - mse: 0.3215 - val_loss: 0.0423 - val_mse: 0.0848 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1120 - mse: 0.2956 - val_loss: 0.0480 - val_mse: 0.0963 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0778 - mse: 0.1820 - val_loss: 0.1010 - val_mse: 0.2258 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1002 - mse: 0.2515 - val_loss: 0.1036 - val_mse: 0.2353 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1059 - mse: 0.2965 - val_loss: 0.0530 - val_mse: 0.1070 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1264 - mse: 0.3644 - val_loss: 0.0422 - val_mse: 0.0845 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0905 - mse: 0.2261 - val_loss: 0.0438 - val_mse: 0.0878 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0821 - mse: 0.2175 - val_loss: 0.0746 - val_mse: 0.1584 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0782 - mse: 0.1889 - val_loss: 0.0568 - val_mse: 0.1155 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1002 - mse: 0.2665 - val_loss: 0.0647 - val_mse: 0.1340 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0927 - mse: 0.2450 - val_loss: 0.0419 - val_mse: 0.0839 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0876 - mse: 0.2242 - val_loss: 0.0825 - val_mse: 0.1796 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0859 - mse: 0.2075 - val_loss: 0.0390 - val_mse: 0.0781 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0899 - mse: 0.2520 - val_loss: 0.1059 - val_mse: 0.2465 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0909 - mse: 0.2562 - val_loss: 0.1185 - val_mse: 0.2817 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0973 - mse: 0.2754 - val_loss: 0.0361 - val_mse: 0.0722 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1117 - mse: 0.3504 - val_loss: 0.0345 - val_mse: 0.0691 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0841 - mse: 0.2108 - val_loss: 0.0352 - val_mse: 0.0704 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0666 - mse: 0.1529 - val_loss: 0.0334 - val_mse: 0.0668 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0701 - mse: 0.1710 - val_loss: 0.0377 - val_mse: 0.0754 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0992 - mse: 0.2736 - val_loss: 0.0362 - val_mse: 0.0724 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0883 - mse: 0.2322 - val_loss: 0.0927 - val_mse: 0.2095 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1000 - mse: 0.3306 - val_loss: 0.0721 - val_mse: 0.1543 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0736 - mse: 0.1792 - val_loss: 0.0328 - val_mse: 0.0657 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0606 - mse: 0.1341 - val_loss: 0.2058 - val_mse: 0.6009 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0782 - mse: 0.1910 - val_loss: 0.0423 - val_mse: 0.0851 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0642 - mse: 0.1642 - val_loss: 0.0616 - val_mse: 0.1286 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0704 - mse: 0.1657 - val_loss: 0.0571 - val_mse: 0.1178 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0920 - mse: 0.2520 - val_loss: 0.1011 - val_mse: 0.2371 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0861 - mse: 0.2452 - val_loss: 0.0444 - val_mse: 0.0895 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0651 - mse: 0.1503 - val_loss: 0.0330 - val_mse: 0.0661 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0674 - mse: 0.1619 - val_loss: 0.0289 - val_mse: 0.0578 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0883 - mse: 0.2187 - val_loss: 0.0295 - val_mse: 0.0590 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0904 - mse: 0.2474 - val_loss: 0.0400 - val_mse: 0.0804 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0688 - mse: 0.1768 - val_loss: 0.0441 - val_mse: 0.0891 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0562 - mse: 0.1284 - val_loss: 0.0305 - val_mse: 0.0610 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0937 - mse: 0.2654 - val_loss: 0.0659 - val_mse: 0.1398 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0801 - mse: 0.2103 - val_loss: 0.0426 - val_mse: 0.0861 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0837 - mse: 0.2529 - val_loss: 0.0512 - val_mse: 0.1052 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0580 - mse: 0.1319 - val_loss: 0.0524 - val_mse: 0.1088 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0676 - mse: 0.1797 - val_loss: 0.0322 - val_mse: 0.0643 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0661 - mse: 0.1658 - val_loss: 0.0259 - val_mse: 0.0518 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0762 - mse: 0.1983 - val_loss: 0.0297 - val_mse: 0.0595 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1052 - mse: 0.3737 - val_loss: 0.0470 - val_mse: 0.0963 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0609 - mse: 0.1528 - val_loss: 0.0251 - val_mse: 0.0503 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0760 - mse: 0.2061 - val_loss: 0.0713 - val_mse: 0.1550 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0606 - mse: 0.1551 - val_loss: 0.0707 - val_mse: 0.1547 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0661 - mse: 0.1631 - val_loss: 0.0621 - val_mse: 0.1325 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0811 - mse: 0.2246 - val_loss: 0.0303 - val_mse: 0.0607 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0693 - mse: 0.1771 - val_loss: 0.0271 - val_mse: 0.0542 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0568 - mse: 0.1315 - val_loss: 0.0245 - val_mse: 0.0490 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0520 - mse: 0.1204 - val_loss: 0.0230 - val_mse: 0.0459 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 0.0817 - mse: 0.2118 - val_loss: 0.0521 - val_mse: 0.1087 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0751 - mse: 0.2035 - val_loss: 0.0290 - val_mse: 0.0580 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0826 - mse: 0.2619 - val_loss: 0.0863 - val_mse: 0.1997 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0436 - mse: 0.0963 - val_loss: 0.1521 - val_mse: 0.4342 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0628 - mse: 0.1800 - val_loss: 0.2419 - val_mse: 0.8387 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0675 - mse: 0.1688 - val_loss: 0.0711 - val_mse: 0.1566 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0680 - mse: 0.1713 - val_loss: 0.0242 - val_mse: 0.0485 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0940 - mse: 0.2915 - val_loss: 0.0286 - val_mse: 0.0573 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0508 - mse: 0.1256 - val_loss: 0.0594 - val_mse: 0.1265 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0605 - mse: 0.1552 - val_loss: 0.1050 - val_mse: 0.2583 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0451 - mse: 0.1013 - val_loss: 0.0208 - val_mse: 0.0415 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0839 - mse: 0.2360 - val_loss: 0.0636 - val_mse: 0.1371 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0873 - mse: 0.2678 - val_loss: 0.0363 - val_mse: 0.0735 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0634 - mse: 0.1623 - val_loss: 0.0632 - val_mse: 0.1370 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0435 - mse: 0.0954 - val_loss: 0.0199 - val_mse: 0.0399 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0466 - mse: 0.1034 - val_loss: 0.0236 - val_mse: 0.0472 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0581 - mse: 0.1432 - val_loss: 0.1884 - val_mse: 0.5907 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0635 - mse: 0.1731 - val_loss: 0.0191 - val_mse: 0.0382 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0764 - mse: 0.2379 - val_loss: 0.0188 - val_mse: 0.0376 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0506 - mse: 0.1226 - val_loss: 0.0206 - val_mse: 0.0411 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0578 - mse: 0.1505 - val_loss: 0.0183 - val_mse: 0.0366 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0538 - mse: 0.1320 - val_loss: 0.1387 - val_mse: 0.3714 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0512 - mse: 0.1212 - val_loss: 0.0281 - val_mse: 0.0562 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0593 - mse: 0.1498 - val_loss: 0.1575 - val_mse: 0.4577 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0578 - mse: 0.1531 - val_loss: 0.0181 - val_mse: 0.0363 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0413 - mse: 0.1016 - val_loss: 0.0188 - val_mse: 0.0377 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0485 - mse: 0.1144 - val_loss: 0.0354 - val_mse: 0.0715 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0695 - mse: 0.1800 - val_loss: 0.0298 - val_mse: 0.0599 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0394 - mse: 0.0856 - val_loss: 0.0516 - val_mse: 0.1089 - 2s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 378 ended. Search finished for the next optimal point.\n",
            "Time taken: 273.5551\n",
            "Function value obtained: 0.1089\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 379 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 32, 33]\n",
            "Learning Rate: 2.6875280047981044e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 3s - loss: 99.3165 - mse: 60371.6680 - val_loss: 20.5167 - val_mse: 2610.5852 - 3s/epoch - 102ms/step\n",
            "33/33 - 0s - loss: 6.0569 - mse: 297.3917 - val_loss: 2.2925 - val_mse: 32.3150 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.9303 - mse: 6.6370 - val_loss: 0.5614 - val_mse: 2.4400 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.4960 - mse: 1.9448 - val_loss: 0.4430 - val_mse: 1.8126 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.3894 - mse: 1.3274 - val_loss: 0.3417 - val_mse: 1.0026 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.3063 - mse: 0.8889 - val_loss: 0.2697 - val_mse: 0.6774 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.2428 - mse: 0.5862 - val_loss: 0.2293 - val_mse: 0.5122 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.2171 - mse: 0.4814 - val_loss: 0.2142 - val_mse: 0.4641 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.2047 - mse: 0.4395 - val_loss: 0.1985 - val_mse: 0.4149 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.1895 - mse: 0.3909 - val_loss: 0.1882 - val_mse: 0.3868 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.1896 - mse: 0.3966 - val_loss: 0.2154 - val_mse: 0.5036 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1919 - mse: 0.4076 - val_loss: 0.1806 - val_mse: 0.3668 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1823 - mse: 0.3806 - val_loss: 0.1757 - val_mse: 0.3591 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1644 - mse: 0.3330 - val_loss: 0.1873 - val_mse: 0.3888 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1605 - mse: 0.3235 - val_loss: 0.1683 - val_mse: 0.3517 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1561 - mse: 0.3158 - val_loss: 0.1600 - val_mse: 0.3302 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1482 - mse: 0.2978 - val_loss: 0.1485 - val_mse: 0.3004 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1692 - mse: 0.3668 - val_loss: 0.1670 - val_mse: 0.3464 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1609 - mse: 0.3405 - val_loss: 0.1525 - val_mse: 0.3074 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1427 - mse: 0.2886 - val_loss: 0.1365 - val_mse: 0.2736 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1339 - mse: 0.2696 - val_loss: 0.1347 - val_mse: 0.2736 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1289 - mse: 0.2595 - val_loss: 0.1397 - val_mse: 0.2938 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1269 - mse: 0.2563 - val_loss: 0.1283 - val_mse: 0.2568 - 225ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1227 - mse: 0.2485 - val_loss: 0.1218 - val_mse: 0.2438 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1157 - mse: 0.2331 - val_loss: 0.1131 - val_mse: 0.2265 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1096 - mse: 0.2204 - val_loss: 0.1268 - val_mse: 0.2757 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1159 - mse: 0.2392 - val_loss: 0.1110 - val_mse: 0.2244 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.1037 - mse: 0.2088 - val_loss: 0.0983 - val_mse: 0.1969 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0951 - mse: 0.1914 - val_loss: 0.1014 - val_mse: 0.2086 - 243ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0911 - mse: 0.1829 - val_loss: 0.0879 - val_mse: 0.1761 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0838 - mse: 0.1677 - val_loss: 0.0872 - val_mse: 0.1765 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0786 - mse: 0.1574 - val_loss: 0.0757 - val_mse: 0.1514 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0741 - mse: 0.1484 - val_loss: 0.0694 - val_mse: 0.1390 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0671 - mse: 0.1342 - val_loss: 0.0648 - val_mse: 0.1297 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0623 - mse: 0.1245 - val_loss: 0.0609 - val_mse: 0.1217 - 226ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0593 - mse: 0.1185 - val_loss: 0.0580 - val_mse: 0.1160 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0568 - mse: 0.1136 - val_loss: 0.0557 - val_mse: 0.1115 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0546 - mse: 0.1092 - val_loss: 0.0532 - val_mse: 0.1063 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0525 - mse: 0.1050 - val_loss: 0.0509 - val_mse: 0.1019 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0502 - mse: 0.1004 - val_loss: 0.0491 - val_mse: 0.0982 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0485 - mse: 0.0970 - val_loss: 0.0471 - val_mse: 0.0943 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0469 - mse: 0.0938 - val_loss: 0.0456 - val_mse: 0.0912 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0454 - mse: 0.0907 - val_loss: 0.0443 - val_mse: 0.0885 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0437 - mse: 0.0874 - val_loss: 0.0423 - val_mse: 0.0847 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0425 - mse: 0.0852 - val_loss: 0.0421 - val_mse: 0.0841 - 242ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0410 - mse: 0.0821 - val_loss: 0.0399 - val_mse: 0.0799 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0398 - mse: 0.0797 - val_loss: 0.0383 - val_mse: 0.0767 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0387 - mse: 0.0774 - val_loss: 0.0372 - val_mse: 0.0744 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0375 - mse: 0.0753 - val_loss: 0.0363 - val_mse: 0.0725 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0371 - mse: 0.0742 - val_loss: 0.0357 - val_mse: 0.0714 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0351 - mse: 0.0703 - val_loss: 0.0338 - val_mse: 0.0677 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0344 - mse: 0.0688 - val_loss: 0.0333 - val_mse: 0.0665 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0332 - mse: 0.0665 - val_loss: 0.0322 - val_mse: 0.0643 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0323 - mse: 0.0646 - val_loss: 0.0306 - val_mse: 0.0612 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0324 - mse: 0.0649 - val_loss: 0.0301 - val_mse: 0.0603 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0305 - mse: 0.0610 - val_loss: 0.0298 - val_mse: 0.0597 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0299 - mse: 0.0598 - val_loss: 0.0296 - val_mse: 0.0593 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0291 - mse: 0.0582 - val_loss: 0.0287 - val_mse: 0.0574 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0273 - mse: 0.0547 - val_loss: 0.0255 - val_mse: 0.0509 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0261 - mse: 0.0522 - val_loss: 0.0246 - val_mse: 0.0493 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0247 - mse: 0.0498 - val_loss: 0.0233 - val_mse: 0.0467 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0238 - mse: 0.0479 - val_loss: 0.0222 - val_mse: 0.0443 - 232ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0218 - mse: 0.0436 - val_loss: 0.0215 - val_mse: 0.0431 - 227ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0208 - mse: 0.0416 - val_loss: 0.0196 - val_mse: 0.0392 - 222ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0194 - mse: 0.0387 - val_loss: 0.0184 - val_mse: 0.0368 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0189 - mse: 0.0378 - val_loss: 0.0179 - val_mse: 0.0358 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0177 - mse: 0.0355 - val_loss: 0.0164 - val_mse: 0.0328 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0164 - mse: 0.0328 - val_loss: 0.0153 - val_mse: 0.0306 - 230ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0156 - mse: 0.0311 - val_loss: 0.0146 - val_mse: 0.0291 - 233ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0148 - mse: 0.0297 - val_loss: 0.0140 - val_mse: 0.0279 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0141 - mse: 0.0283 - val_loss: 0.0132 - val_mse: 0.0265 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0136 - mse: 0.0272 - val_loss: 0.0127 - val_mse: 0.0254 - 231ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0130 - mse: 0.0260 - val_loss: 0.0123 - val_mse: 0.0246 - 229ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0125 - mse: 0.0250 - val_loss: 0.0115 - val_mse: 0.0231 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0118 - mse: 0.0237 - val_loss: 0.0111 - val_mse: 0.0221 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0114 - mse: 0.0229 - val_loss: 0.0109 - val_mse: 0.0219 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0109 - mse: 0.0218 - val_loss: 0.0103 - val_mse: 0.0207 - 245ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0106 - mse: 0.0211 - val_loss: 0.0099 - val_mse: 0.0197 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0101 - mse: 0.0202 - val_loss: 0.0094 - val_mse: 0.0188 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0094 - mse: 0.0188 - val_loss: 0.0090 - val_mse: 0.0180 - 244ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0183 - val_loss: 0.0087 - val_mse: 0.0173 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0083 - val_mse: 0.0165 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0084 - mse: 0.0168 - val_loss: 0.0080 - val_mse: 0.0160 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0080 - mse: 0.0160 - val_loss: 0.0077 - val_mse: 0.0155 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0074 - val_mse: 0.0149 - 254ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0072 - val_mse: 0.0144 - 256ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0078 - mse: 0.0156 - val_loss: 0.0069 - val_mse: 0.0138 - 238ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0070 - mse: 0.0139 - val_loss: 0.0067 - val_mse: 0.0133 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0072 - mse: 0.0144 - val_loss: 0.0087 - val_mse: 0.0175 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0075 - mse: 0.0150 - val_loss: 0.0065 - val_mse: 0.0129 - 234ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0065 - mse: 0.0130 - val_loss: 0.0061 - val_mse: 0.0123 - 235ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0058 - val_mse: 0.0116 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0055 - val_mse: 0.0111 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0055 - mse: 0.0111 - val_loss: 0.0053 - val_mse: 0.0107 - 241ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0052 - mse: 0.0104 - val_loss: 0.0048 - val_mse: 0.0096 - 237ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0048 - mse: 0.0095 - val_loss: 0.0046 - val_mse: 0.0092 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0045 - mse: 0.0089 - val_loss: 0.0044 - val_mse: 0.0088 - 236ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0043 - val_mse: 0.0085 - 239ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0046 - mse: 0.0091 - val_loss: 0.0043 - val_mse: 0.0086 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0039 - val_mse: 0.0078 - 233ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 379 ended. Search finished for the next optimal point.\n",
            "Time taken: 59.4220\n",
            "Function value obtained: 0.0078\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 380 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 32, 46]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 136\n",
            "----------------------------------------\n",
            "62/62 - 3s - loss: 168.1384 - mse: 137135.8281 - val_loss: 153.9105 - val_mse: 118073.6406 - 3s/epoch - 55ms/step\n",
            "62/62 - 0s - loss: 156.0305 - mse: 117870.5078 - val_loss: 142.6190 - val_mse: 101387.4531 - 350ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 143.5721 - mse: 99864.5547 - val_loss: 129.7615 - val_mse: 83682.6406 - 352ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 127.2393 - mse: 78048.0391 - val_loss: 112.4771 - val_mse: 62780.7930 - 355ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 110.3056 - mse: 58713.3242 - val_loss: 96.9433 - val_mse: 46406.2695 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 93.9386 - mse: 42077.3477 - val_loss: 81.8454 - val_mse: 32870.9727 - 356ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 78.3212 - mse: 29323.3223 - val_loss: 67.0799 - val_mse: 21923.1016 - 357ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 63.1895 - mse: 18911.1074 - val_loss: 53.2340 - val_mse: 13673.4873 - 357ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 50.0518 - mse: 11796.0186 - val_loss: 41.8327 - val_mse: 8405.0312 - 356ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 34.2899 - mse: 5472.1099 - val_loss: 20.1189 - val_mse: 1657.7939 - 374ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 8.7761 - mse: 402.0454 - val_loss: 3.9714 - val_mse: 45.0727 - 362ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 3.7439 - mse: 37.2350 - val_loss: 3.5408 - val_mse: 33.8987 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 3.3784 - mse: 30.5273 - val_loss: 3.2243 - val_mse: 27.6437 - 363ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 3.0895 - mse: 25.5051 - val_loss: 2.9809 - val_mse: 23.4586 - 363ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.8337 - mse: 21.2758 - val_loss: 2.7153 - val_mse: 19.7557 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.5877 - mse: 18.0207 - val_loss: 2.4914 - val_mse: 17.1194 - 366ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.3963 - mse: 15.7649 - val_loss: 2.3174 - val_mse: 14.9699 - 373ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.2461 - mse: 13.9484 - val_loss: 2.1926 - val_mse: 13.3997 - 384ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.1336 - mse: 12.7072 - val_loss: 2.0884 - val_mse: 12.3541 - 378ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 2.0407 - mse: 11.7646 - val_loss: 1.9954 - val_mse: 11.5154 - 378ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.9586 - mse: 11.0128 - val_loss: 1.9316 - val_mse: 10.6668 - 384ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.8959 - mse: 10.4288 - val_loss: 1.8641 - val_mse: 10.1101 - 374ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.8373 - mse: 9.8817 - val_loss: 1.8180 - val_mse: 9.5932 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.7816 - mse: 9.3656 - val_loss: 1.7539 - val_mse: 9.1752 - 381ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.7377 - mse: 8.9903 - val_loss: 1.7091 - val_mse: 8.7674 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.6905 - mse: 8.6144 - val_loss: 1.6703 - val_mse: 8.4049 - 375ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.6506 - mse: 8.2026 - val_loss: 1.6243 - val_mse: 8.1616 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.6132 - mse: 7.9491 - val_loss: 1.5880 - val_mse: 7.8651 - 379ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.5800 - mse: 7.7311 - val_loss: 1.5707 - val_mse: 7.5402 - 368ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.5508 - mse: 7.5088 - val_loss: 1.5264 - val_mse: 7.2925 - 361ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.5169 - mse: 7.2412 - val_loss: 1.5371 - val_mse: 7.2194 - 383ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.4849 - mse: 7.0009 - val_loss: 1.4731 - val_mse: 6.8366 - 381ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.4565 - mse: 6.8129 - val_loss: 1.4396 - val_mse: 6.6321 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.4294 - mse: 6.5849 - val_loss: 1.4016 - val_mse: 6.5583 - 362ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.4007 - mse: 6.3618 - val_loss: 1.3743 - val_mse: 6.3907 - 372ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.3764 - mse: 6.2358 - val_loss: 1.3482 - val_mse: 6.2526 - 365ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.3583 - mse: 6.1222 - val_loss: 1.3250 - val_mse: 5.9799 - 364ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.3260 - mse: 5.8899 - val_loss: 1.3005 - val_mse: 5.8225 - 371ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.3006 - mse: 5.7237 - val_loss: 1.2750 - val_mse: 5.7834 - 365ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.2784 - mse: 5.5895 - val_loss: 1.2543 - val_mse: 5.5119 - 365ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.2596 - mse: 5.4587 - val_loss: 1.2332 - val_mse: 5.7310 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.2365 - mse: 5.3487 - val_loss: 1.2184 - val_mse: 5.1699 - 349ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.2100 - mse: 5.1141 - val_loss: 1.1907 - val_mse: 5.0591 - 361ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.1973 - mse: 5.1355 - val_loss: 1.1719 - val_mse: 4.9092 - 368ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.1675 - mse: 4.9112 - val_loss: 1.1427 - val_mse: 4.9474 - 368ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.1416 - mse: 4.7132 - val_loss: 1.1268 - val_mse: 5.0866 - 387ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.1221 - mse: 4.5694 - val_loss: 1.1036 - val_mse: 4.8726 - 360ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.1012 - mse: 4.4488 - val_loss: 1.0850 - val_mse: 4.4139 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.0771 - mse: 4.3106 - val_loss: 1.0634 - val_mse: 4.2946 - 369ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.0559 - mse: 4.1965 - val_loss: 1.0591 - val_mse: 4.1726 - 367ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.0414 - mse: 4.1287 - val_loss: 1.0180 - val_mse: 4.2678 - 361ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 1.0155 - mse: 3.9500 - val_loss: 1.0017 - val_mse: 3.9369 - 357ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.9934 - mse: 3.8453 - val_loss: 0.9763 - val_mse: 3.9388 - 358ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.9817 - mse: 3.8130 - val_loss: 0.9610 - val_mse: 3.7127 - 365ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.9546 - mse: 3.6318 - val_loss: 0.9481 - val_mse: 3.5908 - 349ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.9385 - mse: 3.5264 - val_loss: 0.9209 - val_mse: 3.5037 - 348ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.9271 - mse: 3.5598 - val_loss: 0.8995 - val_mse: 3.4205 - 354ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.8945 - mse: 3.2916 - val_loss: 0.8777 - val_mse: 3.4235 - 341ms/epoch - 5ms/step\n",
            "62/62 - 0s - loss: 0.8780 - mse: 3.2180 - val_loss: 0.8590 - val_mse: 3.2398 - 347ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.8599 - mse: 3.1527 - val_loss: 0.8670 - val_mse: 3.1480 - 342ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.8395 - mse: 3.0561 - val_loss: 0.8190 - val_mse: 3.1404 - 344ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.8210 - mse: 2.9513 - val_loss: 0.8022 - val_mse: 2.9159 - 349ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.8017 - mse: 2.8719 - val_loss: 0.7818 - val_mse: 2.8426 - 342ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.7803 - mse: 2.7473 - val_loss: 0.7659 - val_mse: 3.0079 - 347ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.7593 - mse: 2.6718 - val_loss: 0.7817 - val_mse: 2.7762 - 343ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.7365 - mse: 2.5629 - val_loss: 0.7278 - val_mse: 2.8123 - 338ms/epoch - 5ms/step\n",
            "62/62 - 0s - loss: 0.7311 - mse: 2.5815 - val_loss: 0.7046 - val_mse: 2.5146 - 347ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.7086 - mse: 2.4493 - val_loss: 0.6899 - val_mse: 2.3825 - 352ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.6836 - mse: 2.3401 - val_loss: 0.6735 - val_mse: 2.3005 - 349ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.6625 - mse: 2.2366 - val_loss: 0.6464 - val_mse: 2.3040 - 348ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.6453 - mse: 2.1716 - val_loss: 0.6298 - val_mse: 2.1548 - 357ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.6216 - mse: 2.0770 - val_loss: 0.6155 - val_mse: 2.0799 - 345ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.6137 - mse: 2.0708 - val_loss: 0.5981 - val_mse: 2.0124 - 351ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5917 - mse: 1.9732 - val_loss: 0.5768 - val_mse: 1.9711 - 360ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5766 - mse: 1.9069 - val_loss: 0.5972 - val_mse: 2.0390 - 373ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5539 - mse: 1.7940 - val_loss: 0.5807 - val_mse: 1.9696 - 363ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5467 - mse: 1.7897 - val_loss: 0.5293 - val_mse: 1.7892 - 377ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5229 - mse: 1.6601 - val_loss: 0.5134 - val_mse: 1.7144 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.5084 - mse: 1.6044 - val_loss: 0.4993 - val_mse: 1.6753 - 370ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4932 - mse: 1.5419 - val_loss: 0.4896 - val_mse: 1.6777 - 358ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4853 - mse: 1.5372 - val_loss: 0.5170 - val_mse: 2.0307 - 359ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4702 - mse: 1.4675 - val_loss: 0.4543 - val_mse: 1.4426 - 364ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4520 - mse: 1.3732 - val_loss: 0.4630 - val_mse: 1.4559 - 365ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4423 - mse: 1.3483 - val_loss: 0.4449 - val_mse: 1.5203 - 358ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4285 - mse: 1.2939 - val_loss: 0.4268 - val_mse: 1.3036 - 356ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4140 - mse: 1.2247 - val_loss: 0.4035 - val_mse: 1.2138 - 352ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.4027 - mse: 1.1809 - val_loss: 0.4081 - val_mse: 1.3360 - 350ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3856 - mse: 1.1012 - val_loss: 0.3770 - val_mse: 1.1285 - 346ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3721 - mse: 1.0553 - val_loss: 0.3686 - val_mse: 1.0725 - 351ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3634 - mse: 1.0124 - val_loss: 0.3677 - val_mse: 1.1233 - 351ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3542 - mse: 0.9860 - val_loss: 0.3491 - val_mse: 0.9945 - 347ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3508 - mse: 0.9715 - val_loss: 0.3429 - val_mse: 0.9987 - 346ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3348 - mse: 0.9058 - val_loss: 0.3283 - val_mse: 0.9199 - 363ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3273 - mse: 0.8795 - val_loss: 0.3224 - val_mse: 0.9029 - 355ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3202 - mse: 0.8514 - val_loss: 0.3148 - val_mse: 0.8608 - 350ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3102 - mse: 0.8146 - val_loss: 0.3282 - val_mse: 0.9407 - 354ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3120 - mse: 0.8249 - val_loss: 0.3030 - val_mse: 0.8157 - 350ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.3018 - mse: 0.7834 - val_loss: 0.3002 - val_mse: 0.8075 - 351ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.2996 - mse: 0.7841 - val_loss: 0.2915 - val_mse: 0.7762 - 353ms/epoch - 6ms/step\n",
            "62/62 - 0s - loss: 0.2901 - mse: 0.7470 - val_loss: 0.2987 - val_mse: 0.8111 - 352ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 380 ended. Search finished for the next optimal point.\n",
            "Time taken: 70.2078\n",
            "Function value obtained: 0.8111\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 381 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [71, 34, 128]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 166\n",
            "----------------------------------------\n",
            "51/51 - 3s - loss: 452.1668 - mse: 1006008.0000 - val_loss: 421.8132 - val_mse: 903581.2500 - 3s/epoch - 63ms/step\n",
            "51/51 - 0s - loss: 436.2002 - mse: 937099.8750 - val_loss: 406.9077 - val_mse: 840889.2500 - 306ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 420.6739 - mse: 871739.3750 - val_loss: 392.2274 - val_mse: 781379.6250 - 303ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 405.4310 - mse: 810106.8125 - val_loss: 377.9130 - val_mse: 725453.1875 - 309ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 390.4671 - mse: 750552.7500 - val_loss: 363.9109 - val_mse: 672744.0000 - 308ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 375.8261 - mse: 695754.4375 - val_loss: 350.0524 - val_mse: 622530.0000 - 334ms/epoch - 7ms/step\n",
            "51/51 - 0s - loss: 361.4333 - mse: 643389.0000 - val_loss: 336.6264 - val_mse: 575758.6875 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 347.3654 - mse: 594622.4375 - val_loss: 323.2913 - val_mse: 531169.6875 - 322ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 333.4771 - mse: 548060.5625 - val_loss: 310.0236 - val_mse: 489031.6250 - 318ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 318.8255 - mse: 501383.3125 - val_loss: 295.6241 - val_mse: 444969.2812 - 320ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 303.5669 - mse: 455274.2500 - val_loss: 280.8591 - val_mse: 402295.5625 - 325ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 287.5570 - mse: 408824.4688 - val_loss: 265.1673 - val_mse: 358853.2812 - 319ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 270.8986 - mse: 363676.4375 - val_loss: 249.0062 - val_mse: 316810.2188 - 306ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 253.7094 - mse: 319400.5000 - val_loss: 232.5705 - val_mse: 276752.7500 - 308ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 235.6425 - mse: 275849.2188 - val_loss: 213.8850 - val_mse: 234616.7031 - 304ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 215.8309 - mse: 231310.7031 - val_loss: 196.5723 - val_mse: 198088.9844 - 302ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 198.4863 - mse: 196212.2969 - val_loss: 180.0824 - val_mse: 166438.2812 - 297ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 181.4042 - mse: 163410.3906 - val_loss: 164.3191 - val_mse: 138749.4062 - 303ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 164.8439 - mse: 135747.1094 - val_loss: 148.5516 - val_mse: 113541.3828 - 304ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 148.6947 - mse: 110271.0312 - val_loss: 133.5570 - val_mse: 91841.1797 - 294ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 133.4829 - mse: 88941.5234 - val_loss: 120.0086 - val_mse: 74109.5156 - 293ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 119.7409 - mse: 71726.1875 - val_loss: 106.5354 - val_mse: 58769.7422 - 302ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 104.2294 - mse: 54713.4883 - val_loss: 90.4339 - val_mse: 42699.2852 - 298ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 86.3263 - mse: 38131.2383 - val_loss: 72.8088 - val_mse: 27879.9922 - 299ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 67.9802 - mse: 23747.8711 - val_loss: 55.4354 - val_mse: 16399.6016 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 49.1142 - mse: 12801.4023 - val_loss: 37.2903 - val_mse: 7608.7705 - 293ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 30.2359 - mse: 5071.5098 - val_loss: 19.5823 - val_mse: 2232.3972 - 297ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 12.4195 - mse: 993.3975 - val_loss: 4.2371 - val_mse: 140.6739 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 1.2212 - mse: 23.5094 - val_loss: 0.4379 - val_mse: 2.8455 - 295ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.4149 - mse: 1.8678 - val_loss: 0.3684 - val_mse: 1.3510 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3917 - mse: 1.5618 - val_loss: 0.3607 - val_mse: 1.3096 - 295ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3840 - mse: 1.5312 - val_loss: 0.3514 - val_mse: 1.3309 - 297ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3751 - mse: 1.5069 - val_loss: 0.3457 - val_mse: 1.2163 - 301ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3646 - mse: 1.4252 - val_loss: 0.3332 - val_mse: 1.3367 - 301ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3553 - mse: 1.4225 - val_loss: 0.3263 - val_mse: 1.1251 - 301ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3436 - mse: 1.3082 - val_loss: 0.3159 - val_mse: 1.0688 - 305ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3322 - mse: 1.2647 - val_loss: 0.3091 - val_mse: 0.9661 - 304ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3198 - mse: 1.1906 - val_loss: 0.2906 - val_mse: 0.9897 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.3053 - mse: 1.0934 - val_loss: 0.2789 - val_mse: 0.9252 - 329ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2906 - mse: 1.0281 - val_loss: 0.2681 - val_mse: 0.8243 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2765 - mse: 0.9275 - val_loss: 0.2582 - val_mse: 0.7562 - 342ms/epoch - 7ms/step\n",
            "51/51 - 0s - loss: 0.2660 - mse: 0.8475 - val_loss: 0.2487 - val_mse: 0.7345 - 347ms/epoch - 7ms/step\n",
            "51/51 - 0s - loss: 0.2558 - mse: 0.7834 - val_loss: 0.2420 - val_mse: 0.6524 - 343ms/epoch - 7ms/step\n",
            "51/51 - 0s - loss: 0.2456 - mse: 0.7194 - val_loss: 0.2364 - val_mse: 0.6718 - 331ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2392 - mse: 0.6699 - val_loss: 0.2302 - val_mse: 0.6137 - 332ms/epoch - 7ms/step\n",
            "51/51 - 0s - loss: 0.2346 - mse: 0.6454 - val_loss: 0.2259 - val_mse: 0.5708 - 329ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2300 - mse: 0.6061 - val_loss: 0.2237 - val_mse: 0.5790 - 321ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2285 - mse: 0.5910 - val_loss: 0.2280 - val_mse: 0.6305 - 322ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2257 - mse: 0.5830 - val_loss: 0.2211 - val_mse: 0.5245 - 328ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2218 - mse: 0.5558 - val_loss: 0.2183 - val_mse: 0.5222 - 320ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2218 - mse: 0.5576 - val_loss: 0.2173 - val_mse: 0.5343 - 324ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2198 - mse: 0.5407 - val_loss: 0.2159 - val_mse: 0.5172 - 316ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2185 - mse: 0.5344 - val_loss: 0.2168 - val_mse: 0.5408 - 330ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2188 - mse: 0.5347 - val_loss: 0.2144 - val_mse: 0.5100 - 314ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2206 - mse: 0.5385 - val_loss: 0.2159 - val_mse: 0.5377 - 311ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2163 - mse: 0.5255 - val_loss: 0.2149 - val_mse: 0.5311 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2154 - mse: 0.5194 - val_loss: 0.2167 - val_mse: 0.5025 - 319ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2158 - mse: 0.5204 - val_loss: 0.2153 - val_mse: 0.5403 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2148 - mse: 0.5181 - val_loss: 0.2116 - val_mse: 0.4993 - 317ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2145 - mse: 0.5164 - val_loss: 0.2111 - val_mse: 0.5026 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2124 - mse: 0.5073 - val_loss: 0.2105 - val_mse: 0.4963 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2118 - mse: 0.5029 - val_loss: 0.2200 - val_mse: 0.5871 - 305ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2203 - mse: 0.5497 - val_loss: 0.2168 - val_mse: 0.5643 - 310ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2144 - mse: 0.5124 - val_loss: 0.2102 - val_mse: 0.5100 - 302ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2108 - mse: 0.5026 - val_loss: 0.2084 - val_mse: 0.4909 - 303ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2127 - mse: 0.5144 - val_loss: 0.2085 - val_mse: 0.4997 - 305ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2108 - mse: 0.5065 - val_loss: 0.2109 - val_mse: 0.4862 - 311ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2085 - mse: 0.4927 - val_loss: 0.2108 - val_mse: 0.4857 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2089 - mse: 0.4966 - val_loss: 0.2077 - val_mse: 0.4792 - 317ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2088 - mse: 0.5006 - val_loss: 0.2060 - val_mse: 0.4874 - 322ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2073 - mse: 0.4883 - val_loss: 0.2053 - val_mse: 0.4782 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2090 - mse: 0.5003 - val_loss: 0.2066 - val_mse: 0.4755 - 308ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2055 - mse: 0.4873 - val_loss: 0.2077 - val_mse: 0.5140 - 323ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2054 - mse: 0.4842 - val_loss: 0.2036 - val_mse: 0.4769 - 329ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2035 - mse: 0.4801 - val_loss: 0.2033 - val_mse: 0.4700 - 308ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2048 - mse: 0.4867 - val_loss: 0.2053 - val_mse: 0.5018 - 307ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2035 - mse: 0.4779 - val_loss: 0.2018 - val_mse: 0.4692 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2049 - mse: 0.4863 - val_loss: 0.2020 - val_mse: 0.4803 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2024 - mse: 0.4798 - val_loss: 0.2006 - val_mse: 0.4638 - 309ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2030 - mse: 0.4763 - val_loss: 0.2003 - val_mse: 0.4606 - 306ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2013 - mse: 0.4729 - val_loss: 0.1992 - val_mse: 0.4639 - 316ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2017 - mse: 0.4747 - val_loss: 0.1990 - val_mse: 0.4688 - 309ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2020 - mse: 0.4793 - val_loss: 0.1984 - val_mse: 0.4547 - 302ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2030 - mse: 0.4863 - val_loss: 0.2072 - val_mse: 0.4784 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2037 - mse: 0.4806 - val_loss: 0.1979 - val_mse: 0.4738 - 314ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.2015 - mse: 0.4903 - val_loss: 0.1968 - val_mse: 0.4693 - 308ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1983 - mse: 0.4664 - val_loss: 0.1957 - val_mse: 0.4471 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1996 - mse: 0.4772 - val_loss: 0.1998 - val_mse: 0.5009 - 298ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1969 - mse: 0.4687 - val_loss: 0.1921 - val_mse: 0.4413 - 301ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1951 - mse: 0.4595 - val_loss: 0.1936 - val_mse: 0.4417 - 303ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1918 - mse: 0.4465 - val_loss: 0.1899 - val_mse: 0.4351 - 300ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1922 - mse: 0.4520 - val_loss: 0.2040 - val_mse: 0.4736 - 297ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1952 - mse: 0.4654 - val_loss: 0.1905 - val_mse: 0.4346 - 298ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1914 - mse: 0.4529 - val_loss: 0.1912 - val_mse: 0.4688 - 305ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1876 - mse: 0.4382 - val_loss: 0.1857 - val_mse: 0.4249 - 303ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1860 - mse: 0.4324 - val_loss: 0.1908 - val_mse: 0.4364 - 306ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1906 - mse: 0.4505 - val_loss: 0.1949 - val_mse: 0.4488 - 297ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1850 - mse: 0.4266 - val_loss: 0.1895 - val_mse: 0.4686 - 302ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1850 - mse: 0.4299 - val_loss: 0.1827 - val_mse: 0.4170 - 312ms/epoch - 6ms/step\n",
            "51/51 - 0s - loss: 0.1839 - mse: 0.4250 - val_loss: 0.1916 - val_mse: 0.4869 - 308ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 381 ended. Search finished for the next optimal point.\n",
            "Time taken: 66.9259\n",
            "Function value obtained: 0.4869\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 382 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [96, 128, 93]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3559894635615092\n",
            "Batch Size: 238\n",
            "----------------------------------------\n",
            "36/36 - 3s - loss: 354446.0000 - mse: 26923155587072.0000 - val_loss: 0.0309 - val_mse: 0.0618 - 3s/epoch - 90ms/step\n",
            "36/36 - 0s - loss: 0.0150 - mse: 0.0300 - val_loss: 0.0100 - val_mse: 0.0199 - 251ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 250ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 249ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 247ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 252ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 248ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 245ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 249ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 247ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 251ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 249ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 250ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 243ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 248ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 248ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 251ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 254ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 258ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 258ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 280ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 266ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 269ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0171 - 279ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 274ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 263ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 254ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0087 - val_mse: 0.0175 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 263ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0171 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 250ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 285ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 268ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0087 - val_mse: 0.0174 - 271ms/epoch - 8ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 254ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 264ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 267ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 256ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 263ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0091 - val_mse: 0.0181 - 252ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0169 - 264ms/epoch - 7ms/step\n",
            "36/36 - 0s - loss: 0.0088 - mse: 0.0177 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.00987903]\n",
            "\n",
            "Iteration No: 382 ended. Search finished for the next optimal point.\n",
            "Time taken: 60.4475\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 383 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 32, 128]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.34354238120636604\n",
            "Batch Size: 79\n",
            "----------------------------------------\n",
            "107/107 - 4s - loss: 551.6726 - mse: 3134628.0000 - val_loss: 199.9734 - val_mse: 200388.0312 - 4s/epoch - 34ms/step\n",
            "107/107 - 1s - loss: 540.9899 - mse: 2853220.7500 - val_loss: 187.2890 - val_mse: 175780.7500 - 562ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 515.4968 - mse: 2746526.2500 - val_loss: 176.4227 - val_mse: 156006.5156 - 557ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 510.0441 - mse: 2417268.7500 - val_loss: 166.0346 - val_mse: 138243.5938 - 562ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 497.9013 - mse: 2395204.5000 - val_loss: 156.0195 - val_mse: 122118.4609 - 568ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 495.3348 - mse: 2685455.0000 - val_loss: 146.2088 - val_mse: 107296.1250 - 562ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 452.2908 - mse: 1906590.0000 - val_loss: 137.5587 - val_mse: 95045.6719 - 598ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 474.8678 - mse: 2401506.7500 - val_loss: 129.6990 - val_mse: 84533.7031 - 606ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 463.5302 - mse: 2262000.0000 - val_loss: 122.1178 - val_mse: 75015.4062 - 615ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 461.9811 - mse: 2415640.5000 - val_loss: 114.3094 - val_mse: 65785.5000 - 592ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 457.4630 - mse: 2460094.2500 - val_loss: 108.1555 - val_mse: 58920.5000 - 584ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 431.6719 - mse: 1934665.8750 - val_loss: 102.0193 - val_mse: 52432.6836 - 587ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 443.6967 - mse: 2203312.0000 - val_loss: 95.8433 - val_mse: 46282.2109 - 590ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 412.5150 - mse: 1981139.5000 - val_loss: 89.6809 - val_mse: 40559.4453 - 598ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 398.3008 - mse: 1822137.3750 - val_loss: 84.1746 - val_mse: 35735.3711 - 582ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 400.5649 - mse: 1584262.7500 - val_loss: 79.3583 - val_mse: 31768.5078 - 595ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 383.0854 - mse: 1577909.6250 - val_loss: 74.9615 - val_mse: 28346.6738 - 594ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 393.7256 - mse: 1703701.8750 - val_loss: 70.1126 - val_mse: 24799.6250 - 580ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 378.9171 - mse: 1641233.1250 - val_loss: 65.6348 - val_mse: 21739.5449 - 595ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 356.7736 - mse: 1286619.7500 - val_loss: 61.3561 - val_mse: 19001.5918 - 581ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 364.0265 - mse: 1406130.6250 - val_loss: 57.5571 - val_mse: 16732.4902 - 569ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 368.0371 - mse: 1508311.5000 - val_loss: 53.6455 - val_mse: 14559.4385 - 564ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 370.1743 - mse: 1542635.0000 - val_loss: 49.8911 - val_mse: 12625.5371 - 564ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 337.7906 - mse: 1136147.7500 - val_loss: 46.6882 - val_mse: 11065.1396 - 578ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 353.9156 - mse: 1432227.3750 - val_loss: 43.4923 - val_mse: 9616.5381 - 593ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 354.6608 - mse: 1480555.5000 - val_loss: 40.2832 - val_mse: 8281.5127 - 589ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 327.6666 - mse: 1045107.2500 - val_loss: 37.6816 - val_mse: 7268.4053 - 577ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 339.7694 - mse: 1154526.0000 - val_loss: 35.0795 - val_mse: 6311.3145 - 593ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 326.2396 - mse: 1080897.1250 - val_loss: 32.5966 - val_mse: 5454.9419 - 559ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 321.6595 - mse: 1046621.8750 - val_loss: 29.5749 - val_mse: 4529.5645 - 552ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 312.9487 - mse: 924930.1250 - val_loss: 27.6237 - val_mse: 3962.8345 - 563ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 312.7905 - mse: 1025933.8750 - val_loss: 24.5748 - val_mse: 3158.8730 - 554ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 326.6406 - mse: 1201007.5000 - val_loss: 21.9488 - val_mse: 2528.3191 - 556ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 315.9264 - mse: 1205404.1250 - val_loss: 19.3650 - val_mse: 1972.6031 - 568ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 313.8968 - mse: 1190437.3750 - val_loss: 17.1619 - val_mse: 1552.0829 - 564ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 307.8422 - mse: 1049674.8750 - val_loss: 14.8080 - val_mse: 1157.5464 - 578ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 311.4271 - mse: 1053441.7500 - val_loss: 12.5795 - val_mse: 840.2636 - 580ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 303.7041 - mse: 999072.7500 - val_loss: 10.6937 - val_mse: 612.9857 - 581ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 294.4936 - mse: 876024.1250 - val_loss: 8.9202 - val_mse: 431.4667 - 596ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 305.9502 - mse: 1067831.7500 - val_loss: 7.9538 - val_mse: 346.1964 - 618ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 299.1547 - mse: 1103841.0000 - val_loss: 6.1671 - val_mse: 211.5284 - 599ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 283.1664 - mse: 788580.9375 - val_loss: 4.7004 - val_mse: 124.4916 - 610ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 294.7373 - mse: 916340.2500 - val_loss: 3.3540 - val_mse: 63.4273 - 595ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 277.1255 - mse: 744476.1250 - val_loss: 2.4535 - val_mse: 33.3078 - 620ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 274.6574 - mse: 686989.0000 - val_loss: 1.5645 - val_mse: 13.4106 - 611ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 275.3548 - mse: 786201.0625 - val_loss: 0.7068 - val_mse: 3.0745 - 625ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 270.9124 - mse: 750655.9375 - val_loss: 0.3449 - val_mse: 0.9630 - 635ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 278.9246 - mse: 840394.7500 - val_loss: 0.3028 - val_mse: 0.6963 - 601ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 276.3761 - mse: 826816.1875 - val_loss: 0.4100 - val_mse: 1.4455 - 619ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 269.9460 - mse: 712807.3750 - val_loss: 0.2879 - val_mse: 0.6137 - 588ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 273.9306 - mse: 909167.3750 - val_loss: 0.4252 - val_mse: 2.0107 - 585ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 268.2392 - mse: 884370.6875 - val_loss: 1.0511 - val_mse: 8.7139 - 594ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 259.1594 - mse: 736645.4375 - val_loss: 1.2358 - val_mse: 8.6452 - 589ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 257.5832 - mse: 684990.9375 - val_loss: 1.2223 - val_mse: 7.0807 - 604ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 262.1740 - mse: 728450.7500 - val_loss: 0.8499 - val_mse: 4.0182 - 603ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 257.2730 - mse: 777258.9375 - val_loss: 1.7209 - val_mse: 26.7380 - 579ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 266.9927 - mse: 866515.1250 - val_loss: 2.4853 - val_mse: 52.0043 - 602ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 255.6329 - mse: 615471.2500 - val_loss: 2.9956 - val_mse: 71.2574 - 581ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 253.0759 - mse: 704490.0000 - val_loss: 3.2525 - val_mse: 80.4427 - 589ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 260.6836 - mse: 814031.5000 - val_loss: 3.4027 - val_mse: 85.5765 - 576ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 252.6828 - mse: 628837.1875 - val_loss: 3.7107 - val_mse: 100.2599 - 583ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 245.5421 - mse: 662633.7500 - val_loss: 4.1887 - val_mse: 125.2205 - 602ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 247.7187 - mse: 598728.5000 - val_loss: 4.5283 - val_mse: 144.3547 - 624ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 246.8789 - mse: 634271.2500 - val_loss: 4.8422 - val_mse: 163.2218 - 606ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 251.7812 - mse: 665075.8125 - val_loss: 5.2078 - val_mse: 191.1154 - 607ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 247.8700 - mse: 678558.6875 - val_loss: 5.5695 - val_mse: 216.6861 - 627ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 232.0293 - mse: 546282.6250 - val_loss: 5.7630 - val_mse: 235.8878 - 608ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 245.1065 - mse: 687048.0625 - val_loss: 5.9826 - val_mse: 254.3177 - 601ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 244.6268 - mse: 703603.4375 - val_loss: 5.9746 - val_mse: 252.0131 - 619ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 235.9814 - mse: 624939.8750 - val_loss: 6.2249 - val_mse: 271.7834 - 621ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 236.1030 - mse: 619911.8750 - val_loss: 5.9940 - val_mse: 247.9495 - 621ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 225.4572 - mse: 498498.0312 - val_loss: 5.5837 - val_mse: 213.8072 - 621ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 233.9799 - mse: 608511.6875 - val_loss: 5.8245 - val_mse: 230.4942 - 606ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 233.6062 - mse: 584017.3125 - val_loss: 5.6964 - val_mse: 219.4473 - 585ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 228.2338 - mse: 584932.5625 - val_loss: 5.4836 - val_mse: 203.2431 - 587ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 227.4753 - mse: 552014.3750 - val_loss: 5.3127 - val_mse: 191.5169 - 606ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 222.8490 - mse: 481337.2188 - val_loss: 5.3864 - val_mse: 196.2663 - 624ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 236.6176 - mse: 676166.1875 - val_loss: 5.4741 - val_mse: 201.7896 - 615ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 234.2021 - mse: 574640.5625 - val_loss: 5.4080 - val_mse: 196.7148 - 606ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 224.7145 - mse: 532449.8125 - val_loss: 5.4723 - val_mse: 201.0171 - 609ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 220.5370 - mse: 522666.9375 - val_loss: 5.5086 - val_mse: 203.5297 - 613ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 220.7151 - mse: 568184.4375 - val_loss: 5.4959 - val_mse: 202.7818 - 618ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 223.4175 - mse: 568335.5625 - val_loss: 5.5312 - val_mse: 205.2913 - 614ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 222.7175 - mse: 607275.9375 - val_loss: 5.5684 - val_mse: 207.7773 - 625ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 221.5431 - mse: 498780.9062 - val_loss: 5.6379 - val_mse: 212.6279 - 589ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 208.6018 - mse: 425949.6875 - val_loss: 5.7004 - val_mse: 217.0221 - 600ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 210.2623 - mse: 409591.0000 - val_loss: 5.7667 - val_mse: 221.6943 - 586ms/epoch - 5ms/step\n",
            "107/107 - 1s - loss: 214.6848 - mse: 502469.4062 - val_loss: 5.6986 - val_mse: 217.1074 - 594ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 221.5855 - mse: 563292.5625 - val_loss: 5.7710 - val_mse: 222.2686 - 595ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 220.6188 - mse: 560190.5000 - val_loss: 5.7484 - val_mse: 220.7467 - 601ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 207.2592 - mse: 449263.2500 - val_loss: 5.8163 - val_mse: 225.5672 - 597ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 212.9803 - mse: 449322.8125 - val_loss: 5.6049 - val_mse: 209.5624 - 590ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 211.9417 - mse: 510083.8125 - val_loss: 5.5235 - val_mse: 202.9971 - 602ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 211.0997 - mse: 516391.1875 - val_loss: 5.4620 - val_mse: 198.6149 - 625ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 208.1891 - mse: 457661.6250 - val_loss: 5.5023 - val_mse: 201.7175 - 605ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 205.0955 - mse: 418740.5625 - val_loss: 5.5396 - val_mse: 204.0740 - 600ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 207.7116 - mse: 508822.4688 - val_loss: 5.4551 - val_mse: 197.8282 - 616ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 201.6171 - mse: 419464.1562 - val_loss: 5.5090 - val_mse: 201.4043 - 617ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 201.5634 - mse: 434887.6875 - val_loss: 5.4922 - val_mse: 200.3710 - 617ms/epoch - 6ms/step\n",
            "107/107 - 1s - loss: 211.2750 - mse: 490552.7812 - val_loss: 5.4384 - val_mse: 196.6463 - 628ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 383 ended. Search finished for the next optimal point.\n",
            "Time taken: 94.5760\n",
            "Function value obtained: 196.6463\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 384 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [62, 128, 73]\n",
            "Learning Rate: 1.8775268622072515e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.39165673945702945\n",
            "Batch Size: 26\n",
            "----------------------------------------\n",
            "323/323 - 4s - loss: 1207.8109 - mse: 15608391.0000 - val_loss: 127.5948 - val_mse: 88592.2344 - 4s/epoch - 14ms/step\n",
            "323/323 - 1s - loss: 959.9124 - mse: 10362983.0000 - val_loss: 44.5207 - val_mse: 10208.2842 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 849.9594 - mse: 7659055.5000 - val_loss: 23.9799 - val_mse: 3253.1321 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 746.1109 - mse: 5589633.5000 - val_loss: 18.7925 - val_mse: 2014.9191 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 662.7736 - mse: 5140708.0000 - val_loss: 12.3063 - val_mse: 792.1135 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 592.1931 - mse: 3664626.0000 - val_loss: 10.8649 - val_mse: 622.8932 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 520.1812 - mse: 2690869.0000 - val_loss: 10.4714 - val_mse: 627.7819 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 500.1391 - mse: 2767952.2500 - val_loss: 8.9450 - val_mse: 496.1279 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 459.1379 - mse: 2415095.2500 - val_loss: 3.3640 - val_mse: 60.0154 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 419.7751 - mse: 1829035.3750 - val_loss: 4.9484 - val_mse: 132.1190 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 379.6983 - mse: 1604296.0000 - val_loss: 5.1165 - val_mse: 154.1657 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 331.0995 - mse: 1071927.0000 - val_loss: 5.7810 - val_mse: 184.6017 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 324.8929 - mse: 1226930.1250 - val_loss: 2.2316 - val_mse: 37.6383 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 293.2848 - mse: 829147.8750 - val_loss: 5.2755 - val_mse: 188.3713 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 254.6873 - mse: 666075.9375 - val_loss: 5.6415 - val_mse: 207.9723 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 250.6994 - mse: 627213.8750 - val_loss: 7.1849 - val_mse: 321.6649 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 220.7295 - mse: 529381.8750 - val_loss: 6.6192 - val_mse: 269.7005 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 211.6611 - mse: 524005.6562 - val_loss: 6.0695 - val_mse: 237.7541 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 187.3691 - mse: 341228.4062 - val_loss: 5.8876 - val_mse: 230.4988 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 174.4241 - mse: 291015.8750 - val_loss: 6.3570 - val_mse: 262.7807 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 165.4666 - mse: 291110.2812 - val_loss: 4.1451 - val_mse: 114.7426 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 146.9282 - mse: 217838.4062 - val_loss: 5.1717 - val_mse: 177.1352 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 137.1685 - mse: 173447.0312 - val_loss: 4.1414 - val_mse: 122.2804 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 130.4927 - mse: 232799.8750 - val_loss: 3.8005 - val_mse: 95.5234 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 126.4396 - mse: 171182.4844 - val_loss: 3.8489 - val_mse: 101.2426 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 110.4909 - mse: 133817.5781 - val_loss: 2.1637 - val_mse: 34.3302 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 98.2109 - mse: 82351.3750 - val_loss: 2.2895 - val_mse: 37.7158 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 96.4215 - mse: 89278.2266 - val_loss: 2.0731 - val_mse: 31.6426 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 88.3966 - mse: 82181.5703 - val_loss: 1.5629 - val_mse: 18.9980 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 81.7171 - mse: 76199.9688 - val_loss: 0.5940 - val_mse: 3.1198 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 78.0429 - mse: 62780.5234 - val_loss: 0.6902 - val_mse: 4.1785 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 71.7905 - mse: 49549.4219 - val_loss: 0.5839 - val_mse: 2.9786 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 65.4926 - mse: 41792.6992 - val_loss: 0.4295 - val_mse: 1.6025 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 65.1749 - mse: 49402.2891 - val_loss: 0.3573 - val_mse: 1.0950 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 58.9339 - mse: 39531.5859 - val_loss: 0.4082 - val_mse: 1.4491 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 56.8800 - mse: 39413.6172 - val_loss: 0.3015 - val_mse: 0.7820 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 53.8399 - mse: 33267.2383 - val_loss: 0.2640 - val_mse: 0.6004 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 47.3968 - mse: 21625.5312 - val_loss: 0.2756 - val_mse: 0.6559 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 44.3292 - mse: 22949.2734 - val_loss: 0.2414 - val_mse: 0.5100 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 41.9247 - mse: 20618.2930 - val_loss: 0.2269 - val_mse: 0.4640 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 39.5499 - mse: 18346.5918 - val_loss: 0.2225 - val_mse: 0.4488 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 35.6805 - mse: 13393.3848 - val_loss: 0.2207 - val_mse: 0.4415 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 34.9453 - mse: 15123.3037 - val_loss: 0.2238 - val_mse: 0.4476 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 30.9435 - mse: 10700.0332 - val_loss: 0.2235 - val_mse: 0.4470 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 30.3398 - mse: 10529.3643 - val_loss: 0.2216 - val_mse: 0.4432 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 27.1817 - mse: 8440.2822 - val_loss: 0.2289 - val_mse: 0.4578 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 26.6920 - mse: 9951.2793 - val_loss: 0.2188 - val_mse: 0.4376 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 22.8171 - mse: 5407.4136 - val_loss: 0.2984 - val_mse: 0.6059 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 22.7874 - mse: 6247.2051 - val_loss: 0.2652 - val_mse: 0.5308 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 22.0351 - mse: 6037.5464 - val_loss: 0.2550 - val_mse: 0.5101 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 20.9651 - mse: 6315.0049 - val_loss: 0.2412 - val_mse: 0.4824 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 17.6422 - mse: 3444.1860 - val_loss: 0.2522 - val_mse: 0.5046 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 16.4914 - mse: 3233.7463 - val_loss: 0.2601 - val_mse: 0.5221 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 15.5031 - mse: 3023.5154 - val_loss: 0.2451 - val_mse: 0.4907 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 14.4908 - mse: 2437.6082 - val_loss: 0.2424 - val_mse: 0.4854 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 13.4689 - mse: 2268.6899 - val_loss: 0.2265 - val_mse: 0.4531 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 12.6208 - mse: 1908.0051 - val_loss: 0.2259 - val_mse: 0.4518 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 12.5062 - mse: 2585.2686 - val_loss: 0.2176 - val_mse: 0.4351 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 10.8628 - mse: 1541.0835 - val_loss: 0.2137 - val_mse: 0.4274 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 10.4066 - mse: 1321.2897 - val_loss: 0.2143 - val_mse: 0.4286 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 9.5756 - mse: 1248.5616 - val_loss: 0.2104 - val_mse: 0.4209 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 9.9146 - mse: 1668.8940 - val_loss: 0.2015 - val_mse: 0.4030 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 7.9937 - mse: 914.3067 - val_loss: 0.1973 - val_mse: 0.3947 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 8.4487 - mse: 1269.3528 - val_loss: 0.1893 - val_mse: 0.3787 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 7.2868 - mse: 809.7501 - val_loss: 0.1851 - val_mse: 0.3703 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 6.6703 - mse: 630.3984 - val_loss: 0.1825 - val_mse: 0.3650 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 6.5137 - mse: 609.6725 - val_loss: 0.1794 - val_mse: 0.3587 - 1s/epoch - 4ms/step\n",
            "323/323 - 2s - loss: 5.7877 - mse: 470.1344 - val_loss: 0.1742 - val_mse: 0.3483 - 2s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 5.3144 - mse: 452.0399 - val_loss: 0.1682 - val_mse: 0.3365 - 2s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 5.3258 - mse: 452.5032 - val_loss: 0.1609 - val_mse: 0.3218 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 4.5865 - mse: 289.2710 - val_loss: 0.1549 - val_mse: 0.3098 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 4.0931 - mse: 251.1687 - val_loss: 0.1507 - val_mse: 0.3015 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 3.9168 - mse: 289.4027 - val_loss: 0.1455 - val_mse: 0.2911 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 3.5276 - mse: 275.5238 - val_loss: 0.1434 - val_mse: 0.2868 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 3.5859 - mse: 346.2057 - val_loss: 0.1401 - val_mse: 0.2803 - 1s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 3.3306 - mse: 240.8055 - val_loss: 0.1370 - val_mse: 0.2740 - 2s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 3.0389 - mse: 237.4918 - val_loss: 0.1351 - val_mse: 0.2703 - 2s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 2.5206 - mse: 124.6025 - val_loss: 0.1328 - val_mse: 0.2656 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 2.6349 - mse: 255.6734 - val_loss: 0.1292 - val_mse: 0.2584 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 2.2893 - mse: 131.5547 - val_loss: 0.1263 - val_mse: 0.2526 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 1.9221 - mse: 85.2215 - val_loss: 0.1232 - val_mse: 0.2464 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 1.8254 - mse: 79.0517 - val_loss: 0.1192 - val_mse: 0.2384 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 1.7851 - mse: 84.4732 - val_loss: 0.1156 - val_mse: 0.2311 - 1s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 1.5096 - mse: 54.8547 - val_loss: 0.1134 - val_mse: 0.2268 - 2s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 1.4916 - mse: 57.2240 - val_loss: 0.1109 - val_mse: 0.2218 - 2s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 1.2878 - mse: 48.1405 - val_loss: 0.1087 - val_mse: 0.2175 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 1.3632 - mse: 104.4932 - val_loss: 0.1065 - val_mse: 0.2129 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 1.0540 - mse: 28.8410 - val_loss: 0.1035 - val_mse: 0.2070 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 1.0843 - mse: 45.6697 - val_loss: 0.1000 - val_mse: 0.1999 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 1.0397 - mse: 50.4346 - val_loss: 0.0974 - val_mse: 0.1949 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 0.8017 - mse: 20.3902 - val_loss: 0.0949 - val_mse: 0.1899 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 0.8152 - mse: 29.3123 - val_loss: 0.0926 - val_mse: 0.1852 - 1s/epoch - 4ms/step\n",
            "323/323 - 2s - loss: 0.7692 - mse: 24.8883 - val_loss: 0.0909 - val_mse: 0.1818 - 2s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 0.6771 - mse: 16.8650 - val_loss: 0.0889 - val_mse: 0.1779 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 0.6790 - mse: 21.5078 - val_loss: 0.0864 - val_mse: 0.1728 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 0.6256 - mse: 33.6608 - val_loss: 0.0836 - val_mse: 0.1672 - 1s/epoch - 4ms/step\n",
            "323/323 - 1s - loss: 0.4756 - mse: 8.1008 - val_loss: 0.0816 - val_mse: 0.1633 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 0.4804 - mse: 12.1630 - val_loss: 0.0790 - val_mse: 0.1580 - 1s/epoch - 5ms/step\n",
            "323/323 - 1s - loss: 0.4400 - mse: 12.7832 - val_loss: 0.0769 - val_mse: 0.1539 - 1s/epoch - 5ms/step\n",
            "323/323 - 2s - loss: 0.4045 - mse: 9.5609 - val_loss: 0.0749 - val_mse: 0.1497 - 2s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 384 ended. Search finished for the next optimal point.\n",
            "Time taken: 177.4511\n",
            "Function value obtained: 0.1497\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 385 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [123, 110, 128]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4289625074392289\n",
            "Batch Size: 58\n",
            "----------------------------------------\n",
            "145/145 - 4s - loss: 1747.0543 - mse: 34208708.0000 - val_loss: 14.7412 - val_mse: 1305.5262 - 4s/epoch - 28ms/step\n",
            "145/145 - 1s - loss: 1713.0911 - mse: 26501558.0000 - val_loss: 29.1323 - val_mse: 4763.0493 - 820ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 1738.4948 - mse: 29884838.0000 - val_loss: 41.5257 - val_mse: 9448.8398 - 827ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 1592.6157 - mse: 22506408.0000 - val_loss: 51.0467 - val_mse: 14082.0264 - 809ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 1646.3593 - mse: 28636688.0000 - val_loss: 61.3130 - val_mse: 20197.4688 - 775ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1599.1573 - mse: 25969052.0000 - val_loss: 67.6857 - val_mse: 24668.2012 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1550.6533 - mse: 24746986.0000 - val_loss: 71.7766 - val_mse: 27918.8164 - 764ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1511.9757 - mse: 21810620.0000 - val_loss: 77.1531 - val_mse: 32329.0547 - 755ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1538.8396 - mse: 25088252.0000 - val_loss: 77.3956 - val_mse: 32934.7148 - 753ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1477.9442 - mse: 23444412.0000 - val_loss: 77.9077 - val_mse: 33703.9297 - 747ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1475.7578 - mse: 23268262.0000 - val_loss: 77.0755 - val_mse: 33040.8945 - 741ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1452.5875 - mse: 19827550.0000 - val_loss: 72.3865 - val_mse: 29279.3418 - 762ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1440.6641 - mse: 21185500.0000 - val_loss: 69.2815 - val_mse: 26870.5254 - 747ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1438.2776 - mse: 21821540.0000 - val_loss: 65.7880 - val_mse: 24235.3359 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1461.4154 - mse: 25927024.0000 - val_loss: 64.3367 - val_mse: 23213.5723 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1330.3790 - mse: 18414024.0000 - val_loss: 60.2173 - val_mse: 20674.1641 - 754ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1297.8510 - mse: 17469652.0000 - val_loss: 53.5526 - val_mse: 16876.4629 - 785ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1339.7002 - mse: 18697826.0000 - val_loss: 49.2513 - val_mse: 14587.6377 - 752ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1386.6703 - mse: 19387910.0000 - val_loss: 39.8951 - val_mse: 10163.0967 - 767ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1299.8046 - mse: 16245477.0000 - val_loss: 34.0106 - val_mse: 7746.9688 - 725ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1362.1084 - mse: 19637528.0000 - val_loss: 26.2081 - val_mse: 4986.9531 - 714ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1287.9314 - mse: 16498306.0000 - val_loss: 15.9382 - val_mse: 2004.7054 - 716ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1224.3593 - mse: 17810252.0000 - val_loss: 10.5143 - val_mse: 841.2385 - 722ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1245.5964 - mse: 15930310.0000 - val_loss: 8.0439 - val_mse: 486.9705 - 730ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1269.7660 - mse: 19505200.0000 - val_loss: 5.4055 - val_mse: 171.7140 - 735ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1233.6232 - mse: 18318678.0000 - val_loss: 4.5734 - val_mse: 56.3567 - 748ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1206.9873 - mse: 15682436.0000 - val_loss: 6.3486 - val_mse: 110.6390 - 762ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1218.3772 - mse: 15207559.0000 - val_loss: 10.9387 - val_mse: 387.2112 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1213.4458 - mse: 14956285.0000 - val_loss: 13.3893 - val_mse: 636.0917 - 768ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1210.6302 - mse: 15832487.0000 - val_loss: 16.8797 - val_mse: 1122.7875 - 761ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1206.9619 - mse: 15040200.0000 - val_loss: 21.2908 - val_mse: 1950.4500 - 755ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1149.7306 - mse: 12720810.0000 - val_loss: 24.3322 - val_mse: 2714.1345 - 791ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1167.5845 - mse: 14147865.0000 - val_loss: 25.7302 - val_mse: 3111.9644 - 784ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1118.9692 - mse: 11599329.0000 - val_loss: 26.0766 - val_mse: 3222.2507 - 801ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 1130.5801 - mse: 11919475.0000 - val_loss: 25.2086 - val_mse: 2965.0000 - 759ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1106.1742 - mse: 11374934.0000 - val_loss: 25.4953 - val_mse: 2925.3928 - 758ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1125.7383 - mse: 13744662.0000 - val_loss: 26.7756 - val_mse: 3125.7275 - 746ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1100.4924 - mse: 12193373.0000 - val_loss: 30.1821 - val_mse: 4080.6357 - 751ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1094.6346 - mse: 12702030.0000 - val_loss: 33.1576 - val_mse: 5244.1426 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1078.3281 - mse: 11609249.0000 - val_loss: 33.7200 - val_mse: 5659.1387 - 740ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1078.2650 - mse: 12580815.0000 - val_loss: 33.1884 - val_mse: 5710.7524 - 746ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1119.0366 - mse: 13394140.0000 - val_loss: 32.4712 - val_mse: 5762.7402 - 728ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1092.6106 - mse: 12699347.0000 - val_loss: 29.1522 - val_mse: 4788.4424 - 749ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1059.3889 - mse: 11555017.0000 - val_loss: 26.9808 - val_mse: 4189.2891 - 748ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1057.9487 - mse: 11622359.0000 - val_loss: 23.2957 - val_mse: 3319.0254 - 741ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1045.5558 - mse: 10686539.0000 - val_loss: 20.8534 - val_mse: 2819.5427 - 740ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1037.7909 - mse: 11080773.0000 - val_loss: 17.4115 - val_mse: 2120.3557 - 754ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1021.9046 - mse: 11173786.0000 - val_loss: 13.4835 - val_mse: 1415.1675 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1049.0870 - mse: 11573827.0000 - val_loss: 8.5839 - val_mse: 616.1802 - 765ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1036.3352 - mse: 11352069.0000 - val_loss: 5.5678 - val_mse: 197.6658 - 743ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1034.9498 - mse: 13045279.0000 - val_loss: 5.6526 - val_mse: 118.1597 - 789ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1013.7396 - mse: 10032548.0000 - val_loss: 8.4501 - val_mse: 289.0484 - 715ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 963.9302 - mse: 10372459.0000 - val_loss: 12.3513 - val_mse: 740.3531 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 958.9720 - mse: 9484895.0000 - val_loss: 14.2860 - val_mse: 1072.7120 - 736ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 996.3171 - mse: 9867857.0000 - val_loss: 14.9580 - val_mse: 1254.8942 - 728ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 949.4173 - mse: 8202852.0000 - val_loss: 15.8551 - val_mse: 1479.8679 - 736ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 1016.4229 - mse: 10493126.0000 - val_loss: 16.2004 - val_mse: 1592.0669 - 731ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 986.5577 - mse: 9593243.0000 - val_loss: 16.3386 - val_mse: 1631.2091 - 735ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 951.7041 - mse: 8716725.0000 - val_loss: 16.3556 - val_mse: 1654.5048 - 748ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 959.4609 - mse: 9091800.0000 - val_loss: 15.9733 - val_mse: 1622.3219 - 759ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 983.7692 - mse: 9646423.0000 - val_loss: 14.4992 - val_mse: 1369.8933 - 747ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 961.5135 - mse: 9873475.0000 - val_loss: 13.7403 - val_mse: 1267.6005 - 781ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 946.6926 - mse: 8725813.0000 - val_loss: 12.9912 - val_mse: 1109.3807 - 803ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 953.2941 - mse: 9594209.0000 - val_loss: 12.2575 - val_mse: 954.7198 - 780ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 908.2454 - mse: 8164065.0000 - val_loss: 11.6993 - val_mse: 882.5658 - 789ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 933.5878 - mse: 10041921.0000 - val_loss: 11.1002 - val_mse: 826.6817 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 943.8556 - mse: 11232299.0000 - val_loss: 10.4350 - val_mse: 752.5997 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 894.5417 - mse: 7887241.0000 - val_loss: 9.5310 - val_mse: 631.6294 - 755ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 924.2731 - mse: 8805145.0000 - val_loss: 8.7696 - val_mse: 522.7956 - 731ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 908.6439 - mse: 8683856.0000 - val_loss: 8.1293 - val_mse: 419.6513 - 740ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 916.9571 - mse: 9067849.0000 - val_loss: 7.5946 - val_mse: 326.5990 - 722ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 910.1473 - mse: 9171005.0000 - val_loss: 8.0735 - val_mse: 348.2781 - 741ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 897.4142 - mse: 8224220.0000 - val_loss: 7.7449 - val_mse: 296.2138 - 743ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 912.1041 - mse: 10226107.0000 - val_loss: 8.2150 - val_mse: 304.8388 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 907.9805 - mse: 8681275.0000 - val_loss: 9.3846 - val_mse: 365.1823 - 732ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 870.6043 - mse: 6645492.0000 - val_loss: 9.3391 - val_mse: 358.6659 - 750ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 883.8799 - mse: 7948695.5000 - val_loss: 10.4997 - val_mse: 462.9797 - 778ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 877.8590 - mse: 8531200.0000 - val_loss: 10.2845 - val_mse: 444.1386 - 785ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 849.9332 - mse: 6728075.0000 - val_loss: 10.6057 - val_mse: 477.1104 - 786ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 871.6993 - mse: 7416793.0000 - val_loss: 11.3395 - val_mse: 555.0134 - 801ms/epoch - 6ms/step\n",
            "145/145 - 1s - loss: 880.1201 - mse: 7973038.0000 - val_loss: 12.3055 - val_mse: 666.7250 - 739ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 843.5574 - mse: 6765498.5000 - val_loss: 13.3980 - val_mse: 806.3663 - 738ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 889.0363 - mse: 9096930.0000 - val_loss: 14.3020 - val_mse: 940.7903 - 745ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 847.9103 - mse: 7481425.5000 - val_loss: 14.5963 - val_mse: 995.5333 - 746ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 826.0214 - mse: 5855984.5000 - val_loss: 16.0007 - val_mse: 1229.3547 - 743ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 822.8765 - mse: 7016010.5000 - val_loss: 16.1188 - val_mse: 1262.5649 - 746ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 823.2294 - mse: 7375305.0000 - val_loss: 16.5252 - val_mse: 1347.4702 - 744ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 821.8239 - mse: 6402539.5000 - val_loss: 16.9635 - val_mse: 1430.1138 - 725ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 835.1940 - mse: 6556625.5000 - val_loss: 17.4660 - val_mse: 1509.2838 - 732ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 811.7129 - mse: 7077354.5000 - val_loss: 18.0366 - val_mse: 1611.1129 - 714ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 790.8010 - mse: 6276515.5000 - val_loss: 18.4885 - val_mse: 1701.5846 - 727ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 842.0098 - mse: 7130352.0000 - val_loss: 19.2518 - val_mse: 1844.2786 - 730ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 815.0591 - mse: 6260929.5000 - val_loss: 18.9943 - val_mse: 1774.8350 - 760ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 801.2285 - mse: 6272432.5000 - val_loss: 19.3238 - val_mse: 1805.2887 - 740ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 795.2100 - mse: 5833600.0000 - val_loss: 19.8524 - val_mse: 1894.8430 - 765ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 810.3124 - mse: 7915531.0000 - val_loss: 19.6863 - val_mse: 1835.0002 - 742ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 788.9308 - mse: 5697227.5000 - val_loss: 19.8443 - val_mse: 1841.3832 - 726ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 780.9407 - mse: 5712873.0000 - val_loss: 20.5181 - val_mse: 1903.9354 - 718ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 776.1356 - mse: 5639617.5000 - val_loss: 21.0755 - val_mse: 1939.0602 - 718ms/epoch - 5ms/step\n",
            "145/145 - 1s - loss: 776.3793 - mse: 5844520.0000 - val_loss: 21.6502 - val_mse: 1991.7932 - 736ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 385 ended. Search finished for the next optimal point.\n",
            "Time taken: 107.9962\n",
            "Function value obtained: 1991.7932\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 386 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 112]\n",
            "Learning Rate: 7.390612081037543e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4207684112233833\n",
            "Batch Size: 178\n",
            "----------------------------------------\n",
            "48/48 - 3s - loss: 4419.1709 - mse: 160867440.0000 - val_loss: 1884.3953 - val_mse: 17934424.0000 - 3s/epoch - 56ms/step\n",
            "48/48 - 0s - loss: 3744.3076 - mse: 112114352.0000 - val_loss: 1453.0417 - val_mse: 10671020.0000 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 3140.9543 - mse: 76369408.0000 - val_loss: 1113.3132 - val_mse: 6251740.5000 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2991.0010 - mse: 84005352.0000 - val_loss: 823.5362 - val_mse: 3413167.5000 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2679.6401 - mse: 61964708.0000 - val_loss: 588.7880 - val_mse: 1737897.8750 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2477.7126 - mse: 59624024.0000 - val_loss: 393.1393 - val_mse: 770259.1250 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2267.7822 - mse: 48257216.0000 - val_loss: 240.1798 - val_mse: 283893.8438 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2129.2207 - mse: 42191256.0000 - val_loss: 100.7850 - val_mse: 47534.4414 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1949.2800 - mse: 35177944.0000 - val_loss: 7.9195 - val_mse: 117.3379 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1817.8264 - mse: 29289106.0000 - val_loss: 52.5683 - val_mse: 17048.7734 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1723.0906 - mse: 30219592.0000 - val_loss: 105.5512 - val_mse: 62519.9180 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1602.5836 - mse: 23565302.0000 - val_loss: 139.4270 - val_mse: 106506.0312 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1493.0413 - mse: 20290366.0000 - val_loss: 165.8611 - val_mse: 147091.4844 - 274ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1452.9178 - mse: 21169320.0000 - val_loss: 170.6159 - val_mse: 152251.7344 - 270ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1366.2844 - mse: 17049010.0000 - val_loss: 167.7437 - val_mse: 147542.6406 - 268ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1363.7502 - mse: 17555740.0000 - val_loss: 158.1810 - val_mse: 132120.7969 - 273ms/epoch - 6ms/step\n",
            "48/48 - 1s - loss: 1234.1797 - mse: 14697822.0000 - val_loss: 145.6016 - val_mse: 111599.0000 - 814ms/epoch - 17ms/step\n",
            "48/48 - 0s - loss: 1250.0305 - mse: 16885330.0000 - val_loss: 131.0269 - val_mse: 90491.4844 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1161.0265 - mse: 13220215.0000 - val_loss: 111.1287 - val_mse: 65543.1094 - 299ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1087.0630 - mse: 12346043.0000 - val_loss: 101.6573 - val_mse: 57531.3359 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1023.2645 - mse: 9315780.0000 - val_loss: 102.0945 - val_mse: 58204.0078 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1046.1215 - mse: 10150925.0000 - val_loss: 89.8780 - val_mse: 45442.9453 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 984.5632 - mse: 8941125.0000 - val_loss: 77.4938 - val_mse: 34398.2188 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 946.3632 - mse: 9362365.0000 - val_loss: 60.2814 - val_mse: 21652.3613 - 305ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 964.4506 - mse: 9045616.0000 - val_loss: 27.4047 - val_mse: 4880.0103 - 311ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 933.6885 - mse: 7759352.5000 - val_loss: 22.0073 - val_mse: 2796.6943 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 885.2628 - mse: 7642072.0000 - val_loss: 18.4297 - val_mse: 1822.0259 - 307ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 887.0844 - mse: 7639021.5000 - val_loss: 39.4892 - val_mse: 6232.2251 - 306ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 880.2251 - mse: 8715984.0000 - val_loss: 75.2538 - val_mse: 26419.4121 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 820.0770 - mse: 5772342.5000 - val_loss: 103.1477 - val_mse: 51632.9570 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 836.4313 - mse: 7801026.5000 - val_loss: 127.5035 - val_mse: 81374.7891 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 840.8457 - mse: 6414722.0000 - val_loss: 146.9926 - val_mse: 113315.0078 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 808.5698 - mse: 6222701.5000 - val_loss: 157.2737 - val_mse: 133145.4062 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 763.7669 - mse: 5208668.0000 - val_loss: 169.1122 - val_mse: 153336.2188 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 785.5633 - mse: 7490282.5000 - val_loss: 187.0694 - val_mse: 188019.7812 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 757.9274 - mse: 5698395.5000 - val_loss: 206.2871 - val_mse: 226378.7344 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 742.8792 - mse: 5538259.5000 - val_loss: 207.1487 - val_mse: 232312.7500 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 781.0873 - mse: 6476478.0000 - val_loss: 225.2019 - val_mse: 271469.1562 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 747.5386 - mse: 5544787.0000 - val_loss: 222.8894 - val_mse: 267754.3750 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 726.4208 - mse: 5977728.0000 - val_loss: 225.6033 - val_mse: 274439.8750 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 728.7585 - mse: 5551735.5000 - val_loss: 221.9394 - val_mse: 266013.6562 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 747.4132 - mse: 5488052.0000 - val_loss: 209.1190 - val_mse: 237483.6875 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 730.9359 - mse: 5554088.5000 - val_loss: 208.6454 - val_mse: 236119.0469 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 724.3511 - mse: 5254842.5000 - val_loss: 203.6438 - val_mse: 224853.8906 - 281ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 702.6522 - mse: 4680065.0000 - val_loss: 209.2542 - val_mse: 236924.8750 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 694.2390 - mse: 4594610.0000 - val_loss: 220.9629 - val_mse: 262547.8125 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 698.3894 - mse: 5507872.0000 - val_loss: 222.8578 - val_mse: 265649.6562 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 673.6119 - mse: 4017951.7500 - val_loss: 208.0097 - val_mse: 230754.2188 - 276ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 687.2825 - mse: 4495401.5000 - val_loss: 200.6816 - val_mse: 214899.6094 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 673.8926 - mse: 4459160.5000 - val_loss: 196.7831 - val_mse: 206868.7656 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 691.3169 - mse: 5156805.0000 - val_loss: 189.1091 - val_mse: 191102.0938 - 272ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 648.5209 - mse: 4073513.0000 - val_loss: 191.3136 - val_mse: 195792.0312 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 637.2721 - mse: 3940963.7500 - val_loss: 192.2429 - val_mse: 197575.0469 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 637.9942 - mse: 4152189.0000 - val_loss: 191.6543 - val_mse: 196949.2656 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 643.8168 - mse: 4390701.0000 - val_loss: 186.3174 - val_mse: 186282.8594 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 611.7545 - mse: 3892313.7500 - val_loss: 187.4899 - val_mse: 188564.2500 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 630.4783 - mse: 3855585.0000 - val_loss: 194.7156 - val_mse: 203032.3594 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 625.7219 - mse: 3843297.5000 - val_loss: 203.3394 - val_mse: 221166.7656 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 628.8973 - mse: 4291655.5000 - val_loss: 205.6317 - val_mse: 226382.9219 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 604.5050 - mse: 3494536.5000 - val_loss: 208.0952 - val_mse: 232075.6250 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 592.1773 - mse: 3062026.5000 - val_loss: 203.8497 - val_mse: 223141.6250 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 590.5972 - mse: 3566704.0000 - val_loss: 205.9051 - val_mse: 227776.8438 - 312ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 587.5210 - mse: 3132253.0000 - val_loss: 201.3140 - val_mse: 218073.5312 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 601.7570 - mse: 4140487.2500 - val_loss: 184.2198 - val_mse: 183566.0000 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 569.0772 - mse: 3226941.0000 - val_loss: 183.6597 - val_mse: 182710.3750 - 301ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 575.5331 - mse: 3422579.5000 - val_loss: 180.5144 - val_mse: 176579.7188 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 573.1195 - mse: 3600939.7500 - val_loss: 167.8139 - val_mse: 152589.7656 - 275ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 542.1957 - mse: 2622568.5000 - val_loss: 160.8403 - val_mse: 140215.3906 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 562.4601 - mse: 3285372.5000 - val_loss: 161.0676 - val_mse: 140401.1719 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 545.8672 - mse: 2897273.5000 - val_loss: 164.1064 - val_mse: 146312.5625 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 542.2343 - mse: 2847615.0000 - val_loss: 158.9701 - val_mse: 137471.0469 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 551.7747 - mse: 2978907.7500 - val_loss: 161.7093 - val_mse: 142278.2656 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 529.0039 - mse: 3085355.7500 - val_loss: 161.6813 - val_mse: 142325.2812 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 544.3774 - mse: 3101620.0000 - val_loss: 167.8962 - val_mse: 153155.6875 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 527.7598 - mse: 2802292.5000 - val_loss: 168.6246 - val_mse: 154559.7969 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 519.7385 - mse: 2633305.0000 - val_loss: 167.5299 - val_mse: 152510.5000 - 278ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 522.4797 - mse: 3095549.0000 - val_loss: 158.0973 - val_mse: 135962.6562 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 509.8451 - mse: 2698535.7500 - val_loss: 155.6861 - val_mse: 131386.4375 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 491.7255 - mse: 2281098.0000 - val_loss: 148.9186 - val_mse: 120426.7578 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 487.9503 - mse: 2296403.7500 - val_loss: 142.4364 - val_mse: 110506.8203 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 499.8748 - mse: 2496680.2500 - val_loss: 136.7534 - val_mse: 102086.2578 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 495.2583 - mse: 2418034.5000 - val_loss: 120.8385 - val_mse: 80280.4766 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 498.9932 - mse: 2755283.5000 - val_loss: 116.1283 - val_mse: 74101.2266 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 467.6810 - mse: 2194409.7500 - val_loss: 112.8082 - val_mse: 70174.2891 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 462.0902 - mse: 2171312.5000 - val_loss: 106.8673 - val_mse: 63245.3086 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 466.9768 - mse: 2226123.0000 - val_loss: 106.9458 - val_mse: 63998.6055 - 277ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 457.3316 - mse: 2337565.0000 - val_loss: 108.5391 - val_mse: 66083.2578 - 280ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 469.5162 - mse: 2266679.0000 - val_loss: 103.1598 - val_mse: 60249.3828 - 279ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 467.0657 - mse: 2197465.2500 - val_loss: 106.4632 - val_mse: 64457.5156 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 445.8123 - mse: 2194833.0000 - val_loss: 100.8061 - val_mse: 58315.0234 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 460.5923 - mse: 2228990.5000 - val_loss: 95.7767 - val_mse: 52999.7617 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 445.7654 - mse: 1966853.8750 - val_loss: 94.7363 - val_mse: 51630.8125 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 447.5306 - mse: 2183039.7500 - val_loss: 94.4921 - val_mse: 51536.0859 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 437.3925 - mse: 1881549.8750 - val_loss: 94.6812 - val_mse: 51609.8828 - 299ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 432.0922 - mse: 1788919.1250 - val_loss: 89.9863 - val_mse: 46840.1523 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 441.6509 - mse: 1915973.2500 - val_loss: 91.4978 - val_mse: 48326.7266 - 303ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 429.4619 - mse: 1902811.6250 - val_loss: 89.0836 - val_mse: 45794.7266 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 425.0081 - mse: 1954415.1250 - val_loss: 89.9361 - val_mse: 46666.7070 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 416.2453 - mse: 1778100.5000 - val_loss: 81.9836 - val_mse: 38966.2930 - 310ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 409.9980 - mse: 1702644.6250 - val_loss: 74.8493 - val_mse: 32603.4551 - 288ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 386 ended. Search finished for the next optimal point.\n",
            "Time taken: 65.0949\n",
            "Function value obtained: 32603.4551\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 387 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 1\n",
            "Layer Nodes: [128]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 3s - loss: 187.6932 - mse: 194205.5625 - val_loss: 100.0655 - val_mse: 55490.2188 - 3s/epoch - 7ms/step\n",
            "525/525 - 2s - loss: 38.0333 - mse: 13957.9941 - val_loss: 7.5442 - val_mse: 167.4763 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 7.1069 - mse: 150.0574 - val_loss: 6.5853 - val_mse: 134.3256 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 6.4202 - mse: 121.7097 - val_loss: 6.0906 - val_mse: 129.8800 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 5.8732 - mse: 101.5432 - val_loss: 5.6387 - val_mse: 92.6360 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 5.5894 - mse: 91.1656 - val_loss: 5.4052 - val_mse: 95.8778 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 5.2970 - mse: 81.0249 - val_loss: 5.0396 - val_mse: 71.6880 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.8992 - mse: 68.7532 - val_loss: 4.7482 - val_mse: 63.6368 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.6726 - mse: 64.0623 - val_loss: 4.4854 - val_mse: 63.5763 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.4759 - mse: 58.3201 - val_loss: 4.3362 - val_mse: 54.1065 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.2913 - mse: 54.3212 - val_loss: 4.1435 - val_mse: 50.9263 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 4.1407 - mse: 50.9354 - val_loss: 3.9911 - val_mse: 47.5553 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.9784 - mse: 48.2282 - val_loss: 3.8387 - val_mse: 46.4449 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.8455 - mse: 44.7779 - val_loss: 3.7132 - val_mse: 45.7068 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.6991 - mse: 41.6345 - val_loss: 3.6330 - val_mse: 38.7148 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.5701 - mse: 39.0116 - val_loss: 3.4458 - val_mse: 36.9636 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.4477 - mse: 36.7467 - val_loss: 3.3248 - val_mse: 34.5641 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.3303 - mse: 33.9459 - val_loss: 3.2452 - val_mse: 31.7849 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.2061 - mse: 31.9971 - val_loss: 3.1297 - val_mse: 35.1360 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 3.0929 - mse: 30.3294 - val_loss: 3.0271 - val_mse: 27.9925 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 3.0016 - mse: 28.6314 - val_loss: 2.9116 - val_mse: 26.2485 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 2.8882 - mse: 26.8758 - val_loss: 2.8153 - val_mse: 24.6557 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 2.7735 - mse: 24.6345 - val_loss: 2.7349 - val_mse: 23.2655 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.6995 - mse: 23.3302 - val_loss: 2.5877 - val_mse: 22.1422 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 2.5734 - mse: 21.0946 - val_loss: 2.6562 - val_mse: 22.2369 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.4893 - mse: 20.4029 - val_loss: 2.4566 - val_mse: 19.2404 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.3905 - mse: 18.8880 - val_loss: 2.3154 - val_mse: 18.5348 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.3245 - mse: 18.0501 - val_loss: 2.2297 - val_mse: 17.6778 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.2253 - mse: 16.7811 - val_loss: 2.1455 - val_mse: 16.2554 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.1521 - mse: 15.7705 - val_loss: 2.0992 - val_mse: 17.3234 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 2.0768 - mse: 14.8539 - val_loss: 2.0991 - val_mse: 14.7610 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.9914 - mse: 13.6752 - val_loss: 1.9303 - val_mse: 12.8319 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.9357 - mse: 13.4175 - val_loss: 1.8679 - val_mse: 12.0529 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.8288 - mse: 11.8375 - val_loss: 1.7906 - val_mse: 13.0495 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.7646 - mse: 11.2990 - val_loss: 1.6926 - val_mse: 10.7584 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.6959 - mse: 10.5471 - val_loss: 1.6536 - val_mse: 9.8350 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.6352 - mse: 9.9793 - val_loss: 1.7775 - val_mse: 11.7196 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.5810 - mse: 9.4938 - val_loss: 1.5566 - val_mse: 10.9320 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4965 - mse: 8.5356 - val_loss: 1.5087 - val_mse: 8.5268 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4582 - mse: 8.3417 - val_loss: 1.3766 - val_mse: 7.8691 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3844 - mse: 7.6080 - val_loss: 1.3621 - val_mse: 7.1887 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3291 - mse: 7.1517 - val_loss: 1.2728 - val_mse: 7.2033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2642 - mse: 6.4601 - val_loss: 1.2048 - val_mse: 6.3046 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2011 - mse: 5.9015 - val_loss: 1.1557 - val_mse: 5.5930 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1595 - mse: 5.8458 - val_loss: 1.1405 - val_mse: 6.4954 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0956 - mse: 5.1837 - val_loss: 1.0463 - val_mse: 4.8316 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0601 - mse: 5.0443 - val_loss: 1.0123 - val_mse: 4.5596 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0014 - mse: 4.5768 - val_loss: 1.0163 - val_mse: 5.7504 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.9592 - mse: 4.2585 - val_loss: 0.9106 - val_mse: 3.9193 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8891 - mse: 3.8457 - val_loss: 0.9113 - val_mse: 4.0404 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8507 - mse: 3.5640 - val_loss: 0.8091 - val_mse: 3.6425 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8070 - mse: 3.4149 - val_loss: 0.7678 - val_mse: 3.1164 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7567 - mse: 3.1304 - val_loss: 0.7073 - val_mse: 2.7905 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7181 - mse: 2.9348 - val_loss: 0.6651 - val_mse: 2.5778 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6645 - mse: 2.5559 - val_loss: 0.6152 - val_mse: 2.3493 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6226 - mse: 2.3825 - val_loss: 0.5838 - val_mse: 2.1974 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5840 - mse: 2.2095 - val_loss: 0.5384 - val_mse: 2.0357 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5423 - mse: 1.9888 - val_loss: 0.6111 - val_mse: 2.6389 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5246 - mse: 1.9788 - val_loss: 0.5258 - val_mse: 2.2347 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.4763 - mse: 1.6655 - val_loss: 0.4429 - val_mse: 1.5621 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.4508 - mse: 1.5872 - val_loss: 0.4174 - val_mse: 1.4315 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4361 - mse: 1.5096 - val_loss: 0.4009 - val_mse: 1.3789 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4134 - mse: 1.4195 - val_loss: 0.4144 - val_mse: 1.5303 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3895 - mse: 1.2983 - val_loss: 0.4176 - val_mse: 1.5699 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3640 - mse: 1.2054 - val_loss: 0.3402 - val_mse: 1.0833 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3484 - mse: 1.1131 - val_loss: 0.3694 - val_mse: 1.3042 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3374 - mse: 1.0663 - val_loss: 0.3076 - val_mse: 0.9375 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3180 - mse: 0.9889 - val_loss: 0.3077 - val_mse: 0.9577 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3066 - mse: 0.9423 - val_loss: 0.2758 - val_mse: 0.8024 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2865 - mse: 0.8476 - val_loss: 0.2708 - val_mse: 0.7894 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2709 - mse: 0.8023 - val_loss: 0.2497 - val_mse: 0.6983 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2764 - mse: 0.8226 - val_loss: 0.2443 - val_mse: 0.6870 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.2517 - mse: 0.7078 - val_loss: 0.2253 - val_mse: 0.6057 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2426 - mse: 0.6798 - val_loss: 0.2323 - val_mse: 0.6503 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2336 - mse: 0.6633 - val_loss: 0.2542 - val_mse: 0.7831 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2287 - mse: 0.6449 - val_loss: 0.2052 - val_mse: 0.5430 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2185 - mse: 0.5990 - val_loss: 0.2474 - val_mse: 0.7726 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1969 - mse: 0.5198 - val_loss: 0.1781 - val_mse: 0.4448 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1883 - mse: 0.4960 - val_loss: 0.1667 - val_mse: 0.4058 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1799 - mse: 0.4619 - val_loss: 0.1962 - val_mse: 0.5409 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1648 - mse: 0.4044 - val_loss: 0.1496 - val_mse: 0.3533 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1589 - mse: 0.3969 - val_loss: 0.1378 - val_mse: 0.3167 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1589 - mse: 0.4100 - val_loss: 0.1298 - val_mse: 0.2940 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1552 - mse: 0.3877 - val_loss: 0.1645 - val_mse: 0.4269 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1369 - mse: 0.3292 - val_loss: 0.1293 - val_mse: 0.3004 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1278 - mse: 0.2974 - val_loss: 0.1279 - val_mse: 0.3006 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1286 - mse: 0.3110 - val_loss: 0.1107 - val_mse: 0.2462 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1274 - mse: 0.3150 - val_loss: 0.0965 - val_mse: 0.2062 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1126 - mse: 0.2687 - val_loss: 0.0924 - val_mse: 0.1968 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1037 - mse: 0.2354 - val_loss: 0.0909 - val_mse: 0.1949 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0945 - mse: 0.2097 - val_loss: 0.0799 - val_mse: 0.1663 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.1024 - mse: 0.2440 - val_loss: 0.1780 - val_mse: 0.4921 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0890 - mse: 0.1959 - val_loss: 0.0703 - val_mse: 0.1443 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0849 - mse: 0.1870 - val_loss: 0.0658 - val_mse: 0.1343 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0771 - mse: 0.1718 - val_loss: 0.2390 - val_mse: 0.8336 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0852 - mse: 0.1991 - val_loss: 0.1356 - val_mse: 0.3598 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0738 - mse: 0.1621 - val_loss: 0.0845 - val_mse: 0.1869 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0738 - mse: 0.1648 - val_loss: 0.1160 - val_mse: 0.2735 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0726 - mse: 0.1675 - val_loss: 0.0516 - val_mse: 0.1040 - 2s/epoch - 3ms/step\n",
            "525/525 - 2s - loss: 0.0664 - mse: 0.1449 - val_loss: 0.0520 - val_mse: 0.1052 - 2s/epoch - 3ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 387 ended. Search finished for the next optimal point.\n",
            "Time taken: 221.9881\n",
            "Function value obtained: 0.1052\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 388 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [128, 128, 97]\n",
            "Learning Rate: 1.204049151755134e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.17756603044887712\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 499.7158 - mse: 2158913.2500 - val_loss: 309.0213 - val_mse: 488174.0000 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 381.9414 - mse: 1387664.6250 - val_loss: 167.8777 - val_mse: 147355.0781 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 303.0393 - mse: 799698.8125 - val_loss: 80.8673 - val_mse: 35389.2227 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 253.5851 - mse: 582014.2500 - val_loss: 29.6841 - val_mse: 5307.9565 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 220.0177 - mse: 424339.8125 - val_loss: 3.2308 - val_mse: 67.5629 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 206.7441 - mse: 407548.7812 - val_loss: 13.8427 - val_mse: 884.4178 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 188.4686 - mse: 305292.5625 - val_loss: 22.1801 - val_mse: 2496.3904 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 180.4260 - mse: 346850.3438 - val_loss: 12.8481 - val_mse: 1038.9749 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 170.0481 - mse: 254951.5938 - val_loss: 4.1827 - val_mse: 68.6378 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 163.9322 - mse: 233864.3906 - val_loss: 21.4612 - val_mse: 2199.7551 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 157.0230 - mse: 232600.3750 - val_loss: 25.9783 - val_mse: 3212.4612 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 154.7456 - mse: 231943.6250 - val_loss: 26.8854 - val_mse: 3425.5051 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 152.8646 - mse: 213974.0469 - val_loss: 21.4781 - val_mse: 2118.6826 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 146.2398 - mse: 195129.8438 - val_loss: 21.6165 - val_mse: 2161.7571 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 145.2164 - mse: 220630.3281 - val_loss: 21.7875 - val_mse: 2207.5889 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 145.1443 - mse: 213938.0469 - val_loss: 19.1959 - val_mse: 1742.3207 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 146.3540 - mse: 235063.7969 - val_loss: 19.8798 - val_mse: 1866.9918 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 132.3820 - mse: 187949.1562 - val_loss: 19.2040 - val_mse: 1743.5160 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 133.4957 - mse: 176398.2812 - val_loss: 21.3939 - val_mse: 2189.2642 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 136.5765 - mse: 204269.2188 - val_loss: 20.2442 - val_mse: 1975.5647 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 129.0884 - mse: 168400.7969 - val_loss: 20.5423 - val_mse: 2030.0702 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 122.3772 - mse: 127922.1719 - val_loss: 19.3775 - val_mse: 1830.5963 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 124.5589 - mse: 152809.3281 - val_loss: 20.9132 - val_mse: 2110.2717 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 121.1654 - mse: 132204.7500 - val_loss: 19.6842 - val_mse: 1913.4445 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 120.9357 - mse: 150595.8594 - val_loss: 20.7982 - val_mse: 2155.1575 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 120.2477 - mse: 145330.1094 - val_loss: 19.5545 - val_mse: 1883.3910 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 116.6706 - mse: 137605.6719 - val_loss: 20.0666 - val_mse: 1996.0602 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 116.0469 - mse: 131284.4844 - val_loss: 20.3633 - val_mse: 2089.7102 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 115.1210 - mse: 135184.4688 - val_loss: 19.9217 - val_mse: 2014.1183 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 109.2899 - mse: 127124.1719 - val_loss: 19.5735 - val_mse: 1913.7408 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 112.8072 - mse: 128376.8203 - val_loss: 20.8429 - val_mse: 2217.5854 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 106.6329 - mse: 105061.5000 - val_loss: 20.2098 - val_mse: 2076.1848 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 112.0314 - mse: 142743.7500 - val_loss: 19.1354 - val_mse: 1878.0538 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 103.4233 - mse: 97661.7656 - val_loss: 16.8737 - val_mse: 1467.4874 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 105.4297 - mse: 109913.1641 - val_loss: 18.8638 - val_mse: 1887.4547 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 99.4068 - mse: 99969.5859 - val_loss: 20.9747 - val_mse: 2327.1770 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 100.8619 - mse: 103504.1250 - val_loss: 21.1910 - val_mse: 2293.9160 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 93.1048 - mse: 91355.2031 - val_loss: 21.8032 - val_mse: 2407.3259 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 96.4675 - mse: 90603.8203 - val_loss: 19.8871 - val_mse: 1889.4828 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 99.0679 - mse: 115485.3203 - val_loss: 20.4427 - val_mse: 2011.2240 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 92.4389 - mse: 81268.7812 - val_loss: 19.8726 - val_mse: 1835.5891 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 94.3998 - mse: 84127.8984 - val_loss: 22.1260 - val_mse: 2365.3818 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 91.5117 - mse: 76649.2656 - val_loss: 22.3256 - val_mse: 2531.2456 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 90.9573 - mse: 86857.9766 - val_loss: 22.5833 - val_mse: 2572.8242 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 90.6108 - mse: 95480.8906 - val_loss: 22.8376 - val_mse: 2756.7876 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 90.2166 - mse: 85278.8047 - val_loss: 19.8885 - val_mse: 2148.4817 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 88.0350 - mse: 77571.2422 - val_loss: 19.4949 - val_mse: 2071.7207 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 85.7038 - mse: 73382.3359 - val_loss: 16.6225 - val_mse: 1515.2433 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 80.9374 - mse: 56994.4297 - val_loss: 15.9696 - val_mse: 1405.9927 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 82.0977 - mse: 69322.4219 - val_loss: 17.2138 - val_mse: 1630.5457 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 84.4079 - mse: 70712.3906 - val_loss: 18.1600 - val_mse: 1790.0449 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 76.8887 - mse: 59113.0859 - val_loss: 20.1047 - val_mse: 2183.1672 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 78.7950 - mse: 65566.5312 - val_loss: 17.9874 - val_mse: 1759.3951 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 81.0594 - mse: 64472.4336 - val_loss: 16.5187 - val_mse: 1491.3579 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 80.8285 - mse: 74224.5312 - val_loss: 16.5597 - val_mse: 1490.9492 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 75.4676 - mse: 54384.0820 - val_loss: 18.3983 - val_mse: 1829.7635 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 75.0660 - mse: 57978.5195 - val_loss: 18.3196 - val_mse: 1818.2721 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 75.0240 - mse: 55252.8164 - val_loss: 19.4176 - val_mse: 2032.8600 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 73.1023 - mse: 47550.5039 - val_loss: 20.2525 - val_mse: 2175.5754 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 69.9649 - mse: 46630.3320 - val_loss: 19.0186 - val_mse: 1886.1022 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 73.0642 - mse: 48735.7930 - val_loss: 19.4529 - val_mse: 1979.8784 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 71.5125 - mse: 50740.1094 - val_loss: 18.3248 - val_mse: 1788.6475 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 68.9928 - mse: 45758.1055 - val_loss: 15.7533 - val_mse: 1369.2334 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 68.9068 - mse: 52316.4609 - val_loss: 15.2809 - val_mse: 1295.6558 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 71.2364 - mse: 50408.7617 - val_loss: 12.5552 - val_mse: 888.2794 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 70.0631 - mse: 48956.5703 - val_loss: 14.1288 - val_mse: 1113.0212 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 62.5688 - mse: 34460.0625 - val_loss: 13.4672 - val_mse: 1014.7103 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 68.7632 - mse: 46750.6406 - val_loss: 15.1530 - val_mse: 1269.5338 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 65.7667 - mse: 45336.3125 - val_loss: 13.8647 - val_mse: 1071.9337 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 62.2444 - mse: 34744.7695 - val_loss: 13.8346 - val_mse: 1065.9193 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 64.2252 - mse: 38911.6641 - val_loss: 13.3988 - val_mse: 1002.4957 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 61.3245 - mse: 35914.7656 - val_loss: 12.9959 - val_mse: 945.8392 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 60.6229 - mse: 37782.2188 - val_loss: 13.9473 - val_mse: 1081.1995 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 63.8580 - mse: 42572.8828 - val_loss: 12.6846 - val_mse: 899.1951 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 63.2266 - mse: 41829.9141 - val_loss: 9.8628 - val_mse: 540.2990 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 57.6436 - mse: 32540.2852 - val_loss: 10.5911 - val_mse: 625.5158 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 61.7299 - mse: 39032.5664 - val_loss: 10.0519 - val_mse: 561.9710 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 59.5591 - mse: 35273.0938 - val_loss: 10.4881 - val_mse: 604.8493 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 60.4690 - mse: 36250.4258 - val_loss: 8.3482 - val_mse: 380.5974 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 58.9899 - mse: 35939.0078 - val_loss: 7.4566 - val_mse: 303.8964 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 56.8377 - mse: 30793.8613 - val_loss: 6.9634 - val_mse: 266.7167 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 58.1036 - mse: 37709.3867 - val_loss: 6.2836 - val_mse: 219.8173 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 57.1892 - mse: 35309.3906 - val_loss: 5.6248 - val_mse: 176.4480 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 57.4147 - mse: 33802.0195 - val_loss: 5.7183 - val_mse: 181.6472 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 53.6668 - mse: 25680.0684 - val_loss: 5.4390 - val_mse: 164.9371 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 52.9831 - mse: 27842.8984 - val_loss: 5.0444 - val_mse: 145.2325 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 52.0832 - mse: 25967.5781 - val_loss: 5.3542 - val_mse: 160.1777 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 51.1762 - mse: 24002.1328 - val_loss: 4.1539 - val_mse: 102.0598 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 50.8669 - mse: 24318.4414 - val_loss: 3.5972 - val_mse: 74.6256 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 52.2848 - mse: 32924.2383 - val_loss: 2.8273 - val_mse: 39.5800 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 51.9908 - mse: 26616.4746 - val_loss: 2.9953 - val_mse: 44.6431 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 51.0133 - mse: 27422.3379 - val_loss: 3.3025 - val_mse: 55.0076 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 48.9262 - mse: 22939.1855 - val_loss: 3.6614 - val_mse: 69.9807 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 48.7720 - mse: 19797.4512 - val_loss: 3.1477 - val_mse: 50.9453 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 47.2770 - mse: 19811.8750 - val_loss: 2.8041 - val_mse: 41.2012 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 47.1226 - mse: 20921.4473 - val_loss: 2.8877 - val_mse: 45.9343 - 3s/epoch - 6ms/step\n",
            "525/525 - 3s - loss: 48.3340 - mse: 24218.4922 - val_loss: 2.6223 - val_mse: 36.6500 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 47.4815 - mse: 22986.5781 - val_loss: 2.0732 - val_mse: 22.4202 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 46.5726 - mse: 21657.6094 - val_loss: 2.1368 - val_mse: 23.9257 - 3s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 48.4964 - mse: 22668.1152 - val_loss: 1.2800 - val_mse: 9.5052 - 3s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 388 ended. Search finished for the next optimal point.\n",
            "Time taken: 285.8089\n",
            "Function value obtained: 9.5052\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 389 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [57, 128, 44]\n",
            "Learning Rate: 1.6144269248722103e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.0\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 4.9092 - mse: 1790.3912 - val_loss: 0.2579 - val_mse: 0.9191 - 5s/epoch - 10ms/step\n",
            "525/525 - 2s - loss: 1.7045 - mse: 37.7289 - val_loss: 1.3284 - val_mse: 13.1647 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0624 - mse: 13.7680 - val_loss: 2.2543 - val_mse: 32.1136 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.2681 - mse: 19.0881 - val_loss: 0.2457 - val_mse: 1.0536 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4094 - mse: 24.2020 - val_loss: 0.9842 - val_mse: 8.5574 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.6110 - mse: 31.3779 - val_loss: 2.2567 - val_mse: 37.2318 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.9867 - mse: 14.5440 - val_loss: 0.3131 - val_mse: 1.2205 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 1.3616 - mse: 20.1078 - val_loss: 1.9624 - val_mse: 24.5740 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.0525 - mse: 14.8348 - val_loss: 1.0842 - val_mse: 10.0463 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 1.2737 - mse: 18.6876 - val_loss: 5.5562 - val_mse: 180.8298 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1104 - mse: 14.1975 - val_loss: 0.6879 - val_mse: 4.1580 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.3498 - mse: 20.9859 - val_loss: 1.6052 - val_mse: 18.8626 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 1.0079 - mse: 12.6137 - val_loss: 3.4856 - val_mse: 76.3881 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 1.5215 - mse: 26.5213 - val_loss: 1.6356 - val_mse: 19.0993 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7469 - mse: 8.6658 - val_loss: 1.4643 - val_mse: 15.9700 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.4612 - mse: 23.7218 - val_loss: 5.2514 - val_mse: 162.0589 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1.1038 - mse: 18.0979 - val_loss: 0.6530 - val_mse: 3.8249 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 1.2087 - mse: 16.7526 - val_loss: 0.6335 - val_mse: 3.4438 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7358 - mse: 7.4680 - val_loss: 0.1034 - val_mse: 0.2450 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.6889 - mse: 7.1772 - val_loss: 0.6178 - val_mse: 4.1068 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.9396 - mse: 13.0099 - val_loss: 0.6716 - val_mse: 4.0762 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.8941 - mse: 10.0406 - val_loss: 1.5182 - val_mse: 16.3422 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.8181 - mse: 8.3182 - val_loss: 0.1867 - val_mse: 0.5230 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.6085 - mse: 5.9618 - val_loss: 1.7500 - val_mse: 21.6341 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7958 - mse: 9.0725 - val_loss: 2.7113 - val_mse: 46.8546 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.7166 - mse: 7.0816 - val_loss: 0.3173 - val_mse: 1.1361 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5363 - mse: 4.2786 - val_loss: 0.6751 - val_mse: 4.1183 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.5957 - mse: 6.2800 - val_loss: 0.5297 - val_mse: 2.9503 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.6012 - mse: 5.5197 - val_loss: 1.2808 - val_mse: 12.7033 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4838 - mse: 3.4791 - val_loss: 0.7683 - val_mse: 5.2212 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.8122 - mse: 9.7985 - val_loss: 0.2593 - val_mse: 1.0141 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4400 - mse: 3.4237 - val_loss: 0.2861 - val_mse: 1.1900 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.5030 - mse: 4.3318 - val_loss: 0.6200 - val_mse: 3.7593 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4108 - mse: 2.6567 - val_loss: 0.0796 - val_mse: 0.1906 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4249 - mse: 3.1607 - val_loss: 0.7602 - val_mse: 5.2441 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.4272 - mse: 3.4231 - val_loss: 0.0488 - val_mse: 0.1101 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2233 - mse: 1.3648 - val_loss: 0.0577 - val_mse: 0.1329 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.3485 - mse: 2.3688 - val_loss: 0.3206 - val_mse: 1.3789 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2665 - mse: 2.3553 - val_loss: 0.0183 - val_mse: 0.0367 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1210 - mse: 0.5684 - val_loss: 0.0100 - val_mse: 0.0200 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1025 - mse: 0.3552 - val_loss: 0.0497 - val_mse: 0.1131 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0863 - mse: 0.3101 - val_loss: 0.0095 - val_mse: 0.0190 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0761 - mse: 0.2465 - val_loss: 0.0491 - val_mse: 0.1179 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0492 - mse: 0.1416 - val_loss: 0.0054 - val_mse: 0.0107 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0279 - mse: 0.0688 - val_loss: 0.0043 - val_mse: 0.0086 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0213 - mse: 0.0587 - val_loss: 0.0055 - val_mse: 0.0110 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0053 - mse: 0.0107 - val_loss: 0.0076 - val_mse: 0.0151 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0279 - mse: 0.0707 - val_loss: 0.0046 - val_mse: 0.0092 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0205 - mse: 0.0498 - val_loss: 0.0346 - val_mse: 0.0737 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0117 - mse: 0.0281 - val_loss: 0.0031 - val_mse: 0.0061 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0026 - val_mse: 0.0051 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0025 - val_mse: 0.0049 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.1284 - mse: 0.6292 - val_loss: 0.0336 - val_mse: 0.0733 - 2s/epoch - 5ms/step\n",
            "525/525 - 3s - loss: 0.0303 - mse: 0.0732 - val_loss: 0.2970 - val_mse: 0.8336 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0098 - mse: 0.0217 - val_loss: 0.0026 - val_mse: 0.0052 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0022 - val_mse: 0.0043 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0082 - mse: 0.0176 - val_loss: 0.0232 - val_mse: 0.0464 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0100 - mse: 0.0272 - val_loss: 0.1380 - val_mse: 0.3870 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0313 - mse: 0.0917 - val_loss: 0.0179 - val_mse: 0.0371 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0096 - mse: 0.0218 - val_loss: 0.0028 - val_mse: 0.0057 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0122 - mse: 0.0288 - val_loss: 0.0352 - val_mse: 0.0812 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1754 - mse: 1.0645 - val_loss: 0.0112 - val_mse: 0.0224 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0067 - mse: 0.0135 - val_loss: 0.0030 - val_mse: 0.0061 - 2s/epoch - 4ms/step\n",
            "525/525 - 3s - loss: 0.0028 - mse: 0.0056 - val_loss: 0.0027 - val_mse: 0.0055 - 3s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0137 - mse: 0.0306 - val_loss: 0.0059 - val_mse: 0.0117 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0043 - val_mse: 0.0086 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0023 - val_mse: 0.0046 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0212 - val_mse: 0.0439 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.2922 - mse: 2.1671 - val_loss: 0.0209 - val_mse: 0.0419 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0409 - mse: 0.1108 - val_loss: 0.0075 - val_mse: 0.0150 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0191 - mse: 0.0417 - val_loss: 0.0057 - val_mse: 0.0114 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0449 - mse: 0.1229 - val_loss: 0.0058 - val_mse: 0.0116 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0336 - mse: 0.0892 - val_loss: 0.0182 - val_mse: 0.0364 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0721 - mse: 0.3298 - val_loss: 0.0100 - val_mse: 0.0200 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0172 - mse: 0.0385 - val_loss: 0.0091 - val_mse: 0.0181 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0165 - mse: 0.0384 - val_loss: 0.0040 - val_mse: 0.0080 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0085 - mse: 0.0176 - val_loss: 0.0040 - val_mse: 0.0079 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0042 - mse: 0.0084 - val_loss: 0.0034 - val_mse: 0.0069 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1047 - mse: 0.6003 - val_loss: 0.0068 - val_mse: 0.0136 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0058 - mse: 0.0117 - val_loss: 0.0037 - val_mse: 0.0074 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0113 - mse: 0.0247 - val_loss: 0.0036 - val_mse: 0.0072 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.1380 - mse: 1.5686 - val_loss: 0.0409 - val_mse: 0.0826 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0254 - mse: 0.0647 - val_loss: 0.0180 - val_mse: 0.0360 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0082 - mse: 0.0167 - val_loss: 0.0037 - val_mse: 0.0073 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0044 - mse: 0.0087 - val_loss: 0.0041 - val_mse: 0.0081 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0284 - mse: 0.1411 - val_loss: 0.6962 - val_mse: 2.5198 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.2269 - mse: 1.2463 - val_loss: 0.0307 - val_mse: 0.0649 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0507 - mse: 0.1533 - val_loss: 0.0081 - val_mse: 0.0165 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0909 - mse: 0.5712 - val_loss: 0.0069 - val_mse: 0.0138 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0057 - mse: 0.0116 - val_loss: 0.0040 - val_mse: 0.0079 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0036 - val_mse: 0.0072 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0856 - mse: 0.3537 - val_loss: 0.0090 - val_mse: 0.0180 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0209 - mse: 0.0458 - val_loss: 0.0080 - val_mse: 0.0159 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0212 - mse: 0.0486 - val_loss: 0.0530 - val_mse: 0.1095 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0241 - mse: 0.0616 - val_loss: 0.0054 - val_mse: 0.0108 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 0.0343 - mse: 0.0892 - val_loss: 0.0275 - val_mse: 0.0550 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0225 - mse: 0.0656 - val_loss: 0.0093 - val_mse: 0.0185 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0071 - mse: 0.0145 - val_loss: 0.0063 - val_mse: 0.0127 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0817 - mse: 0.3176 - val_loss: 0.0065 - val_mse: 0.0131 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 0.0669 - mse: 0.2373 - val_loss: 0.0049 - val_mse: 0.0099 - 2s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 389 ended. Search finished for the next optimal point.\n",
            "Time taken: 270.4448\n",
            "Function value obtained: 0.0099\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 390 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [80, 56]\n",
            "Learning Rate: 6.812407181296576e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4242875437150474\n",
            "Batch Size: 34\n",
            "----------------------------------------\n",
            "247/247 - 4s - loss: 3870.2048 - mse: 139189760.0000 - val_loss: 396.0481 - val_mse: 799607.0625 - 4s/epoch - 16ms/step\n",
            "247/247 - 1s - loss: 3509.3445 - mse: 131492528.0000 - val_loss: 318.8388 - val_mse: 518788.0312 - 976ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 3085.8040 - mse: 100242880.0000 - val_loss: 238.3535 - val_mse: 289145.1250 - 972ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 2732.6836 - mse: 74332616.0000 - val_loss: 208.9584 - val_mse: 219608.0156 - 970ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 2520.7290 - mse: 59748792.0000 - val_loss: 204.9193 - val_mse: 211576.3125 - 973ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 2406.5352 - mse: 62982896.0000 - val_loss: 164.2825 - val_mse: 137683.4375 - 978ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 2166.4968 - mse: 44847984.0000 - val_loss: 127.2467 - val_mse: 91370.1094 - 985ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 2065.8606 - mse: 44696108.0000 - val_loss: 76.3621 - val_mse: 31590.0430 - 985ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1976.3003 - mse: 41672724.0000 - val_loss: 66.4488 - val_mse: 23383.3906 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1856.4296 - mse: 36702244.0000 - val_loss: 48.7364 - val_mse: 12073.5342 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1747.9528 - mse: 29481276.0000 - val_loss: 28.1820 - val_mse: 5693.1987 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1797.3981 - mse: 30693714.0000 - val_loss: 7.5522 - val_mse: 260.5851 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1696.4662 - mse: 27492704.0000 - val_loss: 8.4895 - val_mse: 598.0102 - 999ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1671.2462 - mse: 29014086.0000 - val_loss: 8.4522 - val_mse: 219.5885 - 987ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1693.9445 - mse: 26011382.0000 - val_loss: 14.6588 - val_mse: 947.9328 - 983ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1567.8258 - mse: 24921746.0000 - val_loss: 15.2831 - val_mse: 965.3273 - 982ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1541.1737 - mse: 25251422.0000 - val_loss: 17.8830 - val_mse: 1269.3147 - 948ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1505.2189 - mse: 24711222.0000 - val_loss: 27.3068 - val_mse: 3159.5996 - 989ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1506.0165 - mse: 27508314.0000 - val_loss: 45.2499 - val_mse: 9377.5596 - 963ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1421.2258 - mse: 22432076.0000 - val_loss: 48.7877 - val_mse: 11039.6230 - 963ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1436.1947 - mse: 19636670.0000 - val_loss: 57.0412 - val_mse: 15462.8906 - 958ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1391.7400 - mse: 20749316.0000 - val_loss: 55.3198 - val_mse: 14494.2627 - 980ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1293.7971 - mse: 16750915.0000 - val_loss: 45.3107 - val_mse: 9723.3477 - 993ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1288.5227 - mse: 16694533.0000 - val_loss: 47.9995 - val_mse: 10960.0020 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1263.8265 - mse: 15025158.0000 - val_loss: 53.9293 - val_mse: 13836.3135 - 979ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1270.6212 - mse: 18353256.0000 - val_loss: 48.7653 - val_mse: 11317.9463 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1218.4440 - mse: 16191104.0000 - val_loss: 52.1056 - val_mse: 12870.5859 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1204.1853 - mse: 15011536.0000 - val_loss: 44.8176 - val_mse: 9475.9717 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1159.4753 - mse: 13690428.0000 - val_loss: 48.7656 - val_mse: 11158.2109 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1211.7542 - mse: 15719712.0000 - val_loss: 47.4945 - val_mse: 10495.5801 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1115.8900 - mse: 12462072.0000 - val_loss: 51.0599 - val_mse: 12251.2588 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1131.7474 - mse: 14036742.0000 - val_loss: 44.2475 - val_mse: 9151.4697 - 999ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1101.4913 - mse: 12508089.0000 - val_loss: 32.5084 - val_mse: 4941.2935 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1074.5939 - mse: 11510299.0000 - val_loss: 37.1260 - val_mse: 6453.0073 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1036.5592 - mse: 11024137.0000 - val_loss: 35.4930 - val_mse: 5817.3213 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 1017.0512 - mse: 10852835.0000 - val_loss: 25.7655 - val_mse: 2991.0801 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 960.8331 - mse: 8893774.0000 - val_loss: 31.6204 - val_mse: 4548.1206 - 1000ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 981.2112 - mse: 9205399.0000 - val_loss: 35.0227 - val_mse: 5589.0361 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 940.6069 - mse: 8698062.0000 - val_loss: 39.0982 - val_mse: 6867.6304 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 981.8669 - mse: 10268374.0000 - val_loss: 36.0535 - val_mse: 5858.4717 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 876.2977 - mse: 7576710.5000 - val_loss: 35.2393 - val_mse: 5649.3340 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 859.6246 - mse: 6927340.5000 - val_loss: 31.8373 - val_mse: 4592.4619 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 838.2852 - mse: 6749110.0000 - val_loss: 30.2162 - val_mse: 4137.5649 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 813.3171 - mse: 6713995.5000 - val_loss: 29.0693 - val_mse: 3826.8450 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 825.9329 - mse: 6357861.5000 - val_loss: 22.0878 - val_mse: 2148.5930 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 811.7155 - mse: 6715818.0000 - val_loss: 22.7091 - val_mse: 2239.8884 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 786.2881 - mse: 6301143.0000 - val_loss: 29.8314 - val_mse: 4017.5447 - 1s/epoch - 5ms/step\n",
            "247/247 - 1s - loss: 768.2627 - mse: 6726474.0000 - val_loss: 34.7362 - val_mse: 5524.8174 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 776.5611 - mse: 6630696.5000 - val_loss: 28.9985 - val_mse: 3814.8354 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 700.7683 - mse: 4602837.0000 - val_loss: 26.5690 - val_mse: 3187.7617 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 710.5355 - mse: 4856741.5000 - val_loss: 26.2470 - val_mse: 3111.1636 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 741.9881 - mse: 7063953.0000 - val_loss: 27.5905 - val_mse: 3419.1682 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 654.6271 - mse: 3734206.7500 - val_loss: 33.4741 - val_mse: 5116.7769 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 664.9488 - mse: 4505425.0000 - val_loss: 35.8237 - val_mse: 5859.1304 - 997ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 655.0543 - mse: 4959345.5000 - val_loss: 36.0547 - val_mse: 5967.3999 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 630.2549 - mse: 3515972.0000 - val_loss: 33.9595 - val_mse: 5279.2544 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 623.7291 - mse: 3814863.0000 - val_loss: 36.1110 - val_mse: 5943.7295 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 640.6865 - mse: 4720905.5000 - val_loss: 39.3835 - val_mse: 7009.8628 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 605.3094 - mse: 4045703.0000 - val_loss: 34.0766 - val_mse: 5270.8242 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 604.5038 - mse: 3891257.0000 - val_loss: 34.6892 - val_mse: 5477.5664 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 555.8703 - mse: 2961446.7500 - val_loss: 32.9000 - val_mse: 4867.3882 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 563.9639 - mse: 3393927.0000 - val_loss: 34.1274 - val_mse: 5242.5269 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 556.3843 - mse: 3068641.7500 - val_loss: 33.2612 - val_mse: 4991.1157 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 549.9808 - mse: 3144101.7500 - val_loss: 30.2350 - val_mse: 4157.1465 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 535.7492 - mse: 3038870.2500 - val_loss: 31.4844 - val_mse: 4478.5459 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 502.5999 - mse: 2677377.2500 - val_loss: 29.9531 - val_mse: 4029.2375 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 508.0383 - mse: 2506846.7500 - val_loss: 32.1759 - val_mse: 4692.4785 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 491.4448 - mse: 2664524.0000 - val_loss: 29.0137 - val_mse: 3778.3948 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 482.3942 - mse: 2535872.0000 - val_loss: 25.2182 - val_mse: 2836.6982 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 467.1858 - mse: 2263650.7500 - val_loss: 27.3508 - val_mse: 3346.9299 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 458.0748 - mse: 2199934.7500 - val_loss: 30.0595 - val_mse: 4046.5867 - 1000ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 430.6170 - mse: 1619313.2500 - val_loss: 29.4014 - val_mse: 3844.8801 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 421.3124 - mse: 1686934.2500 - val_loss: 28.5696 - val_mse: 3621.3459 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 425.7988 - mse: 1885397.3750 - val_loss: 26.2707 - val_mse: 3068.6797 - 972ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 402.5190 - mse: 1533574.8750 - val_loss: 24.2718 - val_mse: 2618.0811 - 990ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 415.1398 - mse: 1699699.6250 - val_loss: 23.1452 - val_mse: 2378.9758 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 390.3320 - mse: 1552673.8750 - val_loss: 23.8938 - val_mse: 2556.8704 - 989ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 380.8820 - mse: 1350077.7500 - val_loss: 19.4006 - val_mse: 1658.3152 - 999ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 377.2785 - mse: 1343787.8750 - val_loss: 17.3122 - val_mse: 1311.6091 - 1000ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 370.3395 - mse: 1302292.0000 - val_loss: 17.1954 - val_mse: 1307.4231 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 353.5361 - mse: 1273974.1250 - val_loss: 14.3871 - val_mse: 908.7748 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 359.3790 - mse: 1522658.7500 - val_loss: 17.5550 - val_mse: 1382.9393 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 355.1935 - mse: 1326651.0000 - val_loss: 15.8523 - val_mse: 1145.6045 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 337.0227 - mse: 1202859.2500 - val_loss: 14.6264 - val_mse: 980.4128 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 328.4383 - mse: 1138995.6250 - val_loss: 16.4470 - val_mse: 1227.7113 - 987ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 315.3605 - mse: 1113334.7500 - val_loss: 16.5822 - val_mse: 1243.4082 - 997ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 311.2384 - mse: 988285.0625 - val_loss: 18.5299 - val_mse: 1575.1886 - 998ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 300.8163 - mse: 1018246.5625 - val_loss: 12.6284 - val_mse: 740.0153 - 969ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 289.6650 - mse: 775848.6875 - val_loss: 12.6154 - val_mse: 733.9289 - 966ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 299.6469 - mse: 904430.1875 - val_loss: 13.6561 - val_mse: 883.6921 - 972ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 287.0137 - mse: 758940.6875 - val_loss: 14.1991 - val_mse: 966.4368 - 980ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 290.7422 - mse: 923502.6875 - val_loss: 14.4705 - val_mse: 1013.1304 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 255.2727 - mse: 627112.3750 - val_loss: 14.4918 - val_mse: 1016.1509 - 1s/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 269.9276 - mse: 726447.4375 - val_loss: 14.5058 - val_mse: 1023.5533 - 992ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 274.4469 - mse: 846976.0000 - val_loss: 13.9216 - val_mse: 942.0106 - 994ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 253.6908 - mse: 694461.8750 - val_loss: 12.6331 - val_mse: 762.4180 - 965ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 249.5164 - mse: 597406.6875 - val_loss: 11.7399 - val_mse: 661.6486 - 967ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 241.8769 - mse: 611347.6250 - val_loss: 11.9352 - val_mse: 679.0526 - 956ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 232.4699 - mse: 526891.8750 - val_loss: 11.6144 - val_mse: 641.7682 - 960ms/epoch - 4ms/step\n",
            "247/247 - 1s - loss: 231.3404 - mse: 582429.3125 - val_loss: 10.3524 - val_mse: 494.2904 - 972ms/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 390 ended. Search finished for the next optimal point.\n",
            "Time taken: 135.1516\n",
            "Function value obtained: 494.2904\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 391 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [74, 38]\n",
            "Learning Rate: 0.00029100410360829814\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.23876503663187096\n",
            "Batch Size: 178\n",
            "----------------------------------------\n",
            "48/48 - 3s - loss: 729.7848 - mse: 5534438.5000 - val_loss: 25.4170 - val_mse: 3804.4355 - 3s/epoch - 60ms/step\n",
            "48/48 - 0s - loss: 423.7011 - mse: 1888659.6250 - val_loss: 2.8918 - val_mse: 84.8916 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 304.8824 - mse: 957653.2500 - val_loss: 23.4727 - val_mse: 3029.0327 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 224.8661 - mse: 572385.9375 - val_loss: 24.6711 - val_mse: 3530.2327 - 282ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 164.3329 - mse: 275064.7500 - val_loss: 16.4767 - val_mse: 1613.6663 - 301ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 123.7714 - mse: 150379.6875 - val_loss: 12.6945 - val_mse: 926.9026 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 95.5313 - mse: 96912.8359 - val_loss: 7.5753 - val_mse: 358.4022 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 71.1993 - mse: 58844.5977 - val_loss: 3.7593 - val_mse: 101.4599 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 59.1451 - mse: 52264.3711 - val_loss: 1.1331 - val_mse: 8.0537 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 42.7848 - mse: 21026.7090 - val_loss: 0.8198 - val_mse: 4.5462 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 35.1010 - mse: 15339.1680 - val_loss: 0.7791 - val_mse: 5.2983 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 29.7147 - mse: 13428.3770 - val_loss: 0.2893 - val_mse: 0.9478 - 310ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 23.4407 - mse: 9427.3955 - val_loss: 0.3240 - val_mse: 1.1649 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 19.9219 - mse: 12867.7871 - val_loss: 0.1794 - val_mse: 0.4138 - 285ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 15.7251 - mse: 7140.1138 - val_loss: 0.0995 - val_mse: 0.1989 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 11.1478 - mse: 3488.4939 - val_loss: 0.0694 - val_mse: 0.1389 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 9.2240 - mse: 2172.3521 - val_loss: 0.0474 - val_mse: 0.0948 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 8.3700 - mse: 2786.5547 - val_loss: 0.0313 - val_mse: 0.0626 - 308ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 6.8694 - mse: 1338.2792 - val_loss: 0.0207 - val_mse: 0.0413 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 6.0064 - mse: 2169.9014 - val_loss: 0.0145 - val_mse: 0.0289 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 5.0474 - mse: 1111.1449 - val_loss: 0.0113 - val_mse: 0.0225 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 4.1074 - mse: 858.6353 - val_loss: 0.0096 - val_mse: 0.0192 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 3.2035 - mse: 414.0851 - val_loss: 0.0089 - val_mse: 0.0178 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 3.5385 - mse: 1037.5831 - val_loss: 0.0086 - val_mse: 0.0172 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2.6076 - mse: 402.6332 - val_loss: 0.0085 - val_mse: 0.0170 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2.6471 - mse: 656.6703 - val_loss: 0.0085 - val_mse: 0.0169 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2.5065 - mse: 685.7084 - val_loss: 0.0084 - val_mse: 0.0169 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 2.0652 - mse: 305.9754 - val_loss: 0.0084 - val_mse: 0.0169 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.2660 - mse: 106.5201 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.8057 - mse: 254.2223 - val_loss: 0.0084 - val_mse: 0.0168 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.6909 - mse: 295.8011 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.7471 - mse: 404.4642 - val_loss: 0.0084 - val_mse: 0.0168 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.3054 - mse: 163.3855 - val_loss: 0.0084 - val_mse: 0.0168 - 286ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.7466 - mse: 554.5103 - val_loss: 0.0084 - val_mse: 0.0168 - 307ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.9934 - mse: 118.3015 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.1275 - mse: 171.9577 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.8375 - mse: 160.0616 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.7628 - mse: 69.9919 - val_loss: 0.0084 - val_mse: 0.0168 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 1.1137 - mse: 253.2171 - val_loss: 0.0084 - val_mse: 0.0168 - 309ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.7570 - mse: 133.5042 - val_loss: 0.0084 - val_mse: 0.0168 - 310ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.8896 - mse: 199.0475 - val_loss: 0.0084 - val_mse: 0.0168 - 301ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.7529 - mse: 137.0615 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.8695 - mse: 227.9238 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.5402 - mse: 72.3486 - val_loss: 0.0084 - val_mse: 0.0168 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.5015 - mse: 58.1250 - val_loss: 0.0084 - val_mse: 0.0168 - 312ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 0.6560 - mse: 92.5301 - val_loss: 0.0084 - val_mse: 0.0168 - 317ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 0.6379 - mse: 78.8796 - val_loss: 0.0084 - val_mse: 0.0168 - 305ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.7043 - mse: 207.6647 - val_loss: 0.0084 - val_mse: 0.0168 - 307ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.4762 - mse: 49.3609 - val_loss: 0.0084 - val_mse: 0.0168 - 321ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 0.5064 - mse: 213.4097 - val_loss: 0.0084 - val_mse: 0.0168 - 305ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.5341 - mse: 137.8962 - val_loss: 0.0084 - val_mse: 0.0168 - 325ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 0.4129 - mse: 57.8763 - val_loss: 0.0084 - val_mse: 0.0168 - 303ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3267 - mse: 32.8119 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.4129 - mse: 68.1336 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2935 - mse: 34.1221 - val_loss: 0.0084 - val_mse: 0.0168 - 302ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3364 - mse: 61.6098 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2619 - mse: 19.7776 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2883 - mse: 36.7641 - val_loss: 0.0084 - val_mse: 0.0168 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2842 - mse: 27.2782 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.4423 - mse: 81.0185 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2048 - mse: 18.5946 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3596 - mse: 86.9909 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3016 - mse: 61.8540 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3322 - mse: 70.8862 - val_loss: 0.0084 - val_mse: 0.0168 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2817 - mse: 26.0692 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2805 - mse: 81.3468 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1665 - mse: 14.4348 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2019 - mse: 15.3569 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1865 - mse: 22.9748 - val_loss: 0.0084 - val_mse: 0.0168 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1867 - mse: 14.6048 - val_loss: 0.0084 - val_mse: 0.0168 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2021 - mse: 21.6601 - val_loss: 0.0084 - val_mse: 0.0168 - 300ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.2416 - mse: 25.5940 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0904 - mse: 3.0194 - val_loss: 0.0084 - val_mse: 0.0168 - 288ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1132 - mse: 5.8837 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1601 - mse: 15.0386 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1562 - mse: 8.7920 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.3445 - mse: 94.4250 - val_loss: 0.0084 - val_mse: 0.0168 - 284ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1604 - mse: 19.2544 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1238 - mse: 8.1874 - val_loss: 0.0084 - val_mse: 0.0168 - 304ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1121 - mse: 6.5115 - val_loss: 0.0084 - val_mse: 0.0168 - 339ms/epoch - 7ms/step\n",
            "48/48 - 0s - loss: 0.1255 - mse: 11.0323 - val_loss: 0.0084 - val_mse: 0.0168 - 301ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1039 - mse: 6.4517 - val_loss: 0.0084 - val_mse: 0.0168 - 304ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1365 - mse: 10.9491 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1455 - mse: 16.8716 - val_loss: 0.0084 - val_mse: 0.0168 - 312ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0530 - mse: 3.0869 - val_loss: 0.0084 - val_mse: 0.0168 - 309ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1200 - mse: 14.1566 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0866 - mse: 4.3225 - val_loss: 0.0084 - val_mse: 0.0168 - 297ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0968 - mse: 12.6690 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0705 - mse: 3.3330 - val_loss: 0.0084 - val_mse: 0.0168 - 292ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0707 - mse: 2.7670 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0302 - mse: 0.3718 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0503 - mse: 1.6516 - val_loss: 0.0084 - val_mse: 0.0168 - 293ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0742 - mse: 4.4351 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1280 - mse: 14.9020 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0559 - mse: 3.1743 - val_loss: 0.0084 - val_mse: 0.0167 - 298ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.1522 - mse: 20.5896 - val_loss: 0.0084 - val_mse: 0.0168 - 291ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0585 - mse: 6.3037 - val_loss: 0.0084 - val_mse: 0.0168 - 294ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0363 - mse: 0.5811 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0591 - mse: 2.9736 - val_loss: 0.0084 - val_mse: 0.0168 - 295ms/epoch - 6ms/step\n",
            "48/48 - 0s - loss: 0.0536 - mse: 5.0432 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 391 ended. Search finished for the next optimal point.\n",
            "Time taken: 66.0621\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 392 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [87, 128]\n",
            "Learning Rate: 7.058863696020855e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.17554247205596696\n",
            "Batch Size: 253\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 1203.0851 - mse: 10017727.0000 - val_loss: 1068.6440 - val_mse: 5902781.0000 - 3s/epoch - 83ms/step\n",
            "34/34 - 0s - loss: 1052.8208 - mse: 7681905.0000 - val_loss: 909.6967 - val_mse: 4282233.5000 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 877.8763 - mse: 5539900.5000 - val_loss: 769.7613 - val_mse: 3069445.7500 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 770.2343 - mse: 4516033.0000 - val_loss: 646.9763 - val_mse: 2170050.5000 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 689.3978 - mse: 3877353.5000 - val_loss: 541.3860 - val_mse: 1522994.8750 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 606.4473 - mse: 3069571.2500 - val_loss: 454.2729 - val_mse: 1074890.7500 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 547.0048 - mse: 2613273.2500 - val_loss: 379.8251 - val_mse: 754035.9375 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 485.9625 - mse: 2170731.5000 - val_loss: 316.4162 - val_mse: 524322.6875 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 425.0216 - mse: 1622400.8750 - val_loss: 266.2507 - val_mse: 372361.2188 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 392.1751 - mse: 1242361.2500 - val_loss: 224.1933 - val_mse: 264953.9688 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 375.9801 - mse: 1273648.2500 - val_loss: 193.8029 - val_mse: 197746.7812 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 344.7683 - mse: 1073631.8750 - val_loss: 166.6202 - val_mse: 146425.5000 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 316.9312 - mse: 841514.0000 - val_loss: 144.8816 - val_mse: 111225.7266 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 286.7481 - mse: 701779.5625 - val_loss: 128.2236 - val_mse: 87376.4375 - 251ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 295.5636 - mse: 830627.3125 - val_loss: 110.8991 - val_mse: 65095.6484 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 268.6299 - mse: 640859.6875 - val_loss: 96.6236 - val_mse: 49860.6992 - 256ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 264.4156 - mse: 658722.0000 - val_loss: 83.0122 - val_mse: 36801.4805 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 253.2339 - mse: 615989.2500 - val_loss: 73.6315 - val_mse: 29264.5664 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 245.9703 - mse: 573899.6250 - val_loss: 65.0825 - val_mse: 22852.7266 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 245.9778 - mse: 596629.6250 - val_loss: 60.7907 - val_mse: 20063.7441 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 231.1510 - mse: 496211.1562 - val_loss: 57.8885 - val_mse: 18356.2070 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 217.2503 - mse: 449029.9688 - val_loss: 57.9729 - val_mse: 18549.4375 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 210.0582 - mse: 418459.1250 - val_loss: 55.8520 - val_mse: 17018.6777 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 198.3128 - mse: 368274.8125 - val_loss: 49.2365 - val_mse: 13092.7021 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 204.7623 - mse: 419748.2500 - val_loss: 40.8752 - val_mse: 9047.7275 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 200.9774 - mse: 373937.3438 - val_loss: 31.2697 - val_mse: 5398.4570 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 189.4828 - mse: 385278.4375 - val_loss: 20.5177 - val_mse: 2403.9033 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 192.7965 - mse: 371885.7188 - val_loss: 10.1134 - val_mse: 633.8318 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 181.8768 - mse: 332695.9688 - val_loss: 3.7734 - val_mse: 95.3138 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 169.2633 - mse: 264974.6875 - val_loss: 0.2818 - val_mse: 0.7670 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 181.7966 - mse: 321411.1250 - val_loss: 1.0428 - val_mse: 9.7806 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 171.3803 - mse: 256612.8438 - val_loss: 0.8482 - val_mse: 5.9645 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 166.4189 - mse: 247295.7188 - val_loss: 1.2107 - val_mse: 12.7663 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 172.3444 - mse: 308882.1875 - val_loss: 0.7322 - val_mse: 5.6357 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 171.1223 - mse: 296635.4688 - val_loss: 0.9245 - val_mse: 5.7849 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 175.0708 - mse: 300920.3125 - val_loss: 0.7573 - val_mse: 4.4114 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 170.3376 - mse: 292273.0312 - val_loss: 0.8246 - val_mse: 2.0635 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 165.9807 - mse: 271353.3125 - val_loss: 1.2218 - val_mse: 4.3898 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 170.1675 - mse: 309960.6562 - val_loss: 1.8046 - val_mse: 11.1576 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 171.4923 - mse: 330326.0312 - val_loss: 1.9609 - val_mse: 15.3796 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 161.5571 - mse: 242336.2656 - val_loss: 2.0796 - val_mse: 23.2988 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 162.4391 - mse: 274870.1875 - val_loss: 1.7667 - val_mse: 22.9414 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 160.1327 - mse: 267157.3750 - val_loss: 1.2461 - val_mse: 19.0764 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 169.8853 - mse: 313918.6562 - val_loss: 0.9818 - val_mse: 11.2677 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 167.4696 - mse: 301509.2188 - val_loss: 0.8559 - val_mse: 8.4527 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 159.5777 - mse: 255442.2500 - val_loss: 0.6256 - val_mse: 2.2766 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 158.2116 - mse: 219636.8906 - val_loss: 0.7134 - val_mse: 2.2431 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 155.6067 - mse: 252810.2656 - val_loss: 0.8586 - val_mse: 3.9368 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 154.8954 - mse: 225963.8281 - val_loss: 1.0942 - val_mse: 6.3403 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 154.4793 - mse: 303481.5312 - val_loss: 1.2070 - val_mse: 7.6746 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 157.1675 - mse: 264718.3438 - val_loss: 1.3071 - val_mse: 7.7136 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 145.6878 - mse: 188109.0312 - val_loss: 1.1993 - val_mse: 11.0406 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 144.4556 - mse: 189788.0469 - val_loss: 1.2166 - val_mse: 7.8535 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 152.0809 - mse: 236537.7344 - val_loss: 1.0899 - val_mse: 7.2645 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 144.7062 - mse: 188101.9844 - val_loss: 1.2538 - val_mse: 7.4635 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 153.5521 - mse: 253592.4219 - val_loss: 1.3259 - val_mse: 8.1871 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 145.7758 - mse: 193220.2969 - val_loss: 2.3208 - val_mse: 32.2667 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 147.6618 - mse: 208221.0156 - val_loss: 2.2979 - val_mse: 32.5484 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 150.1100 - mse: 215130.6250 - val_loss: 2.1661 - val_mse: 30.8960 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 143.2628 - mse: 194431.4375 - val_loss: 1.9266 - val_mse: 25.9254 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 148.8153 - mse: 231371.0938 - val_loss: 1.5656 - val_mse: 16.4755 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 144.4891 - mse: 238175.3750 - val_loss: 1.5966 - val_mse: 22.1911 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 146.4219 - mse: 209422.0469 - val_loss: 0.5159 - val_mse: 2.8374 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 140.0032 - mse: 191714.0000 - val_loss: 0.2751 - val_mse: 1.6076 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 137.5143 - mse: 213502.3750 - val_loss: 0.6982 - val_mse: 6.2321 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 141.0663 - mse: 176760.6562 - val_loss: 1.1444 - val_mse: 8.1888 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 132.5459 - mse: 154845.5938 - val_loss: 1.7608 - val_mse: 27.8185 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 140.9106 - mse: 204764.4531 - val_loss: 2.2914 - val_mse: 41.3623 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 142.0223 - mse: 195310.5000 - val_loss: 1.3204 - val_mse: 18.3621 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 142.9606 - mse: 204075.4219 - val_loss: 1.1065 - val_mse: 14.8233 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 139.6525 - mse: 169109.7188 - val_loss: 0.7208 - val_mse: 8.0170 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 133.0804 - mse: 162025.9219 - val_loss: 1.3430 - val_mse: 15.9832 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 133.4344 - mse: 177908.5781 - val_loss: 1.7400 - val_mse: 21.8364 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 135.6134 - mse: 180359.9062 - val_loss: 1.7777 - val_mse: 21.7698 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 134.2101 - mse: 186981.9219 - val_loss: 2.0704 - val_mse: 19.9259 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 135.9384 - mse: 193847.9062 - val_loss: 2.2290 - val_mse: 29.2582 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 130.4925 - mse: 160076.6562 - val_loss: 2.9861 - val_mse: 52.9417 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 134.6667 - mse: 174980.2500 - val_loss: 2.5912 - val_mse: 46.5175 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 129.8506 - mse: 170745.0938 - val_loss: 0.9994 - val_mse: 12.0813 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 134.1259 - mse: 174253.7656 - val_loss: 0.3667 - val_mse: 2.4728 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 129.2621 - mse: 164178.2656 - val_loss: 0.8520 - val_mse: 6.9353 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 125.9461 - mse: 152401.1875 - val_loss: 0.9700 - val_mse: 10.8094 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 121.0606 - mse: 130810.3594 - val_loss: 1.2410 - val_mse: 14.2918 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 129.2712 - mse: 166612.7344 - val_loss: 1.9438 - val_mse: 29.2427 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 133.5998 - mse: 182252.6094 - val_loss: 1.4335 - val_mse: 19.4713 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 127.2602 - mse: 150938.9062 - val_loss: 1.1262 - val_mse: 12.5977 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 120.8758 - mse: 129104.1875 - val_loss: 1.1373 - val_mse: 12.4007 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 127.1606 - mse: 167096.8438 - val_loss: 0.8338 - val_mse: 5.0992 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 126.1626 - mse: 165282.8750 - val_loss: 0.9446 - val_mse: 6.3427 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 123.9862 - mse: 150145.2656 - val_loss: 1.5189 - val_mse: 18.6305 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 120.6146 - mse: 137821.2344 - val_loss: 1.3433 - val_mse: 18.0545 - 252ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 124.7190 - mse: 174151.9219 - val_loss: 1.4927 - val_mse: 16.9380 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 121.4689 - mse: 141239.2656 - val_loss: 1.3107 - val_mse: 17.4724 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 116.8972 - mse: 138870.2344 - val_loss: 1.4329 - val_mse: 19.6936 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 118.0255 - mse: 125516.7109 - val_loss: 1.7632 - val_mse: 27.2743 - 245ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 119.7349 - mse: 131981.9688 - val_loss: 2.5402 - val_mse: 42.7884 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 115.2778 - mse: 123484.0078 - val_loss: 1.7620 - val_mse: 23.7054 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 124.7337 - mse: 175926.2969 - val_loss: 1.4995 - val_mse: 22.3288 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 120.7867 - mse: 151904.2656 - val_loss: 1.9986 - val_mse: 26.4783 - 242ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 117.9459 - mse: 148970.3906 - val_loss: 2.2633 - val_mse: 36.3856 - 232ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 392 ended. Search finished for the next optimal point.\n",
            "Time taken: 60.9513\n",
            "Function value obtained: 36.3856\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 393 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [76, 107]\n",
            "Learning Rate: 0.0059437233308934235\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.32737470028692267\n",
            "Batch Size: 184\n",
            "----------------------------------------\n",
            "46/46 - 3s - loss: 491.1102 - mse: 6348373.0000 - val_loss: 3.6458 - val_mse: 52.9904 - 3s/epoch - 57ms/step\n",
            "46/46 - 0s - loss: 21.2576 - mse: 5212.8057 - val_loss: 0.4218 - val_mse: 1.1946 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 7.3488 - mse: 940.1703 - val_loss: 0.0986 - val_mse: 0.2264 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 3.1255 - mse: 170.3327 - val_loss: 0.0225 - val_mse: 0.0450 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.7021 - mse: 87.9536 - val_loss: 0.0080 - val_mse: 0.0159 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 1.0066 - mse: 39.3003 - val_loss: 0.0058 - val_mse: 0.0116 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.7644 - mse: 39.6248 - val_loss: 0.0303 - val_mse: 0.0610 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.5325 - mse: 20.1863 - val_loss: 0.0056 - val_mse: 0.0113 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.4319 - mse: 17.6847 - val_loss: 0.0053 - val_mse: 0.0106 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3230 - mse: 13.6941 - val_loss: 0.0189 - val_mse: 0.0378 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.3805 - mse: 41.0647 - val_loss: 0.0174 - val_mse: 0.0348 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1905 - mse: 3.2787 - val_loss: 0.0048 - val_mse: 0.0096 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1623 - mse: 4.8634 - val_loss: 0.0066 - val_mse: 0.0131 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1485 - mse: 4.9111 - val_loss: 0.0122 - val_mse: 0.0244 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1472 - mse: 5.5476 - val_loss: 0.0075 - val_mse: 0.0151 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1621 - mse: 9.0248 - val_loss: 0.0097 - val_mse: 0.0193 - 272ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0958 - mse: 2.3993 - val_loss: 0.0082 - val_mse: 0.0164 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0980 - mse: 3.8595 - val_loss: 0.0078 - val_mse: 0.0155 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.1915 - mse: 78.1919 - val_loss: 0.0085 - val_mse: 0.0170 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0826 - mse: 2.0410 - val_loss: 0.0074 - val_mse: 0.0149 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0863 - mse: 7.2867 - val_loss: 0.0078 - val_mse: 0.0156 - 287ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0732 - mse: 2.6319 - val_loss: 0.0080 - val_mse: 0.0160 - 291ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0552 - mse: 0.9106 - val_loss: 0.0083 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0306 - mse: 0.4550 - val_loss: 0.0084 - val_mse: 0.0168 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0752 - mse: 5.2890 - val_loss: 0.0084 - val_mse: 0.0168 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0348 - mse: 0.4242 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0513 - mse: 1.6595 - val_loss: 0.0084 - val_mse: 0.0168 - 274ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0492 - mse: 1.4607 - val_loss: 0.0084 - val_mse: 0.0168 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0466 - mse: 0.9154 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0485 - mse: 6.7260 - val_loss: 0.0084 - val_mse: 0.0167 - 264ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0301 - mse: 0.5095 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0419 - mse: 2.3517 - val_loss: 0.0084 - val_mse: 0.0168 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0242 - mse: 0.2847 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0230 - mse: 0.1871 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0389 - mse: 1.9364 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0419 - mse: 1.8772 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0186 - mse: 0.0774 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0180 - mse: 0.0728 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0212 - mse: 0.1453 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0222 - mse: 0.3513 - val_loss: 0.0084 - val_mse: 0.0168 - 267ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0225 - mse: 0.2406 - val_loss: 0.0084 - val_mse: 0.0167 - 262ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0146 - mse: 0.0500 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0285 - mse: 1.0145 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0227 - mse: 0.3860 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0127 - mse: 0.0363 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0172 - mse: 0.1720 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0338 - mse: 2.4307 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0158 - mse: 0.0986 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0314 - mse: 1.6230 - val_loss: 0.0084 - val_mse: 0.0167 - 276ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0218 - mse: 0.3141 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0144 - mse: 0.0573 - val_loss: 0.0084 - val_mse: 0.0167 - 275ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0124 - mse: 0.0568 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0160 - mse: 0.1231 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0246 - mse: 1.3380 - val_loss: 0.0084 - val_mse: 0.0167 - 279ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0115 - mse: 0.0257 - val_loss: 0.0084 - val_mse: 0.0167 - 290ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0179 - mse: 0.1184 - val_loss: 0.0084 - val_mse: 0.0167 - 277ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0221 - mse: 0.3365 - val_loss: 0.0084 - val_mse: 0.0167 - 294ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0329 - mse: 2.3602 - val_loss: 0.0084 - val_mse: 0.0167 - 302ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0193 - mse: 0.3761 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0111 - mse: 0.0383 - val_loss: 0.0084 - val_mse: 0.0167 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0155 - mse: 0.3226 - val_loss: 0.0084 - val_mse: 0.0167 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0156 - mse: 0.1226 - val_loss: 0.0084 - val_mse: 0.0167 - 301ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0127 - mse: 0.0697 - val_loss: 0.0084 - val_mse: 0.0167 - 306ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0174 - mse: 0.1543 - val_loss: 0.0084 - val_mse: 0.0167 - 289ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0123 - mse: 0.0531 - val_loss: 0.0084 - val_mse: 0.0167 - 295ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0132 - mse: 0.0522 - val_loss: 0.0084 - val_mse: 0.0167 - 286ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0115 - mse: 0.0351 - val_loss: 0.0084 - val_mse: 0.0167 - 292ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0095 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167 - 312ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0132 - mse: 0.0482 - val_loss: 0.0084 - val_mse: 0.0167 - 309ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0099 - mse: 0.0217 - val_loss: 0.0084 - val_mse: 0.0168 - 314ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0105 - mse: 0.0333 - val_loss: 0.0084 - val_mse: 0.0167 - 322ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0128 - mse: 0.0708 - val_loss: 0.0084 - val_mse: 0.0167 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0093 - mse: 0.0191 - val_loss: 0.0084 - val_mse: 0.0167 - 315ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0116 - mse: 0.0532 - val_loss: 0.0084 - val_mse: 0.0167 - 315ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0183 - mse: 0.2003 - val_loss: 0.0084 - val_mse: 0.0167 - 306ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0113 - mse: 0.0429 - val_loss: 0.0084 - val_mse: 0.0167 - 317ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0102 - mse: 0.0272 - val_loss: 0.0084 - val_mse: 0.0167 - 304ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0100 - mse: 0.0254 - val_loss: 0.0084 - val_mse: 0.0167 - 306ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0237 - mse: 1.6865 - val_loss: 0.0084 - val_mse: 0.0167 - 314ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0140 - mse: 0.1023 - val_loss: 0.0084 - val_mse: 0.0168 - 309ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 306ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0096 - mse: 0.0210 - val_loss: 0.0084 - val_mse: 0.0167 - 308ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0100 - mse: 0.0239 - val_loss: 0.0084 - val_mse: 0.0167 - 319ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0126 - mse: 0.0802 - val_loss: 0.0084 - val_mse: 0.0167 - 321ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0104 - mse: 0.0283 - val_loss: 0.0084 - val_mse: 0.0167 - 309ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0168 - 319ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0112 - mse: 0.0621 - val_loss: 0.0084 - val_mse: 0.0167 - 314ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 318ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0110 - mse: 0.0342 - val_loss: 0.0084 - val_mse: 0.0167 - 311ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0102 - mse: 0.0261 - val_loss: 0.0084 - val_mse: 0.0167 - 320ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 315ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0099 - mse: 0.0294 - val_loss: 0.0084 - val_mse: 0.0167 - 332ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0268 - mse: 1.2171 - val_loss: 0.0084 - val_mse: 0.0167 - 298ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0097 - mse: 0.0224 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0168 - 307ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0091 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 310ms/epoch - 7ms/step\n",
            "46/46 - 0s - loss: 0.0093 - mse: 0.0225 - val_loss: 0.0084 - val_mse: 0.0167 - 296ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0151 - mse: 0.3530 - val_loss: 0.0084 - val_mse: 0.0167 - 297ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0090 - mse: 0.0186 - val_loss: 0.0084 - val_mse: 0.0167 - 285ms/epoch - 6ms/step\n",
            "46/46 - 0s - loss: 0.0097 - mse: 0.0219 - val_loss: 0.0084 - val_mse: 0.0167 - 291ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.25440888]\n",
            "\n",
            "Iteration No: 393 ended. Search finished for the next optimal point.\n",
            "Time taken: 68.0311\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 394 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [128, 32]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.20555019899562618\n",
            "Batch Size: 16\n",
            "----------------------------------------\n",
            "525/525 - 5s - loss: 1385.6022 - mse: 15247818.0000 - val_loss: 854.1192 - val_mse: 3792262.7500 - 5s/epoch - 9ms/step\n",
            "525/525 - 2s - loss: 1230.8134 - mse: 12752056.0000 - val_loss: 692.9504 - val_mse: 2509526.0000 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 1142.5964 - mse: 11892219.0000 - val_loss: 547.7516 - val_mse: 1576425.0000 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 990.3858 - mse: 8506650.0000 - val_loss: 423.5352 - val_mse: 943846.5625 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 941.5762 - mse: 8558983.0000 - val_loss: 323.5353 - val_mse: 552120.8125 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 823.6761 - mse: 6491426.0000 - val_loss: 250.7290 - val_mse: 333646.9062 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 805.4548 - mse: 6054727.5000 - val_loss: 192.1931 - val_mse: 196868.1406 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 737.3912 - mse: 5229349.5000 - val_loss: 146.0061 - val_mse: 114792.2500 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 686.7919 - mse: 3995933.5000 - val_loss: 110.2832 - val_mse: 66261.0625 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 678.8175 - mse: 4033816.2500 - val_loss: 75.4990 - val_mse: 31632.2246 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 667.2568 - mse: 4022473.5000 - val_loss: 45.2892 - val_mse: 11386.6094 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 608.6924 - mse: 3179853.5000 - val_loss: 24.6034 - val_mse: 3316.1152 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 568.9891 - mse: 2846923.0000 - val_loss: 14.8003 - val_mse: 1179.7902 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 577.2898 - mse: 2988010.0000 - val_loss: 9.2638 - val_mse: 403.1324 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 560.8920 - mse: 2991738.7500 - val_loss: 6.1805 - val_mse: 161.6960 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 564.9943 - mse: 2975987.0000 - val_loss: 4.6905 - val_mse: 76.4048 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 544.6635 - mse: 2926051.7500 - val_loss: 5.2066 - val_mse: 92.3645 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 534.1278 - mse: 2698025.0000 - val_loss: 6.0734 - val_mse: 119.6246 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 500.2845 - mse: 2119844.2500 - val_loss: 9.8277 - val_mse: 390.8028 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 511.9196 - mse: 2587596.2500 - val_loss: 11.9024 - val_mse: 705.9326 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 493.6991 - mse: 2645921.0000 - val_loss: 11.4481 - val_mse: 695.1597 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 496.3869 - mse: 2166699.5000 - val_loss: 10.5379 - val_mse: 587.2146 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 474.0794 - mse: 2098932.2500 - val_loss: 9.1917 - val_mse: 423.3365 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 456.8463 - mse: 1984985.3750 - val_loss: 8.2916 - val_mse: 336.4684 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 451.2850 - mse: 1854782.0000 - val_loss: 8.8900 - val_mse: 463.9238 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 482.9679 - mse: 2454312.7500 - val_loss: 8.3060 - val_mse: 523.4238 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 471.8736 - mse: 2397680.5000 - val_loss: 5.8801 - val_mse: 377.6933 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 431.9737 - mse: 1662588.3750 - val_loss: 3.6710 - val_mse: 144.3331 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 429.4010 - mse: 1692917.6250 - val_loss: 2.9591 - val_mse: 25.8617 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 430.2336 - mse: 1685899.2500 - val_loss: 5.1433 - val_mse: 73.7330 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 426.6336 - mse: 1783034.5000 - val_loss: 9.7302 - val_mse: 301.6618 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 420.9023 - mse: 1785890.8750 - val_loss: 13.1673 - val_mse: 647.4885 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 417.4925 - mse: 1672313.8750 - val_loss: 16.8435 - val_mse: 1167.5087 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 415.3722 - mse: 1593921.1250 - val_loss: 16.7990 - val_mse: 1125.9840 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 411.4207 - mse: 1692106.0000 - val_loss: 19.4119 - val_mse: 1628.6560 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 406.0796 - mse: 1643635.7500 - val_loss: 19.1208 - val_mse: 1615.6305 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 395.6022 - mse: 1449106.7500 - val_loss: 19.3631 - val_mse: 1698.5364 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 405.8296 - mse: 1680441.5000 - val_loss: 19.2231 - val_mse: 1634.4427 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 401.8319 - mse: 1687747.0000 - val_loss: 20.6608 - val_mse: 1877.6686 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 394.5858 - mse: 1551168.6250 - val_loss: 21.7829 - val_mse: 2088.3835 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 384.2910 - mse: 1348005.5000 - val_loss: 23.2358 - val_mse: 2434.3254 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 387.5800 - mse: 1349116.1250 - val_loss: 24.1930 - val_mse: 2785.3235 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 387.7466 - mse: 1545794.7500 - val_loss: 25.0731 - val_mse: 3511.6299 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 372.5758 - mse: 1306964.6250 - val_loss: 25.5859 - val_mse: 3580.8582 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 367.5686 - mse: 1227608.8750 - val_loss: 25.4411 - val_mse: 3594.2056 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 389.1381 - mse: 1610974.5000 - val_loss: 25.0074 - val_mse: 3656.5532 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 374.1027 - mse: 1421604.7500 - val_loss: 24.8122 - val_mse: 3625.0308 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 369.0183 - mse: 1351782.7500 - val_loss: 23.6501 - val_mse: 3472.4087 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 369.9003 - mse: 1409884.1250 - val_loss: 23.9126 - val_mse: 3574.1587 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 353.9259 - mse: 1183418.5000 - val_loss: 25.1173 - val_mse: 3958.6729 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 353.5528 - mse: 1204786.0000 - val_loss: 22.3190 - val_mse: 3379.8315 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 370.2365 - mse: 1356906.1250 - val_loss: 21.7560 - val_mse: 3367.0208 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 364.7564 - mse: 1492582.0000 - val_loss: 23.1604 - val_mse: 3639.0371 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 337.9254 - mse: 1016118.4375 - val_loss: 22.1647 - val_mse: 3348.0371 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 353.5482 - mse: 1342465.3750 - val_loss: 20.9779 - val_mse: 3039.3298 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 337.8777 - mse: 1113647.1250 - val_loss: 19.3717 - val_mse: 2648.5510 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 337.6013 - mse: 1178634.0000 - val_loss: 20.8469 - val_mse: 2875.0122 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 324.1477 - mse: 1185723.8750 - val_loss: 19.1486 - val_mse: 2602.6619 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 324.8749 - mse: 998137.2500 - val_loss: 18.5277 - val_mse: 2510.3601 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 337.7914 - mse: 1087112.0000 - val_loss: 20.3562 - val_mse: 2877.7200 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 325.0156 - mse: 959852.8750 - val_loss: 19.3274 - val_mse: 2688.7192 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 320.4687 - mse: 986833.1875 - val_loss: 20.2624 - val_mse: 2872.6277 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 326.4756 - mse: 987907.1250 - val_loss: 18.6786 - val_mse: 2562.8650 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 319.7352 - mse: 955059.4375 - val_loss: 17.4655 - val_mse: 2392.1174 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 311.2646 - mse: 999614.6875 - val_loss: 15.8594 - val_mse: 2082.1787 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 308.6459 - mse: 864350.4375 - val_loss: 15.6901 - val_mse: 1953.2896 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 313.8575 - mse: 1101708.6250 - val_loss: 15.4063 - val_mse: 1797.6753 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 307.2697 - mse: 902374.3125 - val_loss: 14.5528 - val_mse: 1553.5642 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 311.7300 - mse: 933656.8125 - val_loss: 14.7359 - val_mse: 1580.7545 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 302.6001 - mse: 935548.7500 - val_loss: 15.3400 - val_mse: 1679.4596 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 307.4394 - mse: 862274.0000 - val_loss: 14.7922 - val_mse: 1526.6387 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 295.5535 - mse: 785275.0000 - val_loss: 15.0494 - val_mse: 1564.4032 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 305.7122 - mse: 1078183.0000 - val_loss: 15.6400 - val_mse: 1698.2792 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 298.3668 - mse: 826447.8125 - val_loss: 15.7775 - val_mse: 1721.3099 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 293.8004 - mse: 784574.3750 - val_loss: 16.4958 - val_mse: 1803.7896 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 303.6766 - mse: 880560.5000 - val_loss: 16.7561 - val_mse: 1817.0500 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 295.2306 - mse: 879630.8750 - val_loss: 15.6132 - val_mse: 1573.8665 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 291.4792 - mse: 830810.5625 - val_loss: 15.6080 - val_mse: 1551.8552 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 304.5595 - mse: 1052308.7500 - val_loss: 15.3844 - val_mse: 1486.7075 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 298.0702 - mse: 1000562.1250 - val_loss: 15.1288 - val_mse: 1387.4393 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 285.6002 - mse: 842473.5000 - val_loss: 15.5341 - val_mse: 1431.4784 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 277.0904 - mse: 790909.9375 - val_loss: 14.5617 - val_mse: 1169.7638 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 282.8151 - mse: 898277.6875 - val_loss: 14.1451 - val_mse: 1111.1560 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 278.2683 - mse: 735824.9375 - val_loss: 13.4623 - val_mse: 1013.2991 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 291.8401 - mse: 833655.6875 - val_loss: 12.9011 - val_mse: 911.5510 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 272.1565 - mse: 773159.8750 - val_loss: 12.6977 - val_mse: 926.3813 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 272.5776 - mse: 694480.5625 - val_loss: 12.5724 - val_mse: 873.3759 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 268.1618 - mse: 661452.6875 - val_loss: 11.5923 - val_mse: 680.9929 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 279.2137 - mse: 752549.1250 - val_loss: 11.1853 - val_mse: 626.0936 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 260.7471 - mse: 633332.8750 - val_loss: 10.6841 - val_mse: 553.3257 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 262.1279 - mse: 713226.4375 - val_loss: 10.1879 - val_mse: 501.0930 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 256.8258 - mse: 604945.2500 - val_loss: 10.4829 - val_mse: 533.2294 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 277.2939 - mse: 849093.2500 - val_loss: 11.0238 - val_mse: 604.7595 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 255.2936 - mse: 631357.7500 - val_loss: 11.2789 - val_mse: 628.5077 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 255.9552 - mse: 648444.6875 - val_loss: 11.3406 - val_mse: 636.1639 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 246.9540 - mse: 549682.2500 - val_loss: 10.8359 - val_mse: 578.1706 - 2s/epoch - 5ms/step\n",
            "525/525 - 2s - loss: 246.0142 - mse: 527365.8125 - val_loss: 9.9980 - val_mse: 469.8130 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 247.5846 - mse: 535618.9375 - val_loss: 9.5079 - val_mse: 421.2382 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 253.9622 - mse: 658245.7500 - val_loss: 8.9501 - val_mse: 369.4212 - 2s/epoch - 4ms/step\n",
            "525/525 - 2s - loss: 246.2392 - mse: 568161.9375 - val_loss: 8.3936 - val_mse: 326.0509 - 2s/epoch - 4ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 394 ended. Search finished for the next optimal point.\n",
            "Time taken: 263.7510\n",
            "Function value obtained: 326.0509\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 395 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [41, 82]\n",
            "Learning Rate: 1e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.3160709079312712\n",
            "Batch Size: 120\n",
            "----------------------------------------\n",
            "70/70 - 3s - loss: 1253.9988 - mse: 14520150.0000 - val_loss: 723.2664 - val_mse: 2614079.0000 - 3s/epoch - 46ms/step\n",
            "70/70 - 0s - loss: 1242.2638 - mse: 15179042.0000 - val_loss: 707.4556 - val_mse: 2500918.0000 - 410ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1208.0712 - mse: 14733839.0000 - val_loss: 692.2584 - val_mse: 2394479.2500 - 411ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1225.3304 - mse: 13813392.0000 - val_loss: 677.0662 - val_mse: 2290471.7500 - 411ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1152.3043 - mse: 12076686.0000 - val_loss: 663.2838 - val_mse: 2198109.7500 - 420ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1117.7980 - mse: 10880837.0000 - val_loss: 650.9002 - val_mse: 2116783.7500 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1152.7323 - mse: 11431176.0000 - val_loss: 637.6354 - val_mse: 2031290.2500 - 397ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1137.7008 - mse: 12721234.0000 - val_loss: 624.8049 - val_mse: 1950269.5000 - 412ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1118.5656 - mse: 11273283.0000 - val_loss: 611.9620 - val_mse: 1870848.0000 - 401ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1131.1802 - mse: 11102137.0000 - val_loss: 599.4178 - val_mse: 1794876.6250 - 420ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1112.3569 - mse: 10667038.0000 - val_loss: 588.3705 - val_mse: 1729281.2500 - 425ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1130.6619 - mse: 11727013.0000 - val_loss: 575.7307 - val_mse: 1655676.5000 - 435ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1110.8129 - mse: 11831580.0000 - val_loss: 565.2969 - val_mse: 1596148.8750 - 418ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1072.1130 - mse: 11367242.0000 - val_loss: 553.0685 - val_mse: 1527761.6250 - 426ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1085.6737 - mse: 11415423.0000 - val_loss: 540.7900 - val_mse: 1460590.2500 - 409ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1116.6400 - mse: 11566656.0000 - val_loss: 529.9656 - val_mse: 1402632.3750 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1097.0681 - mse: 11366886.0000 - val_loss: 519.9894 - val_mse: 1350215.3750 - 398ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1112.0468 - mse: 12769485.0000 - val_loss: 509.2757 - val_mse: 1295028.6250 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1055.3020 - mse: 10595308.0000 - val_loss: 499.9524 - val_mse: 1247975.1250 - 422ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1049.3894 - mse: 9612775.0000 - val_loss: 489.6117 - val_mse: 1196756.2500 - 430ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1066.9548 - mse: 10533936.0000 - val_loss: 479.5628 - val_mse: 1148025.0000 - 409ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 986.2762 - mse: 9154857.0000 - val_loss: 471.0588 - val_mse: 1107579.0000 - 417ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1024.5281 - mse: 9383300.0000 - val_loss: 461.4353 - val_mse: 1062672.7500 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1037.6831 - mse: 9742759.0000 - val_loss: 454.0374 - val_mse: 1028726.7500 - 418ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 1014.0075 - mse: 9844919.0000 - val_loss: 445.4579 - val_mse: 990129.1250 - 389ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 998.4901 - mse: 9691896.0000 - val_loss: 437.0959 - val_mse: 953312.4375 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 999.0157 - mse: 10558325.0000 - val_loss: 430.4301 - val_mse: 924412.6250 - 389ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 985.6655 - mse: 9296231.0000 - val_loss: 422.0445 - val_mse: 888731.8750 - 396ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 988.1054 - mse: 9199085.0000 - val_loss: 414.6149 - val_mse: 857556.6875 - 393ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 965.7415 - mse: 8437308.0000 - val_loss: 407.9690 - val_mse: 830258.8125 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 953.4472 - mse: 8166843.5000 - val_loss: 401.2045 - val_mse: 803024.1875 - 415ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 962.5489 - mse: 8855853.0000 - val_loss: 392.9290 - val_mse: 770198.5000 - 397ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 966.0130 - mse: 8744319.0000 - val_loss: 386.2263 - val_mse: 744148.1250 - 403ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 921.2671 - mse: 7683431.0000 - val_loss: 379.8672 - val_mse: 719887.1875 - 390ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 954.3285 - mse: 8843496.0000 - val_loss: 372.5014 - val_mse: 692185.5000 - 445ms/epoch - 6ms/step\n",
            "70/70 - 1s - loss: 927.6003 - mse: 7928712.5000 - val_loss: 365.8559 - val_mse: 667684.5625 - 729ms/epoch - 10ms/step\n",
            "70/70 - 0s - loss: 988.3897 - mse: 10013647.0000 - val_loss: 359.2366 - val_mse: 643712.4375 - 385ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 983.2333 - mse: 9853285.0000 - val_loss: 352.6208 - val_mse: 620158.7500 - 387ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 949.7979 - mse: 8171956.5000 - val_loss: 346.4404 - val_mse: 598582.0000 - 394ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 908.8893 - mse: 6966466.0000 - val_loss: 339.3927 - val_mse: 574412.8125 - 391ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 901.3384 - mse: 7621240.5000 - val_loss: 334.7093 - val_mse: 558634.8750 - 392ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 935.9506 - mse: 8885256.0000 - val_loss: 328.5774 - val_mse: 538310.9375 - 394ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 872.6500 - mse: 7578966.5000 - val_loss: 323.4005 - val_mse: 521371.7812 - 412ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 882.3586 - mse: 7026854.0000 - val_loss: 318.6254 - val_mse: 506034.8438 - 406ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 885.2328 - mse: 8925302.0000 - val_loss: 313.4979 - val_mse: 489863.3750 - 402ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 868.9123 - mse: 6974332.0000 - val_loss: 308.4054 - val_mse: 474026.0625 - 398ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 951.9032 - mse: 9362645.0000 - val_loss: 303.8520 - val_mse: 460084.7812 - 410ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 887.1442 - mse: 6906271.5000 - val_loss: 298.8323 - val_mse: 445017.7500 - 406ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 875.6826 - mse: 6748128.5000 - val_loss: 293.6173 - val_mse: 429620.8438 - 408ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 893.6226 - mse: 8056561.5000 - val_loss: 288.6779 - val_mse: 415251.5312 - 405ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 893.2086 - mse: 8060747.0000 - val_loss: 284.0250 - val_mse: 401942.0312 - 420ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 900.4277 - mse: 8539322.0000 - val_loss: 280.3254 - val_mse: 391521.1250 - 418ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 889.1042 - mse: 8289422.0000 - val_loss: 275.7593 - val_mse: 378852.1250 - 435ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 859.5569 - mse: 7322694.0000 - val_loss: 272.0032 - val_mse: 368589.3125 - 421ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 858.5508 - mse: 7260698.0000 - val_loss: 267.6958 - val_mse: 357003.0000 - 413ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 886.3865 - mse: 7918367.0000 - val_loss: 263.2875 - val_mse: 345331.8750 - 402ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 869.8775 - mse: 7382075.5000 - val_loss: 258.7949 - val_mse: 333634.5625 - 402ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 847.2104 - mse: 6867312.0000 - val_loss: 254.4316 - val_mse: 322466.2500 - 407ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 852.5000 - mse: 7285278.0000 - val_loss: 248.3505 - val_mse: 307213.7188 - 405ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 849.6523 - mse: 7453438.5000 - val_loss: 244.6852 - val_mse: 298189.4062 - 398ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 834.2513 - mse: 7936909.0000 - val_loss: 241.3056 - val_mse: 290015.8438 - 400ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 841.0576 - mse: 7403559.0000 - val_loss: 237.8515 - val_mse: 281721.4688 - 387ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 800.6432 - mse: 6176663.0000 - val_loss: 234.5264 - val_mse: 273845.0625 - 389ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 840.1238 - mse: 7249210.5000 - val_loss: 230.0111 - val_mse: 263399.9062 - 391ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 808.4940 - mse: 6519792.0000 - val_loss: 225.5907 - val_mse: 253382.1406 - 391ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 817.7589 - mse: 6111231.5000 - val_loss: 221.9408 - val_mse: 245247.0938 - 397ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 817.0480 - mse: 6500079.5000 - val_loss: 219.7876 - val_mse: 240540.2188 - 386ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 826.6039 - mse: 6436862.5000 - val_loss: 216.6202 - val_mse: 233622.2812 - 403ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 811.3666 - mse: 6738049.0000 - val_loss: 213.7425 - val_mse: 227453.7344 - 393ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 802.2762 - mse: 5621912.0000 - val_loss: 210.2725 - val_mse: 220120.4688 - 423ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 798.7691 - mse: 6647428.0000 - val_loss: 206.2361 - val_mse: 211740.7031 - 403ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 802.2515 - mse: 6518639.5000 - val_loss: 203.0331 - val_mse: 205218.6562 - 418ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 803.0870 - mse: 6029374.5000 - val_loss: 200.3994 - val_mse: 199938.7812 - 420ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 773.7887 - mse: 5925886.5000 - val_loss: 197.5171 - val_mse: 194230.5469 - 447ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 769.0613 - mse: 6662258.5000 - val_loss: 194.4773 - val_mse: 188282.5625 - 429ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 760.3607 - mse: 5471973.0000 - val_loss: 192.5006 - val_mse: 184443.9219 - 385ms/epoch - 5ms/step\n",
            "70/70 - 0s - loss: 784.7551 - mse: 5670386.5000 - val_loss: 190.0426 - val_mse: 179774.1719 - 390ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 779.1488 - mse: 6248489.5000 - val_loss: 187.3809 - val_mse: 174799.7656 - 406ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 757.3304 - mse: 5219070.5000 - val_loss: 186.4905 - val_mse: 173132.3594 - 420ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 775.1081 - mse: 5835956.0000 - val_loss: 183.8454 - val_mse: 168253.2500 - 405ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 772.9495 - mse: 6190240.0000 - val_loss: 182.3633 - val_mse: 165559.1094 - 403ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 789.2764 - mse: 5519884.0000 - val_loss: 179.6207 - val_mse: 160617.5781 - 422ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 728.9331 - mse: 5124950.5000 - val_loss: 176.2207 - val_mse: 154585.0938 - 405ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 767.1292 - mse: 5595855.5000 - val_loss: 172.9933 - val_mse: 148971.5469 - 399ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 722.7471 - mse: 4773216.5000 - val_loss: 170.6255 - val_mse: 144950.8125 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 733.2055 - mse: 5522291.5000 - val_loss: 168.7131 - val_mse: 141751.6562 - 388ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 726.3096 - mse: 4625030.5000 - val_loss: 167.5917 - val_mse: 140033.9219 - 390ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 741.2953 - mse: 5302611.5000 - val_loss: 165.8585 - val_mse: 137246.8281 - 394ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 754.8239 - mse: 5855612.0000 - val_loss: 163.2392 - val_mse: 132982.1562 - 397ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 718.1882 - mse: 5098374.5000 - val_loss: 161.1413 - val_mse: 129567.4844 - 397ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 745.8192 - mse: 5547790.0000 - val_loss: 159.1139 - val_mse: 126381.3281 - 421ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 774.3465 - mse: 5873151.5000 - val_loss: 157.6696 - val_mse: 124165.1406 - 394ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 737.7618 - mse: 5308568.5000 - val_loss: 156.5804 - val_mse: 122492.5000 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 715.6023 - mse: 5414939.5000 - val_loss: 154.3942 - val_mse: 119131.7188 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 676.4387 - mse: 3824796.2500 - val_loss: 152.4416 - val_mse: 116201.9922 - 402ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 712.0633 - mse: 4395701.0000 - val_loss: 150.9012 - val_mse: 113975.6875 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 701.0754 - mse: 4656849.0000 - val_loss: 148.6027 - val_mse: 110559.1328 - 413ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 715.1266 - mse: 5129583.5000 - val_loss: 146.9652 - val_mse: 108271.8594 - 395ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 727.6803 - mse: 5238323.5000 - val_loss: 145.2601 - val_mse: 105853.2812 - 405ms/epoch - 6ms/step\n",
            "70/70 - 0s - loss: 705.0885 - mse: 4382241.0000 - val_loss: 144.2527 - val_mse: 104476.7266 - 404ms/epoch - 6ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 395 ended. Search finished for the next optimal point.\n",
            "Time taken: 78.9311\n",
            "Function value obtained: 104476.7266\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 396 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [54, 124]\n",
            "Learning Rate: 1.9490008254332074e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.4786351520356058\n",
            "Batch Size: 33\n",
            "----------------------------------------\n",
            "255/255 - 4s - loss: 2258.6196 - mse: 60168784.0000 - val_loss: 8.5141 - val_mse: 165.8878 - 4s/epoch - 14ms/step\n",
            "255/255 - 1s - loss: 1785.3541 - mse: 46760944.0000 - val_loss: 164.2473 - val_mse: 146305.0938 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1577.0850 - mse: 30331504.0000 - val_loss: 159.6520 - val_mse: 146992.3281 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1482.5752 - mse: 23699058.0000 - val_loss: 69.5101 - val_mse: 29426.9199 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1327.5516 - mse: 16430741.0000 - val_loss: 40.1629 - val_mse: 9793.0127 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1244.4934 - mse: 15628037.0000 - val_loss: 15.2751 - val_mse: 1605.6880 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1194.4102 - mse: 14208433.0000 - val_loss: 14.2112 - val_mse: 1620.6969 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1146.5869 - mse: 13274978.0000 - val_loss: 28.6742 - val_mse: 4919.0005 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1105.6400 - mse: 15357433.0000 - val_loss: 27.4770 - val_mse: 5372.6230 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 1018.5945 - mse: 10640494.0000 - val_loss: 56.0080 - val_mse: 18733.6914 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 972.2278 - mse: 9167553.0000 - val_loss: 40.1300 - val_mse: 10286.7217 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 908.5729 - mse: 7682098.0000 - val_loss: 42.7184 - val_mse: 11544.1924 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 901.3958 - mse: 7746001.0000 - val_loss: 51.7020 - val_mse: 16301.9482 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 839.6583 - mse: 7127274.0000 - val_loss: 49.7809 - val_mse: 14266.1133 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 840.2201 - mse: 6928494.0000 - val_loss: 43.2246 - val_mse: 10756.4834 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 781.4302 - mse: 5686797.0000 - val_loss: 38.2640 - val_mse: 8560.6348 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 737.1176 - mse: 5186198.5000 - val_loss: 55.3279 - val_mse: 17185.6719 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 706.0113 - mse: 5519797.0000 - val_loss: 53.7801 - val_mse: 16220.3271 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 655.4162 - mse: 4328020.0000 - val_loss: 43.4612 - val_mse: 10668.3643 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 654.9648 - mse: 4226031.0000 - val_loss: 37.4284 - val_mse: 8167.6113 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 619.3035 - mse: 3484226.7500 - val_loss: 35.2669 - val_mse: 7382.9282 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 592.0112 - mse: 3375082.5000 - val_loss: 22.5790 - val_mse: 3147.0227 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 566.0442 - mse: 3672660.7500 - val_loss: 28.9150 - val_mse: 4859.0488 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 524.0754 - mse: 2712248.5000 - val_loss: 36.2959 - val_mse: 7529.9521 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 522.2149 - mse: 2822150.5000 - val_loss: 39.9371 - val_mse: 8902.2578 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 490.7785 - mse: 2582558.5000 - val_loss: 22.3881 - val_mse: 2986.4229 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 465.8119 - mse: 2125057.5000 - val_loss: 23.3407 - val_mse: 3243.5356 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 458.7762 - mse: 2161048.2500 - val_loss: 23.5123 - val_mse: 3202.8872 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 465.2588 - mse: 2387660.2500 - val_loss: 27.5983 - val_mse: 4222.8081 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 417.3543 - mse: 1973458.2500 - val_loss: 25.8708 - val_mse: 3830.7275 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 391.6061 - mse: 1438656.7500 - val_loss: 26.9808 - val_mse: 4022.5505 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 393.2554 - mse: 1543942.5000 - val_loss: 32.3655 - val_mse: 5750.5322 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 364.3409 - mse: 1272233.0000 - val_loss: 22.9361 - val_mse: 3037.4980 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 350.3964 - mse: 1407961.2500 - val_loss: 22.7394 - val_mse: 2995.2080 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 325.1765 - mse: 990773.3125 - val_loss: 16.5486 - val_mse: 1569.7778 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 316.4268 - mse: 1032957.7500 - val_loss: 16.2156 - val_mse: 1534.5803 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 322.5951 - mse: 1379054.5000 - val_loss: 12.6478 - val_mse: 939.6342 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 304.2767 - mse: 931124.1875 - val_loss: 8.2083 - val_mse: 412.1814 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 291.1546 - mse: 917289.9375 - val_loss: 7.3438 - val_mse: 337.8138 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 276.9897 - mse: 772940.8750 - val_loss: 6.3474 - val_mse: 264.7510 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 258.0982 - mse: 659171.0625 - val_loss: 4.2070 - val_mse: 115.9988 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 248.4712 - mse: 657714.3125 - val_loss: 11.3195 - val_mse: 769.8787 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 251.8757 - mse: 669890.2500 - val_loss: 12.0687 - val_mse: 878.2514 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 227.1560 - mse: 556353.1875 - val_loss: 7.7331 - val_mse: 402.6149 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 226.5820 - mse: 564726.5000 - val_loss: 6.1974 - val_mse: 284.2727 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 216.4504 - mse: 444441.5938 - val_loss: 0.8670 - val_mse: 3.1761 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 206.4774 - mse: 453629.5000 - val_loss: 1.3310 - val_mse: 4.8541 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 193.0715 - mse: 367963.8125 - val_loss: 3.0888 - val_mse: 34.8564 - 1s/epoch - 4ms/step\n",
            "255/255 - 2s - loss: 186.7900 - mse: 363323.8438 - val_loss: 1.7779 - val_mse: 9.5879 - 2s/epoch - 7ms/step\n",
            "255/255 - 1s - loss: 183.8346 - mse: 388175.4375 - val_loss: 5.3626 - val_mse: 134.0139 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 176.3429 - mse: 303957.1250 - val_loss: 3.9641 - val_mse: 69.4644 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 170.3024 - mse: 299667.9062 - val_loss: 2.5987 - val_mse: 26.7959 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 154.9858 - mse: 220030.2031 - val_loss: 1.5900 - val_mse: 8.1698 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 152.0822 - mse: 241642.8281 - val_loss: 3.3856 - val_mse: 47.6767 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 140.3178 - mse: 175844.9531 - val_loss: 2.4068 - val_mse: 20.8772 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 139.1416 - mse: 181318.7031 - val_loss: 0.9925 - val_mse: 3.2680 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 133.2807 - mse: 186538.5938 - val_loss: 2.4455 - val_mse: 23.1911 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 127.3667 - mse: 177969.2031 - val_loss: 1.7232 - val_mse: 10.4845 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 125.9895 - mse: 178477.4688 - val_loss: 1.8754 - val_mse: 13.1704 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 119.7539 - mse: 138154.1094 - val_loss: 2.2448 - val_mse: 19.8510 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 112.3999 - mse: 136108.7188 - val_loss: 1.4375 - val_mse: 7.5104 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 106.0679 - mse: 103978.8359 - val_loss: 1.3387 - val_mse: 6.7243 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 103.5671 - mse: 113959.5781 - val_loss: 0.7675 - val_mse: 2.1986 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 99.4909 - mse: 104535.1484 - val_loss: 0.5783 - val_mse: 1.9112 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 95.0558 - mse: 106496.1875 - val_loss: 0.5602 - val_mse: 1.7127 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 92.5365 - mse: 81358.7500 - val_loss: 0.6133 - val_mse: 1.4813 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 86.5455 - mse: 77304.1094 - val_loss: 0.8739 - val_mse: 2.7028 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 86.1535 - mse: 104854.8125 - val_loss: 0.4640 - val_mse: 1.1044 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 83.3105 - mse: 85580.7344 - val_loss: 0.5655 - val_mse: 1.3030 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 75.0440 - mse: 55193.5625 - val_loss: 0.4639 - val_mse: 1.0079 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 71.3028 - mse: 48505.2070 - val_loss: 2.1332 - val_mse: 19.3970 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 72.6539 - mse: 67856.9609 - val_loss: 1.7085 - val_mse: 11.9277 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 70.5359 - mse: 67392.7734 - val_loss: 1.8520 - val_mse: 14.4734 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 66.2451 - mse: 52898.2422 - val_loss: 1.0418 - val_mse: 4.0338 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 60.0530 - mse: 42721.0508 - val_loss: 1.1945 - val_mse: 5.7115 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 59.6907 - mse: 44205.1680 - val_loss: 0.9760 - val_mse: 3.7301 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 57.3087 - mse: 36007.0273 - val_loss: 0.4980 - val_mse: 1.0666 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 52.0274 - mse: 29082.9805 - val_loss: 0.4637 - val_mse: 1.5687 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 51.7144 - mse: 29982.2871 - val_loss: 0.4909 - val_mse: 1.8499 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 47.3727 - mse: 22748.6602 - val_loss: 0.5660 - val_mse: 1.3714 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 48.5637 - mse: 27407.6191 - val_loss: 0.5520 - val_mse: 1.3807 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 44.8559 - mse: 20276.3652 - val_loss: 0.9980 - val_mse: 4.6026 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 43.2708 - mse: 19257.8945 - val_loss: 1.0085 - val_mse: 4.9323 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 39.3783 - mse: 16174.5576 - val_loss: 0.8137 - val_mse: 3.2288 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 39.1087 - mse: 16046.3887 - val_loss: 1.0184 - val_mse: 5.1622 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 38.2863 - mse: 15141.7637 - val_loss: 0.9335 - val_mse: 4.3602 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 35.3373 - mse: 15153.6504 - val_loss: 0.9312 - val_mse: 4.5460 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 32.6230 - mse: 12371.3574 - val_loss: 0.6612 - val_mse: 2.4141 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 32.9608 - mse: 12223.6709 - val_loss: 0.6635 - val_mse: 2.3994 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 31.6335 - mse: 11191.0879 - val_loss: 0.6279 - val_mse: 2.1563 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 29.7011 - mse: 9979.1465 - val_loss: 0.5035 - val_mse: 1.4107 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 28.5366 - mse: 9755.7910 - val_loss: 0.5744 - val_mse: 1.8613 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 27.3245 - mse: 7471.7534 - val_loss: 0.4955 - val_mse: 1.4324 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 25.8090 - mse: 8201.3145 - val_loss: 0.4457 - val_mse: 1.1880 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 25.6106 - mse: 8733.3398 - val_loss: 0.3416 - val_mse: 0.7638 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 22.2402 - mse: 5362.5854 - val_loss: 0.3154 - val_mse: 0.6929 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 22.6496 - mse: 6402.5386 - val_loss: 0.2707 - val_mse: 0.5642 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 21.3253 - mse: 5447.0483 - val_loss: 0.2530 - val_mse: 0.5199 - 1s/epoch - 4ms/step\n",
            "255/255 - 1s - loss: 20.5342 - mse: 5077.7993 - val_loss: 0.3037 - val_mse: 0.6649 - 1s/epoch - 5ms/step\n",
            "255/255 - 1s - loss: 18.9366 - mse: 4127.0747 - val_loss: 0.2592 - val_mse: 0.5401 - 1s/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 396 ended. Search finished for the next optimal point.\n",
            "Time taken: 151.8761\n",
            "Function value obtained: 0.5401\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 397 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [94, 118, 123]\n",
            "Learning Rate: 1.6703278286471514e-06\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.44219589602107023\n",
            "Batch Size: 45\n",
            "----------------------------------------\n",
            "187/187 - 4s - loss: 1792.8011 - mse: 32497418.0000 - val_loss: 164.5043 - val_mse: 147282.3750 - 4s/epoch - 22ms/step\n",
            "187/187 - 1s - loss: 1603.3253 - mse: 24375910.0000 - val_loss: 116.1063 - val_mse: 78798.3125 - 923ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1563.1261 - mse: 21283908.0000 - val_loss: 75.9146 - val_mse: 35947.4648 - 913ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1555.5414 - mse: 21997530.0000 - val_loss: 40.8819 - val_mse: 10670.8037 - 925ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1542.3569 - mse: 23853130.0000 - val_loss: 15.8522 - val_mse: 1569.8909 - 924ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1522.4965 - mse: 27373444.0000 - val_loss: 18.6450 - val_mse: 691.2137 - 936ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1450.8922 - mse: 22179090.0000 - val_loss: 49.5784 - val_mse: 8951.3896 - 946ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1387.0466 - mse: 19469322.0000 - val_loss: 74.4979 - val_mse: 22703.1738 - 934ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1345.1716 - mse: 17601268.0000 - val_loss: 96.4725 - val_mse: 42416.0547 - 951ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1380.1199 - mse: 17068350.0000 - val_loss: 107.0166 - val_mse: 53397.0664 - 943ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1332.2050 - mse: 17204834.0000 - val_loss: 115.9914 - val_mse: 62757.3398 - 962ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1301.1378 - mse: 18816446.0000 - val_loss: 120.5888 - val_mse: 69973.0156 - 945ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1311.2384 - mse: 20507866.0000 - val_loss: 117.6289 - val_mse: 67746.6172 - 929ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1283.0311 - mse: 16174156.0000 - val_loss: 113.4194 - val_mse: 63798.5977 - 911ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1248.9623 - mse: 16184058.0000 - val_loss: 106.8307 - val_mse: 56364.7891 - 904ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1309.5017 - mse: 18775374.0000 - val_loss: 99.0245 - val_mse: 48287.8945 - 923ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1203.0112 - mse: 13822350.0000 - val_loss: 92.1243 - val_mse: 41810.7852 - 906ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1242.1508 - mse: 16858696.0000 - val_loss: 85.5068 - val_mse: 35687.6406 - 898ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1193.2006 - mse: 12691307.0000 - val_loss: 80.1287 - val_mse: 30900.0820 - 910ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1198.5038 - mse: 13219193.0000 - val_loss: 77.4757 - val_mse: 28727.0391 - 909ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1191.2653 - mse: 15662742.0000 - val_loss: 78.2326 - val_mse: 29258.1777 - 922ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1097.8036 - mse: 11630888.0000 - val_loss: 80.9797 - val_mse: 31091.5195 - 923ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1139.7294 - mse: 12836639.0000 - val_loss: 85.1820 - val_mse: 34617.8828 - 941ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1105.1598 - mse: 12791817.0000 - val_loss: 83.5116 - val_mse: 33392.7422 - 957ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1109.7943 - mse: 13188503.0000 - val_loss: 81.1980 - val_mse: 31537.7559 - 968ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1121.5991 - mse: 14292598.0000 - val_loss: 76.2221 - val_mse: 27711.5039 - 927ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1104.8538 - mse: 11654181.0000 - val_loss: 73.3246 - val_mse: 25603.9961 - 934ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1104.9114 - mse: 13663253.0000 - val_loss: 73.3129 - val_mse: 25599.7012 - 935ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1054.4540 - mse: 11443329.0000 - val_loss: 68.4565 - val_mse: 22266.0586 - 938ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1096.2823 - mse: 13675661.0000 - val_loss: 64.0170 - val_mse: 19382.3398 - 935ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1070.2657 - mse: 13837415.0000 - val_loss: 56.9652 - val_mse: 15189.1680 - 905ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1067.2883 - mse: 13605441.0000 - val_loss: 53.4781 - val_mse: 13391.9941 - 920ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1068.5802 - mse: 14080235.0000 - val_loss: 53.0785 - val_mse: 13194.1465 - 918ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1029.3094 - mse: 11193742.0000 - val_loss: 50.7461 - val_mse: 12284.1631 - 916ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1042.5938 - mse: 10919356.0000 - val_loss: 51.9469 - val_mse: 13072.8262 - 912ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1008.4158 - mse: 9456141.0000 - val_loss: 52.3258 - val_mse: 13324.8213 - 951ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1005.8853 - mse: 10925249.0000 - val_loss: 52.9073 - val_mse: 13739.8633 - 950ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1022.4886 - mse: 10916230.0000 - val_loss: 52.4626 - val_mse: 13574.0762 - 947ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1004.6605 - mse: 11309585.0000 - val_loss: 52.1930 - val_mse: 13424.4014 - 912ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1016.2847 - mse: 12103905.0000 - val_loss: 50.3716 - val_mse: 12459.3506 - 912ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 981.8003 - mse: 9381465.0000 - val_loss: 49.5637 - val_mse: 11904.6973 - 911ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 1000.9281 - mse: 11080753.0000 - val_loss: 48.3397 - val_mse: 11249.1035 - 909ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 971.0762 - mse: 11010333.0000 - val_loss: 47.6280 - val_mse: 10879.8467 - 913ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 929.0085 - mse: 8315680.0000 - val_loss: 48.3843 - val_mse: 11221.4922 - 914ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 930.9239 - mse: 7778788.5000 - val_loss: 47.9980 - val_mse: 10995.3105 - 923ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 923.7460 - mse: 9064627.0000 - val_loss: 47.0279 - val_mse: 10570.3955 - 917ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 890.2336 - mse: 7401633.5000 - val_loss: 46.1511 - val_mse: 10124.3730 - 909ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 920.4547 - mse: 9471202.0000 - val_loss: 41.6759 - val_mse: 8005.8818 - 943ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 922.0193 - mse: 9004647.0000 - val_loss: 40.2592 - val_mse: 7436.6748 - 954ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 926.2994 - mse: 10194976.0000 - val_loss: 39.0886 - val_mse: 6974.9639 - 973ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 907.6562 - mse: 8007721.0000 - val_loss: 37.4279 - val_mse: 6337.1328 - 910ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 884.1309 - mse: 7745539.0000 - val_loss: 36.2016 - val_mse: 5878.4268 - 922ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 896.2892 - mse: 8877947.0000 - val_loss: 33.5558 - val_mse: 4970.8755 - 916ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 891.6880 - mse: 8484104.0000 - val_loss: 34.3716 - val_mse: 5280.7300 - 932ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 848.3159 - mse: 8823607.0000 - val_loss: 32.3325 - val_mse: 4630.4331 - 912ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 833.1719 - mse: 6174845.0000 - val_loss: 34.3697 - val_mse: 5320.6401 - 920ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 892.8940 - mse: 8190940.5000 - val_loss: 33.8815 - val_mse: 5185.2744 - 933ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 829.4347 - mse: 6905337.5000 - val_loss: 33.9265 - val_mse: 5213.9951 - 919ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 838.7169 - mse: 6954364.0000 - val_loss: 32.2558 - val_mse: 4694.4702 - 927ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 857.0416 - mse: 7622439.5000 - val_loss: 33.0640 - val_mse: 4982.0508 - 924ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 840.9667 - mse: 8048920.5000 - val_loss: 32.1600 - val_mse: 4655.7979 - 980ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 845.9693 - mse: 6925112.0000 - val_loss: 31.0557 - val_mse: 4339.6025 - 986ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 813.4963 - mse: 6356291.0000 - val_loss: 28.0731 - val_mse: 3461.1050 - 982ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 823.3387 - mse: 6913287.0000 - val_loss: 26.0888 - val_mse: 2961.6848 - 953ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 790.9901 - mse: 5954086.0000 - val_loss: 26.6177 - val_mse: 3088.2400 - 952ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 797.5961 - mse: 6180710.5000 - val_loss: 27.1583 - val_mse: 3231.2617 - 945ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 803.1675 - mse: 7410733.0000 - val_loss: 25.6682 - val_mse: 2895.4919 - 971ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 805.3176 - mse: 6837874.0000 - val_loss: 25.5923 - val_mse: 2887.6206 - 945ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 790.1247 - mse: 6803838.0000 - val_loss: 25.5852 - val_mse: 2888.2810 - 948ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 796.9232 - mse: 6325734.0000 - val_loss: 23.6437 - val_mse: 2452.9131 - 934ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 800.0722 - mse: 7145841.0000 - val_loss: 21.3290 - val_mse: 1972.9504 - 949ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 768.8933 - mse: 5784022.0000 - val_loss: 19.9076 - val_mse: 1704.4614 - 944ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 773.0425 - mse: 5608373.5000 - val_loss: 19.7086 - val_mse: 1669.5410 - 987ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 734.1243 - mse: 5354596.0000 - val_loss: 17.3970 - val_mse: 1281.6217 - 966ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 728.5365 - mse: 5190696.5000 - val_loss: 15.8197 - val_mse: 1041.4155 - 962ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 746.3945 - mse: 5318207.5000 - val_loss: 16.6213 - val_mse: 1162.2258 - 920ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 740.8786 - mse: 5515361.0000 - val_loss: 14.4726 - val_mse: 865.0116 - 922ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 771.0211 - mse: 6048246.5000 - val_loss: 13.2949 - val_mse: 733.9958 - 934ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 747.8423 - mse: 5841974.0000 - val_loss: 13.0837 - val_mse: 711.3869 - 946ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 723.1821 - mse: 5172910.5000 - val_loss: 13.3984 - val_mse: 757.6223 - 959ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 749.3264 - mse: 5710757.5000 - val_loss: 13.7484 - val_mse: 804.9265 - 965ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 754.6431 - mse: 6154334.0000 - val_loss: 14.0344 - val_mse: 845.1807 - 973ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 723.2441 - mse: 5739893.5000 - val_loss: 12.5901 - val_mse: 679.2349 - 1s/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 688.6511 - mse: 4775280.5000 - val_loss: 12.5496 - val_mse: 672.7787 - 971ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 700.8040 - mse: 4738136.5000 - val_loss: 10.7803 - val_mse: 488.7284 - 1s/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 685.3378 - mse: 4548601.0000 - val_loss: 10.7664 - val_mse: 493.5536 - 1s/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 693.6959 - mse: 5853027.0000 - val_loss: 9.9525 - val_mse: 417.6612 - 1s/epoch - 6ms/step\n",
            "187/187 - 1s - loss: 702.4971 - mse: 5210088.5000 - val_loss: 10.4116 - val_mse: 462.3951 - 945ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 666.0358 - mse: 4304995.0000 - val_loss: 9.8084 - val_mse: 407.8085 - 949ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 709.7646 - mse: 5499810.5000 - val_loss: 9.4083 - val_mse: 375.8621 - 946ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 691.3819 - mse: 4944339.5000 - val_loss: 8.7077 - val_mse: 325.8908 - 930ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 653.0087 - mse: 4030844.2500 - val_loss: 9.3714 - val_mse: 374.7555 - 923ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 652.6562 - mse: 4422468.0000 - val_loss: 9.6289 - val_mse: 398.6662 - 918ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 671.5813 - mse: 4458765.5000 - val_loss: 8.9141 - val_mse: 340.9439 - 948ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 646.7340 - mse: 4100345.2500 - val_loss: 8.9152 - val_mse: 340.8683 - 938ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 647.0450 - mse: 4243642.5000 - val_loss: 9.3739 - val_mse: 380.5813 - 948ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 620.4681 - mse: 3987104.2500 - val_loss: 8.9623 - val_mse: 347.5321 - 981ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 666.0880 - mse: 5083442.0000 - val_loss: 8.4904 - val_mse: 310.0685 - 996ms/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 616.9877 - mse: 3754290.5000 - val_loss: 8.1209 - val_mse: 277.5777 - 1s/epoch - 5ms/step\n",
            "187/187 - 1s - loss: 620.7740 - mse: 3678435.0000 - val_loss: 7.6982 - val_mse: 250.5408 - 985ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 397 ended. Search finished for the next optimal point.\n",
            "Time taken: 131.7096\n",
            "Function value obtained: 250.5408\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 398 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [121, 125]\n",
            "Learning Rate: 0.0013829383730690863\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.45196540319329925\n",
            "Batch Size: 68\n",
            "----------------------------------------\n",
            "124/124 - 4s - loss: 447.2480 - mse: 2321304.5000 - val_loss: 8.7472 - val_mse: 536.1682 - 4s/epoch - 31ms/step\n",
            "124/124 - 1s - loss: 68.2326 - mse: 57623.1289 - val_loss: 0.4399 - val_mse: 1.8707 - 596ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 23.5502 - mse: 6490.8667 - val_loss: 0.1202 - val_mse: 0.2405 - 594ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 11.4854 - mse: 1788.6982 - val_loss: 0.0617 - val_mse: 0.1235 - 590ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 6.1332 - mse: 568.0403 - val_loss: 0.0264 - val_mse: 0.0527 - 583ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 4.0729 - mse: 453.4669 - val_loss: 0.0138 - val_mse: 0.0277 - 578ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 2.5369 - mse: 198.2053 - val_loss: 0.0088 - val_mse: 0.0176 - 578ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 1.8235 - mse: 100.4295 - val_loss: 0.0084 - val_mse: 0.0168 - 578ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 1.2562 - mse: 66.8341 - val_loss: 0.0086 - val_mse: 0.0173 - 588ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.9017 - mse: 38.7697 - val_loss: 0.0084 - val_mse: 0.0169 - 614ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.6887 - mse: 30.6341 - val_loss: 0.0085 - val_mse: 0.0169 - 602ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.5115 - mse: 15.6848 - val_loss: 0.0085 - val_mse: 0.0170 - 620ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.4795 - mse: 27.0096 - val_loss: 0.0085 - val_mse: 0.0169 - 617ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.3793 - mse: 13.7123 - val_loss: 0.0084 - val_mse: 0.0169 - 593ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.3049 - mse: 9.6807 - val_loss: 0.0084 - val_mse: 0.0168 - 597ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.2110 - mse: 4.5128 - val_loss: 0.0084 - val_mse: 0.0168 - 607ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.2235 - mse: 6.6088 - val_loss: 0.0085 - val_mse: 0.0170 - 598ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.1989 - mse: 10.0674 - val_loss: 0.0084 - val_mse: 0.0168 - 598ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.1626 - mse: 6.7062 - val_loss: 0.0084 - val_mse: 0.0168 - 597ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.1119 - mse: 1.7454 - val_loss: 0.0084 - val_mse: 0.0168 - 591ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.1453 - mse: 3.5735 - val_loss: 0.0084 - val_mse: 0.0167 - 600ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0962 - mse: 1.3811 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.1111 - mse: 2.7994 - val_loss: 0.0084 - val_mse: 0.0167 - 589ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0779 - mse: 1.0163 - val_loss: 0.0084 - val_mse: 0.0168 - 577ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0725 - mse: 0.8521 - val_loss: 0.0084 - val_mse: 0.0167 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0758 - mse: 1.3791 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0551 - mse: 0.9492 - val_loss: 0.0084 - val_mse: 0.0167 - 577ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0836 - mse: 2.0318 - val_loss: 0.0084 - val_mse: 0.0167 - 586ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0705 - mse: 2.0333 - val_loss: 0.0084 - val_mse: 0.0167 - 603ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0588 - mse: 1.3563 - val_loss: 0.0084 - val_mse: 0.0167 - 590ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0381 - mse: 0.3006 - val_loss: 0.0084 - val_mse: 0.0167 - 620ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0341 - mse: 0.3188 - val_loss: 0.0084 - val_mse: 0.0167 - 607ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0499 - mse: 2.2967 - val_loss: 0.0084 - val_mse: 0.0167 - 591ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0366 - mse: 0.5467 - val_loss: 0.0084 - val_mse: 0.0167 - 599ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0319 - mse: 0.2953 - val_loss: 0.0084 - val_mse: 0.0167 - 569ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0273 - mse: 0.1522 - val_loss: 0.0084 - val_mse: 0.0167 - 580ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0270 - mse: 0.2896 - val_loss: 0.0084 - val_mse: 0.0167 - 591ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0329 - mse: 0.2735 - val_loss: 0.0084 - val_mse: 0.0167 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0312 - mse: 0.2767 - val_loss: 0.0084 - val_mse: 0.0167 - 581ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0344 - mse: 0.4340 - val_loss: 0.0084 - val_mse: 0.0167 - 586ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0316 - mse: 0.5162 - val_loss: 0.0084 - val_mse: 0.0167 - 589ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0241 - mse: 0.1469 - val_loss: 0.0084 - val_mse: 0.0167 - 585ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0160 - mse: 0.0533 - val_loss: 0.0084 - val_mse: 0.0167 - 594ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0286 - mse: 0.3703 - val_loss: 0.0084 - val_mse: 0.0167 - 580ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0219 - mse: 0.2389 - val_loss: 0.0084 - val_mse: 0.0167 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0194 - mse: 0.1396 - val_loss: 0.0084 - val_mse: 0.0167 - 593ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0265 - mse: 1.2066 - val_loss: 0.0084 - val_mse: 0.0167 - 591ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0166 - mse: 0.0619 - val_loss: 0.0084 - val_mse: 0.0167 - 616ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0262 - mse: 0.3679 - val_loss: 0.0084 - val_mse: 0.0167 - 625ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0224 - mse: 0.1882 - val_loss: 0.0084 - val_mse: 0.0167 - 609ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0184 - mse: 0.2696 - val_loss: 0.0084 - val_mse: 0.0167 - 604ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0179 - mse: 0.1005 - val_loss: 0.0084 - val_mse: 0.0167 - 572ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0140 - mse: 0.0893 - val_loss: 0.0084 - val_mse: 0.0167 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0185 - mse: 0.1719 - val_loss: 0.0084 - val_mse: 0.0167 - 583ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0142 - mse: 0.1070 - val_loss: 0.0084 - val_mse: 0.0168 - 583ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0135 - mse: 0.0585 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0124 - mse: 0.0304 - val_loss: 0.0084 - val_mse: 0.0167 - 593ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0148 - mse: 0.0944 - val_loss: 0.0084 - val_mse: 0.0167 - 582ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0106 - mse: 0.0261 - val_loss: 0.0084 - val_mse: 0.0167 - 570ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0141 - mse: 0.0511 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0108 - mse: 0.0483 - val_loss: 0.0084 - val_mse: 0.0167 - 575ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0102 - mse: 0.0240 - val_loss: 0.0084 - val_mse: 0.0167 - 582ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0109 - mse: 0.0282 - val_loss: 0.0084 - val_mse: 0.0168 - 590ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0115 - mse: 0.0318 - val_loss: 0.0084 - val_mse: 0.0167 - 587ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0110 - mse: 0.0472 - val_loss: 0.0084 - val_mse: 0.0167 - 570ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0153 - mse: 0.1578 - val_loss: 0.0084 - val_mse: 0.0167 - 586ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0123 - mse: 0.0401 - val_loss: 0.0084 - val_mse: 0.0167 - 623ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0096 - mse: 0.0228 - val_loss: 0.0084 - val_mse: 0.0169 - 600ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0093 - mse: 0.0197 - val_loss: 0.0084 - val_mse: 0.0167 - 610ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0099 - mse: 0.0213 - val_loss: 0.0084 - val_mse: 0.0167 - 623ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0160 - mse: 0.3135 - val_loss: 0.0084 - val_mse: 0.0167 - 594ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0099 - mse: 0.0217 - val_loss: 0.0084 - val_mse: 0.0167 - 589ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0098 - mse: 0.0238 - val_loss: 0.0084 - val_mse: 0.0167 - 596ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0098 - mse: 0.0220 - val_loss: 0.0084 - val_mse: 0.0167 - 593ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0118 - mse: 0.0393 - val_loss: 0.0084 - val_mse: 0.0167 - 589ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0091 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 603ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0112 - mse: 0.0378 - val_loss: 0.0084 - val_mse: 0.0168 - 589ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0084 - val_mse: 0.0167 - 590ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0097 - mse: 0.0225 - val_loss: 0.0084 - val_mse: 0.0167 - 588ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0095 - mse: 0.0210 - val_loss: 0.0084 - val_mse: 0.0167 - 573ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0099 - mse: 0.0272 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0100 - mse: 0.0259 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0095 - mse: 0.0200 - val_loss: 0.0084 - val_mse: 0.0167 - 575ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0098 - mse: 0.0217 - val_loss: 0.0084 - val_mse: 0.0168 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0094 - mse: 0.0202 - val_loss: 0.0084 - val_mse: 0.0167 - 577ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0092 - mse: 0.0189 - val_loss: 0.0084 - val_mse: 0.0167 - 602ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0095 - mse: 0.0224 - val_loss: 0.0084 - val_mse: 0.0168 - 585ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0157 - mse: 0.2122 - val_loss: 0.0084 - val_mse: 0.0168 - 615ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0084 - val_mse: 0.0167 - 605ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0096 - mse: 0.0203 - val_loss: 0.0084 - val_mse: 0.0168 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0103 - mse: 0.0278 - val_loss: 0.0084 - val_mse: 0.0167 - 585ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0104 - mse: 0.0351 - val_loss: 0.0084 - val_mse: 0.0167 - 578ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0090 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 578ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0097 - mse: 0.0224 - val_loss: 0.0084 - val_mse: 0.0167 - 579ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0117 - mse: 0.0823 - val_loss: 0.0084 - val_mse: 0.0167 - 586ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0095 - mse: 0.0236 - val_loss: 0.0084 - val_mse: 0.0167 - 576ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0091 - mse: 0.0187 - val_loss: 0.0084 - val_mse: 0.0167 - 584ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0089 - mse: 0.0180 - val_loss: 0.0084 - val_mse: 0.0167 - 587ms/epoch - 5ms/step\n",
            "124/124 - 1s - loss: 0.0142 - mse: 0.2129 - val_loss: 0.0084 - val_mse: 0.0167 - 597ms/epoch - 5ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 398 ended. Search finished for the next optimal point.\n",
            "Time taken: 93.2128\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 399 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 2\n",
            "Layer Nodes: [35, 79]\n",
            "Learning Rate: 5.614609482793394e-05\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.02492083881179493\n",
            "Batch Size: 253\n",
            "----------------------------------------\n",
            "34/34 - 3s - loss: 649.4641 - mse: 2493037.2500 - val_loss: 244.5846 - val_mse: 309904.9062 - 3s/epoch - 75ms/step\n",
            "34/34 - 0s - loss: 174.8608 - mse: 274527.8125 - val_loss: 59.9039 - val_mse: 17366.7480 - 225ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 130.8963 - mse: 162718.1406 - val_loss: 5.9827 - val_mse: 134.5299 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 116.0848 - mse: 123559.1172 - val_loss: 6.3675 - val_mse: 159.8275 - 215ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 106.1722 - mse: 102333.5781 - val_loss: 4.8087 - val_mse: 92.4680 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 96.0075 - mse: 100614.8281 - val_loss: 1.4747 - val_mse: 7.4065 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 83.1316 - mse: 67898.3594 - val_loss: 0.6353 - val_mse: 3.2050 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 74.6125 - mse: 64207.0586 - val_loss: 2.0538 - val_mse: 19.6626 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 59.8395 - mse: 40612.0898 - val_loss: 3.1635 - val_mse: 68.9190 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 52.4967 - mse: 36054.5430 - val_loss: 1.2734 - val_mse: 12.2947 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 46.8844 - mse: 34134.6055 - val_loss: 0.5987 - val_mse: 2.4530 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 35.6133 - mse: 18962.4102 - val_loss: 1.1352 - val_mse: 12.0425 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 26.8552 - mse: 11560.3799 - val_loss: 0.5540 - val_mse: 2.4343 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 21.0413 - mse: 7682.0718 - val_loss: 0.4462 - val_mse: 1.2237 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 18.6576 - mse: 6987.0605 - val_loss: 0.4761 - val_mse: 1.4487 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 16.6312 - mse: 6542.5942 - val_loss: 0.2947 - val_mse: 0.6874 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 14.3972 - mse: 4173.2964 - val_loss: 0.2210 - val_mse: 0.4681 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 15.8589 - mse: 7706.1616 - val_loss: 0.2087 - val_mse: 0.4440 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 13.8144 - mse: 6412.5103 - val_loss: 0.2587 - val_mse: 0.5429 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 13.1415 - mse: 3880.3518 - val_loss: 0.2050 - val_mse: 0.4168 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 14.2332 - mse: 5789.8315 - val_loss: 0.2216 - val_mse: 0.4640 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 13.9289 - mse: 4696.2490 - val_loss: 0.2348 - val_mse: 0.4889 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 13.3536 - mse: 4565.5825 - val_loss: 0.1932 - val_mse: 0.3987 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.9547 - mse: 4560.6870 - val_loss: 0.1587 - val_mse: 0.3179 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 13.8111 - mse: 4924.4272 - val_loss: 0.1836 - val_mse: 0.3750 - 222ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 13.4804 - mse: 5601.8091 - val_loss: 0.1714 - val_mse: 0.3438 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.0852 - mse: 3846.6704 - val_loss: 0.1725 - val_mse: 0.3450 - 221ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 12.2094 - mse: 3907.6179 - val_loss: 0.1658 - val_mse: 0.3320 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.4822 - mse: 3848.3311 - val_loss: 0.1510 - val_mse: 0.3028 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.0400 - mse: 3667.3823 - val_loss: 0.2173 - val_mse: 0.5798 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.8417 - mse: 5508.2217 - val_loss: 0.1407 - val_mse: 0.2831 - 221ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.5651 - mse: 3453.9023 - val_loss: 0.1276 - val_mse: 0.2561 - 230ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.9626 - mse: 6870.1455 - val_loss: 0.1441 - val_mse: 0.2921 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.4719 - mse: 3161.2971 - val_loss: 0.1177 - val_mse: 0.2358 - 219ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 13.2047 - mse: 5720.6157 - val_loss: 0.1243 - val_mse: 0.2593 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.7589 - mse: 4185.4995 - val_loss: 0.1526 - val_mse: 0.3411 - 223ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.2398 - mse: 2953.2188 - val_loss: 0.0986 - val_mse: 0.1972 - 220ms/epoch - 6ms/step\n",
            "34/34 - 0s - loss: 11.6754 - mse: 5205.8135 - val_loss: 0.0961 - val_mse: 0.1927 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.7331 - mse: 4385.2295 - val_loss: 0.0992 - val_mse: 0.1985 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 12.6878 - mse: 4292.0625 - val_loss: 0.0852 - val_mse: 0.1711 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.4361 - mse: 4536.0000 - val_loss: 0.0812 - val_mse: 0.1625 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.6712 - mse: 3305.9026 - val_loss: 0.0951 - val_mse: 0.1903 - 226ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.6551 - mse: 4021.7876 - val_loss: 0.0850 - val_mse: 0.1700 - 224ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.4175 - mse: 3730.2563 - val_loss: 0.0928 - val_mse: 0.1861 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.3045 - mse: 2729.3442 - val_loss: 0.0658 - val_mse: 0.1317 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.3831 - mse: 2607.4146 - val_loss: 0.0716 - val_mse: 0.1431 - 231ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.9974 - mse: 3334.2256 - val_loss: 0.0706 - val_mse: 0.1419 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.3354 - mse: 2642.1321 - val_loss: 0.0629 - val_mse: 0.1259 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 11.6199 - mse: 3720.3640 - val_loss: 0.0731 - val_mse: 0.1463 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.8093 - mse: 3176.7461 - val_loss: 0.0985 - val_mse: 0.2344 - 234ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.3561 - mse: 3557.8035 - val_loss: 0.0562 - val_mse: 0.1125 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.3131 - mse: 3837.1780 - val_loss: 0.0512 - val_mse: 0.1024 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.3969 - mse: 2079.8884 - val_loss: 0.0497 - val_mse: 0.0994 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.4655 - mse: 2409.6260 - val_loss: 0.0567 - val_mse: 0.1144 - 227ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.9216 - mse: 3140.2332 - val_loss: 0.0517 - val_mse: 0.1038 - 228ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.1504 - mse: 3225.5576 - val_loss: 0.0428 - val_mse: 0.0855 - 232ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.2078 - mse: 2213.3047 - val_loss: 0.0457 - val_mse: 0.0915 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.4296 - mse: 2112.1050 - val_loss: 0.0405 - val_mse: 0.0810 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.6900 - mse: 2206.6633 - val_loss: 0.0450 - val_mse: 0.0925 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.2488 - mse: 2256.9646 - val_loss: 0.0397 - val_mse: 0.0797 - 233ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.5147 - mse: 2999.0630 - val_loss: 0.0748 - val_mse: 0.1535 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.5599 - mse: 1887.6182 - val_loss: 0.0483 - val_mse: 0.0973 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.2775 - mse: 2469.1323 - val_loss: 0.0726 - val_mse: 0.1524 - 246ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.2966 - mse: 3451.8347 - val_loss: 0.0398 - val_mse: 0.0803 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 10.6019 - mse: 3719.3472 - val_loss: 0.0383 - val_mse: 0.0782 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.3787 - mse: 2932.8755 - val_loss: 0.0299 - val_mse: 0.0599 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.5905 - mse: 2077.4800 - val_loss: 0.0629 - val_mse: 0.1422 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.7738 - mse: 2450.8286 - val_loss: 0.0306 - val_mse: 0.0627 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.4732 - mse: 2704.0564 - val_loss: 0.0240 - val_mse: 0.0480 - 236ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.8523 - mse: 2383.6785 - val_loss: 0.0306 - val_mse: 0.0614 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.8513 - mse: 2702.1353 - val_loss: 0.0231 - val_mse: 0.0463 - 249ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 9.4633 - mse: 3643.2683 - val_loss: 0.0524 - val_mse: 0.1058 - 235ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.2438 - mse: 2047.8981 - val_loss: 0.0199 - val_mse: 0.0398 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.7605 - mse: 1650.0601 - val_loss: 0.0204 - val_mse: 0.0407 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.4073 - mse: 2245.6997 - val_loss: 0.0301 - val_mse: 0.0605 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.5086 - mse: 2293.8188 - val_loss: 0.0169 - val_mse: 0.0337 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.5079 - mse: 2595.8723 - val_loss: 0.0224 - val_mse: 0.0447 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.6719 - mse: 1699.3663 - val_loss: 0.0237 - val_mse: 0.0474 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.9925 - mse: 2012.4242 - val_loss: 0.0379 - val_mse: 0.0758 - 239ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.7755 - mse: 1622.4230 - val_loss: 0.0216 - val_mse: 0.0431 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.0509 - mse: 2180.4604 - val_loss: 0.0304 - val_mse: 0.0607 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.3000 - mse: 2896.5991 - val_loss: 0.0379 - val_mse: 0.0791 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.8785 - mse: 2179.5459 - val_loss: 0.0227 - val_mse: 0.0453 - 237ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.1742 - mse: 2097.1755 - val_loss: 0.0276 - val_mse: 0.0562 - 238ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.4839 - mse: 1595.0502 - val_loss: 0.0806 - val_mse: 0.2125 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.3009 - mse: 1769.4264 - val_loss: 0.0165 - val_mse: 0.0332 - 243ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.4744 - mse: 2813.0051 - val_loss: 0.0225 - val_mse: 0.0451 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.6510 - mse: 1983.3284 - val_loss: 0.0498 - val_mse: 0.1013 - 250ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.4055 - mse: 1574.5952 - val_loss: 0.0438 - val_mse: 0.0897 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.3726 - mse: 1475.2289 - val_loss: 0.0123 - val_mse: 0.0245 - 229ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.1201 - mse: 1592.1328 - val_loss: 0.0118 - val_mse: 0.0235 - 247ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.0692 - mse: 1417.5303 - val_loss: 0.0102 - val_mse: 0.0204 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 8.0131 - mse: 1986.3617 - val_loss: 0.0105 - val_mse: 0.0210 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.5512 - mse: 1937.3486 - val_loss: 0.0107 - val_mse: 0.0214 - 248ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.1495 - mse: 1553.7391 - val_loss: 0.0109 - val_mse: 0.0220 - 253ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.2156 - mse: 1677.4283 - val_loss: 0.0262 - val_mse: 0.0535 - 244ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 7.7544 - mse: 1960.9185 - val_loss: 0.0143 - val_mse: 0.0289 - 259ms/epoch - 8ms/step\n",
            "34/34 - 0s - loss: 6.4736 - mse: 1386.5967 - val_loss: 0.0183 - val_mse: 0.0366 - 240ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 6.9727 - mse: 1450.3452 - val_loss: 0.0153 - val_mse: 0.0305 - 241ms/epoch - 7ms/step\n",
            "34/34 - 0s - loss: 6.9608 - mse: 1316.9141 - val_loss: 0.0075 - val_mse: 0.0151 - 254ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [2.49808335]\n",
            "\n",
            "Iteration No: 399 ended. Search finished for the next optimal point.\n",
            "Time taken: 63.8760\n",
            "Function value obtained: 0.0151\n",
            "Current minimum: 0.0033\n",
            "Iteration No: 400 started. Searching for the next optimal point.\n",
            "----------------------------------------\n",
            "Model Specifications:\n",
            "Number of Layers: 3\n",
            "Layer Nodes: [69, 108, 49]\n",
            "Learning Rate: 0.1\n",
            "Activation Function: relu\n",
            "Loss Function: huber\n",
            "Optimizer: adam\n",
            "Epochs: 400\n",
            "Dropout Rate: 0.09477321651061782\n",
            "Batch Size: 256\n",
            "----------------------------------------\n",
            "33/33 - 4s - loss: 122191.6406 - mse: 2167938482176.0000 - val_loss: 0.0088 - val_mse: 0.0176 - 4s/epoch - 108ms/step\n",
            "33/33 - 0s - loss: 0.0238 - mse: 0.0475 - val_loss: 0.0085 - val_mse: 0.0170 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0163 - mse: 0.0327 - val_loss: 0.0088 - val_mse: 0.0177 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0132 - mse: 0.0263 - val_loss: 0.0087 - val_mse: 0.0173 - 263ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0115 - mse: 0.0229 - val_loss: 0.0091 - val_mse: 0.0182 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0101 - mse: 0.0201 - val_loss: 0.0093 - val_mse: 0.0186 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0097 - mse: 0.0194 - val_loss: 0.0087 - val_mse: 0.0175 - 264ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0091 - mse: 0.0181 - val_loss: 0.0085 - val_mse: 0.0171 - 262ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0179 - val_loss: 0.0086 - val_mse: 0.0173 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0085 - val_mse: 0.0170 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 287ms/epoch - 9ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 282ms/epoch - 9ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 267ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 273ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 283ms/epoch - 9ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 263ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 265ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 281ms/epoch - 9ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0169 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 269ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 264ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0169 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 271ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 262ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 269ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 270ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0168 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0172 - 249ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0169 - 247ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0088 - mse: 0.0176 - val_loss: 0.0084 - val_mse: 0.0168 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 256ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 251ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0171 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 258ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 253ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0169 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0085 - val_mse: 0.0170 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0086 - val_mse: 0.0172 - 264ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0171 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0089 - mse: 0.0177 - val_loss: 0.0086 - val_mse: 0.0171 - 263ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0085 - val_mse: 0.0170 - 261ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 252ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 266ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0086 - val_mse: 0.0171 - 269ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 264ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 260ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0175 - val_loss: 0.0084 - val_mse: 0.0168 - 275ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 259ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0168 - 277ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0172 - val_loss: 0.0084 - val_mse: 0.0168 - 255ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0084 - val_mse: 0.0167 - 257ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0085 - val_mse: 0.0170 - 254ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 246ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0169 - 248ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0169 - 250ms/epoch - 8ms/step\n",
            "33/33 - 0s - loss: 0.0087 - mse: 0.0174 - val_loss: 0.0085 - val_mse: 0.0170 - 240ms/epoch - 7ms/step\n",
            "33/33 - 0s - loss: 0.0086 - mse: 0.0173 - val_loss: 0.0084 - val_mse: 0.0167 - 241ms/epoch - 7ms/step\n",
            "\n",
            "Predicted Performance: [0.01060114]\n",
            "\n",
            "Iteration No: 400 ended. Search finished for the next optimal point.\n",
            "Time taken: 62.6392\n",
            "Function value obtained: 0.0167\n",
            "Current minimum: 0.0033\n",
            "\n",
            "Best parameters: [2, 70, 128, 89, 156, 400, 0.0030106793913042373, 'relu', 'huber', 'adam', 0.0]\n",
            "Best MSE: 0.0033386482391506433\n"
          ]
        }
      ],
      "source": [
        "# MAIN: Run Bayesian optimization\n",
        "import time\n",
        "#-----------------------------------------------------------\n",
        "    # n_calls : iterations for iptimization\n",
        "    # Recommand : n_calls might be large enough, dependent to Search Space\n",
        "n_calls = 400\n",
        "res_gp = gp_minimize(objective, dimensions=space, n_calls=n_calls, random_state=7, verbose=True)\n",
        "\n",
        "    # Extract and print the best parameters\n",
        "best_params = res_gp.x\n",
        "print(\"\\nBest parameters:\", best_params)\n",
        "print(\"Best MSE:\", res_gp.fun)\n",
        "\n",
        "    # Convert results to DataFrame and save as CSV\n",
        "results_df = pd.DataFrame(res_gp.x_iters, columns=[dimension.name for dimension in space])\n",
        "results_df['MSE'] = res_gp.func_vals\n",
        "\n",
        "    # Optionally, add a column to indicate which configurations are better than a certain threshold\n",
        "result_threshold = 0.00005  # adjust this value as needed\n",
        "results_df['is_better_than_threshold'] = results_df['MSE'] < result_threshold\n",
        "\n",
        "    # Save to CSV\n",
        "results_df.to_csv(\"NAS_Result_{}.csv\".format(\n",
        "    time.strftime('%Y_%m_%d_%H_%M', time.localtime(time.time()))\n",
        "    ), index=False)\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFOAH6IdSFqQ"
      },
      "source": [
        "# 8. Export the best one\n",
        "\n",
        "---\n",
        "\n",
        "And then, ***the best one***'s Inductive Biases would be a friendly guide for your Symbolic Regression later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCsHcVMfSFyE",
        "outputId": "06acee8d-4c1a-47fb-ec4e-f5774fc5dd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "54/54 [==============================] - 3s 9ms/step - loss: 152.8532 - mse: 229009.2656 - val_loss: 6.8196 - val_mse: 214.0191\n",
            "Epoch 2/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 28.8526 - mse: 6986.1377 - val_loss: 10.4520 - val_mse: 277.9122\n",
            "Epoch 3/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 21.3771 - mse: 3525.6492 - val_loss: 36.9789 - val_mse: 7336.1504\n",
            "Epoch 4/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 68.2503 - mse: 50830.7734 - val_loss: 25.6989 - val_mse: 3158.2500\n",
            "Epoch 5/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 31.1901 - mse: 13421.3516 - val_loss: 0.9538 - val_mse: 2.9263\n",
            "Epoch 6/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 10.8507 - mse: 1316.5621 - val_loss: 27.2438 - val_mse: 4013.5786\n",
            "Epoch 7/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 20.6746 - mse: 4467.5435 - val_loss: 10.2751 - val_mse: 498.8921\n",
            "Epoch 8/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 23.8414 - mse: 4117.4600 - val_loss: 35.5607 - val_mse: 6711.4541\n",
            "Epoch 9/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 125.9928 - mse: 183769.2188 - val_loss: 67.9018 - val_mse: 24057.8828\n",
            "Epoch 10/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 40.9359 - mse: 18317.8828 - val_loss: 6.1261 - val_mse: 218.3711\n",
            "Epoch 11/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 2.8891 - mse: 133.9680 - val_loss: 0.4334 - val_mse: 2.0816\n",
            "Epoch 12/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 1.2693 - mse: 16.6143 - val_loss: 1.4791 - val_mse: 16.1217\n",
            "Epoch 13/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.2235 - mse: 1.3472 - val_loss: 0.3674 - val_mse: 1.6669\n",
            "Epoch 14/400\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.0464 - mse: 0.1514 - val_loss: 0.0272 - val_mse: 0.0563\n",
            "Epoch 15/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0190 - mse: 0.0415 - val_loss: 0.0852 - val_mse: 0.2226\n",
            "Epoch 16/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0490 - mse: 0.1155 - val_loss: 0.0423 - val_mse: 0.0885\n",
            "Epoch 17/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0208 - val_loss: 0.0046 - val_mse: 0.0092\n",
            "Epoch 18/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0059 - mse: 0.0117 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 19/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0068 - val_loss: 0.0031 - val_mse: 0.0063\n",
            "Epoch 20/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 21/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0093 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 22/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0077 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 23/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0076 - mse: 0.0153 - val_loss: 0.0139 - val_mse: 0.0280\n",
            "Epoch 24/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0089 - mse: 0.0178 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 25/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0082 - val_loss: 0.0043 - val_mse: 0.0087\n",
            "Epoch 26/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0049 - val_mse: 0.0098\n",
            "Epoch 27/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 28/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0124 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "Epoch 29/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0035 - val_mse: 0.0069\n",
            "Epoch 30/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0057 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 31/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0028 - val_mse: 0.0055\n",
            "Epoch 32/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 33/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 34/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0073 - mse: 0.0153 - val_loss: 0.0309 - val_mse: 0.0635\n",
            "Epoch 35/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0240 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 36/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 37/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 38/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0060 - val_loss: 0.0026 - val_mse: 0.0051\n",
            "Epoch 39/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0054 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 40/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0026 - mse: 0.0051 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 41/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 42/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "Epoch 43/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 44/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0036 - mse: 0.0073 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 45/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 46/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0026 - val_mse: 0.0051\n",
            "Epoch 47/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0055 - val_loss: 0.0024 - val_mse: 0.0047\n",
            "Epoch 48/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 49/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 50/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 51/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0185 - val_loss: 0.0042 - val_mse: 0.0084\n",
            "Epoch 52/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.8600 - mse: 17.9246 - val_loss: 2.4332 - val_mse: 39.3305\n",
            "Epoch 53/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 5.3906 - mse: 313.3775 - val_loss: 20.1895 - val_mse: 2188.0474\n",
            "Epoch 54/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 17.1269 - mse: 10633.9209 - val_loss: 7.4143 - val_mse: 317.6000\n",
            "Epoch 55/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 11.2822 - mse: 1425.1167 - val_loss: 2.5236 - val_mse: 44.5945\n",
            "Epoch 56/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 1.7006 - mse: 32.3966 - val_loss: 1.6002 - val_mse: 19.1141\n",
            "Epoch 57/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.2076 - mse: 1.5617 - val_loss: 0.0108 - val_mse: 0.0217\n",
            "Epoch 58/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0071 - mse: 0.0142 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 59/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 60/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0037 - mse: 0.0075 - val_loss: 0.0033 - val_mse: 0.0065\n",
            "Epoch 61/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0080 - val_loss: 0.0034 - val_mse: 0.0068\n",
            "Epoch 62/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0030 - val_mse: 0.0061\n",
            "Epoch 63/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0192 - val_loss: 0.0066 - val_mse: 0.0132\n",
            "Epoch 64/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0096 - val_loss: 0.0060 - val_mse: 0.0121\n",
            "Epoch 65/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0079 - val_loss: 0.0041 - val_mse: 0.0081\n",
            "Epoch 66/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0089 - val_loss: 0.0039 - val_mse: 0.0077\n",
            "Epoch 67/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 68/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0030 - val_mse: 0.0059\n",
            "Epoch 69/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0051 - val_loss: 0.0026 - val_mse: 0.0052\n",
            "Epoch 70/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0055 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 71/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 72/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0025 - val_mse: 0.0049\n",
            "Epoch 73/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0023 - val_mse: 0.0045\n",
            "Epoch 74/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "Epoch 75/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0045 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 76/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 77/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0043\n",
            "Epoch 78/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 79/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 80/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0050 - val_loss: 0.0029 - val_mse: 0.0057\n",
            "Epoch 81/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 82/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "Epoch 83/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 84/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 85/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 86/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 87/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 88/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 89/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 90/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 91/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 92/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 93/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 94/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 95/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 96/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 97/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 98/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 99/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 100/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 101/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 102/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 103/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 104/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 105/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 106/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 107/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 108/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 109/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 110/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 111/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 112/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 113/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 114/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 115/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 116/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 117/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 118/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 119/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 120/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 121/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 122/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 123/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 124/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 125/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 126/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 127/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 128/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 129/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 130/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 131/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 132/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 133/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 134/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 135/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 136/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 137/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 138/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 139/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 140/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 141/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 142/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 143/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 144/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 145/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 146/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 147/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 148/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 149/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 150/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 151/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 152/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 153/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 154/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 155/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 156/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 157/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 158/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 159/400\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 160/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 161/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 162/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 163/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 164/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 165/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 166/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 167/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 168/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 169/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 170/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 9.1468 - mse: 2842.4031 - val_loss: 6.4237 - val_mse: 265.9382\n",
            "Epoch 171/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 1.7675 - mse: 53.9057 - val_loss: 0.2692 - val_mse: 1.0391\n",
            "Epoch 172/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0871 - mse: 0.2736 - val_loss: 0.0110 - val_mse: 0.0220\n",
            "Epoch 173/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0060 - mse: 0.0121 - val_loss: 0.0127 - val_mse: 0.0253\n",
            "Epoch 174/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0073 - mse: 0.0147 - val_loss: 0.0053 - val_mse: 0.0107\n",
            "Epoch 175/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0037 - mse: 0.0074 - val_loss: 0.0032 - val_mse: 0.0064\n",
            "Epoch 176/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0067 - val_loss: 0.0031 - val_mse: 0.0061\n",
            "Epoch 177/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0062 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 178/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 179/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - mse: 0.0078 - val_loss: 0.0027 - val_mse: 0.0054\n",
            "Epoch 180/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0063 - mse: 0.0127 - val_loss: 0.0040 - val_mse: 0.0080\n",
            "Epoch 181/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 182/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "Epoch 183/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0026 - mse: 0.0053 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 184/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0105 - val_loss: 0.0036 - val_mse: 0.0072\n",
            "Epoch 185/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0063 - val_loss: 0.0041 - val_mse: 0.0083\n",
            "Epoch 186/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0047 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "Epoch 187/400\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0033 - val_mse: 0.0067\n",
            "Best Validation Loss: 0.0012702977983281016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Export best '.h5' file\n",
        "#-----------------------------------------------------------\n",
        "best_number_of_layers = best_params[0]\n",
        "best_layer_nodes = best_params[1:1+best_number_of_layers]\n",
        "best_batch_size = best_params[1+max_layers]\n",
        "best_epochs = best_params[2+max_layers]\n",
        "best_learning_rate = best_params[3+max_layers]\n",
        "best_activation = best_params[4+max_layers]\n",
        "best_loss_function = best_params[5+max_layers]\n",
        "best_optimizer = best_params[6+max_layers]\n",
        "best_dropout_rate = best_params[7+max_layers]\n",
        "\n",
        "best_model = SumNet(\n",
        "    layer_nodes=best_layer_nodes,\n",
        "    learning_rate=best_learning_rate,\n",
        "    activation=best_activation,\n",
        "    dropout_rate=best_dropout_rate,\n",
        "    optimizer=best_optimizer,\n",
        "    loss_function=best_loss_function,\n",
        ")\n",
        "\n",
        "best_model.model.fit(input_data_train, y_train,\n",
        "                     epochs=best_epochs, validation_data=(input_data_val, y_val),\n",
        "                     batch_size=best_batch_size,\n",
        "                     callbacks=[early_stopping])\n",
        "best_model.model.save(\"Best_Model_{}.h5\".format(\n",
        "    time.strftime('%Y_%m_%d_%H_%M', time.localtime(time.time()))\n",
        "    ))\n",
        "\n",
        "best_val_loss = min(best_model.model.history.history['val_loss'])\n",
        "print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "#-----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLj1mBMRxM8t"
      },
      "source": [
        "# 9. Evaluate best_model.h5\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mKnOxUGms_jO",
        "outputId": "b20c4e3c-1c7b-456f-f26c-202b2324056c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[4.18404178e-02],\n",
            "       [2.07500584e-02],\n",
            "       [1.85957413e-02],\n",
            "       ...,\n",
            "       [1.77938334e-04],\n",
            "       [1.36234037e-04],\n",
            "       [8.71897834e-05]]), array([[   23.90033494],\n",
            "       [   48.19263537],\n",
            "       [   53.77575361],\n",
            "       ...,\n",
            "       [ 5619.92449991],\n",
            "       [ 7340.3095509 ],\n",
            "       [11469.23367328]]), array([[3.14718304e-01],\n",
            "       [2.21632608e-01],\n",
            "       [2.09812202e-01],\n",
            "       ...,\n",
            "       [2.04136905e-04],\n",
            "       [1.78619792e-04],\n",
            "       [1.42895833e-04]]), array([[   403.98939528],\n",
            "       [  1156.73798763],\n",
            "       [  1363.46420906],\n",
            "       ...,\n",
            "       [135734.07202216],\n",
            "       [202611.79263949],\n",
            "       [395726.15749901]]), array([[2.24798788e+00],\n",
            "       [1.58309006e+00],\n",
            "       [1.49865859e+00],\n",
            "       ...,\n",
            "       [1.36091270e-03],\n",
            "       [1.19079861e-03],\n",
            "       [9.52638889e-04]]), array([[ 59.96253512],\n",
            "       [120.90845582],\n",
            "       [134.91570402],\n",
            "       ...,\n",
            "       [401.47753427],\n",
            "       [524.37882028],\n",
            "       [819.34190668]])]\n",
            "329/329 [==============================] - 1s 2ms/step\n",
            "(10498,)\n",
            "(10498,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Split X_selected into 6 separate tensors\n",
        "X_array = X_selected.to_numpy()\n",
        "input_tensors = [X_array[:, i:i+1] for i in range(6)]\n",
        "\n",
        "print(input_tensors)\n",
        "\n",
        "# Predict using the model\n",
        "y_pred_NN = best_model.model.predict(input_tensors)\n",
        "y_pred_NN = y_pred_NN.ravel()\n",
        "\n",
        "y_test_NN = y\n",
        "\n",
        "print(y_pred_NN.shape)\n",
        "print(y_test_NN.shape)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# R squared\n",
        "r2 = r2_score(y_test_NN, y_pred_NN)\n",
        "\n",
        "# COV\n",
        "cov = (np.std(y_pred_NN - y_test_NN) / np.mean(y_test_NN))\n",
        "\n",
        "# Mean\n",
        "MEAN = np.mean(y_pred_NN/y_test_NN)\n",
        "\n",
        "# Show Plot: Data vs Predicted Value\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(y_test_NN, y_pred_NN, alpha=0.2)\n",
        "plt.plot([0.4, 1.0], [0.4, 1.0], color='red', linestyle='--')  # y=x line\n",
        "plt.title(f\"Data vs Predicted (R^2: {r2:.5f}, COV: {cov:.5f}, MEAN: {MEAN:.5f})\")\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "#plt.xlim([0.4, 1])\n",
        "#plt.ylim([0.4, 1])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMwDjkqzSHZt"
      },
      "source": [
        "---\n",
        "# Chapter.3 Symbolic Regression\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82tTKTIr5IeB"
      },
      "source": [
        "# 1. Generate Train Data for PySR\n",
        "---\n",
        "In this section(chapter), 2 equations would be developed.\n",
        "\n",
        "Each equations would be fitted to model_g, and model_f.\n",
        "\n",
        "According to the inductive biases of well-optimized MLP SumNet,\n",
        "\n",
        "your Symbolic Regression would be well-fitted:\n",
        "\n",
        "> * Lower Complexity\n",
        "> * Faster fitting speed\n",
        "> * Greatly Practical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GTmqeaAzSHip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585188f2-fb16-49b7-a887-4d30441978cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "263/263 [==============================] - 1s 2ms/step\n",
            "(8398, 6) (8398, 2) (8398,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate random indices for 80% of the rows\n",
        "idx = np.random.choice(len(X_selected), size=int(0.8 * len(X_selected)), replace=False)\n",
        "\n",
        "# Select rows from X_selected using the generated indices\n",
        "X_for_pysr = X_selected.iloc[idx]\n",
        "\n",
        "# Split the DataFrame into separate Series (tensors)\n",
        "input_tensors = [X_for_pysr.iloc[:, i] for i in range(X_for_pysr.shape[1])]\n",
        "\n",
        "# Predict using the model\n",
        "y_for_pysr = best_model.model_g.predict(input_tensors)\n",
        "\n",
        "# Get the real y-values using the generated indices\n",
        "z_for_pysr = y.iloc[idx] if isinstance(y, pd.Series) else y[idx]\n",
        "\n",
        "# Print the shapes\n",
        "print(X_for_pysr.shape, y_for_pysr.shape, z_for_pysr.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmVUX-gO5OTy"
      },
      "source": [
        "# 2. Generate Dataframe\n",
        "---\n",
        "Symbolic Regression with Julia is quite fragile.\n",
        "\n",
        "don't forget to export your tasks as *pickle*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "533p8WFU5ObE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2d4a20-a555-4607-8e1d-a54bfc597b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           X_0           X_1       X_2            X_3       X_4          X_5  \\\n",
            "0     0.000832   1201.348046  0.000986   19403.521380  0.004930   192.664942   \n",
            "1     0.000508   1968.604926  0.001044   55167.535034  0.007829   386.667836   \n",
            "2     0.000091  10964.048894  0.000403  661157.024793  0.002750  1969.463856   \n",
            "3     0.000670   1491.425484  0.002754   47851.562500  0.020247   391.311896   \n",
            "4     0.000909   1100.298185  0.001021   26014.693484  0.014581   179.542748   \n",
            "...        ...           ...       ...            ...       ...          ...   \n",
            "8393  0.013096     76.360710  0.040291    1084.322083  0.302184    57.758961   \n",
            "8394  0.000434   2304.886114  0.001845   87500.000000  0.013564   585.662019   \n",
            "8395  0.000338   2958.039892  0.002438  200000.000000  0.026122  1306.394529   \n",
            "8396  0.000809   1236.095114  0.000686   22070.388053  0.006237   160.902221   \n",
            "8397  0.007573    132.055352  0.010240    1116.071429  0.051200    35.714286   \n",
            "\n",
            "             y_0         y_1  z_for_pysr  \n",
            "0      41.770592   11.700694    0.736113  \n",
            "1     101.717705   29.742359    0.689958  \n",
            "2     770.243774  250.731049    0.457216  \n",
            "3      81.197929   25.617466    0.777595  \n",
            "4      45.177803   13.683259    0.704230  \n",
            "...          ...         ...         ...  \n",
            "8393    3.714017    0.583812    0.932197  \n",
            "8394  141.240860   43.966373    0.657679  \n",
            "8395  246.881729   89.388306    0.587161  \n",
            "8396   34.970818   12.105294    0.728446  \n",
            "8397    7.406366    0.710784    0.783308  \n",
            "\n",
            "[8398 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert DataFrame to NumPy arrays\n",
        "X_for_pysr_np = X_for_pysr.values\n",
        "\n",
        "# Assuming y_for_pysr and z_for_pysr are PyTorch tensors\n",
        "y_for_pysr_np = np.array(y_for_pysr)\n",
        "z_for_pysr_np = np.array(z_for_pysr)\n",
        "\n",
        "\n",
        "\n",
        "# Convert arrays to pandas DataFrame\n",
        "df = pd.DataFrame(X_for_pysr_np, columns=[f'X_{i}' for i in range(N)])\n",
        "\n",
        "#df = pd.DataFrame(y_for_pysr_np, columns=[f'y_{i}' for i in range(num_of_med_vals)])\n",
        "\n",
        "for i in range(num_of_med_vals):\n",
        "  df[f'y_{i}'] = y_for_pysr_np[:,i]\n",
        "df['z_for_pysr'] = z_for_pysr_np\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv(\"data.csv\", index=False)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rukGXtWr5Oiv"
      },
      "source": [
        "# 3. Pick out the sample, for PySR\n",
        "---\n",
        "Symbolic Regression is very sensive to its input data, and hyperparameters.\n",
        "\n",
        "Don't be afraid to adjust you size of sample.\n",
        "\n",
        "Get ready for ***trial & error***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "offsK8Ul5Oqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989f2c92-496b-4609-8ff6-42c1cab4a4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000,)\n",
            "[[1.05730800e-03 9.45798195e+02 1.23221472e-03 2.03047570e+04\n",
            "  1.54026840e-02 1.58250773e+02]\n",
            " [7.71869042e-04 1.29555656e+03 2.48242424e-03 3.90625000e+04\n",
            "  1.69256198e-02 4.08248290e+02]\n",
            " [5.58773117e-05 1.78963513e+04 1.90527778e-04 9.63507166e+05\n",
            "  9.52638889e-04 2.30353453e+03]\n",
            " ...\n",
            " [9.45961570e-05 1.05712540e+04 1.78619792e-04 4.20231866e+05\n",
            "  1.19079861e-03 1.08760052e+03]\n",
            " [2.18788782e-03 4.57061825e+02 4.40605625e-02 2.58553213e+04\n",
            "  2.75378516e-01 8.58113950e+02]\n",
            " [9.08844542e-04 1.10029818e+03 1.02068452e-03 2.60146935e+04\n",
            "  1.45812075e-02 1.79542748e+02]]\n",
            "[[ 37.994026   11.867606 ]\n",
            " [ 63.830193   22.03986  ]\n",
            " [958.87317   334.91745  ]\n",
            " ...\n",
            " [396.12515   145.64499  ]\n",
            " [  7.5380306  14.126882 ]\n",
            " [ 45.177803   13.683259 ]]\n",
            "[0.69956286 0.74822413 0.43421302 ... 0.55708317 0.88339841 0.70422952]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df_loaded = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# 필요한 columns 추출\n",
        "X_loaded_np = df_loaded[[f'X_{i}' for i in range(N)]].values\n",
        "y_loaded_np = df_loaded[[f'y_{i}' for i in range(num_of_med_vals)]].values\n",
        "z_loaded_np = df_loaded['z_for_pysr'].values\n",
        "\n",
        "rstate = np.random.RandomState(0)\n",
        "sample_idx = rstate.choice(X_for_pysr.shape[0], size=3000, replace=False)\n",
        "\n",
        "print(sample_idx.shape)\n",
        "print(X_loaded_np[sample_idx])\n",
        "print(y_loaded_np[sample_idx])\n",
        "print(z_loaded_np[sample_idx])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKj76oq65Oxj"
      },
      "source": [
        "# 4. Fit model_G for your SumNet.model_g\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IFWQ0mcl5O6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c26d49-1641-487f-d0af-5736ec0b8752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1281: UserWarning: Note: Using a large maxsize for the equation search will be exponentially slower and use significant memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using features ['x0' 'x1' 'x2' 'x3' 'x4' 'x5']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:231: UserWarning: Julia has already started. The new Julia options {'threads': 4} will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[x5*(-sqrt(x0) - x0 - 0.0001826631709538925*x5 + 0.0009012760858277101*sqrt(x1 + x3) + 0.06475786900052342) + 8.2473249639826158 - (-0.7132554098230932*x0 + 0.0009012760858277101*sqrt(x3))*(x2 + 3.34633022341101e-6/x2)/x0, -x2 + 1.6590695727403017e-5*x5**2 + 0.14776121253627854 - 0.05715337554546851/((x0 + x4)*(-x2 + x4 + 0.6128355879358304)) - 1.888872169112173*(x2 - 0.21817390544779822)**3/x0]\n"
          ]
        }
      ],
      "source": [
        "from pysr import PySRRegressor\n",
        "\n",
        "model_G = PySRRegressor(\n",
        "    procs=4,\n",
        "    populations=8,\n",
        "    # ^ 2 populations per core, so one is always running.\n",
        "    population_size=50,\n",
        "    # ^ Slightly larger populations, for greater diversity.\n",
        "    ncyclesperiteration=500,\n",
        "    # ^ Generations between migrations.\n",
        "    niterations=50,  # Run forever: 10000000\n",
        "    early_stop_condition=(\n",
        "        \"stop_if(loss, complexity) = loss < 3e-5 && complexity < 280\"\n",
        "        # Stop early if we find a good and simple equation\n",
        "    ),\n",
        "    #timeout_in_seconds=60*60*1,\n",
        "    # ^ Alternatively, stop after 'timeout_in_seconds'sec have passed.\n",
        "    maxsize=300,\n",
        "    # ^ Allow greater complexity.\n",
        "    maxdepth=12,\n",
        "    # ^ But, avoid deep nesting.\n",
        "    binary_operators=[\"*\", \"+\", \"-\", \"/\"],\n",
        "    unary_operators=[\"square\", \"cube\", \"exp\",\"sqrt\"],\n",
        "    constraints={\n",
        "        \"/\": (-1, 9),\n",
        "        \"square\": 9,\n",
        "        \"cube\": 9,\n",
        "        \"exp\": 9,\n",
        "        \"sqrt\": 9,\n",
        "    },\n",
        "    # ^ Limit the complexity within each argument.\n",
        "    # \"inv\": (-1, 9) states that the numerator has no constraint,\n",
        "    # but the denominator has a max complexity of 9.\n",
        "    # \"exp\": 9 simply states that `exp` can only have\n",
        "    # an expression of complexity 9 as input.\n",
        "    nested_constraints={\n",
        "        \"square\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"cube\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"exp\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"sqrt\": {\"square\": 0, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "    },\n",
        "    # ^ Nesting constraints on operators. For example,\n",
        "    # \"square(exp(x))\" is not allowed, since \"square\": {\"exp\": 0}.\n",
        "    complexity_of_operators={\"/\": 2, \"exp\": 3},\n",
        "    # ^ Custom complexity of particular operators.\n",
        "    complexity_of_constants=2,\n",
        "    # ^ Punish constants more than variables\n",
        "    select_k_features=N,\n",
        "    # ^ Train on only the 'k' most important features\n",
        "    progress=True,\n",
        "    # ^ Can set to false if printing to a file.\n",
        "    weight_randomize=0.1,\n",
        "    # ^ Randomize the tree much more frequently\n",
        "    cluster_manager=None,\n",
        "    # ^ Can be set to, e.g., \"slurm\", to run a slurm\n",
        "    # cluster. Just launch one script from the head node.\n",
        "    precision=64,\n",
        "    # ^ Higher precision calculations.\n",
        "    warm_start=True,\n",
        "    # ^ Start from where left off.\n",
        "    turbo=True,\n",
        "    # ^ Faster evaluation (experimental)\n",
        "    julia_project=None,\n",
        "    # ^ Can set to the path of a folder containing the\n",
        "    # \"SymbolicRegression.jl\" repo, for custom modifications.\n",
        "    update=False,\n",
        "    # ^ Don't update Julia packages\n",
        "    model_selection='accuracy',\n",
        "    parsimony=0.001, # Recommended Value: Target Loss / 10\n",
        ")\n",
        "\n",
        "model_G.fit(X_loaded_np[sample_idx], y_loaded_np[sample_idx])\n",
        "\n",
        "# model_G.equations_[[\"complexity\", \"loss\", \"equation\"]]\n",
        "\n",
        "print(model_G.sympy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-GDmDVg5PD1"
      },
      "source": [
        "# 5. Fit model_G for your SumNet.model_f\n",
        "---\n",
        "Simply do the same for model_F, yet be careful that model_F don't need much times than that of model_G.\n",
        "\n",
        "It's just (1 input)-(1 output) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "agkKKA6x5PJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da62edd-cb6b-4021-b2e3-f75b197ef98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1281: UserWarning: Note: Using a large maxsize for the equation search will be exponentially slower and use significant memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/julia_helpers.py:231: UserWarning: Julia has already started. The new Julia options {'threads': 4} will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8314646830007171 - 2.497794946852951*(0.00094415180086255548*x0 - 0.00094415180086255548*x1 - 0.005589387166936187 - 0.00054525874712079084*(x1 + 1.8703357508079716e-6)/(0.8327607963589698*x1 + 1)**3)/(0.0018555758654034058*x1 + 1)**3\n"
          ]
        }
      ],
      "source": [
        "model_F = PySRRegressor(\n",
        "    procs=4,\n",
        "    populations=8,\n",
        "    # ^ 2 populations per core, so one is always running.\n",
        "    population_size=50,\n",
        "    # ^ Slightly larger populations, for greater diversity.\n",
        "    ncyclesperiteration=500,\n",
        "    # ^ Generations between migrations.\n",
        "    niterations=20,  # Run forever: 10000000\n",
        "    early_stop_condition=(\n",
        "        \"stop_if(loss, complexity) = loss < 3e-5 && complexity < 90\"\n",
        "        # Stop early if we find a good and simple equation\n",
        "    ),\n",
        "    #timeout_in_seconds=60*60*0.5,\n",
        "    # ^ Alternatively, stop after 'timeout_in_seconds'sec have passed.\n",
        "    maxsize=100,\n",
        "    # ^ Allow greater complexity.\n",
        "    maxdepth=15,\n",
        "    # ^ But, avoid deep nesting.\n",
        "    binary_operators=[\"*\", \"+\", \"-\", \"/\"],\n",
        "    unary_operators=[\"square\", \"cube\", \"exp\",\"sqrt\"],\n",
        "    constraints={\n",
        "        \"/\": (-1, 9),\n",
        "        \"square\": 9,\n",
        "        \"cube\": 9,\n",
        "        \"exp\": 9,\n",
        "        \"sqrt\": 9,\n",
        "    },\n",
        "    # ^ Limit the complexity within each argument.\n",
        "    # \"inv\": (-1, 9) states that the numerator has no constraint,\n",
        "    # but the denominator has a max complexity of 9.\n",
        "    # \"exp\": 9 simply states that `exp` can only have\n",
        "    # an expression of complexity 9 as input.\n",
        "    nested_constraints={\n",
        "        \"square\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"cube\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"exp\": {\"square\": 1, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "        \"sqrt\": {\"square\": 0, \"cube\": 1, \"exp\": 0, \"sqrt\": 0},\n",
        "    },\n",
        "    # ^ Nesting constraints on operators. For example,\n",
        "    # \"square(exp(x))\" is not allowed, since \"square\": {\"exp\": 0}.\n",
        "    complexity_of_operators={\"/\": 2, \"exp\": 3},\n",
        "    # ^ Custom complexity of particular operators.\n",
        "    complexity_of_constants=2,\n",
        "    # ^ Punish constants more than variables\n",
        "    select_k_features=None,\n",
        "    # ^ Train on only the 'k' most important features\n",
        "    progress=True,\n",
        "    # ^ Can set to false if printing to a file.\n",
        "    weight_randomize=0.1,\n",
        "    # ^ Randomize the tree much more frequently\n",
        "    cluster_manager=None,\n",
        "    # ^ Can be set to, e.g., \"slurm\", to run a slurm\n",
        "    # cluster. Just launch one script from the head node.\n",
        "    precision=64,\n",
        "    # ^ Higher precision calculations.\n",
        "    warm_start=True,\n",
        "    # ^ Start from where left off.\n",
        "    turbo=True,\n",
        "    # ^ Faster evaluation (experimental)\n",
        "    julia_project=None,\n",
        "    # ^ Can set to the path of a folder containing the\n",
        "    # \"SymbolicRegression.jl\" repo, for custom modifications.\n",
        "    update=False,\n",
        "    # ^ Don't update Julia packages\n",
        "    model_selection='accuracy',\n",
        "    parsimony=0.005 # Recommended Value: Target Loss / 10\n",
        ")\n",
        "\n",
        "y_reshaped = y_loaded_np[sample_idx].reshape(-1, num_of_med_vals)\n",
        "z_reshaped = z_loaded_np[sample_idx].reshape(-1, 1)\n",
        "\n",
        "model_F.fit(y_reshaped, z_reshaped)\n",
        "\n",
        "\n",
        "model_F.equations_[[\"complexity\", \"loss\", \"equation\"]]\n",
        "\n",
        "print(model_F.sympy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAAWWSeI8oDr"
      },
      "source": [
        "# 6. Print out the result\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8ZV9I6k38oLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6f2fd62-d443-46a7-e1aa-d497f3c3360f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of EF Designer:\n",
            "1) Function g(x) is:\n",
            "[x5*(-sqrt(x0) - x0 - 0.0001826631709538925*x5 + 0.0009012760858277101*sqrt(x1 + x3) + 0.06475786900052342) + 8.2473249639826158 - (-0.7132554098230932*x0 + 0.0009012760858277101*sqrt(x3))*(x2 + 3.34633022341101e-6/x2)/x0, -x2 + 1.6590695727403017e-5*x5**2 + 0.14776121253627854 - 0.05715337554546851/((x0 + x4)*(-x2 + x4 + 0.6128355879358304)) - 1.888872169112173*(x2 - 0.21817390544779822)**3/x0]\n",
            "2) Function f(x) is:\n",
            "0.8314646830007171 - 2.497794946852951*(0.00094415180086255548*x0 - 0.00094415180086255548*x1 - 0.005589387166936187 - 0.00054525874712079084*(x1 + 1.8703357508079716e-6)/(0.8327607963589698*x1 + 1)**3)/(0.0018555758654034058*x1 + 1)**3\n",
            "[0.7323888  0.57845685 0.79816458 ... 0.83672884 0.81171694 0.81428887]\n",
            "[0.69768508 0.49199587 0.85335365 ... 0.86095365 0.96188571 0.9130381 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but PySRRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Result of EF Designer:\")\n",
        "print(\"1) Function g(x) is:\")\n",
        "print(model_G.sympy())\n",
        "print(\"2) Function f(x) is:\")\n",
        "print(model_F.sympy())\n",
        "\n",
        "G_output = model_G.predict(X_val.reshape(-1,N))\n",
        "z_pred = model_F.predict(G_output.reshape(-1, num_of_med_vals))\n",
        "\n",
        "z_test = y_val\n",
        "\n",
        "# for plot\n",
        "min_axis = min(np.amin(z_pred), np.amin(z_test))\n",
        "max_axis = max(np.amax(z_pred), np.amax(z_test))\n",
        "\n",
        "print(z_pred)\n",
        "print(z_test)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# R squared\n",
        "r2 = r2_score(z_test, z_pred)\n",
        "\n",
        "# COV\n",
        "cov = (np.std(z_pred - z_test) / np.mean(z_test))\n",
        "\n",
        "# Mean\n",
        "MEAN = np.mean(z_pred/z_test)\n",
        "\n",
        "# Show Plot: Data vs Predicted Value\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(z_test, z_pred, alpha=0.2)\n",
        "plt.plot([min_axis, max_axis], [min_axis, max_axis], color='red', linestyle='--')  # y=x line\n",
        "plt.title(f\"Data vs Predicted (R^2: {r2:.5f}, COV: {cov:.5f}, MEAN: {MEAN:.5f})\")\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "#plt.xlim([0.4, 1])\n",
        "#plt.ylim([0.4, 1])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PvzemEN8oWQ"
      },
      "source": [
        "---\n",
        "# ~Fin."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "73Z-uPv6Bi__",
        "1KFM0G8SF1o-",
        "Vn39PBOtGZXO",
        "RvF1W5QeGfkG",
        "LSzgwcZeGqDi",
        "HT2VOpnMMwOV",
        "PaBDv2hRRUA7",
        "C07r1Om1Rk_p",
        "d4sDGWzdSBq2",
        "YcPCoGr7SDUi",
        "lIDSxiT2SEcZ",
        "yFOAH6IdSFqQ",
        "vLj1mBMRxM8t"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPAE+X/Fz2vINBUzmMbD5GB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}